{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import thulac\n",
    "import timeit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize.stanford_segmenter import StanfordSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bosonnlp import BosonNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thu1 = thulac.thulac(seg_only=True)  #默认模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = BosonNLP('9UKerw8k.13445.iKi57Vd-7oP3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segmenter = StanfordSegmenter(path_to_jar='/Users/nhu2000/desktop/nltk/stanford-segmenter-2014-08-27/stanford-segmenter-3.4.1.jar', \n",
    "                              path_to_slf4j='/Users/nhu2000/desktop/nltk/stanford-segmenter-2014-08-27/slf4j-api.jar',\n",
    "                              path_to_sihan_corpora_dict='/Users/nhu2000/desktop/nltk/stanford-segmenter-2014-08-27/data', \n",
    "                              path_to_model='/Users/nhu2000/desktop/nltk/stanford-segmenter-2014-08-27/data/pku.gz', \n",
    "                              path_to_dict='/Users/nhu2000/desktop/nltk/stanford-segmenter-2014-08-27/data/dict-chris6.ser.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/nutch-crawl-huizhou-domain_only2-02-15-2017-cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_columns2():\n",
    "    return ('url', 'domain', 'title', 'segment', 'target') \n",
    "def get_empty_columns2():\n",
    "    return ('', '', '', '', '') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns = get_columns2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "idx = 0\n",
    "for i in range(0, len(df_no_dup)):\n",
    "    new_df.loc[idx] = get_empty_columns2()\n",
    "    t0 = df_no_dup.loc[i]['title'].decode('utf-8')\n",
    "    t1 = df_no_dup.loc[i]['domain']\n",
    "    if t1 == '99huizhou.com':\n",
    "        cnt = 0\n",
    "        #print '99huizhou.com ----'\n",
    "    elif u'连载,' not in t0: # and i > 0 and i < 30000:\n",
    "        #print i, t1\n",
    "        if u'-徽文化' in t0:\n",
    "            t0 = t0.replace(u'-徽文化', '')\n",
    "            #print i, t0\n",
    "        if u'徽文化频道' in t0:\n",
    "            t0 = t0.replace(u'徽文化频道', '') \n",
    "            #print t0[:-28]\n",
    "        if u'中安在线' in t0 :\n",
    "            t0 = t0.replace(u'中安在线', '') \n",
    "            #print '中安在线----', t0[:-23]\n",
    "        elif 'www.ahage.net' in t0:\n",
    "            if u'安徽文化网' in t0:\n",
    "                t0 = t0.replace(u'安徽文化网', '') \n",
    "            if 'www.ahage.net' in t0:\n",
    "                t0 = t0.replace('www.ahage.net', '') \n",
    "            if u'我的网站' in t0:\n",
    "                t0 = t0.replace(u'我的网站', '') \n",
    "            #print 'www.ahage.net----', t0\n",
    "        elif 'ahage.net' in t0:\n",
    "            if u'| 安徽文化人的网上家园，网上最大的安徽历史文化资料中心' in t0:\n",
    "                t0 = t0.replace(u'| 安徽文化人的网上家园，网上最大的安徽历史文化资料中心', '')\n",
    "            if u'安徽文化网' in t0:\n",
    "                t0 = t0.replace(u'安徽文化网', '') \n",
    "            if 'ahage.net' in t0:\n",
    "                t0 = t0.replace('ahage.net', '') \n",
    "            if u'_我的网站' in t0:\n",
    "                t0 = t0.replace(u'_我的网站', '') \n",
    "            print 'ahage.net----', t0\n",
    "        else:\n",
    "            if u'我的网站' in t0:\n",
    "                t0 = t0.replace(u'我的网站', '')    \n",
    "\n",
    "        if u'-- 徽 文化' in t0:\n",
    "            t0 = t0.replace(u'-- 徽 文化', '') \n",
    "                \n",
    "        t0 = t0.replace('_', '')\n",
    "        \n",
    "        print i, t0\n",
    "        #t1 = thu1.cut(t0, text=True)  #进行一句话分词\n",
    "        t20 = nlp.tag(t0)\n",
    "        t2 = ' '.join(['%s' % it for it in t20[0]['word']])\n",
    "            #t3 = segmenter.segment(t0)\n",
    "            #t1 = segmenter.segment(t0)\n",
    "        new_df.loc[idx]['segment'] = t2\n",
    "        new_df.loc[idx]['domain'] = t1\n",
    "        new_df.loc[idx]['title'] = df_no_dup.loc[i]['title']\n",
    "        new_df.loc[idx]['url'] = df_no_dup.loc[i]['url']\n",
    "\n",
    "            #print 'thulac', t1\n",
    "            #print 'bosonNLP', t2\n",
    "            #print 'Stanford', t3\n",
    "        idx += 1\n",
    "        \n",
    "elapsed = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# segment 200 titles\n",
    "#thulac: 1488608471.37 10.8885960579  \n",
    "#bosonNLP: 1488610643.7 18.3403289318  (4989.22923803)\n",
    "#Stanford: 1488608674.82 458.130723\n",
    "print start_time, elapsed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/segments/titles/bosonNLP/solor-bosonNLP-segment-' + str(0) + '-' + str(i) + '.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>segment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://cul.anhuinews.com/system/2009/03/05/002...</td>\n",
       "      <td>anhuinews.com</td>\n",
       "      <td>第十六章(2)-月上重火,连载,阅读-中安在线-徽文化</td>\n",
       "      <td>第十六 章 ( 2 ) - 月 上 重 火 , 连载 , 阅读 - 中安 在线 - 徽 文化</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://cul.anhuinews.com/system/2009/03/05/002...</td>\n",
       "      <td>anhuinews.com</td>\n",
       "      <td>第十六章(1)-月上重火,连载,阅读-中安在线-徽文化</td>\n",
       "      <td>第十六 章 ( 1 ) - 月 上 重 火 , 连载 , 阅读 - 中安 在线 - 徽 文化</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://cul.anhuinews.com/system/2009/03/05/002...</td>\n",
       "      <td>anhuinews.com</td>\n",
       "      <td>第十五章(4)-月上重火,连载,阅读-中安在线-徽文化</td>\n",
       "      <td>第十五 章 ( 4 ) - 月 上 重 火 , 连载 , 阅读 - 中安 在线 - 徽 文化</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://cul.anhuinews.com/system/2009/03/05/002...</td>\n",
       "      <td>anhuinews.com</td>\n",
       "      <td>第十五章(3)-月上重火,连载,阅读-中安在线-徽文化</td>\n",
       "      <td>第十五 章 ( 3 ) - 月 上 重 火 , 连载 , 阅读 - 中安 在线 - 徽 文化</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://cul.anhuinews.com/system/2009/03/05/002...</td>\n",
       "      <td>anhuinews.com</td>\n",
       "      <td>第十五章(2)-月上重火,连载,阅读-中安在线-徽文化</td>\n",
       "      <td>第十五 章 ( 2 ) - 月 上 重 火 , 连载 , 阅读 - 中安 在线 - 徽 文化</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url         domain  \\\n",
       "0  http://cul.anhuinews.com/system/2009/03/05/002...  anhuinews.com   \n",
       "1  http://cul.anhuinews.com/system/2009/03/05/002...  anhuinews.com   \n",
       "2  http://cul.anhuinews.com/system/2009/03/05/002...  anhuinews.com   \n",
       "3  http://cul.anhuinews.com/system/2009/03/05/002...  anhuinews.com   \n",
       "4  http://cul.anhuinews.com/system/2009/03/05/002...  anhuinews.com   \n",
       "\n",
       "                         title  \\\n",
       "0  第十六章(2)-月上重火,连载,阅读-中安在线-徽文化   \n",
       "1  第十六章(1)-月上重火,连载,阅读-中安在线-徽文化   \n",
       "2  第十五章(4)-月上重火,连载,阅读-中安在线-徽文化   \n",
       "3  第十五章(3)-月上重火,连载,阅读-中安在线-徽文化   \n",
       "4  第十五章(2)-月上重火,连载,阅读-中安在线-徽文化   \n",
       "\n",
       "                                          segment target  \n",
       "0  第十六 章 ( 2 ) - 月 上 重 火 , 连载 , 阅读 - 中安 在线 - 徽 文化         \n",
       "1  第十六 章 ( 1 ) - 月 上 重 火 , 连载 , 阅读 - 中安 在线 - 徽 文化         \n",
       "2  第十五 章 ( 4 ) - 月 上 重 火 , 连载 , 阅读 - 中安 在线 - 徽 文化         \n",
       "3  第十五 章 ( 3 ) - 月 上 重 火 , 连载 , 阅读 - 中安 在线 - 徽 文化         \n",
       "4  第十五 章 ( 2 ) - 月 上 重 火 , 连载 , 阅读 - 中安 在线 - 徽 文化         "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(fname, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Weixin\n",
    "df = pd.read_csv('../scrape/data/weixin/weixin_huizhou.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>image</th>\n",
       "      <th>brief</th>\n",
       "      <th>body</th>\n",
       "      <th>raw_page</th>\n",
       "      <th>from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>歙县论坛</td>\n",
       "      <td>http://mp.weixin.qq.com</td>\n",
       "      <td>http://mp.weixin.qq.com/s?__biz=MjM5OTc1NDAxMg...</td>\n",
       "      <td>【徽州】《梦里徽州——新安江风情画卷》</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>［汪观清专访］一生痴绝处，无梦到徽州。    汪观清，安徽歙县人。他创作的《梦里..</td>\n",
       "      <td>\\n                        \\n\\n                ...</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n        &lt;meta http-equiv=\"Conten...</td>\n",
       "      <td>微信</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>徽州微旅游</td>\n",
       "      <td>http://mp.weixin.qq.com</td>\n",
       "      <td>http://mp.weixin.qq.com/s?__biz=MzA4NDI0MzMwNA...</td>\n",
       "      <td>古村的梦——古建筑博物馆</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>千年的光阴，在轮回里，阴晴圆缺，一场梦醒时分，恍若隔世，重新遇见你眉目缱绻飘零，..</td>\n",
       "      <td>\\n                        \\n\\n                ...</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n        &lt;meta http-equiv=\"Conten...</td>\n",
       "      <td>微信</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>徽州范儿</td>\n",
       "      <td>http://mp.weixin.qq.com</td>\n",
       "      <td>http://mp.weixin.qq.com/s?__biz=MzIyOTQ4MjEyNA...</td>\n",
       "      <td>苞芦松 | 传承四百年的徽州小食</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>编辑小语：在徽州，有一种延续了四百年的休闲食品。金黄的外表，清脆的口感，颇像“膨..</td>\n",
       "      <td>\\n                        \\n\\n                ...</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n        &lt;meta http-equiv=\"Conten...</td>\n",
       "      <td>微信</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>徽州大论坛</td>\n",
       "      <td>http://mp.weixin.qq.com</td>\n",
       "      <td>http://mp.weixin.qq.com/s?__biz=MzI3MTAwNTA4NA...</td>\n",
       "      <td>【徽州大家谈】墨客典籍与现代生活的交融地</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>徽州古城坐落在歙县县城徽城的中心，也是千年徽州府治的所在地。在这里，记者们不仅参..</td>\n",
       "      <td>\\n                        \\n\\n                ...</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n        &lt;meta http-equiv=\"Conten...</td>\n",
       "      <td>微信</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>徽州大论坛</td>\n",
       "      <td>http://mp.weixin.qq.com</td>\n",
       "      <td>http://mp.weixin.qq.com/s?__biz=MzI3MTAwNTA4NA...</td>\n",
       "      <td>【徽州大家谈】时代呼唤中华商魂——我所知的徽商</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>有大专家在视频里向年青人“说”徽商，他告诉人们，历史上的徽商，只不过是从“晋商”..</td>\n",
       "      <td>\\n                        \\n\\n                ...</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n        &lt;meta http-equiv=\"Conten...</td>\n",
       "      <td>微信</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt source                   domain  \\\n",
       "0  2017-02-10   歙县论坛  http://mp.weixin.qq.com   \n",
       "1  2017-02-08  徽州微旅游  http://mp.weixin.qq.com   \n",
       "2  2017-01-30   徽州范儿  http://mp.weixin.qq.com   \n",
       "3  2017-01-30  徽州大论坛  http://mp.weixin.qq.com   \n",
       "4  2017-01-28  徽州大论坛  http://mp.weixin.qq.com   \n",
       "\n",
       "                                                 url                    title  \\\n",
       "0  http://mp.weixin.qq.com/s?__biz=MjM5OTc1NDAxMg...      【徽州】《梦里徽州——新安江风情画卷》   \n",
       "1  http://mp.weixin.qq.com/s?__biz=MzA4NDI0MzMwNA...             古村的梦——古建筑博物馆   \n",
       "2  http://mp.weixin.qq.com/s?__biz=MzIyOTQ4MjEyNA...         苞芦松 | 传承四百年的徽州小食   \n",
       "3  http://mp.weixin.qq.com/s?__biz=MzI3MTAwNTA4NA...     【徽州大家谈】墨客典籍与现代生活的交融地   \n",
       "4  http://mp.weixin.qq.com/s?__biz=MzI3MTAwNTA4NA...  【徽州大家谈】时代呼唤中华商魂——我所知的徽商   \n",
       "\n",
       "   summary  image                                       brief  \\\n",
       "0      NaN    NaN  ［汪观清专访］一生痴绝处，无梦到徽州。    汪观清，安徽歙县人。他创作的《梦里..   \n",
       "1      NaN    NaN  千年的光阴，在轮回里，阴晴圆缺，一场梦醒时分，恍若隔世，重新遇见你眉目缱绻飘零，..   \n",
       "2      NaN    NaN  编辑小语：在徽州，有一种延续了四百年的休闲食品。金黄的外表，清脆的口感，颇像“膨..   \n",
       "3      NaN    NaN  徽州古城坐落在歙县县城徽城的中心，也是千年徽州府治的所在地。在这里，记者们不仅参..   \n",
       "4      NaN    NaN  有大专家在视频里向年青人“说”徽商，他告诉人们，历史上的徽商，只不过是从“晋商”..   \n",
       "\n",
       "                                                body  \\\n",
       "0  \\n                        \\n\\n                ...   \n",
       "1  \\n                        \\n\\n                ...   \n",
       "2  \\n                        \\n\\n                ...   \n",
       "3  \\n                        \\n\\n                ...   \n",
       "4  \\n                        \\n\\n                ...   \n",
       "\n",
       "                                            raw_page from  \n",
       "0  <html><head>\\n        <meta http-equiv=\"Conten...   微信  \n",
       "1  <html><head>\\n        <meta http-equiv=\"Conten...   微信  \n",
       "2  <html><head>\\n        <meta http-equiv=\"Conten...   微信  \n",
       "3  <html><head>\\n        <meta http-equiv=\"Conten...   微信  \n",
       "4  <html><head>\\n        <meta http-equiv=\"Conten...   微信  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns = get_columns2())\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(df)):\n",
    "    url = df.loc[i]['url']\n",
    "    t0 = df.loc[i]['title'].decode('utf-8')\n",
    "    \n",
    "    new_df.loc[idx] = get_empty_columns2()\n",
    "    t20 = nlp.tag(t0)\n",
    "    t2 = ' '.join(['%s' % it for it in t20[0]['word']])\n",
    "    \n",
    "    new_df.loc[idx]['segment'] = t2\n",
    "    new_df.loc[idx]['domain'] = 'qq.com'\n",
    "    new_df.loc[idx]['title'] = df_no_dup.loc[i]['title']\n",
    "    new_df.loc[idx]['url'] = df_no_dup.loc[i]['url']\n",
    "    idx += 1\n",
    "    print i, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>segment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://cul.anhuinews.com/system/2009/03/05/002...</td>\n",
       "      <td>qq.com</td>\n",
       "      <td>第十六章(2)-月上重火,连载,阅读-中安在线-徽文化</td>\n",
       "      <td>【 徽州 】 《 梦里徽州 —— 新安江 风情 画卷 》</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://cul.anhuinews.com/system/2009/03/05/002...</td>\n",
       "      <td>qq.com</td>\n",
       "      <td>第十六章(1)-月上重火,连载,阅读-中安在线-徽文化</td>\n",
       "      <td>古村 的 梦 —— 古建筑 博物馆</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://cul.anhuinews.com/system/2009/03/05/002...</td>\n",
       "      <td>qq.com</td>\n",
       "      <td>第十五章(4)-月上重火,连载,阅读-中安在线-徽文化</td>\n",
       "      <td>苞芦松 | 传承 四百 年 的 徽州 小 食</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://cul.anhuinews.com/system/2009/03/05/002...</td>\n",
       "      <td>qq.com</td>\n",
       "      <td>第十五章(3)-月上重火,连载,阅读-中安在线-徽文化</td>\n",
       "      <td>【 徽州 大家 谈 】 墨客 典籍 与 现代 生活 的 交融地</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://cul.anhuinews.com/system/2009/03/05/002...</td>\n",
       "      <td>qq.com</td>\n",
       "      <td>第十五章(2)-月上重火,连载,阅读-中安在线-徽文化</td>\n",
       "      <td>【 徽州 大家 谈 】 时代 呼唤 中华 商魂 —— 我 所 知 的 徽商</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  domain  \\\n",
       "0  http://cul.anhuinews.com/system/2009/03/05/002...  qq.com   \n",
       "1  http://cul.anhuinews.com/system/2009/03/05/002...  qq.com   \n",
       "2  http://cul.anhuinews.com/system/2009/03/05/002...  qq.com   \n",
       "3  http://cul.anhuinews.com/system/2009/03/05/002...  qq.com   \n",
       "4  http://cul.anhuinews.com/system/2009/03/05/002...  qq.com   \n",
       "\n",
       "                         title                                segment  target  \n",
       "0  第十六章(2)-月上重火,连载,阅读-中安在线-徽文化           【 徽州 】 《 梦里徽州 —— 新安江 风情 画卷 》       1  \n",
       "1  第十六章(1)-月上重火,连载,阅读-中安在线-徽文化                      古村 的 梦 —— 古建筑 博物馆       1  \n",
       "2  第十五章(4)-月上重火,连载,阅读-中安在线-徽文化                 苞芦松 | 传承 四百 年 的 徽州 小 食       1  \n",
       "3  第十五章(3)-月上重火,连载,阅读-中安在线-徽文化        【 徽州 大家 谈 】 墨客 典籍 与 现代 生活 的 交融地       1  \n",
       "4  第十五章(2)-月上重火,连载,阅读-中安在线-徽文化  【 徽州 大家 谈 】 时代 呼唤 中华 商魂 —— 我 所 知 的 徽商       1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/classifier/bosonNLP/weixin-bosonNLP-segment-' + str(idx) + '.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(fname, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#News \n",
    "import glob\n",
    "all_files = glob.glob(\"../scrape/data/news/\" + \"/*.csv\")\n",
    "\n",
    "init = 0\n",
    "#print all_files\n",
    "for file_ in all_files:\n",
    "    print file_\n",
    "    with open(file_) as data_file:  \n",
    "        df = pd.read_csv(data_file)\n",
    "        if init == 0:\n",
    "            joined = df\n",
    "            init = 1\n",
    "        else:\n",
    "            joined = joined.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup = joined.dropna(subset =['title']) \n",
    "df_no_dup = df_no_dup.drop_duplicates(['title'])\n",
    "df_no_dup = df_no_dup.dropna(subset =['url']) \n",
    "df_no_dup = df_no_dup.drop_duplicates(['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_no_dup.to_csv('temp.csv', encoding='utf-8', index=False)\n",
    "df_no_dup = pd.read_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns = get_columns2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i in range(0, len(df_no_dup)):\n",
    "    url = df_no_dup.loc[i]['url']\n",
    "    t0 = df_no_dup.loc[i]['title'].decode('utf-8')\n",
    "    \n",
    "    new_df.loc[idx] = get_empty_columns2()\n",
    "    t20 = nlp.tag(t0)\n",
    "    t2 = ' '.join(['%s' % it for it in t20[0]['word']])\n",
    "    \n",
    "    new_df.loc[idx]['segment'] = t2\n",
    "    #new_df.loc[idx]['domain'] = 'qq.com'\n",
    "    new_df.loc[idx]['title'] = df_no_dup.loc[i]['title']\n",
    "    new_df.loc[idx]['url'] = df_no_dup.loc[i]['url']\n",
    "    idx += 1\n",
    "    print i, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/classifier/bosonNLP/news-bosonNLP-segment-' + str(idx) + '.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(fname, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CSE\n",
    "import glob\n",
    "all_files = glob.glob(\"../scrape/data/google/cse/\" + \"/*.csv\")\n",
    "\n",
    "init = 0\n",
    "#print all_files\n",
    "for file_ in all_files:\n",
    "    print file_\n",
    "    with open(file_) as data_file:  \n",
    "        df = pd.read_csv(data_file)\n",
    "        if init == 0:\n",
    "            joined = df\n",
    "            init = 1\n",
    "        else:\n",
    "            joined = joined.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup = joined.dropna(subset =['title']) \n",
    "df_no_dup = df_no_dup.drop_duplicates(['title'])\n",
    "df_no_dup = df_no_dup.dropna(subset =['url']) \n",
    "df_no_dup = df_no_dup.drop_duplicates(['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup.to_csv('temp.csv', encoding='utf-8', index=False)\n",
    "df_no_dup = pd.read_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns = get_columns2())\n",
    "idx = 0\n",
    "for i in range(0, len(df_no_dup)):\n",
    "    url = df_no_dup.loc[i]['url']\n",
    "    t0 = df_no_dup.loc[i]['title'].decode('utf-8')\n",
    "    \n",
    "    new_df.loc[idx] = get_empty_columns2()\n",
    "    t20 = nlp.tag(t0)\n",
    "    t2 = ' '.join(['%s' % it for it in t20[0]['word']])\n",
    "    \n",
    "    new_df.loc[idx]['segment'] = t2\n",
    "    new_df.loc[idx]['title'] = df_no_dup.loc[i]['title']\n",
    "    new_df.loc[idx]['url'] = df_no_dup.loc[i]['url']\n",
    "    idx += 1\n",
    "    print i, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/classifier/bosonNLP/cse-bosonNLP-segment-' + str(idx) + '.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(fname, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#general\n",
    "import glob\n",
    "all_files = glob.glob(\"../scrape/data/general/\" + \"/*.csv\")\n",
    "\n",
    "init = 0\n",
    "#print all_files\n",
    "for file_ in all_files:\n",
    "    print file_\n",
    "    with open(file_) as data_file:  \n",
    "        df = pd.read_csv(data_file)\n",
    "        if init == 0:\n",
    "            joined = df\n",
    "            init = 1\n",
    "        else:\n",
    "            joined = joined.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup = joined.dropna(subset =['title']) \n",
    "df_no_dup = df_no_dup.drop_duplicates(['title'])\n",
    "df_no_dup = df_no_dup.dropna(subset =['url']) \n",
    "df_no_dup = df_no_dup.drop_duplicates(['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup.to_csv('temp.csv', encoding='utf-8', index=False)\n",
    "df_no_dup = pd.read_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns = get_columns2())\n",
    "idx = 0\n",
    "for i in range(0, len(df_no_dup)):\n",
    "    url = df_no_dup.loc[i]['url']\n",
    "    t0 = df_no_dup.loc[i]['title'].decode('utf-8')\n",
    "    \n",
    "    new_df.loc[idx] = get_empty_columns2()\n",
    "    t20 = nlp.tag(t0)\n",
    "    t2 = ' '.join(['%s' % it for it in t20[0]['word']])\n",
    "    \n",
    "    new_df.loc[idx]['segment'] = t2\n",
    "    new_df.loc[idx]['title'] = df_no_dup.loc[i]['title']\n",
    "    new_df.loc[idx]['url'] = df_no_dup.loc[i]['url']\n",
    "    idx += 1\n",
    "    print i, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/classifier/bosonNLP/general-bosonNLP-segment-' + str(idx) + '.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(fname, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#forums\n",
    "df = pd.read_csv('../scrape/data/forums/tianya_huiwenhua.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup = df.dropna(subset =['title']) \n",
    "df_no_dup = df_no_dup.drop_duplicates(['title'])\n",
    "df_no_dup = df_no_dup.dropna(subset =['url']) \n",
    "df_no_dup = df_no_dup.drop_duplicates(['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup.to_csv('temp.csv', encoding='utf-8', index=False)\n",
    "df_no_dup = pd.read_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns = get_columns2())\n",
    "idx = 0\n",
    "for i in range(0, len(df_no_dup)):\n",
    "    url = df_no_dup.loc[i]['url']\n",
    "    t0 = df_no_dup.loc[i]['title'].decode('utf-8')\n",
    "    \n",
    "    new_df.loc[idx] = get_empty_columns2()\n",
    "    t20 = nlp.tag(t0)\n",
    "    t2 = ' '.join(['%s' % it for it in t20[0]['word']])\n",
    "    \n",
    "    new_df.loc[idx]['segment'] = t2\n",
    "    new_df.loc[idx]['title'] = df_no_dup.loc[i]['title']\n",
    "    new_df.loc[idx]['url'] = df_no_dup.loc[i]['url']\n",
    "    idx += 1\n",
    "    print i, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/classifier/bosonNLP/tianya-bosonNLP-segment-' + str(idx) + '.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(fname, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baidu tieba\n",
    "df = pd.read_csv('../scrape/data/forums/baidu-huizhouba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_no_dup = df.dropna(subset =['title']) \n",
    "#df_no_dup = df_no_dup.drop_duplicates(['title'])\n",
    "df_no_dup = df.dropna(subset =['url']) \n",
    "df_no_dup = df_no_dup.drop_duplicates(['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup.to_csv('temp.csv', encoding='utf-8', index=False)\n",
    "df_no_dup = pd.read_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns = get_columns2())\n",
    "idx = 0\n",
    "for i in range(0, len(df_no_dup)):\n",
    "    url = df_no_dup.loc[i]['url']\n",
    "    t0 = df_no_dup.loc[i]['title'].decode('utf-8')\n",
    "    \n",
    "    new_df.loc[idx] = get_empty_columns2()\n",
    "    t20 = nlp.tag(t0)\n",
    "    t2 = ' '.join(['%s' % it for it in t20[0]['word']])\n",
    "    \n",
    "    new_df.loc[idx]['segment'] = t2\n",
    "    new_df.loc[idx]['title'] = df_no_dup.loc[i]['title']\n",
    "    new_df.loc[idx]['url'] = df_no_dup.loc[i]['url']\n",
    "    idx += 1\n",
    "    print i, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/classifier/bosonNLP/baidutieba-bosonNLP-segment-' + str(idx) + '.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(fname, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tianxia huizhou\n",
    "df = pd.read_csv('../scrape/data/general/tianxiahuizhou.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_no_dup = df.dropna(subset =['title']) \n",
    "#df_no_dup = df_no_dup.drop_duplicates(['title'])\n",
    "df_no_dup = df.dropna(subset =['url']) \n",
    "df_no_dup = df_no_dup.drop_duplicates(['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns = get_columns2())\n",
    "idx = 0\n",
    "for i in range(0, len(df_no_dup)):\n",
    "    url = df_no_dup.loc[i]['url']\n",
    "    t0 = df_no_dup.loc[i]['title'].decode('utf-8')\n",
    "    \n",
    "    new_df.loc[idx] = get_empty_columns2()\n",
    "    t20 = nlp.tag(t0)\n",
    "    t2 = ' '.join(['%s' % it for it in t20[0]['word']])\n",
    "    \n",
    "    new_df.loc[idx]['segment'] = t2\n",
    "    new_df.loc[idx]['title'] = df_no_dup.loc[i]['title']\n",
    "    new_df.loc[idx]['url'] = df_no_dup.loc[i]['url']\n",
    "    idx += 1\n",
    "    print i, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/classifier/bosonNLP/tianxiahuizhou-bosonNLP-segment-' + str(idx) + '.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(fname, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
