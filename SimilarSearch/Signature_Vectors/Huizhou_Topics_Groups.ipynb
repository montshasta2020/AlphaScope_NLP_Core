{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urlparse import urlparse\n",
    "import tldextract\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "huizhou_stop_words = [u'的', u'了', u'在', u'是', u'安徽', u'和', u'有', u'我', u'年', u'上', u'他', u'我们', \n",
    "                      u'为', u'与', u'人', u'也', u'于', u'中', u'就', u'都', u'在线', u'等', u'不', u'网站', u'你', \n",
    "                      u'一个', u'到', u'之', u'对', u'说', u'进入', u'后', u'月', u'将', u'时', u'又', u'被', u'会员'\n",
    "                     u'版权', u'论坛', u'以', u'而', u'着', u'下', u'这', u'但', u'要', u'或', u'首页', u'这',\n",
    "                     u'地', u'从', u'卡', u'来', '多', u'日', u'她', u'还', u'联系', u'那', u'一处', u'一直', u'个', \n",
    "                     u'向', u'并', u'曾', u'这样', u'里', u'合肥', u'推荐', u'专栏', u'相关', u'当前', u'所有', u'中心'\n",
    "                     u'频道', u'编辑', u'位置', u'第一', u'社区', u'看', '中安', u'安徽省', u'大', u'许可证', u'许可',\n",
    "                     u'让', u'没有', u'什么', u'其', '请', '该', '用', '积分', u'凤阳', u'一篇', u'版权', u'县',\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Toolbox (object):\n",
    "    def __init__(self):\n",
    "        self.init = 1\n",
    "        \n",
    "    def sort_dict (self, d, max=50):\n",
    "        t = sorted(d.items(), key=lambda x: (-x[1], x[0]))\n",
    "        return t[:max]\n",
    "    \n",
    "    def add_dict (self, x, y):\n",
    "        d = { k: x.get(k, 0) + y.get(k, 0) for k in set(x) | set(y) }\n",
    "        return d\n",
    "    \n",
    "    def create_dict(self, k1, v1, filters = True):\n",
    "        if filters == True:\n",
    "            k1_list0 = k1.strip('()').split(',')\n",
    "            v1_list0 = v1.strip('()').split(',')\n",
    "            #print v1_list0\n",
    "            #print k1_list0\n",
    "            k1_list1 = filter(None, k1_list0)        \n",
    "            v1_list1 = filter(None, v1_list0)\n",
    "        else:\n",
    "            k1_list1 = k1\n",
    "            v1_list1 = v1\n",
    "        \n",
    "        #print ' '.join(k1_list1)\n",
    "        k2_list1 = [item.decode('utf-8') for item in k1_list1]\n",
    "        v2_list1 = [float(item) for item in v1_list1]\n",
    "\n",
    "    def create_vec(self, k1, v1):\n",
    "        return (zip(k1, v1))\n",
    "    \n",
    "    def get_dict_top_n(self, d, max=50):\n",
    "        ret = self.sort_dict(d, max)\n",
    "        words, fq = zip(*ret)\n",
    "        sum_up = sum(fq)\n",
    "        fq_normalized = tuple(item/sum_up for item in fq)\n",
    "        \n",
    "        return dict(zip(words, fq_normalized))\n",
    "    \n",
    "    #calculate cosine between two dictionaries\n",
    "    def get_sim(self, vec1, vec2):\n",
    "        \n",
    "        #get intersection\n",
    "        intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "        \n",
    "        #print intersection\n",
    "        numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "        #print 'num ---', numerator\n",
    "        #print vec1.keys()\n",
    "        #print vec1.values()\n",
    "        #print vec2.keys()\n",
    "        #print vec2.values()        \n",
    "        \n",
    "        sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "        sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "        denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "        if not denominator:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return float(numerator) / denominator\n",
    "        \n",
    "    def sum_vects(self, vects):\n",
    "        sum_vects = None\n",
    "        for vec in vects:\n",
    "            if sum_vects == None:\n",
    "                sum_vects = vec\n",
    "            else:\n",
    "                sum_vects = self.add_dict(sum_vects, vec)\n",
    "        #only return first 100 after additions\n",
    "        #print type(sum_vecs)\n",
    "        return self.get_dict_top_n(sum_vects)\n",
    "    \n",
    "    def unserialized(self, x, eval_val=True):\n",
    "        #print '----- in'\n",
    "        #print x\n",
    "        d = dict()\n",
    "        s = x.strip('{}')\n",
    "        #s = s.strip('[]')\n",
    "        ret = s.split(',')\n",
    "\n",
    "        #print ret\n",
    "        for t in ret:\n",
    "            r = t.split(':')\n",
    "            #print r[0], r[1]\n",
    "            key = eval(r[0].decode('utf-8'))\n",
    "            if eval_val == True:\n",
    "                d[key] = float(r[1])\n",
    "            else:\n",
    "                d[key] = r[1]\n",
    "        #print len(ret)\n",
    "        #print 'split -----'\n",
    "        #print ' '.join(ret)\n",
    "        return d\n",
    "        \n",
    "    def get_centroid_df(self, check, t_sim, num=2000):        \n",
    "        if len(check) > num:\n",
    "            #sampling     \n",
    "            ratio = num*1.0/len(check)\n",
    "            print 'ratio ---', ratio \n",
    "            msk = np.random.rand(len(check)) < ratio\n",
    "            tmp = check[msk]\n",
    "            check = tmp\n",
    "    \n",
    "        check.info()\n",
    "        check_vecs = check['s_vec']\n",
    "        return self.sum_vects(check_vecs) \n",
    "    \n",
    "    def set_contained_flag(self, x, y):\n",
    "        x_keys = x.keys()\n",
    "        y_keys = y.keys()\n",
    "        for s in y_keys:\n",
    "            if s in x_keys:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aT = Toolbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/nhu2000/projects/SimilarSearch/data/clean/huizhou-web-slim_v1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['url'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unseralized\n",
    "t0 = time()\n",
    "df['s_vec'] = df.s_vec.map(lambda x: aT.unserialized(x))\n",
    "print time() - t0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_func(x):\n",
    "    s = x.split(',')\n",
    "    t = [r.split(':')[0] for r in s]\n",
    "    print ' '.join(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculte similarity\n",
    "def calculate_sim(x, in_dict):\n",
    "    #print in_dict\n",
    "    tb = Toolbox()\n",
    "    return tb.get_sim(x, in_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge the dict\n",
    "def map_merge_vec(k, v):\n",
    "    tb = Toolbox()\n",
    "    return tb.create_dict(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get contents for '徽州'\n",
    "s_dict = dict()\n",
    "s_dict[u'徽文化'] = 0.5\n",
    "s_dict[u'徽州'] = 0.5\n",
    "t_sim = 'hz_sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "#df[t_sim] = df.s_vec.map(lambda x: calculate_sim(x, dsi_dict))\n",
    "df['s_check'] = df.s_vec.map(lambda x: aT.set_contained_flag(x, s_dict))\n",
    "check = df[df['s_check'] == True]\n",
    "print 'after s_check', time() - t0\n",
    "\n",
    "print '---- check len---', len(check)\n",
    "\n",
    "#cc = check[:10]\n",
    "\n",
    "centroid_vec = aT.get_centroid_df(check, t_sim)\n",
    "print 'after centroid', time() - t0\n",
    "#only work on non duplicated ones\n",
    "df[t_sim] = df.s_vec.map(lambda x: aT.get_sim(x, centroid_vec))\n",
    "s_sim = df[t_sim].values.argsort()[::-1]\n",
    "print time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = df[df[t_sim] > 0.50]\n",
    "out_df.info()\n",
    "s_sim = out_df[t_sim].values.argsort()[::-1]\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print out centroid \n",
    "vec1 = centroid_vec\n",
    "ret = aT.sort_dict(centroid_vec)\n",
    "words, cnt = zip(*ret)\n",
    "print 'centroid --- for 徽文化'\n",
    "for i in range(0, len(words)):\n",
    "    print i, words[i], cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get contents for '徽学'\n",
    "s_dict = dict()\n",
    "s_dict[u'徽学'] = 0.4\n",
    "s_dict[u'文书'] = 0.3\n",
    "s_dict[u'签约'] = 0.3\n",
    "t_sim = 'hx_sim'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "#df[t_sim] = df.s_vec.map(lambda x: calculate_sim(x, dsi_dict))\n",
    "df['s_check'] = df.s_vec.map(lambda x: aT.set_contained_flag(x, s_dict))\n",
    "check = df[df['s_check'] == True]\n",
    "print 'after s_check', time() - t0\n",
    "\n",
    "print '---- check len---', len(check)\n",
    "\n",
    "#cc = check[:10]\n",
    "\n",
    "centroid_vec = aT.get_centroid_df(check, t_sim)\n",
    "print 'after centroid', time() - t0\n",
    "#only work on non duplicated ones\n",
    "df[t_sim] = df.s_vec.map(lambda x: aT.get_sim(x, centroid_vec))\n",
    "s_sim = df[t_sim].values.argsort()[::-1]\n",
    "print time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = df[df[t_sim] > 0.50]\n",
    "out_df.info()\n",
    "s_sim = out_df[t_sim].values.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print out centroid \n",
    "ret = aT.sort_dict(centroid_vec)\n",
    "vec2 = centroid_vec\n",
    "\n",
    "words, cnt = zip(*ret)\n",
    "print 'centroid --- for 徽学'\n",
    "for i in range(0, len(words)):\n",
    "    print i, words[i], cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i in s_sim:\n",
    "    if out_df.iloc[i][t_sim] > 0.3:\n",
    "        title = out_df.iloc[i]['title']\n",
    "        sim_val = out_df.iloc[i][t_sim]\n",
    "        idx += 1\n",
    "        print idx, i, title, sim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get contents for '新安'\n",
    "s_dict = dict()\n",
    "s_dict[u'新安'] = 0.4\n",
    "s_dict[u'理学'] = 0.3\n",
    "s_dict[u'风水'] = 0.3\n",
    "s_dict\n",
    "t_sim = 'xa_sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "#df[t_sim] = df.s_vec.map(lambda x: calculate_sim(x, dsi_dict))\n",
    "df['s_check'] = df.s_vec.map(lambda x: aT.set_contained_flag(x, s_dict))\n",
    "check = df[df['s_check'] == True]\n",
    "print 'after s_check', time() - t0\n",
    "\n",
    "print '---- check len---', len(check)\n",
    "\n",
    "#cc = check[:10]\n",
    "\n",
    "centroid_vec = aT.get_centroid_df(check, t_sim)\n",
    "print 'after centroid', time() - t0\n",
    "#only work on non duplicated ones\n",
    "df[t_sim] = df.s_vec.map(lambda x: aT.get_sim(x, centroid_vec))\n",
    "s_sim = df[t_sim].values.argsort()[::-1]\n",
    "print time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = df[df[t_sim] > 0.50]\n",
    "out_df.info()\n",
    "s_sim = out_df[t_sim].values.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print out centroid \n",
    "ret = aT.sort_dict(centroid_vec)\n",
    "vec3 = centroid_vec\n",
    "\n",
    "words, cnt = zip(*ret)\n",
    "print 'centroid --- for 新安'\n",
    "for i in range(0, len(words)):\n",
    "    print i, words[i], cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i in s_sim:\n",
    "    if out_df.iloc[i][t_sim] > 0.3:\n",
    "        title = out_df.iloc[i]['title']\n",
    "        sim_val = out_df.iloc[i][t_sim]\n",
    "        idx += 1\n",
    "        print idx, i, title, sim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get contents for '古村落'\n",
    "s_dict = dict()\n",
    "s_dict[u'古村落'] = 0.2\n",
    "s_dict[u'民居'] = 0.2\n",
    "s_dict[u'祠堂'] = 0.2\n",
    "s_dict[u'旅游'] = 0.2\n",
    "s_dict[u'徽州'] = 0.2\n",
    "\n",
    "s_dict\n",
    "t_sim = 'cl_sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "#df[t_sim] = df.s_vec.map(lambda x: calculate_sim(x, dsi_dict))\n",
    "df['s_check'] = df.s_vec.map(lambda x: aT.set_contained_flag(x, s_dict))\n",
    "check = df[df['s_check'] == True]\n",
    "print 'after s_check', time() - t0\n",
    "\n",
    "print '---- check len---', len(check)\n",
    "\n",
    "#cc = check[:10]\n",
    "\n",
    "centroid_vec = aT.get_centroid_df(check, t_sim)\n",
    "print 'after centroid', time() - t0\n",
    "#only work on non duplicated ones\n",
    "df[t_sim] = df.s_vec.map(lambda x: aT.get_sim(x, centroid_vec))\n",
    "s_sim = df[t_sim].values.argsort()[::-1]\n",
    "print time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = df[df[t_sim] > 0.50]\n",
    "out_df.info()\n",
    "s_sim = out_df[t_sim].values.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print out centroid \n",
    "ret = aT.sort_dict(centroid_vec)\n",
    "vec4 = centroid_vec\n",
    "\n",
    "words, cnt = zip(*ret)\n",
    "print 'centroid --- for 古村落'\n",
    "for i in range(0, len(words)):\n",
    "    print i, words[i], cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i in s_sim:\n",
    "    if out_df.iloc[i][t_sim] > 0.3:\n",
    "        title = out_df.iloc[i]['title']\n",
    "        sim_val = out_df.iloc[i][t_sim]\n",
    "        url = out_df.iloc[i]['url']\n",
    "        \n",
    "        idx += 1\n",
    "        print idx, i, title, sim_val\n",
    "        print url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get contents for '徽雕'\n",
    "s_dict = dict()\n",
    "s_dict[u'徽雕'] = 0.3\n",
    "s_dict[u'雕刻'] = 0.2\n",
    "s_dict[u'三雕'] = 0.2\n",
    "s_dict[u'建筑'] = 0.2\n",
    "\n",
    "t_sim = 'hd_sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "#df[t_sim] = df.s_vec.map(lambda x: calculate_sim(x, dsi_dict))\n",
    "df['s_check'] = df.s_vec.map(lambda x: aT.set_contained_flag(x, s_dict))\n",
    "check = df[df['s_check'] == True]\n",
    "print 'after s_check', time() - t0\n",
    "\n",
    "print '---- check len---', len(check)\n",
    "\n",
    "#cc = check[:10]\n",
    "\n",
    "centroid_vec = aT.get_centroid_df(check, t_sim)\n",
    "print 'after centroid', time() - t0\n",
    "#only work on non duplicated ones\n",
    "df[t_sim] = df.s_vec.map(lambda x: aT.get_sim(x, centroid_vec))\n",
    "s_sim = df[t_sim].values.argsort()[::-1]\n",
    "print time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = df[df[t_sim] > 0.50]\n",
    "out_df.info()\n",
    "s_sim = out_df[t_sim].values.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print out centroid \n",
    "ret = aT.sort_dict(centroid_vec)\n",
    "vec5 = centroid_vec\n",
    "\n",
    "words, cnt = zip(*ret)\n",
    "print 'centroid --- for 徽雕'\n",
    "for i in range(0, len(words)):\n",
    "    print i, words[i], cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i in s_sim:\n",
    "    if out_df.iloc[i][t_sim] > 0.3:\n",
    "        title = out_df.iloc[i]['title']\n",
    "        sim_val = out_df.iloc[i][t_sim]\n",
    "        idx += 1\n",
    "        print idx, i, title, sim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get contents for '徽商'\n",
    "s_dict = dict()\n",
    "s_dict[u'徽商'] = 0.4\n",
    "s_dict[u'罗盘'] = 0.3\n",
    "s_dict[u'茶叶'] = 0.3\n",
    "\n",
    "t_sim = 'hs_sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "#df[t_sim] = df.s_vec.map(lambda x: calculate_sim(x, dsi_dict))\n",
    "df['s_check'] = df.s_vec.map(lambda x: aT.set_contained_flag(x, s_dict))\n",
    "check = df[df['s_check'] == True]\n",
    "print 'after s_check', time() - t0\n",
    "\n",
    "print '---- check len---', len(check)\n",
    "\n",
    "#cc = check[:10]\n",
    "\n",
    "centroid_vec = aT.get_centroid_df(check, t_sim)\n",
    "print 'after centroid', time() - t0\n",
    "#only work on non duplicated ones\n",
    "df[t_sim] = df.s_vec.map(lambda x: aT.get_sim(x, centroid_vec))\n",
    "s_sim = df[t_sim].values.argsort()[::-1]\n",
    "print time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = df[df[t_sim] > 0.50]\n",
    "out_df.info()\n",
    "s_sim = out_df[t_sim].values.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print out centroid \n",
    "ret = aT.sort_dict(centroid_vec)\n",
    "vec6 = centroid_vec\n",
    "\n",
    "words, cnt = zip(*ret)\n",
    "print 'centroid --- for 徽商'\n",
    "for i in range(0, len(words)):\n",
    "    print i, words[i], cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i in s_sim:\n",
    "    if out_df.iloc[i][t_sim] > 0.3:\n",
    "        title = out_df.iloc[i]['title']\n",
    "        sim_val = out_df.iloc[i][t_sim]\n",
    "        idx += 1\n",
    "        print idx, i, title, sim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get contents for '徽剧'\n",
    "s_dict = dict()\n",
    "s_dict[u'徽剧'] = 0.4\n",
    "s_dict[u'徽墨'] = 0.2\n",
    "s_dict[u'徽砚'] = 0.2\n",
    "s_dict[u'徽菜'] = 0.2\n",
    "\n",
    "t_sim = 'hj_sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "#df[t_sim] = df.s_vec.map(lambda x: calculate_sim(x, dsi_dict))\n",
    "df['s_check'] = df.s_vec.map(lambda x: aT.set_contained_flag(x, s_dict))\n",
    "check = df[df['s_check'] == True]\n",
    "print 'after s_check', time() - t0\n",
    "\n",
    "print '---- check len---', len(check)\n",
    "\n",
    "#cc = check[:10]\n",
    "\n",
    "centroid_vec = aT.get_centroid_df(check, t_sim)\n",
    "print 'after centroid', time() - t0\n",
    "#only work on non duplicated ones\n",
    "df[t_sim] = df.s_vec.map(lambda x: aT.get_sim(x, centroid_vec))\n",
    "s_sim = df[t_sim].values.argsort()[::-1]\n",
    "print time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = df[df[t_sim] > 0.50]\n",
    "out_df.info()\n",
    "s_sim = out_df[t_sim].values.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print out centroid \n",
    "ret = aT.sort_dict(centroid_vec)\n",
    "vec7 = centroid_vec\n",
    "\n",
    "words, cnt = zip(*ret)\n",
    "print 'centroid --- for 徽剧'\n",
    "for i in range(0, len(words)):\n",
    "    print i, words[i], cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get contents for '民俗'\n",
    "s_dict = dict()\n",
    "s_dict[u'民俗'] = 0.2\n",
    "s_dict[u'教育'] = 0.2\n",
    "s_dict[u'历史'] = 0.2\n",
    "s_dict[u'博物馆'] = 0.2\n",
    "s_dict[u'徽州'] = 0.2\n",
    "\n",
    "t_sim = 'ms_sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "#df[t_sim] = df.s_vec.map(lambda x: calculate_sim(x, dsi_dict))\n",
    "df['s_check'] = df.s_vec.map(lambda x: aT.set_contained_flag(x, s_dict))\n",
    "check = df[df['s_check'] == True]\n",
    "print 'after s_check', time() - t0\n",
    "\n",
    "print '---- check len---', len(check)\n",
    "\n",
    "#cc = check[:10]\n",
    "\n",
    "centroid_vec = aT.get_centroid_df(check, t_sim)\n",
    "print 'after centroid', time() - t0\n",
    "#only work on non duplicated ones\n",
    "df[t_sim] = df.s_vec.map(lambda x: aT.get_sim(x, centroid_vec))\n",
    "s_sim = df[t_sim].values.argsort()[::-1]\n",
    "print time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = df[df[t_sim] > 0.50]\n",
    "out_df.info()\n",
    "s_sim = out_df[t_sim].values.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print out centroid \n",
    "ret = aT.sort_dict(centroid_vec)\n",
    "vec8 = centroid_vec\n",
    "\n",
    "words, cnt = zip(*ret)\n",
    "print 'centroid --- for 民俗'\n",
    "for i in range(0, len(words)):\n",
    "    print i, words[i], cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get contents for '历史'\n",
    "s_dict = dict()\n",
    "s_dict[u'名人'] = 0.3\n",
    "s_dict[u'人物'] = 0.3\n",
    "s_dict[u'徽州'] = 0.4\n",
    "\n",
    "t_sim = 'ls_sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "#df[t_sim] = df.s_vec.map(lambda x: calculate_sim(x, dsi_dict))\n",
    "df['s_check'] = df.s_vec.map(lambda x: aT.set_contained_flag(x, s_dict))\n",
    "check = df[df['s_check'] == True]\n",
    "print 'after s_check', time() - t0\n",
    "\n",
    "print '---- check len---', len(check)\n",
    "\n",
    "#cc = check[:10]\n",
    "\n",
    "centroid_vec = aT.get_centroid_df(check, t_sim)\n",
    "print 'after centroid', time() - t0\n",
    "#only work on non duplicated ones\n",
    "df[t_sim] = df.s_vec.map(lambda x: aT.get_sim(x, centroid_vec))\n",
    "s_sim = df[t_sim].values.argsort()[::-1]\n",
    "print time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = df[df[t_sim] > 0.50]\n",
    "out_df.info()\n",
    "s_sim = out_df[t_sim].values.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print out centroid \n",
    "ret = aT.sort_dict(centroid_vec)\n",
    "vec9 = centroid_vec\n",
    "\n",
    "words, cnt = zip(*ret)\n",
    "print 'centroid --- for 人物'\n",
    "for i in range(0, len(words)):\n",
    "    print i, words[i], cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get contents for '旅游'\n",
    "s_dict = dict()\n",
    "s_dict[u'徽州'] = 0.4\n",
    "s_dict[u'旅游'] = 0.3\n",
    "s_dict[u'推荐'] = 0.3\n",
    "\n",
    "s_dict\n",
    "t_sim = 'ly_sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "#df[t_sim] = df.s_vec.map(lambda x: calculate_sim(x, dsi_dict))\n",
    "df['s_check'] = df.s_vec.map(lambda x: aT.set_contained_flag(x, s_dict))\n",
    "check = df[df['s_check'] == True]\n",
    "print 'after s_check', time() - t0\n",
    "\n",
    "print '---- check len---', len(check)\n",
    "\n",
    "#cc = check[:10]\n",
    "\n",
    "centroid_vec = aT.get_centroid_df(check, t_sim)\n",
    "print 'after centroid', time() - t0\n",
    "#only work on non duplicated ones\n",
    "df[t_sim] = df.s_vec.map(lambda x: aT.get_sim(x, centroid_vec))\n",
    "s_sim = df[t_sim].values.argsort()[::-1]\n",
    "print time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = df[df[t_sim] > 0.55]\n",
    "out_df.info()\n",
    "s_sim = out_df[t_sim].values.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print out centroid \n",
    "ret = aT.sort_dict(centroid_vec)\n",
    "vec10 = centroid_vec\n",
    "\n",
    "words, cnt = zip(*ret)\n",
    "print 'centroid --- for 人物'\n",
    "for i in range(0, len(words)):\n",
    "    print i, words[i], cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "s_sim = df['hz_sim'].values.argsort()[::-1]\n",
    "\n",
    "for i in s_sim:\n",
    "    title = df.iloc[i]['title']\n",
    "    sim_val = df.iloc[i]['hz_sim']\n",
    "    print(idx, i, sim_val, title)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9554316768725106"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aT.get_sim(vec1, vec8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio = 0.42\n",
    "#title, 'hz_sim', 'hx_sim', 'xa_sim', 'cl_sim', 'hd_sim', 'hs_sim', 'ms_sim', 'ls_sim', 'ly_sim' \n",
    "new_df = df[(df['hz_sim'] > ratio) | (df['hd_sim'] > ratio) | (df['ls_sim'] > ratio) | \n",
    "            (df['cl_sim'] > ratio) | (df['hj_sim'] > ratio) | (df['ms_sim'] > ratio) |  \n",
    "            (df['hs_sim'] > ratio) | (df['xa_sim'] > ratio) | (df['hx_sim'] > ratio)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv('/Users/nhu2000/projects/SimilarSearch/data/clean/huizhou-web-slim_r_0_5.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('/Users/nhu2000/projects/SimilarSearch/data/clean/huizhou-web-slim_v1.2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clean up for web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_summary(t):\n",
    "    \n",
    "    if u'------分隔线----------------------------' in t:\n",
    "        print 'found one -------'\n",
    "    x = t.replace(u'------分隔线----------------------------', '')    \n",
    "    x = x.replace(u'————————————————————————————————————————————', '')\n",
    "    x = x.replace('！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！。！！！！！！！！！！！！！！！！！！', '')\n",
    "    sentences = x.split('\\n')\n",
    "    #print 'len -----', len(sentences)\n",
    "    #skip the first sentences\n",
    "    if len(sentences) > 3:\n",
    "        s = '。'.join(sentences[1:]).decode('utf-8')\n",
    "    else:\n",
    "        s = x.strip().decode('utf-8')\n",
    "    if len(s) > 100:\n",
    "        ret = ''.join(s[:100]) + '...'\n",
    "    else:\n",
    "        ret = s\n",
    "    \n",
    "    if len(s) < 10:\n",
    "        ret = x\n",
    "        \n",
    "    if ret[0] == u'。':\n",
    "        return ret[1:].strip()\n",
    "    else:\n",
    "         return ret.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = ['test', 'test2']\n",
    "print '。'.join(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global idx\n",
    "idx = 0\n",
    "def map_strip_titles(x):\n",
    "    global idx\n",
    "    #print idx\n",
    "    #print x\n",
    "    x = x.replace('-故园徽州网 - Powered by Discuz!', '')\n",
    "    x = x.replace('婺源论坛 - 江西婺源旅游 - 婺源老家旅游论坛第一门户', '')\n",
    "    x = x.replace('-中国华文教育网', '')\n",
    "    x = x.replace('-中安在线-徽文化', '')\n",
    "    x = x.replace('中国华文教育网－', '')\n",
    "\n",
    "    \n",
    "    t = x.split('_')\n",
    "    s = t[0]\n",
    "    idx += 1\n",
    "    #print s\n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv('/Users/nhu2000/projects/SimilarSearch/data/final/huizhou-final-v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_df['url'] = orig_df.url.map(lambda x: map_update_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_df.to_csv('/Users/nhu2000/projects/SimilarSearch/data/final/huizhou-final-v2.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_content_by_url(url):\n",
    "    df = orig_df[orig_df['url'] == url]\n",
    "    return df.iloc[0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "def remove_non_chinese(s):\n",
    "    r = [c for c in s if unicodedata.category(c).startswith('L')]\n",
    "#print r\n",
    "    return ''.join(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def map_update_summary(x, y):\n",
    "    s = remove_non_chinese(x.decode('utf-8'))\n",
    "    if re.match('^[0-9a-z]+$',s.lower()):\n",
    "        print 'length =', len(s)        \n",
    "        return y\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_update_url(x):\n",
    "    if 'http' not in x:\n",
    "        return 'http://' + x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df['url'] = new_df.url.map(lambda x: map_update_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df['title'] = new_df.title.map(lambda x: map_strip_titles(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df['content'] = new_df.url.map(lambda x: get_content_by_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df['summary'] = new_df.content.map(lambda x: get_summary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df['summary'] = (map(map_update_summary, new_df['summary'],new_df['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_df['s_vec_str'] = new_df.s_vec.map(lambda x: str(x))\n",
    "out_new_df = new_df.dropna(subset = ['s_vec_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(new_df)):\n",
    "    url = new_df.iloc[i]['url']\n",
    "    t = new_df.iloc[i]['title']\n",
    "    s = new_df.iloc[i]['summary']\n",
    "    #print i, t\n",
    "    #print s\n",
    "    if 'http:' not in url: #i == 6255:\n",
    "        print url\n",
    "        print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = new_df[['url', 'title', 'summary', 's_vec', 'hz_sim', 'hd_sim', 'ls_sim', 'cl_sim', 'hj_sim', \n",
    "                'ms_sim', 'hs_sim', 'xa_sim', 'hx_sim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df.to_csv('/Users/nhu2000/projects/SimilarSearch/data/clean/huizhou-web-slim_v1_3.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df_full = new_df[['url', 'title', 's_vec',  'content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_content_seg_by_url(url):\n",
    "    df = orig_df[orig_df['url'] == url]\n",
    "    return df.iloc[0]['content_seg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_full['content_seg'] = out_df_full.url.map(lambda x: get_content_seg_by_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>s_vec</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://cul.anhuinews.com/system/2016/01/26/007...</td>\n",
       "      <td>徽州古民居雕刻装饰研究</td>\n",
       "      <td>{u'是从': 0.0189873417722, u'还有': 0.012658227848...</td>\n",
       "      <td>徽州因明清两朝的繁盛而在历史上留下浓墨重彩的一笔，建筑就是那个时代的重要表现之一。当时的徽商...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://cul.anhuinews.com/system/2014/07/11/006...</td>\n",
       "      <td>徽州为什么称为“文献之邦”</td>\n",
       "      <td>{u'宋代': 0.0142857142857, u'孤本': 0.014285714285...</td>\n",
       "      <td>徽州作为极具特色的地域文化区，在宋代就已经基本形成。明代以来徽商迅速崛起，更加有力的推动了教...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://cul.anhuinews.com/system/2014/06/26/006...</td>\n",
       "      <td>安徽省非物质文化遗产：砖雕、石雕、木雕</td>\n",
       "      <td>{u'迄今': 0.012987012987, u'雕刻': 0.038961038961,...</td>\n",
       "      <td>古代徽州辖地包括今天的安徽省黄山市和江西省婺源县。\"徽州三雕\"为古代徽州地区明清建筑的装饰性...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>http://cul.anhuinews.com/system/2014/06/26/006...</td>\n",
       "      <td>徽州文化中的烟文化</td>\n",
       "      <td>{u'地方': 0.01, u'理应': 0.01, u'哪个': 0.01, u'加工':...</td>\n",
       "      <td>徽州文化的内容包罗万象，如徽州土地制度、徽商、徽州历史名人、徽州科技、新安理学、新安医学、徽...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>http://cul.anhuinews.com/system/2014/06/19/006...</td>\n",
       "      <td>马头墙内外的徽州女人</td>\n",
       "      <td>{u'信条': 0.00909090909091, u'贞节牌坊': 0.018181818...</td>\n",
       "      <td>安徽南端的徽州地域，黄山白岳新安江山水秀美，在蓝天白云绿水青山掩映之中，徽州古村落高低起伏、...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url                title  \\\n",
       "5   http://cul.anhuinews.com/system/2016/01/26/007...          徽州古民居雕刻装饰研究   \n",
       "7   http://cul.anhuinews.com/system/2014/07/11/006...        徽州为什么称为“文献之邦”   \n",
       "9   http://cul.anhuinews.com/system/2014/06/26/006...  安徽省非物质文化遗产：砖雕、石雕、木雕   \n",
       "10  http://cul.anhuinews.com/system/2014/06/26/006...            徽州文化中的烟文化   \n",
       "12  http://cul.anhuinews.com/system/2014/06/19/006...           马头墙内外的徽州女人   \n",
       "\n",
       "                                                s_vec  \\\n",
       "5   {u'是从': 0.0189873417722, u'还有': 0.012658227848...   \n",
       "7   {u'宋代': 0.0142857142857, u'孤本': 0.014285714285...   \n",
       "9   {u'迄今': 0.012987012987, u'雕刻': 0.038961038961,...   \n",
       "10  {u'地方': 0.01, u'理应': 0.01, u'哪个': 0.01, u'加工':...   \n",
       "12  {u'信条': 0.00909090909091, u'贞节牌坊': 0.018181818...   \n",
       "\n",
       "                                              content  \n",
       "5   徽州因明清两朝的繁盛而在历史上留下浓墨重彩的一笔，建筑就是那个时代的重要表现之一。当时的徽商...  \n",
       "7   徽州作为极具特色的地域文化区，在宋代就已经基本形成。明代以来徽商迅速崛起，更加有力的推动了教...  \n",
       "9   古代徽州辖地包括今天的安徽省黄山市和江西省婺源县。\"徽州三雕\"为古代徽州地区明清建筑的装饰性...  \n",
       "10  徽州文化的内容包罗万象，如徽州土地制度、徽商、徽州历史名人、徽州科技、新安理学、新安医学、徽...  \n",
       "12  安徽南端的徽州地域，黄山白岳新安江山水秀美，在蓝天白云绿水青山掩映之中，徽州古村落高低起伏、...  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df_full.to_csv('/Users/nhu2000/projects/SimilarSearch/data/clean/huizhou-web-full_v1_3.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('/Users/nhu2000/projects/SimilarSearch/data/clean/huizhou_full_v2_0.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
