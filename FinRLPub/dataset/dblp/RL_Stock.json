{
"result":{
"query":"reinforce* learning* stock*",
"status":{
"@code":"200",
"text":"OK"
},
"time":{
"@unit":"msecs",
"text":"6.54"
},
"completions":{
"@total":"7",
"@computed":"7",
"@sent":"7",
"c":[
{
"@sc":"48",
"@dc":"47",
"@oc":"48",
"@id":"47124640",
"text":"stock"
},
{
"@sc":"5",
"@dc":"5",
"@oc":"5",
"@id":"47124716",
"text":"stockholm"
},
{
"@sc":"1",
"@dc":"1",
"@oc":"1",
"@id":"47124729",
"text":"stockinger"
},
{
"@sc":"1",
"@dc":"1",
"@oc":"1",
"@id":"47124684",
"text":"stocker"
},
{
"@sc":"1",
"@dc":"1",
"@oc":"1",
"@id":"47124803",
"text":"stockton"
},
{
"@sc":"1",
"@dc":"1",
"@oc":"1",
"@id":"47124815",
"text":"stockyards"
},
{
"@sc":"1",
"@dc":"1",
"@oc":"1",
"@id":"47124865",
"text":"stoecklein"
}
]
},
"hits":{
"@total":"57",
"@computed":"57",
"@sent":"57",
"@first":"0",
"hit":[{
"@score":"4",
"@id":"220503",
"info":{"authors":{"author":{"@pid":"164/9013","text":"Vidit Saxena"}},"title":"Machine Learning for Wireless Link Adaptation: Supervised and Reinforcement Learning Theory and Algorithms.","year":"2021","type":"Books and Theses","access":"closed","key":"phd/basesearch/Saxena21a","ee":"https://nbn-resolving.org/urn:nbn:se:kth:diva-293545","url":"https://dblp.org/rec/phd/basesearch/Saxena21a"},
"url":"URL#220503"
},
{
"@score":"4",
"@id":"241200",
"info":{"authors":{"author":[{"@pid":"07/5975","text":"Salvatore Carta"},{"@pid":"227/2073","text":"Andrea Corriga"},{"@pid":"123/7604","text":"Anselmo Ferreira"},{"@pid":"162/1651","text":"Alessandro Sebastian Podda"},{"@pid":"r/DiegoReforgiatoRecupero","text":"Diego Reforgiato Recupero"}]},"title":"A multi-layer and multi-ensemble stock trader using deep learning and deep reinforcement learning.","venue":"Appl. Intell.","volume":"51","number":"2","pages":"889-905","year":"2021","type":"Journal Articles","access":"closed","key":"journals/apin/CartaCFPR21","doi":"10.1007/S10489-020-01839-5","ee":"https://doi.org/10.1007/s10489-020-01839-5","url":"https://dblp.org/rec/journals/apin/CartaCFPR21"},
"url":"URL#241200"
},
{
"@score":"4",
"@id":"581205",
"info":{"authors":{"author":[{"@pid":"277/5373","text":"Mehran Taghian"},{"@pid":"243/7157","text":"Ahmad Asadi"},{"@pid":"44/839","text":"Reza Safabakhsh"}]},"title":"A Reinforcement Learning Based Encoder-Decoder Framework for Learning Stock Trading Rules.","venue":"CoRR","volume":"abs/2101.03867","year":"2021","type":"Informal Publications","access":"open","key":"journals/corr/abs-2101-03867","ee":"https://arxiv.org/abs/2101.03867","url":"https://dblp.org/rec/journals/corr/abs-2101-03867"},
"url":"URL#581205"
},
{
"@score":"4",
"@id":"706342",
"info":{"authors":{"author":[{"@pid":"92/11296","text":"Yuming Li"},{"@pid":"242/2912","text":"Pin Ni"},{"@pid":"158/5207","text":"Victor Chang 0001"}]},"title":"Application of deep reinforcement learning in stock trading strategies and stock forecasting.","venue":"Computing","volume":"102","number":"6","pages":"1305-1322","year":"2020","type":"Journal Articles","access":"closed","key":"journals/computing/LiNC20","doi":"10.1007/S00607-019-00773-W","ee":"https://doi.org/10.1007/s00607-019-00773-w","url":"https://dblp.org/rec/journals/computing/LiNC20"},
"url":"URL#706342"
},
{
"@score":"4",
"@id":"1005556",
"info":{"authors":{"author":[{"@pid":"86/10313","text":"Jong Hun Woo"},{"@pid":"13/10488","text":"Young In Cho"},{"@pid":"289/4714","text":"Sang Hyeon Yu"},{"@pid":"289/4695","text":"So Hyun Nam"},{"@pid":"194/0512","text":"Haoyu Zhu"},{"@pid":"87/11193","text":"Dong-Hoon Kwak"},{"@pid":"176/1606","text":"Jong Ho Nam"}]},"title":"Machine Learning (Reinforcement Learning)-Based Steel Stock Yard Planning Algorithm.","venue":"WSC","pages":"1560-1571","year":"2020","type":"Conference and Workshop Papers","access":"closed","key":"conf/wsc/WooCYNZKN20","doi":"10.1109/WSC48552.2020.9384049","ee":"https://doi.org/10.1109/WSC48552.2020.9384049","url":"https://dblp.org/rec/conf/wsc/WooCYNZKN20"},
"url":"URL#1005556"
},
{
"@score":"3",
"@id":"44972",
"info":{"authors":{"author":[{"@pid":"278/2301","text":"Hongfeng Xu"},{"@pid":"02/4099","text":"Lei Chai"},{"@pid":"75/9709","text":"Zhiming Luo"},{"@pid":"51/2064","text":"Shaozi Li"}]},"title":"Stock movement prediction via gated recurrent unit network based on reinforcement learning with incorporated attention mechanisms.","venue":"Neurocomputing","volume":"467","pages":"214-228","year":"2022","type":"Journal Articles","access":"closed","key":"journals/ijon/XuCLL22","doi":"10.1016/J.NEUCOM.2021.09.072","ee":"https://doi.org/10.1016/j.neucom.2021.09.072","url":"https://dblp.org/rec/journals/ijon/XuCLL22"},
"url":"URL#44972"
},
{
"@score":"3",
"@id":"115218",
"info":{"authors":{"author":[{"@pid":"240/9208","text":"Porter Jenkins"},{"@pid":"01/6961-1","text":"Hua Wei 0001"},{"@pid":"256/5351","text":"J. Stockton Jenkins"},{"@pid":"27/178","text":"Zhenhui Li"}]},"title":"Bayesian Model-Based Offline Reinforcement Learning for Product Allocation.","venue":"AAAI","pages":"12531-12537","year":"2022","type":"Conference and Workshop Papers","access":"closed","key":"conf/aaai/Jenkins0JL22","ee":"https://ojs.aaai.org/index.php/AAAI/article/view/21523","url":"https://dblp.org/rec/conf/aaai/Jenkins0JL22"},
"url":"URL#115218"
},
{
"@score":"3",
"@id":"123964",
"info":{"authors":{"author":[{"@pid":"308/6774","text":"Uta Pigorsch"},{"@pid":"17/7988","text":"Sebastian Sch√§fer"}]},"title":"High-Dimensional Stock Portfolio Trading with Deep Reinforcement Learning.","venue":"CIFEr","pages":"1-8","year":"2022","type":"Conference and Workshop Papers","access":"closed","key":"conf/cifer/PigorschS22","doi":"10.1109/CIFER52523.2022.9776121","ee":"https://doi.org/10.1109/CIFEr52523.2022.9776121","url":"https://dblp.org/rec/conf/cifer/PigorschS22"},
"url":"URL#123964"
},
{
"@score":"3",
"@id":"137504",
"info":{"authors":{"author":[{"@pid":"85/6319","text":"Xiaojie Li"},{"@pid":"23/8313","text":"Chaoran Cui"},{"@pid":"04/915","text":"Donglin Cao"},{"@pid":"10/1178","text":"Juan Du"},{"@pid":"153/0702","text":"Chunyun Zhang"}]},"title":"Hypergraph-Based Reinforcement Learning for Stock Portfolio Selection.","venue":"ICASSP","pages":"4028-4032","year":"2022","type":"Conference and Workshop Papers","access":"closed","key":"conf/icassp/LiCCDZ22","doi":"10.1109/ICASSP43922.2022.9747138","ee":"https://doi.org/10.1109/ICASSP43922.2022.9747138","url":"https://dblp.org/rec/conf/icassp/LiCCDZ22"},
"url":"URL#137504"
},
{
"@score":"3",
"@id":"143634",
"info":{"authors":{"author":[{"@pid":"20/1801","text":"Jun Ge"},{"@pid":"323/8399","text":"Yuanqi Qin"},{"@pid":"177/9141","text":"Yaling Li"},{"@pid":"323/7966","text":"yanjia Huang"},{"@pid":"67/6924","text":"Hao Hu"}]},"title":"Single stock trading with deep reinforcement learning: A comparative study.","venue":"ICMLC","pages":"34-43","year":"2022","type":"Conference and Workshop Papers","access":"closed","key":"conf/icmlc2/GeQLHH22","doi":"10.1145/3529836.3529857","ee":"https://doi.org/10.1145/3529836.3529857","url":"https://dblp.org/rec/conf/icmlc2/GeQLHH22"},
"url":"URL#143634"
},
{
"@score":"3",
"@id":"184257",
"info":{"authors":{"author":[{"@pid":"241/4071","text":"Federico Cornalba"},{"@pid":"315/4054","text":"Constantin Disselkamp"},{"@pid":"315/4169","text":"Davide Scassola"},{"@pid":"168/4749","text":"Christopher Helf"}]},"title":"Multi-Objective reward generalization: Improving performance of Deep Reinforcement Learning for selected applications in stock and cryptocurrency trading.","venue":"CoRR","volume":"abs/2203.04579","year":"2022","type":"Informal Publications","access":"open","key":"journals/corr/abs-2203-04579","doi":"10.48550/ARXIV.2203.04579","ee":"https://doi.org/10.48550/arXiv.2203.04579","url":"https://dblp.org/rec/journals/corr/abs-2203-04579"},
"url":"URL#184257"
},
{
"@score":"3",
"@id":"203151",
"info":{"authors":{"author":[{"@pid":"133/5796","text":"Huifang Huang"},{"@pid":"45/5162","text":"Ting Gao"},{"@pid":"311/5499","text":"Yi Gui"},{"@pid":"73/4155","text":"Jin Guo"},{"@pid":"21/1048","text":"Peng Zhang"}]},"title":"Stock Trading Optimization through Model-based Reinforcement Learning with Resistance Support Relative Strength.","venue":"CoRR","volume":"abs/2205.15056","year":"2022","type":"Informal Publications","access":"open","key":"journals/corr/abs-2205-15056","doi":"10.48550/ARXIV.2205.15056","ee":"https://doi.org/10.48550/arXiv.2205.15056","url":"https://dblp.org/rec/journals/corr/abs-2205-15056"},
"url":"URL#203151"
},
{
"@score":"3",
"@id":"206306",
"info":{"authors":{"author":[{"@pid":"322/4149","text":"Zitao Song"},{"@pid":"322/3860","text":"Xuyang Jin"},{"@pid":"52/9457","text":"Chenliang Li"}]},"title":"Safe-FinRL: A Low Bias and Variance Deep Reinforcement Learning Implementation for High-Freq Stock Trading.","venue":"CoRR","volume":"abs/2206.05910","year":"2022","type":"Informal Publications","access":"open","key":"journals/corr/abs-2206-05910","doi":"10.48550/ARXIV.2206.05910","ee":"https://doi.org/10.48550/arXiv.2206.05910","url":"https://dblp.org/rec/journals/corr/abs-2206-05910"},
"url":"URL#206306"
},
{
"@score":"3",
"@id":"220361",
"info":{"authors":{"author":{"@pid":"07/7237","text":"Athanasios Karapantelakis"}},"title":"Mobile Network Operator Collaboration using Deep Reinforcement Learning.","year":"2021","type":"Books and Theses","access":"closed","key":"phd/basesearch/Karapantelakis21","ee":"https://nbn-resolving.org/urn:nbn:se:kth:diva-289651","url":"https://dblp.org/rec/phd/basesearch/Karapantelakis21"},
"url":"URL#220361"
},
{
"@score":"3",
"@id":"295368",
"info":{"authors":{"author":[{"@pid":"210/0892","text":"Shruti Mittal"},{"@pid":"216/6999","text":"Chander Kumar Nagpal"}]},"title":"Reinforcement learning based predictive analytics framework for survival in stock market.","venue":"Int. J. Intell. Eng. Informatics","volume":"9","number":"3","pages":"294-327","year":"2021","type":"Journal Articles","access":"closed","key":"journals/ijiei/MittalN21","doi":"10.1504/IJIEI.2021.118275","ee":"https://doi.org/10.1504/IJIEI.2021.118275","url":"https://dblp.org/rec/journals/ijiei/MittalN21"},
"url":"URL#295368"
},
{
"@score":"3",
"@id":"298765",
"info":{"authors":{"author":[{"@pid":"42/10808","text":"Cong Ma"},{"@pid":"74/982-1","text":"Jiangshe Zhang 0001"},{"@pid":"12/6911","text":"Junmin Liu"},{"@pid":"180/0182","text":"Lizhen Ji"},{"@pid":"16/722","text":"Fei Gao"}]},"title":"A parallel multi-module deep reinforcement learning algorithm for stock trading.","venue":"Neurocomputing","volume":"449","pages":"290-302","year":"2021","type":"Journal Articles","access":"closed","key":"journals/ijon/MaZLJG21","doi":"10.1016/J.NEUCOM.2021.04.005","ee":"https://doi.org/10.1016/j.neucom.2021.04.005","url":"https://dblp.org/rec/journals/ijon/MaZLJG21"},
"url":"URL#298765"
},
{
"@score":"3",
"@id":"344221",
"info":{"authors":{"author":[{"@pid":"286/0372","text":"Rasha AbdelKawy"},{"@pid":"286/0606","text":"Walid M. Abdelmoez"},{"@pid":"46/5176","text":"Amin A. Shoukry"}]},"title":"A synchronous deep reinforcement learning model for automated multi-stock trading.","venue":"Prog. Artif. Intell.","volume":"10","number":"1","pages":"83-97","year":"2021","type":"Journal Articles","access":"closed","key":"journals/pai/AbdelKawyAS21","doi":"10.1007/S13748-020-00225-Z","ee":"https://doi.org/10.1007/s13748-020-00225-z","url":"https://dblp.org/rec/journals/pai/AbdelKawyAS21"},
"url":"URL#344221"
},
{
"@score":"3",
"@id":"445158",
"info":{"authors":{"author":[{"@pid":"283/1275","text":"Prahlad Koratamaddi"},{"@pid":"283/0282","text":"Karan Wadhwani"},{"@pid":"21/8158","text":"Mridul Gupta"},{"@pid":"41/1616","text":"Sriram G. Sanjeevi"}]},"title":"A Multi-Agent Reinforcement Learning Approach for Stock Portfolio Allocation.","venue":"COMAD/CODS","pages":"410","year":"2021","type":"Conference and Workshop Papers","access":"closed","key":"conf/comad/KoratamaddiWGS21","doi":"10.1145/3430984.3431045","ee":"https://doi.org/10.1145/3430984.3431045","url":"https://dblp.org/rec/conf/comad/KoratamaddiWGS21"},
"url":"URL#445158"
},
{
"@score":"3",
"@id":"500211",
"info":{"authors":{"author":[{"@pid":"262/7772","text":"Shaobo Hu"},{"@pid":"94/1239","text":"Hongying Zheng"},{"@pid":"11/3561","text":"Jianyong Chen"}]},"title":"A Novel Deep Reinforcement Learning Framework for Stock Portfolio Optimization.","venue":"ICONIP","pages":"205-212","year":"2021","type":"Conference and Workshop Papers","access":"closed","key":"conf/iconip/HuZC21","doi":"10.1007/978-3-030-92307-5_24","ee":"https://doi.org/10.1007/978-3-030-92307-5_24","url":"https://dblp.org/rec/conf/iconip/HuZC21"},
"url":"URL#500211"
},
{
"@score":"3",
"@id":"506335",
"info":{"authors":{"author":[{"@pid":"f/PMFiorini","text":"Pierre M. Fiorini"},{"@pid":"310/0971","text":"Pierce-Gabriel Fiorini"}]},"title":"A Simple Reinforcement Learning Algorithm for Stock Trading.","venue":"IDAACS","pages":"824-830","year":"2021","type":"Conference and Workshop Papers","access":"closed","key":"conf/idaacs/FioriniF21","doi":"10.1109/IDAACS53288.2021.9660900","ee":"https://doi.org/10.1109/IDAACS53288.2021.9660900","url":"https://dblp.org/rec/conf/idaacs/FioriniF21"},
"url":"URL#506335"
},
{
"@score":"3",
"@id":"618715",
"info":{"authors":{"author":{"@pid":"296/1708","text":"Supriya Bajpai"}},"title":"Application of deep reinforcement learning for Indian stock trading automation.","venue":"CoRR","volume":"abs/2106.16088","year":"2021","type":"Informal Publications","access":"open","key":"journals/corr/abs-2106-16088","ee":"https://arxiv.org/abs/2106.16088","url":"https://dblp.org/rec/journals/corr/abs-2106-16088"},
"url":"URL#618715"
},
{
"@score":"3",
"@id":"619165",
"info":{"authors":{"author":[{"@pid":"296/1492","text":"Edward Elson Kosasih"},{"@pid":"85/1303","text":"Alexandra Brintrup"}]},"title":"Reinforcement Learning Provides a Flexible Approach for Realistic Supply Chain Safety Stock Optimisation.","venue":"CoRR","volume":"abs/2107.00913","year":"2021","type":"Informal Publications","access":"open","key":"journals/corr/abs-2107-00913","ee":"https://arxiv.org/abs/2107.00913","url":"https://dblp.org/rec/journals/corr/abs-2107-00913"},
"url":"URL#619165"
},
{
"@score":"3",
"@id":"619172",
"info":{"authors":{"author":[{"@pid":"296/3850","text":"Anil Berk Altuner"},{"@pid":"124/7283","text":"Zeynep Hilal Kilimci"}]},"title":"A Novel Deep Reinforcement Learning Based Stock Direction Prediction using Knowledge Graph and Community Aware Sentiments.","venue":"CoRR","volume":"abs/2107.00931","year":"2021","type":"Informal Publications","access":"open","key":"journals/corr/abs-2107-00931","ee":"https://arxiv.org/abs/2107.00931","url":"https://dblp.org/rec/journals/corr/abs-2107-00931"},
"url":"URL#619172"
},
{
"@score":"3",
"@id":"625526",
"info":{"authors":{"author":[{"@pid":"298/8150","text":"Zhaolu Dong"},{"@pid":"06/4186","text":"Shan Huang"},{"@pid":"298/7320","text":"Simiao Ma"},{"@pid":"254/0301","text":"Yining Qian"}]},"title":"Factor Representation and Decision Making in Stock Markets Using Deep Reinforcement Learning.","venue":"CoRR","volume":"abs/2108.01758","year":"2021","type":"Informal Publications","access":"open","key":"journals/corr/abs-2108-01758","ee":"https://arxiv.org/abs/2108.01758","url":"https://dblp.org/rec/journals/corr/abs-2108-01758"},
"url":"URL#625526"
},
{
"@score":"3",
"@id":"634780",
"info":{"authors":{"author":[{"@pid":"302/3545","text":"Anselmo Ramalho Pitombeira-Neto"},{"@pid":"302/4393","text":"Arthur H. Fonseca Murta"}]},"title":"A Reinforcement Learning Approach to the Stochastic Cutting Stock Problem.","venue":"CoRR","volume":"abs/2109.09592","year":"2021","type":"Informal Publications","access":"open","key":"journals/corr/abs-2109-09592","ee":"https://arxiv.org/abs/2109.09592","url":"https://dblp.org/rec/journals/corr/abs-2109-09592"},
"url":"URL#634780"
},
{
"@score":"3",
"@id":"652820",
"info":{"authors":{"author":[{"@pid":"308/6774","text":"Uta Pigorsch"},{"@pid":"17/7988","text":"Sebastian Sch√§fer"}]},"title":"High-Dimensional Stock Portfolio Trading with Deep Reinforcement Learning.","venue":"CoRR","volume":"abs/2112.04755","year":"2021","type":"Informal Publications","access":"open","key":"journals/corr/abs-2112-04755","ee":"https://arxiv.org/abs/2112.04755","url":"https://dblp.org/rec/journals/corr/abs-2112-04755"},
"url":"URL#652820"
},
{
"@score":"3",
"@id":"660413",
"info":{"authors":{"author":{"@pid":"16/3283-51","text":"Xi Chen 0051"}},"title":"Data-Efficient Reinforcement and Transfer Learning in Robotics.","year":"2020","type":"Books and Theses","access":"closed","key":"phd/basesearch/Chen20f","ee":"https://nbn-resolving.org/urn:nbn:se:kth:diva-285993","url":"https://dblp.org/rec/phd/basesearch/Chen20f"},
"url":"URL#660413"
},
{
"@score":"3",
"@id":"689723",
"info":{"authors":{"author":[{"@pid":"282/7194","text":"Tommi Huotari"},{"@pid":"195/2634","text":"Jyrki Savolainen"},{"@pid":"01/4206","text":"Mikael Collan"}]},"title":"Deep Reinforcement Learning Agent for S&amp;P 500 Stock Selection.","venue":"Axioms","volume":"9","number":"4","pages":"130","year":"2020","type":"Journal Articles","access":"open","key":"journals/axioms/HuotariSC20","doi":"10.3390/AXIOMS9040130","ee":"https://doi.org/10.3390/axioms9040130","url":"https://dblp.org/rec/journals/axioms/HuotariSC20"},
"url":"URL#689723"
},
{
"@score":"3",
"@id":"704638",
"info":{"authors":{"author":[{"@pid":"278/4677","text":"Xiaqun Liu"},{"@pid":"148/9363","text":"Yaming Zhuang"},{"@pid":"71/6718","text":"Jinsheng Li"},{"@pid":"69/5011","text":"Wei Zhou"}]},"title":"A Model for Evolution of Investors Behavior in Stock Market Based on Reinforcement Learning in Network.","venue":"Complex.","volume":"2020","pages":"3561538:1-3561538:13","year":"2020","type":"Journal Articles","access":"open","key":"journals/complexity/LiuZLZ20","doi":"10.1155/2020/3561538","ee":"https://doi.org/10.1155/2020/3561538","url":"https://dblp.org/rec/journals/complexity/LiuZLZ20"},
"url":"URL#704638"
},
{
"@score":"3",
"@id":"740575",
"info":{"authors":{"author":[{"@pid":"193/7615","text":"Byeong-Seop Kim"},{"@pid":"193/7654","text":"Yongkuk Jeong"},{"@pid":"88/10935","text":"Jong-Gye Shin"}]},"title":"Spatial arrangement using deep reinforcement learning to minimise rearrangement in ship block stockyards.","venue":"Int. J. Prod. Res.","volume":"58","number":"16","pages":"5062-5076","year":"2020","type":"Journal Articles","access":"open","key":"journals/ijpr/KimJS20","doi":"10.1080/00207543.2020.1748247","ee":"https://doi.org/10.1080/00207543.2020.1748247","url":"https://dblp.org/rec/journals/ijpr/KimJS20"},
"url":"URL#740575"
},
{
"@score":"3",
"@id":"747766",
"info":{"authors":{"author":[{"@pid":"04/55-1","text":"Xing Wu 0001"},{"@pid":"264/3747","text":"Haolei Chen"},{"@pid":"188/9873","text":"Jianjia Wang"},{"@pid":"76/4882","text":"Luigi Troiano"},{"@pid":"35/3222","text":"Vincenzo Loia"},{"@pid":"49/6628","text":"Hamido Fujita"}]},"title":"Adaptive stock trading strategies with deep reinforcement learning methods.","venue":"Inf. Sci.","volume":"538","pages":"142-158","year":"2020","type":"Journal Articles","access":"closed","key":"journals/isci/WuCWTLF20","doi":"10.1016/J.INS.2020.05.066","ee":"https://doi.org/10.1016/j.ins.2020.05.066","url":"https://dblp.org/rec/journals/isci/WuCWTLF20"},
"url":"URL#747766"
},
{
"@score":"3",
"@id":"758701",
"info":{"authors":{"author":[{"@pid":"266/4886","text":"Tai-Li Luo"},{"@pid":"20/1550","text":"Mu-En Wu"},{"@pid":"60/2777-1","text":"Chien-Ming Chen 0001"}]},"title":"A framework of deep reinforcement learning for stock evaluation functions.","venue":"J. Intell. Fuzzy Syst.","volume":"38","number":"5","pages":"5639-5649","year":"2020","type":"Journal Articles","access":"closed","key":"journals/jifs/LuoWC20","doi":"10.3233/JIFS-179653","ee":"https://doi.org/10.3233/JIFS-179653","url":"https://dblp.org/rec/journals/jifs/LuoWC20"},
"url":"URL#758701"
},
{
"@score":"3",
"@id":"870690",
"info":{"authors":{"author":[{"@pid":"211/8506","text":"Badr Hirchoua"},{"@pid":"89/10502","text":"Brahim Ouhbi"},{"@pid":"66/10502","text":"Bouchra Frikh"}]},"title":"Rules Based Policy for Stock Trading: A New Deep Reinforcement Learning Method.","venue":"Cloudtech","pages":"1-6","year":"2020","type":"Conference and Workshop Papers","access":"closed","key":"conf/cloudtech/HirchouaOF20","doi":"10.1109/CLOUDTECH49835.2020.9365878","ee":"https://doi.org/10.1109/CloudTech49835.2020.9365878","url":"https://dblp.org/rec/conf/cloudtech/HirchouaOF20"},
"url":"URL#870690"
},
{
"@score":"3",
"@id":"908768",
"info":{"authors":{"author":[{"@pid":"226/0938","text":"Hongyang Yang"},{"@pid":"125/9849","text":"Xiao-Yang Liu"},{"@pid":"94/1198","text":"Shan Zhong"},{"@pid":"75/6446","text":"Anwar Walid"}]},"title":"Deep reinforcement learning for automated stock trading: an ensemble strategy.","venue":"ICAIF","pages":"31:1-31:8","year":"2020","type":"Conference and Workshop Papers","access":"closed","key":"conf/icaif/YangLZW20","doi":"10.1145/3383455.3422540","ee":"https://doi.org/10.1145/3383455.3422540","url":"https://dblp.org/rec/conf/icaif/YangLZW20"},
"url":"URL#908768"
},
{
"@score":"3",
"@id":"943697",
"info":{"authors":{"author":[{"@pid":"11/8045","text":"Leonardo Conegundes Martinez"},{"@pid":"73/6430","text":"Adriano C√©sar Machado Pereira"}]},"title":"Beating the Stock Market with a Deep Reinforcement Learning Day Trading System.","venue":"IJCNN","pages":"1-8","year":"2020","type":"Conference and Workshop Papers","access":"closed","key":"conf/ijcnn/MartinezP20","doi":"10.1109/IJCNN48605.2020.9206938","ee":"https://doi.org/10.1109/IJCNN48605.2020.9206938","url":"https://dblp.org/rec/conf/ijcnn/MartinezP20"},
"url":"URL#943697"
},
{
"@score":"3",
"@id":"993879",
"info":{"authors":{"author":[{"@pid":"282/7606","text":"Abdulrahman A. Ahmed"},{"@pid":"82/4809","text":"Ayman Ghoneim"},{"@pid":"04/4967","text":"Mohamed Saleh"}]},"title":"Optimizing stock market execution costs using reinforcement learning.","venue":"SSCI","pages":"1083-1090","year":"2020","type":"Conference and Workshop Papers","access":"closed","key":"conf/ssci/AhmedGS20","doi":"10.1109/SSCI47803.2020.9308153","ee":"https://doi.org/10.1109/SSCI47803.2020.9308153","url":"https://dblp.org/rec/conf/ssci/AhmedGS20"},
"url":"URL#993879"
},
{
"@score":"3",
"@id":"1011980",
"info":{"authors":{"author":{"@pid":"243/5933","text":"Wenhang Bao"}},"title":"Fairness in Multi-agent Reinforcement Learning for Stock Trading.","venue":"CoRR","volume":"abs/2001.00918","year":"2020","type":"Informal Publications","access":"open","key":"journals/corr/abs-2001-00918","ee":"http://arxiv.org/abs/2001.00918","url":"https://dblp.org/rec/journals/corr/abs-2001-00918"},
"url":"URL#1011980"
},
{
"@score":"3",
"@id":"1074401",
"info":{"authors":{"author":[{"@pid":"125/9849","text":"Xiao-Yang Liu"},{"@pid":"226/0938","text":"Hongyang Yang"},{"@pid":"11/1394","text":"Qian Chen"},{"@pid":"250/0635","text":"Runjia Zhang"},{"@pid":"52/6918","text":"Liuqing Yang"},{"@pid":"255/6487","text":"Bowen Xiao"},{"@pid":"246/4851","text":"Christina Dan Wang"}]},"title":"FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance.","venue":"CoRR","volume":"abs/2011.09607","year":"2020","type":"Informal Publications","access":"open","key":"journals/corr/abs-2011-09607","ee":"https://arxiv.org/abs/2011.09607","url":"https://dblp.org/rec/journals/corr/abs-2011-09607"},
"url":"URL#1074401"
},
{
"@score":"3",
"@id":"1079245",
"info":{"authors":{"author":{"@pid":"59/8239","text":"Le Trung Hieu"}},"title":"Deep Reinforcement Learning for Stock Portfolio Optimization.","venue":"CoRR","volume":"abs/2012.06325","year":"2020","type":"Informal Publications","access":"open","key":"journals/corr/abs-2012-06325","ee":"https://arxiv.org/abs/2012.06325","url":"https://dblp.org/rec/journals/corr/abs-2012-06325"},
"url":"URL#1079245"
},
{
"@score":"3",
"@id":"1285857",
"info":{"authors":{"author":[{"@pid":"92/11296","text":"Yuming Li"},{"@pid":"242/2912","text":"Pin Ni"},{"@pid":"158/5207","text":"Victor Chang 0001"}]},"title":"An Empirical Research on the Investment Strategy of Stock Market based on Deep Reinforcement Learning model.","venue":"COMPLEXIS","pages":"52-58","year":"2019","type":"Conference and Workshop Papers","access":"closed","key":"conf/complexis/LiN019","doi":"10.5220/0007722000520058","ee":"https://doi.org/10.5220/0007722000520058","url":"https://dblp.org/rec/conf/complexis/LiN019"},
"url":"URL#1285857"
},
{
"@score":"3",
"@id":"1331340",
"info":{"authors":{"author":{"@pid":"181/0669","text":"Quang-Vinh Dang 0001"}},"title":"Reinforcement Learning in Stock Trading.","venue":"ICCSAMA","pages":"311-322","year":"2019","type":"Conference and Workshop Papers","access":"closed","key":"conf/iccsama/Dang19","doi":"10.1007/978-3-030-38364-0_28","ee":"https://doi.org/10.1007/978-3-030-38364-0_28","url":"https://dblp.org/rec/conf/iccsama/Dang19"},
"url":"URL#1331340"
},
{
"@score":"3",
"@id":"1351339",
"info":{"authors":{"author":[{"@pid":"225/0473","text":"Hong-Gi Shin"},{"@pid":"r/IlkyeunRa","text":"Ilkyeun Ra"},{"@pid":"55/2494","text":"Yong-Hoon Choi"}]},"title":"A Deep Multimodal Reinforcement Learning System Combined with CNN and LSTM for Stock Trading.","venue":"ICTC","pages":"7-11","year":"2019","type":"Conference and Workshop Papers","access":"closed","key":"conf/ictc/ShinRC19","doi":"10.1109/ICTC46691.2019.8939991","ee":"https://doi.org/10.1109/ICTC46691.2019.8939991","url":"https://dblp.org/rec/conf/ictc/ShinRC19"},
"url":"URL#1351339"
},
{
"@score":"3",
"@id":"1361526",
"info":{"authors":{"author":[{"@pid":"25/5536-5","text":"Jia Wu 0005"},{"@pid":"82/4206","text":"Chen Wang"},{"@pid":"249/8339","text":"Lidong Xiong"},{"@pid":"249/8306","text":"Hongyong Sun"}]},"title":"Quantitative Trading on Stock Market Based on Deep Reinforcement Learning.","venue":"IJCNN","pages":"1-8","year":"2019","type":"Conference and Workshop Papers","access":"closed","key":"conf/ijcnn/WuWXS19","doi":"10.1109/IJCNN.2019.8851831","ee":"https://doi.org/10.1109/IJCNN.2019.8851831","url":"https://dblp.org/rec/conf/ijcnn/WuWXS19"},
"url":"URL#1361526"
},
{
"@score":"3",
"@id":"1488836",
"info":{"authors":{"author":[{"@pid":"209/5277","text":"Jonas Heitz"},{"@pid":"38/5145","text":"Kurt Stockinger"}]},"title":"Join Query Optimization with Deep Reinforcement Learning Algorithms.","venue":"CoRR","volume":"abs/1911.11689","year":"2019","type":"Informal Publications","access":"open","key":"journals/corr/abs-1911-11689","ee":"http://arxiv.org/abs/1911.11689","url":"https://dblp.org/rec/journals/corr/abs-1911-11689"},
"url":"URL#1488836"
},
{
"@score":"3",
"@id":"1713535",
"info":{"authors":{"author":[{"@pid":"18/8201","text":"Qinma Kang"},{"@pid":"256/8980","text":"Huizhuo Zhou"},{"@pid":"244/1338","text":"Yunfan Kang"}]},"title":"An Asynchronous Advantage Actor-Critic Reinforcement Learning Method for Stock Selection and Portfolio Management.","venue":"ICBDR","pages":"141-145","year":"2018","type":"Conference and Workshop Papers","access":"closed","key":"conf/icbdr/KangZK18","doi":"10.1145/3291801.3291831","ee":"https://doi.org/10.1145/3291801.3291831","url":"https://dblp.org/rec/conf/icbdr/KangZK18"},
"url":"URL#1713535"
},
{
"@score":"3",
"@id":"1730389",
"info":{"authors":{"author":[{"@pid":"40/5552-1","text":"Yingying Zhu 0001"},{"@pid":"04/999","text":"Hui Yang"},{"@pid":"13/1729","text":"Jianmin Jiang"},{"@pid":"80/2732","text":"Qiang Huang"}]},"title":"An Adaptive Box-Normalization Stock Index Trading Strategy Based on Reinforcement Learning.","venue":"ICONIP","pages":"335-346","year":"2018","type":"Conference and Workshop Papers","access":"closed","key":"conf/iconip/ZhuYJH18","doi":"10.1007/978-3-030-04182-3_30","ee":"https://doi.org/10.1007/978-3-030-04182-3_30","url":"https://dblp.org/rec/conf/iconip/ZhuYJH18"},
"url":"URL#1730389"
},
{
"@score":"3",
"@id":"1740075",
"info":{"authors":{"author":[{"@pid":"225/3972","text":"Seol Hwang"},{"@pid":"225/4004","text":"Sang Pyo Hong"},{"@pid":"116/3643","text":"Young Jae Jang"}]},"title":"Dynamic Scheduling of the Dual Stocker System Using Reinforcement Learning.","venue":"APMS","pages":"482-489","year":"2018","type":"Conference and Workshop Papers","access":"closed","key":"conf/ifip5-7/HwangHJ18","doi":"10.1007/978-3-319-99704-9_59","ee":"https://doi.org/10.1007/978-3-319-99704-9_59","url":"https://dblp.org/rec/conf/ifip5-7/HwangHJ18"},
"url":"URL#1740075"
},
{
"@score":"3",
"@id":"1858288",
"info":{"authors":{"author":[{"@pid":"230/4318","text":"Zhuoran Xiong"},{"@pid":"125/9849","text":"Xiao-Yang Liu"},{"@pid":"94/1198","text":"Shan Zhong"},{"@pid":"226/0938","text":"Hongyang Yang"},{"@pid":"75/6446","text":"Anwar Walid"}]},"title":"Practical Deep Reinforcement Learning Approach for Stock Trading.","venue":"CoRR","volume":"abs/1811.07522","year":"2018","type":"Informal Publications","access":"open","key":"journals/corr/abs-1811-07522","ee":"http://arxiv.org/abs/1811.07522","url":"https://dblp.org/rec/journals/corr/abs-1811-07522"},
"url":"URL#1858288"
},
{
"@score":"3",
"@id":"1859806",
"info":{"authors":{"author":[{"@pid":"220/5717","text":"Xian Yeow Lee"},{"@pid":"192/1502","text":"Aditya Balu"},{"@pid":"180/5772","text":"Daniel Stoecklein"},{"@pid":"90/8130","text":"Baskar Ganapathysubramanian"},{"@pid":"33/7053","text":"Soumik Sarkar"}]},"title":"Flow Shape Design for Microfluidic Devices Using Deep Reinforcement Learning.","venue":"CoRR","volume":"abs/1811.12444","year":"2018","type":"Informal Publications","access":"open","key":"journals/corr/abs-1811-12444","ee":"http://arxiv.org/abs/1811.12444","url":"https://dblp.org/rec/journals/corr/abs-1811-12444"},
"url":"URL#1859806"
},
{
"@score":"3",
"@id":"1866630",
"info":{"authors":{"author":{"@pid":"227/5625","text":"Mohammad Sadegh Talebi Mazraeh Shahi"}},"title":"Minimizing Regret in Combinatorial Bandits and Reinforcement Learning.","year":"2017","type":"Books and Theses","access":"closed","key":"phd/basesearch/Shahi17","ee":"https://nbn-resolving.org/urn:nbn:se:kth:diva-219970","url":"https://dblp.org/rec/phd/basesearch/Shahi17"},
"url":"URL#1866630"
},
{
"@score":"3",
"@id":"2102396",
"info":{"authors":{"author":[{"@pid":"201/0754","text":"Weiyu Si"},{"@pid":"73/3357","text":"Jinke Li"},{"@pid":"27/5296","text":"Peng Ding"},{"@pid":"25/2624","text":"Ruonan Rao"}]},"title":"A Multi-objective Deep Reinforcement Learning Approach for Stock Index Future&apos;s Intraday Trading.","venue":"ISCID","pages":"431-436","year":"2017","type":"Conference and Workshop Papers","access":"closed","key":"conf/iscid/SiLDR17","doi":"10.1109/ISCID.2017.210","ee":"https://doi.org/10.1109/ISCID.2017.210","url":"https://dblp.org/rec/conf/iscid/SiLDR17"},
"url":"URL#2102396"
},
{
"@score":"3",
"@id":"2502045",
"info":{"authors":{"author":[{"@pid":"173/8847","text":"Alvin Pastore"},{"@pid":"157/5151","text":"Umberto Esposito"},{"@pid":"86/3867","text":"Eleni Vasilaki"}]},"title":"Modelling Stock-market Investors as Reinforcement Learning Agents [Correction].","venue":"CoRR","volume":"abs/1609.06086","year":"2016","type":"Informal Publications","access":"open","key":"journals/corr/PastoreEV16","ee":"http://arxiv.org/abs/1609.06086","url":"https://dblp.org/rec/journals/corr/PastoreEV16"},
"url":"URL#2502045"
},
{
"@score":"3",
"@id":"2664117",
"info":{"authors":{"author":[{"@pid":"173/8847","text":"Alvin Pastore"},{"@pid":"157/5151","text":"Umberto Esposito"},{"@pid":"86/3867","text":"Eleni Vasilaki"}]},"title":"Modelling stock-market investors as Reinforcement Learning agents.","venue":"EAIS","pages":"1-6","year":"2015","type":"Conference and Workshop Papers","access":"closed","key":"conf/eais/PastoreEV15","doi":"10.1109/EAIS.2015.7368789","ee":"https://doi.org/10.1109/EAIS.2015.7368789","url":"https://dblp.org/rec/conf/eais/PastoreEV15"},
"url":"URL#2664117"
},
{
"@score":"3",
"@id":"3669399",
"info":{"authors":{"author":[{"@pid":"38/1264","text":"Zhiyong Tan"},{"@pid":"q/HiokChaiQuek","text":"Chai Quek"},{"@pid":"18/5638-2","text":"Philip Y. K. Cheng"}]},"title":"Stock trading with cycles: A financial application of ANFIS and reinforcement learning.","venue":"Expert Syst. Appl.","volume":"38","number":"5","pages":"4741-4755","year":"2011","type":"Journal Articles","access":"closed","key":"journals/eswa/TanQC11","doi":"10.1016/J.ESWA.2010.09.001","ee":"https://doi.org/10.1016/j.eswa.2010.09.001","url":"https://dblp.org/rec/journals/eswa/TanQC11"},
"url":"URL#3669399"
},
{
"@score":"3",
"@id":"4224661",
"info":{"authors":{"author":[{"@pid":"14/6258","text":"Jack Stockholm"},{"@pid":"87/3187","text":"Philippe Pasquier"}]},"title":"Reinforcement Learning of Listener Response for Mood Classification of Audio.","venue":"CSE","pages":"849-853","year":"2009","type":"Conference and Workshop Papers","access":"closed","key":"conf/cse/StockholmP09","doi":"10.1109/CSE.2009.184","ee":"https://doi.org/10.1109/CSE.2009.184","url":"https://dblp.org/rec/conf/cse/StockholmP09"},
"url":"URL#4224661"
},
{
"@score":"3",
"@id":"4762140",
"info":{"authors":{"author":[{"@pid":"28/5196","text":"Jangmin O"},{"@pid":"92/3440","text":"Jongwoo Lee"},{"@pid":"85/4031","text":"Jae Won Lee"},{"@pid":"09/5682","text":"Byoung-Tak Zhang"}]},"title":"Adaptive stock trading with dynamic asset allocation using reinforcement learning.","venue":"Inf. Sci.","volume":"176","number":"15","pages":"2121-2147","year":"2006","type":"Journal Articles","access":"closed","key":"journals/isci/OLLZ06","doi":"10.1016/J.INS.2005.10.009","ee":"https://doi.org/10.1016/j.ins.2005.10.009","url":"https://dblp.org/rec/journals/isci/OLLZ06"},
"url":"URL#4762140"
},
{
"@score":"3",
"@id":"5377135",
"info":{"authors":{"author":[{"@pid":"28/5196","text":"Jangmin O"},{"@pid":"85/4031","text":"Jae Won Lee"},{"@pid":"09/5682","text":"Byoung-Tak Zhang"}]},"title":"Stock Trading System Using Reinforcement Learning with Cooperative Agents.","venue":"ICML","pages":"451-458","year":"2002","type":"Conference and Workshop Papers","access":"unavailable","key":"conf/icml/OLZ02","url":"https://dblp.org/rec/conf/icml/OLZ02"},
"url":"URL#5377135"
}
]
}
}
}
