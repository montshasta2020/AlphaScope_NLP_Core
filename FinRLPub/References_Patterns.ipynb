{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231eb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pattern 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab437d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c92601d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d0b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.layout import LAParams, LTTextBox\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.converter import TextConverter\n",
    "import io\n",
    "\n",
    "resource_manager = PDFResourceManager()\n",
    "fake_file_handle = io.StringIO()\n",
    "converter = TextConverter(resource_manager, fake_file_handle, laparams=LAParams())\n",
    "page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "\n",
    "\n",
    "def pdf_get_text(fn):\n",
    "    \n",
    "    from pdfminer.layout import LAParams, LTTextBox\n",
    "    from pdfminer.pdfpage import PDFPage\n",
    "    from pdfminer.pdfinterp import PDFResourceManager\n",
    "    from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "    from pdfminer.converter import PDFPageAggregator\n",
    "    from pdfminer.converter import TextConverter\n",
    "    import io\n",
    "\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, fake_file_handle, laparams=LAParams())\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "    \n",
    "\n",
    "    with open(fn, 'rb') as fh:\n",
    "\n",
    "        for page in PDFPage.get_pages(fh,\n",
    "                                      caching=True,\n",
    "                                      check_extractable=True):\n",
    "            page_interpreter.process_page(page)\n",
    "\n",
    "        text = fake_file_handle.getvalue()\n",
    "\n",
    "    close open handles\n",
    "    converter.close()\n",
    "    fake_file_handle.close()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6518e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_csv(filename):\n",
    "    from cStringIO import StringIO  \n",
    "    from pdfminer.converter import LTChar, TextConverter    #<-- changed\n",
    "    from pdfminer.layout import LAParams\n",
    "    from pdfminer.pdfparser import PDFDocument, PDFParser\n",
    "    from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "\n",
    "    class CsvConverter(TextConverter):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            TextConverter.__init__(self, *args, **kwargs)\n",
    "\n",
    "        def end_page(self, i):\n",
    "            from collections import defaultdict\n",
    "            lines = defaultdict(lambda : {})\n",
    "            for child in self.cur_item.objs:\n",
    "                if isinstance(child, LTChar):               #<-- changed\n",
    "                    (_,_,x,y) = child.bbox                   \n",
    "                    line = lines[int(-y)]\n",
    "                    line[x] = child.text.encode(self.codec)\n",
    "\n",
    "            for y in sorted(lines.keys()):\n",
    "                line = lines[y]\n",
    "                self.outfp.write(\";\".join(line[x] for x in sorted(line.keys())))\n",
    "                self.outfp.write(\"\\n\")\n",
    "\n",
    "    # ... the following part of the code is a remix of the \n",
    "    # convert() function in the pdfminer/tools/pdf2text module\n",
    "    rsrc = PDFResourceManager()\n",
    "    outfp = StringIO()\n",
    "    device = CsvConverter(rsrc, outfp, codec=\"utf-8\", laparams=LAParams())  #<-- changed\n",
    "        # becuase my test documents are utf-8 (note: utf-8 is the default codec)\n",
    "\n",
    "    doc = PDFDocument()\n",
    "    fp = open(filename, 'rb')\n",
    "    parser = PDFParser(fp)       \n",
    "    parser.set_document(doc)     \n",
    "    doc.set_parser(parser)       \n",
    "    doc.initialize('')\n",
    "\n",
    "    interpreter = PDFPageInterpreter(rsrc, device)\n",
    "\n",
    "    for i, page in enumerate(doc.get_pages()):\n",
    "        outfp.write(\"START PAGE %d\\n\" % i)\n",
    "        if page is not None:\n",
    "            interpreter.process_page(page)\n",
    "        outfp.write(\"END PAGE %d\\n\" % i)\n",
    "\n",
    "    device.close()\n",
    "    fp.close()\n",
    "\n",
    "    return outfp.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cff342fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_collections/Using image recognition for trading.pdf\n",
      "??????????\n",
      "all_collections/An Automatic Stock Trading System using Particle Swarm Optimization .pdf\n",
      "Found: REFERENCES 80705\n",
      "all_collections/thru_earnings_ws_estimize_delta_event_study.pdf\n",
      "Found: REFERENCES 80705\n",
      "all_collections/Best technical indicators for Bitcoin from TA-lib _ by Berend _ Coinmonks _ Mar, 2022 _ Medium.pdf\n",
      "Found: REFERENCES 80705\n",
      "all_collections/Deep learning for relaive stock performance prediction.pdf\n",
      "Found: REFERENCES 80705\n",
      "all_collections/Stock Prices Prediction using Deep Learning Models.pdf\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "unpack requires a buffer of 2 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_collections/*.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(fn)        \n\u001b[0;32m----> 5\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mpdf_get_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     idx1 \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREFERENCES\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     idx2 \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReferences\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mpdf_get_text\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m PDFPage\u001b[38;5;241m.\u001b[39mget_pages(fh,\n\u001b[1;32m     20\u001b[0m                                   caching\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m                                   check_extractable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 22\u001b[0m         \u001b[43mpage_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     text \u001b[38;5;241m=\u001b[39m fake_file_handle\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# close open handles\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#converter.close()\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#fake_file_handle.close()\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pdfminer/pdfinterp.py:851\u001b[0m, in \u001b[0;36mPDFPageInterpreter.process_page\u001b[0;34m(self, page)\u001b[0m\n\u001b[1;32m    849\u001b[0m     ctm \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39mx0, \u001b[38;5;241m-\u001b[39my0)\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mbegin_page(page, ctm)\n\u001b[0;32m--> 851\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mend_page(page)\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pdfminer/pdfinterp.py:863\u001b[0m, in \u001b[0;36mPDFPageInterpreter.render_contents\u001b[0;34m(self, resources, streams, ctm)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_resources(resources)\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_state(ctm)\n\u001b[0;32m--> 863\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pdfminer/pdfinterp.py:887\u001b[0m, in \u001b[0;36mPDFPageInterpreter.execute\u001b[0;34m(self, streams)\u001b[0m\n\u001b[1;32m    885\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexec: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, name, args)\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m nargs:\n\u001b[0;32m--> 887\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    889\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexec: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, name)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pdfminer/pdfinterp.py:771\u001b[0m, in \u001b[0;36mPDFPageInterpreter.do_TJ\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PDFInterpreterError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo font specified!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_string\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtextstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraphicstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pdfminer/pdfdevice.py:85\u001b[0m, in \u001b[0;36mPDFTextDevice.render_string\u001b[0;34m(self, textstate, seq, ncs, graphicstate)\u001b[0m\n\u001b[1;32m     81\u001b[0m     textstate\u001b[38;5;241m.\u001b[39mlinematrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_string_vertical(\n\u001b[1;32m     82\u001b[0m         seq, matrix, textstate\u001b[38;5;241m.\u001b[39mlinematrix, font, fontsize,\n\u001b[1;32m     83\u001b[0m         scaling, charspace, wordspace, rise, dxscale, ncs, graphicstate)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     textstate\u001b[38;5;241m.\u001b[39mlinematrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_string_horizontal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtextstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinematrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdxscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraphicstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pdfminer/pdfdevice.py:100\u001b[0m, in \u001b[0;36mPDFTextDevice.render_string_horizontal\u001b[0;34m(self, seq, matrix, pos, font, fontsize, scaling, charspace, wordspace, rise, dxscale, ncs, graphicstate)\u001b[0m\n\u001b[1;32m     98\u001b[0m     needcharspace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cid \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m needcharspace:\n\u001b[1;32m    102\u001b[0m             x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m charspace\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pdfminer/pdffont.py:744\u001b[0m, in \u001b[0;36mPDFCIDFont.decode\u001b[0;34m(self, bytes)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pdfminer/cmapdb.py:121\u001b[0m, in \u001b[0;36mIdentityCMap.decode\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    119\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(code)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstruct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "\u001b[0;31merror\u001b[0m: unpack requires a buffer of 2 bytes"
     ]
    }
   ],
   "source": [
    "for fn in glob.glob('all_collections/*.pdf'):\n",
    "\n",
    "    print(fn)        \n",
    "    \n",
    "    text = pdf_get_text(fn)\n",
    "\n",
    "    idx1 = text.find('REFERENCES')\n",
    "    idx2 = text.find('References')\n",
    "    \n",
    "    if idx1 != -1:\n",
    "        print ('Found: REFERENCES', idx1)\n",
    "    elif idx2 != -1:\n",
    "        print ('Found: References', idx2)\n",
    "    else:\n",
    "        print('??????????')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d49ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18768361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b624137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e45d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2cba63b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "0 all_collections/Using image recognition for trading.pdf\n",
      "??????????\n",
      "1 all_collections/An Automatic Stock Trading System using Particle Swarm Optimization .pdf\n",
      "??????????\n",
      "2 all_collections/thru_earnings_ws_estimize_delta_event_study.pdf\n",
      "??????????\n",
      "3 all_collections/Best technical indicators for Bitcoin from TA-lib _ by Berend _ Coinmonks _ Mar, 2022 _ Medium.pdf\n",
      "??????????\n",
      "4 all_collections/Deep learning for relaive stock performance prediction.pdf\n",
      "Found: References 29093\n",
      "5 all_collections/Stock Prices Prediction using Deep Learning Models.pdf\n",
      "??????????\n",
      "6 all_collections/Attentive Neural Models for Algorithmic Trading-1.pdf\n",
      "Found: References 84862\n",
      "7 all_collections/Optimization Techniques: An Overview.pdf\n",
      "Found: References 56566\n",
      "8 all_collections/A multi-layer and multi-ensemble stock trader using deep learning and deep reinforcement learning .pdf\n",
      "Found: REFERENCES 187895\n",
      "9 all_collections/Deep Reinforcement Learning- An Overview.pdf\n",
      "Found: REFERENCES 31650\n",
      "10 all_collections/Neural Architecture Search for Time Series Classification.pdf\n",
      "??????????\n",
      "11 all_collections/A review of Reinforcement learning for financial time series prediction and portfolio optimization _ by Nick Smith _ Journal of Quantitative finance _ Medium.pdf\n",
      "Found: References 33719\n",
      "12 all_collections/On the efciency of nature-inspired metaheuristics in expensive global optimization with limited budget.pdf\n",
      "Found: REFERENCES 44968\n",
      "13 all_collections/Bilinear Input Normalization for Neural Networks.pdf\n",
      "??????????\n",
      "14 all_collections/Classification Problem in Imbalanced Datasets.pdf\n",
      "??????????\n",
      "15 all_collections/The Evolution of Rough Sets.pdf\n",
      "Found: REFERENCES 41635\n",
      "16 all_collections/Dealing with Class Imbalance using Thresholding.pdf\n",
      "??????????\n",
      "17 all_collections/Immunity to Device Variations in a Spiking Neural Network With Memristive Nanodevices.pdf\n",
      "Found: References 9051\n",
      "18 all_collections/A Survey and Classification of Methods for (Mostly) Unsupervised Learning of Morphology.pdf\n",
      "Found: References 42570\n",
      "19 all_collections/A Novel Ensemble Deep Learning Mode.pdf\n",
      "??????????\n",
      "20 all_collections/Lin-Feature Investigation for Stock Market Prediction.pdf\n",
      "??????????\n",
      "21 all_collections/Time series forecasting with applications to finance.pdf\n",
      "??????????\n",
      "22 all_collections/Gated Value Network for Multilabel Classification.pdf\n",
      "Found: REFERENCES 22790\n",
      "23 all_collections/SURVEY ON STOCK MARKET PRICE PREDICTION VIA DEEP NEURAL  NETWORKS.pdf\n",
      "Found: References 12415\n",
      "24 all_collections/Long Term Stock Prediction Based On Financial Statements.pdf\n",
      "??????????\n",
      "25 all_collections/Approaching Time-Series with a Tree-based Model _ by Agnis Liukis _ Towards Data Science.pdf\n",
      "??????????\n",
      "26 all_collections/Deep Learning for Stock Price Forecasting.pdf\n",
      "Found: References 4957\n",
      "27 all_collections/ROUGH SETS AND FUZZY SETS.pdf\n",
      "??????????\n",
      "28 all_collections/Comparative Study of Stock Trend Prediction using Time Delay Recurrent and Probabilistic Neural Networks.pdf\n",
      "Found: References 136036\n",
      "29 all_collections/Stock Market Forecasting Using Computational Intelligence: A Survey.pdf\n",
      "Found: REFERENCES 20861\n",
      "30 all_collections/Forecasting Stock Prices from the Limit Order Book using Convolutional Neural Networks.pdf\n",
      "??????????\n",
      "31 all_collections/Stable-Baselines3_ Reliable Reinforcement Learning Implementations _ Antonin Raffin _ Homepage.pdf\n",
      "Found: REFERENCES 35717\n",
      "32 all_collections/ANALYSIS OF DAILY STOCK TREND PREDICTION USING ARIMA MODEL.pdf\n",
      "Found: References 34731\n",
      "33 all_collections/A hybrid stock trading framework integrating technical analysis with machine learning techniques.pdf\n",
      "??????????\n",
      "34 all_collections/Predicting Stock Market Movements Using A Neural Network Applied To The Deutsche Börse Public Dataset.pdf\n",
      "Found: References 48240\n",
      "35 all_collections/Deep_Learning_for_Time_Series_Tutorial.pdf\n",
      "Found: References 26124\n",
      "36 all_collections/Golden section search over hyper-rectangle: A Direct search method.pdf\n",
      "Found: References 16130\n",
      "37 all_collections/Optimal Feature Selection of Technical Indicator and Stock Prediction Using Machine Learning Technique.pdf\n",
      "Found: References 108245\n",
      "38 all_collections/A Survey of Preference-Based Reinforcement Learning Methods.pdf\n",
      "Found: References 40202\n",
      "39 all_collections/Incorporating Transformers and Attention Networks for Stock Movement Prediction.pdf\n",
      "??????????\n",
      "40 all_collections/A Note on Evolutionary Algorithms and Its Applications.pdf\n",
      "Found: References 20053\n",
      "41 all_collections/A research overview of manifold-learning-based multiobjective evolutionary algorithm .pdf\n",
      "Found: REFERENCES 22307\n",
      "42 all_collections/Machine Learning in Stock Price Prediction Using Long Short-Term.pdf\n",
      "??????????\n",
      "43 all_collections/What is Reinforcement Learning_ Overview, Comparisons and Applications _ AltexSoft.pdf\n",
      "Found: References 99458\n",
      "44 all_collections/A Tutorial Survey of Reinforcement Learn.pdf\n",
      "??????????\n",
      "45 all_collections/Implementation Classification.pdf\n",
      "Found: References 149578\n",
      "46 all_collections/Benchmark and Survey of Automated Machine Learning Frameworks.pdf\n",
      "Found: REFERENCES 31450\n",
      "47 all_collections/a-literature-survey-on-stocks-predictions-using-hybrid-machine-learning-and-deep-learning-models-IJERTV8IS100002.pdf\n",
      "??????????\n",
      "48 all_collections/Review 01 -- Reinforcement learning in financial markets - a survey.pdf\n",
      "Found: References 87396\n",
      "49 all_collections/Technical Analysis of Stock Trends (Robert D. Edwards, John Magee).pdf\n",
      "Found: References 41552\n",
      "50 all_collections/Using_neural_networks_to_forecast_stock_market_price.pdf\n",
      "??????????\n",
      "51 all_collections/Game Theory Using Genetic Algorithms.pdf\n",
      "Found: References 64140\n",
      "52 all_collections/Continuous vs. Discrete Optimization of Deep Neural Networks.pdf\n",
      "Found: REFERENCES 23131\n",
      "53 all_collections/Automated Trading System - A Survey.pdf\n",
      "Found: References 33128\n",
      "54 all_collections/The Likelihood of Various Stock Market Return Distributions, Part 1: Principles of Inference.pdf\n",
      "Found: References 21242\n",
      "55 all_collections/Pattern recognition with Spiking Neural Networks: a simple training method.pdf\n",
      "Found: References 77659\n",
      "56 all_collections/A Survey on Semi-parametric Machine Learning.pdf\n",
      "Found: REFERENCES 52795\n",
      "57 all_collections/Journal of Forecasting - 2018 - Ntakaris - Benchmark dataset for mid‐price forecasting of limit order book data with.pdf\n",
      "Found: REFERENCES 23615\n",
      "58 all_collections/A REINFORCEMENT LEARNING ALGORITHM WITH EVOLVING FUZZY NEURAL NETWORKS.pdf\n",
      "??????????\n",
      "59 all_collections/Predicting Bitcoin Price Trends.pdf\n",
      "Found: References 17337\n",
      "60 all_collections/Making Financial Trading by Recurrent Reinforcement Learning.pdf\n",
      "??????????\n",
      "61 all_collections/Cross-Validation Techniques. This article aims to explain different… _ by Abhigyan _ Geek Culture _ Medium.pdf\n",
      "Found: References 28376\n",
      "62 all_collections/A Dynamic Adjusting Reward Function Method for Deep Reinforcement Learning with Adjustable Parameters.pdf\n",
      "Found: References 33763\n",
      "63 all_collections/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization.pdf\n",
      "Found: References 94901\n",
      "64 all_collections/Learning the dynamics of technical trading strategies.pdf\n",
      "Found: References 28270\n",
      "65 all_collections/Testing different Reinforcement Learning configurations for financial trading: Introduction and applications.pdf\n",
      "Found: References 3831\n",
      "66 all_collections/A Search Heuristic Guided Reinforcement Learning Approach to the Traveling Salesman Problem.pdf\n",
      "??????????\n",
      "67 all_collections/****Stock movement_ Predict a 5 Pct rise in 10 days with GAN.pdf\n",
      "Found: References 22643\n",
      "68 all_collections/Biomimetic Use of Genetic Algorithms.pdf\n",
      "??????????\n",
      "69 all_collections/Training of Spiking Neural Networks with Reinforcement Learning.pdf\n",
      "??????????\n",
      "70 all_collections/10 creative applications of symbolic regression - TuringBot.pdf\n",
      "Found: References 15231\n",
      "71 all_collections/Predicting stock prices using deep learning | by Yacoub Ahmed | Towards Data Science.pdf\n",
      "??????????\n",
      "72 all_collections/Predictive-Analytics-For-Dummies-E-book-by-Tangent-Works.pdf\n",
      "??????????\n",
      "73 all_collections/Booms and Busts_ An Encyclopedia of Economic History from the First Stock Market Crash of 1792 to the Current Global Economic Crisis ( PDFDrive ).pdf\n",
      "??????????\n",
      "74 all_collections/STOCK MOVEMENT PREDICTION WITH DEEP LEARNING FINANCE TWEETS SENTIMENT, TECHNICAL INDICATORS AND CANDLESTICK CHARTING.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "75 all_collections/Data mining for imbalanced data:Improving classifiers by selective pre-processing of examples .pdf\n",
      "??????????\n",
      "76 all_collections/Reinforcement learning improves behaviour from evaluative feedback.pdf\n",
      "??????????\n",
      "77 all_collections/Adaptive Normalization: A Novel Data Normalization Approach for Non-Stationary Time Series .pdf\n",
      "Found: References 30751\n",
      "78 all_collections/C__Users_matqsb_Documents_My files_Research_Presentation_Mike Paper 3_Salah_post_thesis Oct 20 v3.dvi.pdf\n",
      "Found: References 55865\n",
      "79 all_collections/Volume Weighted Average Price Optimal Execution.pdf\n",
      "??????????\n",
      "80 all_collections/Dynamics of Gene Expression in an Artificial Genome.pdf\n",
      "Found: REFERENCES 15561\n",
      "81 all_collections/A-Review-On-Big-Data-With-Machine-Learning-And-Fuzzy-Logic-For-Better-Decision-Making.pdf\n",
      "Found: REFERENCES 24462\n",
      "82 all_collections/Reinforcement Learning Algorithms for Automated Stock Trading.pdf\n",
      "Found: References 184221\n",
      "83 all_collections/technical-analysis-of-stocks-amp-commodities-oct-2018.pdf\n",
      "Found: References 24529\n",
      "84 all_collections/Learning Robust Features using Deep Learning for Automatic Seizure Detection.pdf\n",
      "Found: REFERENCES 26482\n",
      "85 all_collections/Complex Stock Trading Strategy Based on Particle Swarm Optimization.pdf\n",
      "Found: References 35842\n",
      "86 all_collections/Stock Market Prediction on High-Frequency Data Using Generative Adversarial Nets.pdf\n",
      "Found: References 12985\n",
      "87 all_collections/A reinforcement learning model based on reward correction for quantitative stock selection.pdf\n",
      "Found: References 38772\n",
      "88 all_collections/Time-Series Clustering and Association Analysis of Financial Data .pdf\n",
      "Found: References 6089\n",
      "89 all_collections/Fuzzy rough sets 1.pdf\n",
      "Found: REFERENCES 59004\n",
      "90 all_collections/Generative_Adversarial_Networks_for_Financial_Trad.pdf\n",
      "??????????\n",
      "91 all_collections/Replacing financial charting with sequence models for trading stocks.pdf\n",
      "??????????\n",
      "92 all_collections/Using the latest advancements in deep learning to predict stock price movements | by Boris B | Towards Data Science.pdf\n",
      "Found: References 63538\n",
      "93 all_collections/Introduction_to_Evolutionary_Algorithms.pdf\n",
      "Found: REFERENCES 2326\n",
      "94 all_collections/Fuzzy SETS UNCERTAINTY AND INFORMATION.pdf\n",
      "??????????\n",
      "95 all_collections/Time Series Forecasting with Deep Learning Models.pdf\n",
      "Found: References 2848\n",
      "96 all_collections/Understanding Feature Importance in Financial Machine Learning _ by Lucas Astorian _ Medium.pdf\n",
      "??????????\n",
      "97 all_collections/A Comparision of normalization techniques.pdf\n",
      "Found: REFERENCES 34398\n",
      "98 all_collections/Agent Inspired Trading Using Recurrent Reinforcement Learning and LSTM Neural Networks.pdf\n",
      "Found: REFERENCES 21594\n",
      "99 all_collections/Statsmodels- Econometric and statistical modeling with Python.pdf\n",
      "??????????\n",
      "100 all_collections/An overview of time series forecasting models.pdf\n",
      "Found: References 28384\n",
      "101 all_collections/Google AI Uses Temporal Fusion Transformer for Time Series Forecasting.pdf\n",
      "Found: References 58918\n",
      "102 all_collections/TCCT: Tightly-coupled convolutional transformer on time series  forecasting.pdf\n",
      "??????????\n",
      "103 all_collections/AI in Finance_ how to finally start to believe your backtests [2_3] _ by Alexandr Honchar _ Towards Data Science.pdf\n",
      "Found: REFERENCES 84143\n",
      "104 all_collections/Temporal Relational Ranking for Stock Prediction.pdf\n",
      "Found: References 25120\n",
      "105 all_collections/Towards Effective Classification of Imbalanced Data with Convolutional Neural Networks.pdf\n",
      "??????????\n",
      "106 all_collections/Hands-On Machine Learning with Scikit-Learn and TensorFlow_ Concepts, Tools, and Techniques to Build Intelligent Systems.pdf\n",
      "??????????\n",
      "107 all_collections/Feature Scaling _ Standardization Vs Normalization.pdf\n",
      "Found: References 85301\n",
      "108 all_collections/Maximum and minimum stock price forecasting of Brazilian power distribution companies based on artificial neural networks.pdf\n",
      "??????????\n",
      "109 all_collections/A STUDY ON FINANCIAL TIME SERIES FORECASTING AND SYMBOLIC REGRESSION BY MEANS OF A HYBRID PROBABILISTIC MODEL-BUILDING CARTESIAN GENETIC PROGRAMMING METHODOLOGY.pdf\n",
      "??????????\n",
      "110 all_collections/SNN Project Intro.pdf\n",
      "Found: REFERENCES 29574\n",
      "111 all_collections/A review of feature selection methods with applications.pdf\n",
      "??????????\n",
      "112 all_collections/10-EvolutionaryComputation.pdf\n",
      "??????????\n",
      "113 all_collections/reinforcement learning - Suitable reward function for trading buy and sell orders - Artificial Intelligence Stack Exchange.pdf\n",
      "Found: References 25239\n",
      "114 all_collections/Adaptation in Evolutionary Computation:A Survey.pdf\n",
      "??????????\n",
      "115 all_collections/Predicting stock price dynamics using stacked GRU's and LSTM's.pdf\n",
      "??????????\n",
      "116 all_collections/Evolutionary Computations for Trading Systems.pdf\n",
      "Found: REFERENCES 43017\n",
      "117 all_collections/Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system.pdf\n",
      "Found: References 41317\n",
      "118 all_collections/Stock Price Pattern Prediction Based on Complex Network and Machine Learning.pdf\n",
      "Found: References 163508\n",
      "119 all_collections/A Survey of Adaptive Resonance Theory Neural Network Models for Engineering Applications.pdf\n",
      "Found: References 19710\n",
      "120 all_collections/Heuristic Search Based Explorationin Reinforcement Learning.pdf\n",
      "Found: References 45867\n",
      "121 all_collections/FUZZY, DISTRIBUTED, INSTANCE COUNTING, AND DEFAULT ARTMAP NEURAL NETWORKS FOR FINANCIAL DIAGNOSIS.pdf\n",
      "Found: References 40795\n",
      "122 all_collections/Neural Architecture Search for Spiking Neural Networks.pdf\n",
      "??????????\n",
      "123 all_collections/Practical Text Classification With Python and Keras – Real Python.pdf\n",
      "??????????\n",
      "124 all_collections/A Review of Artificial Intelligence in Investment.pdf\n",
      "??????????\n",
      "125 all_collections/Convolutional Neural Network for Predicting Company Performance Based on Historical Financial Statement Information.pdf\n",
      "Found: References 72154\n",
      "126 all_collections/Trend Filtering Methods for Momentum Strategies.pdf\n",
      "Found: REFERENCES 57743\n",
      "127 all_collections/Stock Trend Prediction Using Candlestick Charting and Ensemble Machine Learning T Machine Learning Techniques with a No echniques with a Novelty Feature Engineering e Engineering Scheme .pdf\n",
      "Found: REFERENCES 30816\n",
      "128 all_collections/Interval_Forecasting_of_Financial_Time_Series_by_Accelerated_Particle_Swarm-Optimized_Multi-Output_Machine_Learning_System.pdf\n",
      "Found: References 28817\n",
      "129 all_collections/Deep Learning for Forecasting Stock Returns in the Cross-Section.pdf\n",
      "Found: References 408677\n",
      "130 all_collections/Applications of artificial neural networks in financial market forecasting - PhD thesis.pdf\n",
      "??????????\n",
      "131 all_collections/A Game-Theoretic Investigation of Selection Methods Used in Evolutionary Algorithms.pdf\n",
      "??????????\n",
      "132 all_collections/Optimizing Multiple Stock Trading Rules using Genetic  Algorithms.pdf\n",
      "Found: References 20753\n",
      "133 all_collections/Overview of Time Series Forecasting from Statistical to Recent ML Approaches _ by Phylypo Tum _ Medium.pdf\n",
      "Found: REFERENCES 33927\n",
      "134 all_collections/Global Adaptive Input Normalization for Short-Term Electric Load Forecasting.pdf\n",
      "Found: References 21558\n",
      "135 all_collections/Time Series Anomaly Detection using LSTM Autoencoders with PyTorch in Python _ Curiousily - Hacker's Guide to Machine Learning.pdf\n",
      "??????????\n",
      "136 all_collections/Symbolic Reinforcement Learning using Inductive Logic Programming Philippines Population Prediction: 2010-2020.pdf\n",
      "Found: References 83378\n",
      "137 all_collections/Modeling and Monitoring Erosion of the Leading Edge of Wind Turbine Blades.pdf\n",
      "??????????\n",
      "138 all_collections/Self-Constructing Fuzzy Neural Network Speed Controller for Permanent-Magnet Synchronous Motor Drive.pdf\n",
      "Found: References 42032\n",
      "139 all_collections/Financial Time Series Prediction Using Spiking Neural Networks-2.pdf\n",
      "Found: References 804\n",
      "140 all_collections/FinRL FAQ v0.1.pdf\n",
      "??????????\n",
      "141 all_collections/Digest generation for the news articles using LSTMs.pdf\n",
      "??????????\n",
      "142 all_collections/Combining Exploitation-Based and Exploration-Based Approach in Reinforcement Learning.pdf\n",
      "Found: References 6457\n",
      "143 all_collections/Nonstationary time series transformation methods: An experimental review.pdf\n",
      "??????????\n",
      "144 all_collections/Deep Learning Prediction on Price Movement of NASDAQ.pdf\n",
      "??????????\n",
      "145 all_collections/Foreword: special issue on computational finance and economics 2009.pdf\n",
      "Found: REFERENCES 32310\n",
      "146 all_collections/Survey on Machine Learning for Stcok.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: REFERENCES 248503\n",
      "147 all_collections/A Survey on Policy Search for Robotics.pdf\n",
      "Found: REFERENCES 68918\n",
      "148 all_collections/A Survey on Transfer Learning.pdf\n",
      "??????????\n",
      "149 all_collections/A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem.pdf\n",
      "??????????\n",
      "150 all_collections/Time-Series-Forecasting-of-Amazon-Stock-Prices-using-Neural-Networks-LSTM-and-GAN.pdf\n",
      "Found: References 22637\n",
      "151 all_collections/Feature Selection Based on Evolutionary Algorithms for Affective Computing and Stress Recognition.pdf\n",
      "??????????\n",
      "152 all_collections/(paper) Transformers in Time Series ; A Survey - AAA (All About AI).pdf\n",
      "Found: REFERENCES 23420\n",
      "153 all_collections/A REVIEW PAPER ON PORTFOLIO OPTIMIZATION USING GENETIC ALGORITHM.pdf\n",
      "??????????\n",
      "154 all_collections/Evaluation and potential improvements of a deep reinforcement learning model for automated stock trading.pdf\n",
      "??????????\n",
      "155 all_collections/Fidelity Learning Center_ Technical Analysis Indicator Guide - 003.pdf\n",
      "Found: References 43644\n",
      "156 all_collections/Unsupervised Learning - A Systematic Literature Review.pdf\n",
      "Found: References 13641\n",
      "157 all_collections/AUTOMATED MACHINE LEARNING OVERVIEW.pdf\n",
      "Found: References 49026\n",
      "158 all_collections/Evolutionary_Optimization_Evopt_A_Brief_Review_And.pdf\n",
      "Found: REFERENCES 24489\n",
      "159 all_collections/Multivariate Time Series Classification Using Spiking Neural Networks.pdf\n",
      "??????????\n",
      "160 all_collections/10 Misconceptions about Neural Networks.pdf\n",
      "Found: References 14768\n",
      "161 all_collections/Predicting Stock Price Movement with Event-Driven Deep Learning Approach.pdf\n",
      "Found: References 45559\n",
      "162 all_collections/Reinforcement Learning for Automated Financial Trading: Basics and Applications.pdf\n",
      "Found: References 65507\n",
      "163 all_collections/Development of stock market trend prediction system using multiple regression .pdf\n",
      "??????????\n",
      "164 all_collections/Genetic Algorithms and their Applications 1996.pdf\n",
      "Found: REFERENCES 46073\n",
      "165 all_collections/Deep Reinforcement Learning for Trading2.pdf\n",
      "??????????\n",
      "166 all_collections/Stock reward function - Lokad Technical Documentation.pdf\n",
      "Found: References 18417\n",
      "167 all_collections/Stock Movement Prediction using Technical and Data.pdf\n",
      "Found: References 11444\n",
      "168 all_collections/Evolving Trading Strategies With Genetic Programming - Encoding Trading Strategies · Fabian Kostadinov.pdf\n",
      "Found: References 28237\n",
      "169 all_collections/Enforcing constraints for time series prediction in supervised, unsupervised and reinforcement learning.pdf\n",
      "??????????\n",
      "170 all_collections/Reinforcement Learning algorithms an intuitive overview _ by SmartLab AI _ Medium.pdf\n",
      "Found: REFERENCES 10501\n",
      "171 all_collections/Price Trend Prediction of Stock Market Using Outlier Data Mining Algorithm.pdf\n",
      "??????????\n",
      "172 all_collections/reinforcement learning - How should I define the reward function for a stock trading-like game_ - Artificial Intelligence Stack Exchange.pdf\n",
      "Found: REFERENCES 5121\n",
      "173 all_collections/EXTRACTING THE BEST FEATURES FROM MULTI-COMPANY STOCK DATA TO IMPROVE STOCK PRICE PREDICTION.pdf\n",
      "??????????\n",
      "174 all_collections/CNS Tech Lab.pdf\n",
      "Found: References 43954\n",
      "175 all_collections/Enhancing Stock Market Prediction with Extended Coupled Hidden Markov Model over Multi-Sourced Data.pdf\n",
      "Found: References 85547\n",
      "176 all_collections/Biomimetics: lessons from nature – an overview.pdf\n",
      "??????????\n",
      "177 all_collections/Self-optimization of EA_ Evolutionary and genetic algorithms - MQL5 Articles.pdf\n",
      "Found: References 7481\n",
      "178 all_collections/Prediction of Cryptocurrency Price Movements from Order Book Data Using LSTM Neural Networks.pdf\n",
      "Found: References 11545\n",
      "179 all_collections/The Applications of Genetic Algorithms in Stock Market Data Mining Optimisation.pdf\n",
      "??????????\n",
      "180 all_collections/Hierarchical Modelling for Financial Data.pdf\n",
      "??????????\n",
      "181 all_collections/Trading Through Reinforcement Learning using LSTM Neural Networks _ by Armando Vieira _ Medium.pdf\n",
      "??????????\n",
      "182 all_collections/A Volume-Weighted Average Paper.pdf\n",
      "??????????\n",
      "183 all_collections/A Deep Learning Approach for Stock Market Prediction.pdf\n",
      "??????????\n",
      "184 all_collections/Algos Gone Wild: Risk in the World of Automated Trading Strategies .pdf\n",
      "Found: References 34328\n",
      "185 all_collections/Getting Returns from RL Algorithms - matthewmcateer.me.pdf\n",
      "Found: References 24402\n",
      "186 all_collections/Stock price prediction using Generative Adversarial Networks.pdf\n",
      "Found: References 31951\n",
      "187 all_collections/Spike-Timing-Dependent Hebbian Plasticity as Temporal Difference Learning.pdf\n",
      "Found: REFERENCES 13986\n",
      "188 all_collections/A Customer Churn Prediction Model Based on XGBoost and MLP.pdf\n",
      "??????????\n",
      "189 all_collections/A Trend-Following Strategy in Python. _ by Sofien Kaabar, CFA _ Medium.pdf\n",
      "Found: References 63087\n",
      "190 all_collections/An efcient stock market prediction model using hybrid feature reduction method based on variational autoencoders and recursive feature elimination.pdf\n",
      "Found: REFERENCES 96800\n",
      "191 all_collections/Normalization Techniques in Training DNNs: Methodology, Analysis and Application.pdf\n",
      "Found: REFERENCES 39441\n",
      "192 all_collections/THE DISTRIBUTION OF STOCK MARKET RETURNS AND RETURNS OF SOUTHEAST EUROPEAN EMERGING MARKETS.pdf\n",
      "Found: References 32040\n",
      "193 all_collections/Learning Connections in Financial Time Series.pdf\n",
      "??????????\n",
      "194 all_collections/Reinforcement learning in financial markets - a survey.pdf\n",
      "??????????\n",
      "195 all_collections/QuantConnect-PairTradinginPython.pdf\n",
      "Found: References 1205\n",
      "196 all_collections/A Unified View of Nonconvex Heuristic Approach for Low-Rank and Sparse Structure Learning.pdf\n",
      "Found: References 20044\n",
      "197 all_collections/Stock Market Prediction using CNN and LSTM.pdf\n",
      "Found: References 38998\n",
      "198 all_collections/Modeling of Extreme Values via Exponential Normalization Compared with Linear and Power Normalization.pdf\n",
      "Found: REFERENCES 89533\n",
      "199 all_collections/DEEP EXECUTION - VALUE AND POLICY BASED REINFORCEMENT LEARNING FOR TRADING AND BEATING MARKET BENCHMARKS.pdf\n",
      "Found: References 21255\n",
      "200 all_collections/Reinforcement Learning in Trading.pdf\n",
      "Found: References 29014\n",
      "201 all_collections/Deep Transformer Models for Time Series Forecasting-The Influenza Prevalence Case.pdf\n",
      "Found: References 10168\n",
      "202 all_collections/Financial Data Mining with Genetic Programming.pdf\n",
      "Found: References 22593\n",
      "203 all_collections/Building and Evaluating Interpretable Models using Symbolic Regression and Generalized Additive Models.pdf\n",
      "??????????\n",
      "204 all_collections/Computational learning techniques for intraday FX trading using popular technical indicators.pdf\n",
      "Found: References 26050\n",
      "205 all_collections/Improving On-policy Learning with Statistical Reward Accumulation.pdf\n",
      "Found: References 42047\n",
      "206 all_collections/a survey of inverse reinforcement learning techniques.pdf\n",
      "??????????\n",
      "207 all_collections/Opinion: Machine learning won’t crack the stock market— but here’s when investors should trust AI.pdf\n",
      "Found: References 105351\n",
      "208 all_collections/An Analysis of Publications on Particle Swarm Optimisation Applications Particle Swarm Optimisation.pdf\n",
      "Found: REFERENCES 27226\n",
      "209 all_collections/Cost-Sensitive Learning Methods for Imbalanced Data.pdf\n",
      "??????????\n",
      "210 all_collections/Deep Direct Reinforcement Learning for Financial Signal Representation and Trading.pdf\n",
      "Found: References 35040\n",
      "211 all_collections/Successful Technical Trading Agents Using Genetic Programming.pdf\n",
      "Found: References 106266\n",
      "212 all_collections/Machine Learning Methods in Finance.pdf\n",
      "Found: References 58405\n",
      "213 all_collections/Deep Reinforcement Learning For Trading - A Critical Survey.pdf\n",
      "Found: References 61120\n",
      "214 all_collections/Using genetic algorithms to find technical trading rules.pdf\n",
      "??????????\n",
      "215 all_collections/Policy invariance under reward transformations: Theory and application to reward shaping.pdf\n",
      "Found: References 33566\n",
      "216 all_collections/Optimal Control Using Adaptive Resonance Theory and Q-Learning.pdf\n",
      "Found: REFERENCES 57058\n",
      "217 all_collections/Auto-Pytorch: Multi-Fidelity MetaLearning for Efficient and Robust AutoDL .pdf\n",
      "Found: References 65407\n",
      "218 all_collections/TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate Time Series Data.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "219 all_collections/Pairs Rotation With Ehlers Loops.pdf\n",
      "Found: REFERENCES 54561\n",
      "220 all_collections/AdaRNN: Adaptive Learning and Forecasting for Time Series∗.pdf\n",
      "Found: References 139643\n",
      "221 all_collections/AutoML performance in model fitting .pdf\n",
      "Found: REFERENCES 8740\n",
      "222 all_collections/STRUCTURED LOW-RANK MATRIX RECOVERY VIA OPTIMIZATION METHODS.pdf\n",
      "Found: References 222516\n",
      "223 all_collections/Language models are few-shot learners.pdf\n",
      "Found: REFERENCES 59791\n",
      "224 all_collections/Reinforcement Learning: A Tutorial Survey and Recent Advances.pdf\n",
      "Found: References 42249\n",
      "225 all_collections/A Biologically Plausible Supervised Learning Method for Spiking Neural Networks Using the Symmetric STDP Rule.pdf\n",
      "??????????\n",
      "226 all_collections/METRIC-SPACE ANALYSIS OF SPIKE TRAINS: THEORY, ALGORITHMS, AND APPLICATION.pdf\n",
      "Found: REFERENCES 74867\n",
      "227 all_collections/A Brief Survey of Deep Reinforcement Learning.pdf\n",
      "??????????\n",
      "228 all_collections/Technical Analysis Of The Financial Markets.pdf\n",
      "Found: References 56036\n",
      "229 all_collections/Reinforcement_Learning_for_Systematic_FX_Trading.pdf\n",
      "Found: References 16056\n",
      "230 all_collections/Practical Deep Reinforcement Learning Approach for Stock Trading.pdf\n",
      "Found: References 41335\n",
      "231 all_collections/Stock selection with random forest: An exploitation of excess return in the Chinese stock market.pdf\n",
      "Found: References 78506\n",
      "232 all_collections/Scaling laws for neural language models.pdf\n",
      "Found: REFERENCES 35804\n",
      "233 all_collections/A FINE-GRAINED ANALYSIS ON DISTRIBUTION SHIFT.pdf\n",
      "Found: References 39622\n",
      "234 all_collections/Regularized Evolution for Image Classifier Architecture Search.pdf\n",
      "Found: REFERENCES 17835\n",
      "235 all_collections/MULTIVARIATE TIME-SERIES ANALYSIS VIA MANIFOLD LEARNING.pdf\n",
      "Found: REFERENCES 21514\n",
      "236 all_collections/DSANet: Dual Self-Attention Network for Multivariate Time Series Forecasting.pdf\n",
      "Found: References 47753\n",
      "237 all_collections/Reinforcement-Learning-For-Automated-Trading.pdf\n",
      "Found: References 21727\n",
      "238 all_collections/Comparison_of_Auto_PyTorch_and_AutoCVE.pdf\n",
      "Found: References 37738\n",
      "239 all_collections/Scaling tree-based automated machine learning to biomedical big data with a feature set selector _ Bioinformatics _ Oxford Academic.pdf\n",
      "Found: REFERENCES 40115\n",
      "240 all_collections/SAMPLE-EFFICIENT AUTOMATED DEEP REINFORCEMENT LEARNING .pdf\n",
      "??????????\n",
      "241 all_collections/A REVIEW OF STOCK TREND PREDICTION WITH COMBINATION OF EFFECTIVE MULTI TECHNICAL INDICATOR STRATEGY.pdf\n",
      "Found: REFERENCES 43057\n",
      "242 all_collections/Integrated_Long-Term_Stock_Selection_Models_Based_on_Feature_Selection_and_Machine_Learning_Algorithms_for_China_Stock_Market.pdf\n",
      "Found: References 41529\n",
      "243 all_collections/Robust manifold broad learning system for large-scale noisy chaotic time series prediction: A perturbation perspective.pdf\n",
      "??????????\n",
      "244 all_collections/Reducing bias in the measurement of selection.pdf\n",
      "Found: REFERENCES 40605\n",
      "245 all_collections/Thresholded-ConvNet-Ensembles-Neural-Networks-for-Technical-Forecasting.pdf\n",
      "Found: References 19237\n",
      "246 all_collections/NIPS-1998-reinforcement-learning-for-trading-Paper.pdf\n",
      "Found: References 37780\n",
      "247 all_collections/Extending Deep Reinforcement Learning Frameworks in Cryptocurrency Market Making.pdf\n",
      "Found: REFERENCES 41317\n",
      "248 all_collections/Predicting Stock Market Trends Using Machine Learning and Deep Learning Algorithms Via Continuous and Binary Data a Comparative Analysis.pdf\n",
      "Found: References 31840\n",
      "249 all_collections/Carving Out Evolutionary Paths Towards Greater Complexity.pdf\n",
      "??????????\n",
      "250 all_collections/Stock Forecasting with Transformer Architecture & Attention Mechanism — Neuravest.pdf\n",
      "Found: References 17880\n",
      "251 all_collections/Option Pricing with Deep Learning.pdf\n",
      "Found: REFERENCES 45660\n",
      "252 all_collections/The Empirical Distribution of UK and US Stock Returns.pdf\n",
      "Found: REFERENCES 103813\n",
      "253 all_collections/Reinforcement Learning for An ART-B ased Fuzzy Adaptive Learning Control Network .pdf\n",
      "Found: References 30783\n",
      "254 all_collections/Spiking Neural Networks for Computational Intelligence: An Overview.pdf\n",
      "??????????\n",
      "255 all_collections/Hyperparameter tuning using optuna for FinRL _ by Astarag Mohapatra _ Analytics Vidhya _ Medium.pdf\n",
      "??????????\n",
      "256 all_collections/Best Automatic Machine Learning (AutoML) Frameworks in 2022 _ Geniusee.pdf\n",
      "Found: References 44013\n",
      "257 all_collections/A Review of Algorithms and Hardware Implementations for Spiking Neural Networks.pdf\n",
      "Found: References 28535\n",
      "258 all_collections/Image Recognition in Stock Prediction with Visual Explanations from Grad-CAM.pdf\n",
      "Found: REFERENCES 65303\n",
      "259 all_collections/INTRODUCTION TO MODELING AND GENERATING PROBABILISTIC INPUT PROCESSES FOR SIMULATION.pdf\n",
      "Found: References 43757\n",
      "260 all_collections/QF-TraderNet_ Intraday Trading via Deep Reinforcement With Quantum Price Levels Based Profit-And-Loss Control - PMC.pdf\n",
      "??????????\n",
      "261 all_collections/Deep reinforcement learning for time series_ playing idealized trading games.pdf\n",
      "Found: References 37521\n",
      "262 all_collections/Using Structured Events to Predict Stock Price Movement: An Empirical Investigation.pdf\n",
      "Found: REFERENCES 14074\n",
      "263 all_collections/Character Recognition using Spiking Neural Networks.pdf\n",
      "Found: References 63600\n",
      "264 all_collections/PERFORMANCE FUNCTIONS AND REINFORCEMENT LEARNING FOR TRADING SYSTEMS AND PORTFOLIOS.pdf\n",
      "Found: References 29673\n",
      "265 all_collections/Encoding Time Series as Images for Visual Inspection and Classification Using Tiled Convolutional Neural Networks.pdf\n",
      "Found: REFERENCES 87901\n",
      "266 all_collections/STATISTICAL ANALYSIS OF GENETIC ALGORITHMS IN DISCOVERING TECHNICAL TRADING STRATEGIES.pdf\n",
      "Found: References 27579\n",
      "267 all_collections/Deep Reinforcement Learning for Automated Stock Trading _ by Bruce Yang _ Towards Data Science.pdf\n",
      "Found: References 969\n",
      "268 all_collections/Stock market prediction - Wikipedia.pdf\n",
      "Found: REFERENCES 26673\n",
      "269 all_collections/LSTM Fully Convolutional Networks for Time Series Classification.pdf\n",
      "??????????\n",
      "270 all_collections/GAN_Stock - Summary.pdf\n",
      "??????????\n",
      "271 all_collections/Text mining approaches for stock market prediction.pdf\n",
      "??????????\n",
      "272 all_collections/Quantitative Trading Strategies Deep Learning: Pairs Trading.pdf\n",
      "Found: References 2867\n",
      "273 all_collections/The price dynamics of common trading strategies.pdf\n",
      "Found: References 22273\n",
      "274 all_collections/Introduction to Deep Learning Business Applications for Developers .pdf\n",
      "Found: REFERENCES 41069\n",
      "275 all_collections/A Hierarchical Fused Fuzzy Deep Neural Network for Data Classiification.pdf\n",
      "Found: References 19752\n",
      "276 all_collections/Applying Data Mining Techniques to Stock Market  Analysis.pdf\n",
      "Found: References 17973\n",
      "277 all_collections/Sparse Coding and Decorrelation in Primary Visual Cortex During Natural Vision.pdf\n",
      "Found: References 18583\n",
      "278 all_collections/An Attention-Based LSTM Model for Stock Price Trend Prediction Using Limit Order Books .pdf\n",
      "Found: REFERENCES 11490\n",
      "279 all_collections/A novel artificial neural network trained using evolutionary algorithms for reinforcement learning.pdf\n",
      "Found: REFERENCES 60419\n",
      "280 all_collections/BindsNET_A_Machine_Learning-Oriented_Spiking_Neural_Networks_Library_in_Python.pdf\n",
      "Found: References 35598\n",
      "281 all_collections/Optimization of Quantitative Financial Data Analysis System Based on Deep Learning.pdf\n",
      "Found: References 37820\n",
      "282 all_collections/Policy invariance under reward transformations_.pdf\n",
      "Found: References 43051\n",
      "283 all_collections/High Frequency Trading for Active High Frequency Trading.pdf\n",
      "??????????\n",
      "284 all_collections/Low-Rank Structure Learning via Nonconvex Heuristic Recovery.pdf\n",
      "Found: References 158079\n",
      "285 all_collections/Neural-Symbolic Learning and Reasoning:A Survey and Interpretation.pdf\n",
      "Found: References 68365\n",
      "286 all_collections/Neural Bag-of-Features Learning.pdf\n",
      "Found: REFERENCES 67157\n",
      "287 all_collections/Dimensionality Reduction using Similarity-induced Embeddings.pdf\n",
      "Found: REFERENCES 1469826\n",
      "288 all_collections/Global Optimization Algorithms Theory and Application.pdf\n",
      "Found: References 11068\n",
      "289 all_collections/MACHINE LEARNING IN QUANTITATIVE FINANCE.pdf\n",
      "Found: REFERENCES 43328\n",
      "290 all_collections/Stock Trend Prediction: Based on Machine Learning Methods.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "291 all_collections/A Comparison of Genotype Representations to Acquire Stock Trading Strategy Using Genetic Algorithms.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid FloatObject b'0.00-2547933'\n",
      "Invalid FloatObject b'0.00-11111111'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "292 all_collections/Human-level control through deep reinforcement learning.pdf\n",
      "??????????\n",
      "293 all_collections/The Inverse Fisher Transform.pdf\n",
      "Found: References 94787\n",
      "294 all_collections/Automated Reinforcement Learning (AutoRL): A Survey and Open Problems.pdf\n",
      "Found: References 31165\n",
      "295 all_collections/Stock market as temporal network.pdf\n",
      "Found: References 79527\n",
      "296 all_collections/Evolutionary convolutional neural networks: An application to handwriting recognition.pdf\n",
      "Found: REFERENCES 41963\n",
      "297 all_collections/Enhancing Time Series Momentum Strategies Using Deep Neural Networks.pdf\n",
      "Found: REFERENCES 20039\n",
      "298 all_collections/Wide & Deep Learning for Recommender Systems.pdf\n",
      "Found: References 56594\n",
      "299 all_collections/An Overview of Genetic Algorithms : Part 1, Fundamentals.pdf\n",
      "??????????\n",
      "300 all_collections/Resampling Methods: Cross Validation.pdf\n",
      "Found: REFERENCES 39617\n",
      "301 all_collections/Stock_Market_Forecasting_Using_Deep_Learning_and_Technical_Analysis_A_Systematic_Review.pdf\n",
      "Found: REFERENCES 18495\n",
      "302 all_collections/a-review-on-data-normalization-techniques.pdf\n",
      "??????????\n",
      "303 all_collections/7 Candlestick Patterns that Predict a Bullish Move • TradeSmart University.pdf\n",
      "??????????\n",
      "304 all_collections/Predicting Short-Term Stock Movements with Quantitative Finance and Machine Learning in Python | by Mat Steininger | Towards Data Science.pdf\n",
      "??????????\n",
      "305 all_collections/Predicting Financial Markets using Text on the Web.pdf\n",
      "Found: References 22756\n",
      "306 all_collections/A Survey of Exploration Strategies in Reinforcement Learning .pdf\n",
      "Found: References 51232\n",
      "307 all_collections/Multivariate Real Time Series Data Using Six Unsupervised Machine Learning Algorithms _ IntechOpen.pdf\n",
      "Found: References 49596\n",
      "308 all_collections/A GA-based fuzzy adaptive learning control network.pdf\n",
      "Found: References 14709\n",
      "309 all_collections/Price Formation in Stock Markets Using Fundamental Analysis.pdf\n",
      "??????????\n",
      "310 all_collections/Foreword: special issue on computational finance and economics 2012.pdf\n",
      "Found: REFERENCES 80701\n",
      "311 all_collections/ARTMAP: Supervised real-time learning and classification of nonstationary data by a self-organizing neural network.pdf\n",
      "Found: References 37820\n",
      "312 all_collections/Policy invariance under reward transformations:Theory and application to reward shaping.pdf\n",
      "??????????\n",
      "313 all_collections/Heuristic Optimization.pdf\n",
      "Found: References 19242\n",
      "314 all_collections/Applying fuzzy logic and machine learning techniques in financial performance predictions .pdf\n",
      "Found: References 55079\n",
      "315 all_collections/Neuroevolution: From architectures to learning.pdf\n",
      "Found: References 1582\n",
      "316 all_collections/A TRADING SYSTEM BASED ON FUZZY LOGIC.pdf\n",
      "Found: REFERENCES 106402\n",
      "317 all_collections/Deep_Reinforcement_Learning_Versus_Evoluation Strategies: A Comparative Survey.pdf\n",
      "Found: REFERENCES 13622\n",
      "318 all_collections/OVERVIEW OF HANDLING IMBALANCED DATASETS IN MACHINE LEARNING.pdf\n",
      "Found: References 41185\n",
      "319 all_collections/Multisource financial sentiment analysis for detecting Bitcoin price change indications using deep learning.pdf\n",
      "Found: References 37815\n",
      "320 all_collections/Large-scale evolution of image classifiers.pdf\n",
      "??????????\n",
      "321 all_collections/An Introduction to Genetic Algorithms for Numerical Optimization.pdf\n",
      "Found: References 67779\n",
      "322 all_collections/Data-driven construction of Convex Region Surrogate Models.pdf\n",
      "Found: References 250811\n",
      "323 all_collections/Machine Learning for Financial Market Prediction.pdf\n",
      "Found: REFERENCES 36441\n",
      "324 all_collections/NAST_ Non-Autoregressive Spatial-Temporal Transformer for Time Series Forecasting – arXiv Vanity.pdf\n",
      "Found: References 117309\n",
      "325 all_collections/Deep learning for time series classification: a review.pdf\n",
      "??????????\n",
      "326 all_collections/Do candlestick patterns work on their own_ A systematic FX back-test using Python. _ by Sofien Kaabar, CFA _ Medium.pdf\n",
      "??????????\n",
      "327 all_collections/An Analysis of Technical Trading Strategies.pdf\n",
      "Found: References 16804\n",
      "328 all_collections/Deep Candlestick Mining.pdf\n",
      "Found: REFERENCES 52267\n",
      "329 all_collections/application-of-data-mining-techniques-in-stock-markets.pdf\n",
      "??????????\n",
      "330 all_collections/A new evolutionary system for evolving Artificial Neural Networks.pdf\n",
      "??????????\n",
      "331 all_collections/A hitchhikers guide to FinRL_ A Deep Reinforcement Learning Framework for Quantitative Finance _ by Astarag Mohapatra _ Analytics Vidhya _ Medium.pdf\n",
      "Found: References 37819\n",
      "332 all_collections/Reinforcement Learning for Visual Object Detection.pdf\n",
      "Found: References 15139\n",
      "333 all_collections/The extraction of trading rules from stock market data using rough sets.pdf\n",
      "Found: REFERENCES 76481\n",
      "334 all_collections/A state-of-the-Art review of heuristic and metaheuristic optimization techniques for the management of water resources.pdf\n",
      "Found: References 79353\n",
      "335 all_collections/Machine Learning Advances for Time Series Forecasting.pdf\n",
      "Found: References 62432\n",
      "336 all_collections/The profitability of technical analysis Evidence from the piercing line and dark cloud cover patterns in the forex market.pdf\n",
      "Found: References 48048\n",
      "337 all_collections/Fuzzy Rough Sets: from Theory into Practice.pdf\n",
      "Found: References 44483\n",
      "338 all_collections/Reinforcement Learning for Neural Architecture Search: A Review.pdf\n",
      "Found: REFERENCES 32046\n",
      "339 all_collections/Unsupervised Knowledge Transfer using Similarity Embeddings.pdf\n",
      "Found: References 5416\n",
      "340 all_collections/A review of learning in biologically plausible spiking neural networks.pdf\n",
      "Found: REFERENCES 36686\n",
      "341 all_collections/TimeCaps: Capturing Time Series Data with Capsule Networks.pdf\n",
      "??????????\n",
      "342 all_collections/Predicting Stock Market Movements Using Global News Headlines.pdf\n",
      "??????????\n",
      "343 all_collections/Normalization: A Preprocessing Stage.pdf\n",
      "Found: References 26517\n",
      "344 all_collections/A New Approach to Rough Set Based on Remote Neighborhood Systems.pdf\n",
      "Found: References 39287\n",
      "345 all_collections/Drift independent volatility estimation based on on High, Low, Open, and Close Prices.pdf\n",
      "Found: REFERENCES 50957\n",
      "346 all_collections/Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network.pdf\n",
      "Found: References 37357\n",
      "347 all_collections/Segmenting Time Series: A Survey and Novel Approach.pdf\n",
      "Found: References 33975\n",
      "348 all_collections/Automated Machine Learning on Graphs: A Survey.pdf\n",
      "Found: References 14988\n",
      "349 all_collections/Predicting US Stock Market Movement from Political Tweets.pdf\n",
      "Found: REFERENCES 34811\n",
      "350 all_collections/REVERSIBLE INSTANCE NORMALIZATION FOR ACCURATE TIME-SERIES FORECASTING AGAINST DISTRIBUTION SHIFT.pdf\n",
      "??????????\n",
      "351 all_collections/New-High, New-Low System by Dennis Meyers, Ph.D_.pdf\n",
      "??????????\n",
      "352 all_collections/Learning to Trade via Direct Reinforcement.pdf\n",
      "Found: References 28620\n",
      "353 all_collections/Issues in Mining Imbalanced Data Sets - A Review Paper.pdf\n",
      "Found: References 16687\n",
      "354 all_collections/fuzzy-rough-learn 0.1: A Python Library for Machine Learning with Fuzzy Rough Sets.pdf\n",
      "Found: References 30495\n",
      "355 all_collections/Normalization_methods_in_time_series_of_platelet.39.pdf\n",
      "Found: References 17811\n",
      "356 all_collections/Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm.pdf\n",
      "Found: References 69805\n",
      "357 all_collections/Financial time series prediction: an approach using motif information and neural networks.pdf\n",
      "Found: References 42155\n",
      "358 all_collections/Earliness-Aware Deep Convolutional Networks for Early Time Series Classification.pdf\n",
      "Found: REFERENCES 26017\n",
      "359 all_collections/An Overview of the Applications of Particle Swarm in Water Resources Optimization .pdf\n",
      "Found: References 66705\n",
      "360 all_collections/Reinforcement Learning Approaches to Optimal Market Making.pdf\n",
      "Found: REFERENCES 42991\n",
      "361 all_collections/Stock Trend Prediction- Based on Machine Learning Methods.pdf\n",
      "Found: REFERENCES 31929\n",
      "362 all_collections/POSITIVE AND UNLABELED LEARNING ALGORITHMS AND APPLICATIONS:  A Survey.pdf\n",
      "??????????\n",
      "363 all_collections/Identifying-Trading-Opportunities.pdf\n",
      "??????????\n",
      "364 all_collections/Fuzzy Set Theory 2001.pdf\n",
      "Found: References 109956\n",
      "365 all_collections/AutoML: A Survey of the State-of-the-Art.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: References 93351\n",
      "366 all_collections/A Survey on Semi-, Self- and Unsupervised Learning in Image Classification.pdf\n",
      "Found: References 69680\n",
      "367 all_collections/Pattern recognition by self-organizing neural networks.pdf\n",
      "??????????\n",
      "368 all_collections/How to Solve It_ A New Aspect of Mathematical Method.pdf\n",
      "??????????\n",
      "369 all_collections/Google Stock Market Price Prediction using Reinforcement Learning Technique.pdf\n",
      "Found: References 8046\n",
      "370 all_collections/Generating Probability Distributions for Future Stock Prices.pdf\n",
      "??????????\n",
      "371 all_collections/Deep Reward Shaping from Demonstrations.pdf\n",
      "Found: References 106266\n",
      "372 all_collections/Machine Learning Methods in Finance: Recent Applications and Prospects.pdf\n",
      "Found: References 160929\n",
      "373 all_collections/Recent Advances in Reinforcement Learning in Finance.pdf\n",
      "Found: References 11783\n",
      "374 all_collections/Stock market price trendprediction using Customized Deep Learning System.pdf\n",
      "Found: References 26874\n",
      "375 all_collections/Comparative Overview of Rough Set Toolkit Systems for Data Analysis.pdf\n",
      "??????????\n",
      "376 all_collections/Hybrid Autogressive-Recurrent Neural Network Architecture for Algorithmic Trading of Cryptocurrencies.pdf\n",
      "Found: References 14316\n",
      "377 all_collections/Optimization of Multi-Factor Model in Quantitative Trading Based On Reinforcement Learning.pdf\n",
      "??????????\n",
      "378 all_collections/Final presentation.pdf\n",
      "Found: References 24292\n",
      "379 all_collections/IS TECHNICAL ANALYSIS INFORMATIVE IN UK STOCK MARKET? EVIDENCE FROM DECOMPOSITION-BASED VECTOR AUTOREGRESSIVE (DVAR) MODEL.pdf\n",
      "??????????\n",
      "380 all_collections/EVOLUTIONARY COMPUTATION: An Overview.pdf\n",
      "??????????\n",
      "381 all_collections/The Utility Average Stock Market Indicator by Dennis Meyers, P.pdf\n",
      "Found: References 55115\n",
      "382 all_collections/An Introduction to Evolutionary Computation in Finance.pdf\n",
      "Found: REFERENCES 25510\n",
      "383 all_collections/RECENT TRENDS IN TIME SERIES FORECASTING– A SURVEY.pdf\n",
      "Found: References 38149\n",
      "384 all_collections/Chapter 5: Foundations of Data Imbalance and Solutions for a Data Democracy.pdf\n",
      "Found: References 21346\n",
      "385 all_collections/HEBO_Heteroscedastic_Evolutionary_Bayesian_Optimis.pdf\n",
      "Found: References 33981\n",
      "386 all_collections/Multi-Agent Deep Reinforcement Learning for Liquidation Strategy Analysis.pdf\n",
      "Found: References 76790\n",
      "387 all_collections/Automated Reinforcement Learning: An Overview.pdf\n",
      "??????????\n",
      "388 all_collections/Using the latest advancements in deep learning to predict stock price movements _ by Boris B _ Towards Data Science.pdf\n",
      "Found: References 45705\n",
      "389 all_collections/Spatially Encoding Temporal Correlations to Classify Temporal Data Using Convolutional Neural Networks.pdf\n",
      "??????????\n",
      "390 all_collections/reinforcement_learning_from_heuristics-3.pdf\n",
      "Found: References 34243\n",
      "391 all_collections/Optimistic Bull or Pessimistic Bear: Adaptive Deep Reinforcement Learning.pdf\n",
      "Found: References 65163\n",
      "392 all_collections/The applications of artificial neural networks, support vector machines, and long–short term memory for stock market prediction.pdf\n",
      "??????????\n",
      "393 all_collections/Episode 1 — Genetic Algorithm for Reinforcement Learning _ by Moustafa Alzantot _ Becoming Human_ Artificial Intelligence Magazine.pdf\n",
      "Found: References 9548\n",
      "394 all_collections/PySEF: A Python Library for Similarity-based Dimensionality Reduction.pdf\n",
      "??????????\n",
      "395 all_collections/Technical Analysis - Explained.pdf\n",
      "Found: References 27346\n",
      "396 all_collections/Comparison of Genetic Algorithms for Trading Strategies.pdf\n",
      "Found: References 27870\n",
      "397 all_collections/Loss Functions in Time Series Forecasting.pdf\n",
      "Found: REFERENCES 129573\n",
      "398 all_collections/Survey of Clustering Algorithms.pdf\n",
      "??????????\n",
      "399 all_collections/Google AI Blog_ Interpretable Deep Learning for Time Series Forecasting.pdf\n",
      "Found: References 42621\n",
      "400 all_collections/Informer- Beyond Efficient Transformer for Long Sequence Time-Series Forecasting.pdf\n",
      "??????????\n",
      "401 all_collections/ML Approaches for Time Series. In this post I play around with some… _ by Pablo Ruiz _ Towards Data Science.pdf\n",
      "??????????\n",
      "402 all_collections/AutoML _ AutoRL_ AutoML for RL.pdf\n",
      "??????????\n",
      "403 all_collections/The Indomitable Investor_ Why a Few Succeed in the Stock Market When Everyone Else Fails ( PDFDrive ).pdf\n",
      "Found: References 45037\n",
      "404 all_collections/Fuzzy-Based Time Series Forecasting and Modelling:  A Bibliometric Analysis.pdf\n",
      "Found: References 26876\n",
      "405 all_collections/The use of fundamental and technical analyses by foreign exchange dealers Hong Kong evidence.pdf\n",
      "??????????\n",
      "406 all_collections/AutoML - Tutorial 2020.pdf\n",
      "??????????\n",
      "407 all_collections/Data-Science-for-Lazy-People-Automated-Machine-Learning-by-Diego-Hueltes-min.pdf\n",
      "??????????\n",
      "408 all_collections/post_earnings_event_study.pdf\n",
      "Found: REFERENCES 229806\n",
      "409 all_collections/Forecasting the Stock Market Index Using Artificial Intelligence Techniques .pdf\n",
      "??????????\n",
      "410 all_collections/A Survey on LSTM-based Stock Market Prediction.pdf\n",
      "Found: REFERENCES 39697\n",
      "411 all_collections/ROUGH FUZZY SETS AND FUZZY ROUGH SETS.pdf\n",
      "Found: References 110054\n",
      "412 all_collections/momentum-strategies-in-futures Markets and Trend-Following Funds.pdf\n",
      "??????????\n",
      "413 all_collections/Fuzzy-Embedded Gated Recurrent Unit (FE-GRU) System with Application in Stock Trading.pdf\n",
      "Found: REFERENCES 104034\n",
      "414 all_collections/Feature Engineering for Mid-Price Prediction with Deep Learning.pdf\n",
      "??????????\n",
      "415 all_collections/Transferring knowledge as heuristics in reinforcement learning_ A case-based approach _ Elsevier Enhanced Reader.pdf\n",
      "Found: References 12389\n",
      "416 all_collections/Stock Market Trend Prediction Model for the Egyptian Stock Market Using Neural Networks and Fuzzy Logic.pdf\n",
      "Found: References 28160\n",
      "417 all_collections/Feature Engineering & Feature Selection _ by Ke Gui _ Towards Data Science.pdf\n",
      "Found: REFERENCES 22278\n",
      "418 all_collections/A-Hybrid-Approach-To-Evaluate-Stock-Returns-Using-Data-Mining-Techniques.pdf\n",
      "Found: References 41473\n",
      "419 all_collections/Application of Deep Reinforcement Learning in Stock Trading Strategies and Stock Forecasting.pdf\n",
      "??????????\n",
      "420 all_collections/A New Utility Average Stock Market System by Dennis Meyers,.pdf\n",
      "Found: References 76380\n",
      "421 all_collections/Cross-Validation for Selecting a Model Selection Procedure.pdf\n",
      "Found: References 30307\n",
      "422 all_collections/Generating trading rules on the stock markets with.pdf\n",
      "Found: References 32946\n",
      "423 all_collections/The Merits of a Parallel Genetic Algorithm in Solving Hard Optimization Problems.pdf\n",
      "Found: References 46340\n",
      "424 all_collections/Discriminative Clustering using Regularized Subspace Learning.pdf\n",
      "Found: References 89339\n",
      "425 all_collections/A survey of unsupervised learning methods for high-dimensional uncertainty quantification in black-box-type problems.pdf\n",
      "Found: References 79353\n",
      "426 all_collections/Machine learning advances for time series forecasting.pdf\n",
      "Found: References 84451\n",
      "427 all_collections/Reinforcement Learning for Combinatorial Optimization: A Survey.pdf\n",
      "??????????\n",
      "428 all_collections/Stock Market Prediction: A Systematic Review.pdf\n",
      "Found: References 37225\n",
      "429 all_collections/Capturing Financial markets to apply Deep Reinforcement Learning .pdf\n",
      "Found: REFERENCES 12842\n",
      "430 all_collections/Towards Self-Adaptive Efficient Global Optimization.pdf\n",
      "Found: REFERENCES 32235\n",
      "431 all_collections/Stock_Market_Trend_Prediction_Using_High-Order_Information_of_Time_Series.pdf\n",
      "Found: REFERENCES 32998\n",
      "432 all_collections/From Evolutionary Computation to the Evolution of Things.pdf\n",
      "??????????\n",
      "433 all_collections/SELF-LEARNING FUZZY SPIKING NEURAL NETWORK  AS A NONLINEAR PULSE-POSITION THRESHOLD DETECTION DYNAMIC SYSTEM BASED ON SECOND-ORDER CRITICALLY DAMPED RESPONSE UNITS .pdf\n",
      "Found: REFERENCES 16262\n",
      "434 all_collections/Default ARTMAP 2.pdf\n",
      "Found: REFERENCES 34650\n",
      "435 all_collections/Using Genetic Algorithms to Find Technical Trading Rules A Comment on Risk Adjustment.pdf\n",
      "Found: REFERENCES 50195\n",
      "436 all_collections/A critical survey of STDP in Spiking Neural Networks for Pattern Recognition.pdf\n",
      "??????????\n",
      "437 all_collections/GTM_Transformer-Monitoring-Markets-2013_Brochure.pdf\n",
      "Found: REFERENCES 66018\n",
      "438 all_collections/Financial Time Series Prediction Using Spiking Neural Networks Prediction.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "439 all_collections/Parallelism and evolutionary algorithms.pdf\n",
      "??????????\n",
      "440 all_collections/Stock Price Prediction Based on Deep Learning | by Abhijit Roy | Towards Data Science.pdf\n",
      "Found: References 4619\n",
      "441 all_collections/Anomaly Detection of Time Series.pdf\n",
      "Found: References 12057\n",
      "442 all_collections/Unsupervised Learning of Spiking Neural Networks.pdf\n",
      "??????????\n",
      "443 all_collections/4 Common Machine Learning Data Transforms for Time Series Forecasting.pdf\n",
      "??????????\n",
      "444 all_collections/Automatic Trading System based on Genetic Algorithm and Technical Analysis for Stock Index.pdf\n",
      "??????????\n",
      "445 all_collections/How To Automate The Stock Market Using FinRL (Deep Reinforcement Learning Library)_.pdf\n",
      "??????????\n",
      "446 all_collections/Time Series Analysis by State Space Methods.pdf\n",
      "Found: REFERENCES 38220\n",
      "447 all_collections/Stock Market Prediction using Novel Deep Learning Approaches: A Review.pdf\n",
      "Found: References 36508\n",
      "448 all_collections/Stock Market Trading Based on Market Sentiments and Reinforcement Learning.pdf\n",
      "Found: References 100459\n",
      "449 all_collections/Deep Neuro‑Fuzzy System application trends, challenges,  and future perspectives: a systematic survey.pdf\n",
      "??????????\n",
      "450 all_collections/Algorithmic Stock Trading using Deep Reinforcement Learning.pdf\n",
      "Found: References 32833\n",
      "451 all_collections/Time2Vec: Learning a Vector Representation of Time.pdf\n",
      "Found: REFERENCES 41883\n",
      "452 all_collections/Accurate Multivariate Stock Movement Prediction via Data-Axis Transformer with Multi-Level Contexts.pdf\n",
      "Found: REFERENCES 16334\n",
      "453 all_collections/Stock Price Volatility Prediction with Long Short- Term Memory Neural Networks.pdf\n",
      "??????????\n",
      "454 all_collections/Top 10 AutoML Python packages to automate your machine learning tasks.pdf\n",
      "Found: REFERENCES 55151\n",
      "455 all_collections/Deep Reinforcement Learning for Portfolio Management.pdf\n",
      "Found: References 24428\n",
      "456 all_collections/Using neural network to forecast stock index option price: a new hybrid GARCH approach.pdf\n",
      "Found: References 415714\n",
      "457 all_collections/A comprehensive survey on machine learning for networking.pdf\n",
      "Found: REFERENCES 38634\n",
      "458 all_collections/Symbolic regression for scientific discovery: an application to wind speed forecasting .pdf\n",
      "Found: REFERENCES 28897\n",
      "459 all_collections/state-of-the-art-reinforcement-learning-algorithms.pdf\n",
      "Found: References 149609\n",
      "460 all_collections/Transfer Learning for Reinforcement Learning Domains_ A Survey.pdf\n",
      "Found: REFERENCES 47855\n",
      "461 all_collections/A_Hybrid_Model_for_Financial_Time_Series_ForecastingIntegration_of_EWT_ARIMA_With_The_Improved_ABC_Optimized_ELM.pdf\n",
      "Found: References 17612\n",
      "462 all_collections/Feature Selection for Stock Market Analysis.pdf\n",
      "Found: References 98193\n",
      "463 all_collections/Self-normalization for Time Series: A Review of Recent Developments.pdf\n",
      "Found: References 57417\n",
      "464 all_collections/Stock Market Prediction Using Optimized Deep-ConvLSTM Model.pdf\n",
      "??????????\n",
      "465 all_collections/Algorithms, Games, and Evolution.pdf\n",
      "??????????\n",
      "466 all_collections/Classification with Imbalanced Datasets _ Soft Computing and Intelligent Information Systems.pdf\n",
      "Found: REFERENCES 16422\n",
      "467 all_collections/USING FUZZY LOGIC FOR ON-LINE TREND ANALYSIS .pdf\n",
      "??????????\n",
      "468 all_collections/Simulated Annealing for Portfolio Optimization.pdf\n",
      "??????????\n",
      "469 all_collections/The-Complete-Guide-to-Trading.pdf\n",
      "Found: REFERENCES 10904\n",
      "470 all_collections/Forecasting Time Series by SOFNN with Reinforcement Learning.pdf\n",
      "Found: References 22846\n",
      "471 all_collections/Financial Time Series Forecasting Using Optimized Multistage Wavelet Regression.pdf\n",
      "??????????\n",
      "472 all_collections/Neural Architecture Search _ Lil'Log.pdf\n",
      "Found: References 36257\n",
      "473 all_collections/A survey on long short-term memory networks for time series prediction.pdf\n",
      "Found: REFERENCES 124560\n",
      "474 all_collections/On Steady-State Evolutionary Algorithms and Selective Pressure: Why Inverse Rank-Based Allocation of Reproductive Trials Is Best.pdf\n",
      "Found: References 34648\n",
      "475 all_collections/An Introduction to Neural Architecture Search for Convolutional Networks.pdf\n",
      "??????????\n",
      "476 all_collections/A Review of Tournament Selection in Genetic Programming.pdf\n",
      "??????????\n",
      "477 all_collections/Trade-Like-a-Pro-15-High-Profit-Trading-Strategies.pdf\n",
      "Found: References 35960\n",
      "478 all_collections/Automated trading systems statistical and machine learning methods and hardware implementation: a survey .pdf\n",
      "Found: References 89845\n",
      "479 all_collections/characterization_of_financial_time_series.pdf\n",
      "??????????\n",
      "480 all_collections/Winton Stock Market Challenge: Using a Deep Learning Framework for Time Series Stock Market Prediction.pdf\n",
      "??????????\n",
      "481 all_collections/Getting Started with Technical Analysis.pdf\n",
      "Found: References 121664\n",
      "482 all_collections/On Hyperparameter Optimization of Machine Learning Algorithms: Theory and Practice.pdf\n",
      "Found: REFERENCES 22488\n",
      "483 all_collections/dokumen.tips_statsmodels-econometric-and-statistical-modeling-econometric-and-statistical.pdf\n",
      "??????????\n",
      "484 all_collections/Turbo A_D, NH Market System by Dennis Meyers, Ph.D_.pdf\n",
      "??????????\n",
      "485 all_collections/Customize loss function to make LSTM model more applicable in stock price prediction _ by Zedric Cheung _ Towards Data Science.pdf\n",
      "Found: References 24245\n",
      "486 all_collections/Predicting Defective Engines using Convolutional Neural Networks on Temporal Vibration Signals.pdf\n",
      "??????????\n",
      "487 all_collections/Training Strategies for Time Series_Learning for Prediction, Filtering, and Reinforcement Learning.pdf\n",
      "Found: References 26814\n",
      "488 all_collections/Financial Time Series Forecasting: Comparison of Traditional and Spiking Neural Networks .pdf\n",
      "??????????\n",
      "489 all_collections/Recent_advances_in_evolutionary_optimization_techniques_in_applied_electromagnetics.pdf\n",
      "Found: References 36158\n",
      "490 all_collections/Neural Architecture Optimization.pdf\n",
      "Found: References 152855\n",
      "491 all_collections/Cryptocurrency Trading_ A Comprehensive.pdf\n",
      "Found: References 31927\n",
      "492 all_collections/2018-Machine Learning Approaches to Macroeconomic Forecasting.pdf\n",
      "Found: References 14899\n",
      "493 all_collections/A Survey on different datasets employed during stock market prediction.pdf\n",
      "??????????\n",
      "494 all_collections/1-min_Introduction.pdf\n",
      "Found: REFERENCES 25851\n",
      "495 all_collections/Trading The E-Mini by Dennis Meyers, Ph.D_.pdf\n",
      "??????????\n",
      "496 all_collections/Stock-trends-prediction-with-macroeconomic-indicators_Final_year_project.pdf at main · BirdiD_Stock-trends-prediction-with-macroeconomic-indicators.pdf\n",
      "Found: REFERENCES 102297\n",
      "497 all_collections/A survey of transformer.pdf\n",
      "??????????\n",
      "498 all_collections/Transformer Implementation for TimeSeries Forecasting _ by Natasha Klingenbrunn _ MLearning.ai _ MLearning.ai.pdf\n",
      "Found: REFERENCES 33294\n",
      "499 all_collections/EVOLVING REINFORCEMENT LEARNING ALGORITHMS.pdf\n",
      "Found: References 41473\n",
      "500 all_collections/Application of deep reinforcement learning in stock trading strategies and stock forecasting .pdf\n",
      "Found: REFERENCES 34042\n",
      "501 all_collections/TOWARDS UNDERSTANDING REGULARIZATION IN BATCH NORMALIZATION.pdf\n",
      "Found: References 140093\n",
      "502 all_collections/Metaheuristic Techniques.pdf\n",
      "Found: References 33132\n",
      "503 all_collections/How to Combine Tree-Search Methods in Reinforcement Learning.pdf\n",
      "Found: References 68335\n",
      "504 all_collections/Time-varying volatility and the power law distribution of stock returns.pdf\n",
      "Found: References 196936\n",
      "505 all_collections/Rough Sets: A Tutorial.pdf\n",
      "Found: References 37949\n",
      "506 all_collections/Deep Compressed Sensing.pdf\n",
      "Found: References 7691\n",
      "507 all_collections/An_Introduction_to_Rough_Set_Theory_and_Its_Applic.pdf\n",
      "Found: REFERENCES 80243\n",
      "508 all_collections/Taking the Human out of Learning Applications: A Survey on Automated Machine Learning.pdf\n",
      "Found: REFERENCES 68462\n",
      "509 all_collections/Analysis of the Publications on the Applications of .pdf\n",
      "Found: References 6435\n",
      "510 all_collections/AN EVALUATION OF USING DETERMINISTIC HEURISTICS TO ACCELERATE REINFORCEMENT LEARNING .pdf\n",
      "Found: REFERENCES 95304\n",
      "511 all_collections/Neuroevolution in Deep Neural Networks:Current Trends and Future Challenges.pdf\n",
      "Found: References 36604\n",
      "512 all_collections/NeurIPS-2020-learning-to-utilize-shaping-rewards-a-new-approach-of-reward-shaping-Paper.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: References 25411\n",
      "513 all_collections/Stock Portfolio Selection using Data Mining Approach.pdf\n",
      "Found: References 27977\n",
      "514 all_collections/Relative to ARIMA Models.pdf\n",
      "Found: References 43163\n",
      "515 all_collections/Logistic discrimination based on G-mean and F-measure for imbalanced problem.pdf\n",
      "Found: References 61213\n",
      "516 all_collections/High dimensional Bayesian Optimization Algorithm for Complex System in Time Series.pdf\n",
      "Found: References 37225\n",
      "517 all_collections/Capturing Financial markets to apply Deep Reinforcement  Learning.pdf\n",
      "Found: REFERENCES 45924\n",
      "518 all_collections/Investable and Interpretable Machine Learning for Equities.pdf\n",
      "Found: References 72585\n",
      "519 all_collections/Multi-Agent Reinforcement Learning: A Review of Challenges and Applications.pdf\n",
      "Found: References 174961\n",
      "520 all_collections/Review of deep learning: concepts, CNN architectures, challenges, applications, future  directions.pdf\n",
      "Found: References 10892\n",
      "521 all_collections/THE DISTRIBUTION OF RETURNS OF STOCK PRICES.pdf\n",
      "Found: References 24610\n",
      "522 all_collections/TSPred: A framework for nonstationary time series prediction.pdf\n",
      "Found: References 9407\n",
      "523 all_collections/Automated_Stock_Market_Trading_System_Parth_Shah.pdf\n",
      "Found: References 32890\n",
      "524 all_collections/Improved Time Series Prediction and Symbolic Regression with Affine Arithmetic .pdf\n",
      "??????????\n",
      "525 all_collections/Spiking Neural Networks for Financial Data Prediction.pdf\n",
      "??????????\n",
      "526 all_collections/Sparse Coding-Inspired Optimal Trading System for HFT Industry.pdf\n",
      "Found: REFERENCES 22037\n",
      "527 all_collections/Time Series Data Prediction Using Sliding Window Based RBF Neural Network.pdf\n",
      "Found: References 54850\n",
      "528 all_collections/Utilizing Articial Neural Networks and Genetic Algorithms.pdf\n",
      "??????????\n",
      "529 all_collections/Unsupervised Machine Learning.pdf\n",
      "Found: REFERENCES 59280\n",
      "530 all_collections/A-Review-on-Applied-Data-Mining-Techniques-to-Stock-Market-Prediction.pdf\n",
      "??????????\n",
      "531 all_collections/Predicting stock prices with LSTM Networks.pdf\n",
      "Found: References 14173\n",
      "532 all_collections/Feature selection and deep neural networks for stock price direction forecasting using technical analysis indicators .pdf\n",
      "Found: References 18542\n",
      "533 all_collections/Classification of Imbalanced Data:Review of Methods and Applications.pdf\n",
      "??????????\n",
      "534 all_collections/Estimation of a Network with Evolutionary Computation.pdf\n",
      "??????????\n",
      "535 all_collections/Inside 2021 ML Trends_ Reinforcement Learning and AutoML.pdf\n",
      "Found: References 30263\n",
      "536 all_collections/NeurIPS-2018-brits-bidirectional-recurrent-imputation-for-time-series-Paper.pdf\n",
      "Found: REFERENCES 22469\n",
      "537 all_collections/DATA MINING AND NEURAL NETWORK TECHNIQUES IN STOCK MARKET PREDICTION: A METHODOLOGICAL REVIEW.pdf\n",
      "Found: References 41490\n",
      "538 all_collections/Reward Shaping in Episodic Reinforcement Learning.pdf\n",
      "Found: References 20720\n",
      "539 all_collections/Using Random Forest to Learn Imbalanced Data.pdf\n",
      "Found: References 25513\n",
      "540 all_collections/Risk, Reward & Reinforcem.pdf\n",
      "Found: References 39108\n",
      "541 all_collections/AutoML Meets Time Series Regression Design and Analysis of the AutoSeries Challenge.pdf\n",
      "Found: References 34331\n",
      "542 all_collections/NeurIPS-2019-unsupervised-scalable-representation-learning-for-multivariate-time-series-Paper.pdf\n",
      "Found: REFERENCES 100262\n",
      "543 all_collections/Artificial Intelligence and Deep Reinforcement Learning Stock Market Predictions -- dissertation- 2020 (Candlesticks)).pdf\n",
      "Found: References 116894\n",
      "544 all_collections/A Survey on Neural Architecture Search.pdf\n",
      "Found: References 4651\n",
      "545 all_collections/Financial time series forecasting with deep learning : A systematic literature review: 2005–2019.pdf\n",
      "Found: References 28136\n",
      "546 all_collections/Towards co-evolution of fitness predictors and Deep Neural Networks.pdf\n",
      "Found: REFERENCES 67454\n",
      "547 all_collections/Temporal Feature Selection with Symbolic Regression.pdf\n",
      "??????????\n",
      "548 all_collections/Trading IBM Intraday by Dennis Meyers, PhD.pdf\n",
      "Found: REFERENCES 11488\n",
      "549 all_collections/Algorithm AS 99: Fitting Johnson Curves by Moments.pdf\n",
      "Found: References 74467\n",
      "550 all_collections/Predicting Stock Market Returns with Machine Learning.pdf\n",
      "Found: REFERENCES 108462\n",
      "551 all_collections/Surveying stock market forecasting techniques part i: Conventional methods .pdf\n",
      "Found: References 52494\n",
      "552 all_collections/A Carbon Price Forecasting Model Based on Variational Mode Decomposition and Spiking Neural Networks.pdf\n",
      "??????????\n",
      "553 all_collections/A Survey of Reinforcement Learning Techniques: Strategies, Recent Development, and Future Directions.pdf\n",
      "Found: References 97510\n",
      "554 all_collections/(Global) Optimization: Historical notes and recent developments.pdf\n",
      "Found: REFERENCES 106084\n",
      "555 all_collections/Spiking_Neural_Networks_A_Survey.pdf\n",
      "??????????\n",
      "556 all_collections/A review of stock market prediction with Artificial neural network (ANN).pdf\n",
      "Found: References 29791\n",
      "557 all_collections/Using Cases as Heuristics in Reinforcement Learning: a Transfer Learning Application.pdf\n",
      "Found: References 68350\n",
      "558 all_collections/Forecasting East Asian Indices Futures via a Novel Hybrid of Wavelet-PCA Denoising and Artificial Neural Network Models.pdf\n",
      "Found: References 14257\n",
      "559 all_collections/APPLICATION OF DEEP REINFORCEMENT LEARNING FOR INDIAN STOCK TRADING AUTOMATION.pdf\n",
      "Found: References 28398\n",
      "560 all_collections/REVIEW OF STOCK PREDICTION USING MACHINE LEARNING TECHNIQUES.pdf\n",
      "??????????\n",
      "561 all_collections/Scaling Reward Values for Improved Deep Reinforcement Learning _ by Eric Muccino _ Mindboard _ Medium.pdf\n",
      "??????????\n",
      "562 all_collections/Evolutionary Computing Techniques: Genetic Algorithms.pdf\n",
      "Found: References 141180\n",
      "563 all_collections/Game Theory for Multi-Access Edge Computing: Survey, Use Cases, and Future Trends.pdf\n",
      "Found: References 38651\n",
      "564 all_collections/Encoding candlesticks as images for pattern classification using convolutional neural networks.pdf\n",
      "Found: References 49424\n",
      "565 all_collections/TPOT‑NN: augmenting tree‑based automated machine learning with neural network estimators.pdf\n",
      "Found: REFERENCES 39573\n",
      "566 all_collections/QF-TraderNet: Intraday Trading via Deep Reinforcement With Quantum Price Levels Based Profit-And-Loss Control.pdf\n",
      "Found: References 49462\n",
      "567 all_collections/A kernel entropy manifold learning approach for financial data analysis.pdf\n",
      "Found: References 52967\n",
      "568 all_collections/The selection of popular trading strategies.pdf\n",
      "Found: References 338\n",
      "569 all_collections/auto-ml-whitepaper.pdf\n",
      "Found: References 52360\n",
      "570 all_collections/Meta-learning how to forecast time series.pdf\n",
      "Found: REFERENCES 39613\n",
      "571 all_collections/Rough Sets for Feature Selection and  Classification: An Overview with Applications.pdf\n",
      "Found: REFERENCES 46830\n",
      "572 all_collections/LightAutoML: AutoML Solution for a Large Financial Services Ecosystem.pdf\n",
      "??????????\n",
      "573 all_collections/GAN base 7-minute prediction in stock.pdf\n",
      "??????????\n",
      "574 all_collections/Introduction_To_Trading_System_Development_David_Cardoza.pdf\n",
      "Found: References 71870\n",
      "575 all_collections/Nature-inspired algorithms for feed-forward neural network classifiers: A survey of one decade of research.pdf\n",
      "Found: References 28186\n",
      "576 all_collections/Enhancing Stock Price Trend Prediction via a Time-Sensitive Data Augmentation Method.pdf\n",
      "??????????\n",
      "577 all_collections/Part 2: Kinds of RL Algorithms Spinning Up documentation.pdf\n",
      "Found: References 11874\n",
      "578 all_collections/A survey of time series forecasting from stochastic to soft computing.pdf\n",
      "Found: References 105351\n",
      "579 all_collections/Optimisation Applications.pdf\n",
      "Found: References 36644\n",
      "580 all_collections/A brief survey of unsupervised agglomerative hierarchical clustering schemes .pdf\n",
      "??????????\n",
      "581 all_collections/Exotic Trading Strategies on the S&P500 in Python. _ by Sofien Kaabar, CFA _ Investor’s Handbook _ Medium.pdf\n",
      "Found: REFERENCES 58083\n",
      "582 all_collections/Spectrum-Diverse Neuroevolution with Unified Neural Models.pdf\n",
      "Found: References 86512\n",
      "583 all_collections/Efficient Transformers: A Survey.pdf\n",
      "Found: REFERENCES 8732\n",
      "584 all_collections/A Study on Normalization Techniques for Privacy Preserving Data Mining .pdf\n",
      "Found: REFERENCES 30030\n",
      "585 all_collections/Deep Reinforcement Learning for Foreign Exchange Trading – arXiv Vanity.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "586 all_collections/Evolutionary optimization_ A review and implementation of several algorithms.pdf\n",
      "??????????\n",
      "587 all_collections/The Direct Reversal Trading Strategy in Python. _ by Sofien Kaabar, CFA _ Geek Culture _ Medium.pdf\n",
      "Found: References 59326\n",
      "588 all_collections/Application of particle swarm optimization to water management: an introduction and overview.pdf\n",
      "Found: References 18356\n",
      "589 all_collections/Genetic algorithm evolved agent-based equity trading using Technical Analysis and the Capital Asset Pricing Model.pdf\n",
      "Found: References 42789\n",
      "590 all_collections/Automatic Parameter Optimization Using Genetic Algorithm in Deep Reinforcement Learning for Robotic Manipulation Tasks.pdf\n",
      "??????????\n",
      "591 all_collections/Fundamentals of Machine Learning for Predictive Data Analytics.pdf\n",
      "??????????\n",
      "592 all_collections/Machine Learning Stock Market Prediction Studies.pdf\n",
      "??????????\n",
      "593 all_collections/Swarm_intelligence PPT.pdf\n",
      "??????????\n",
      "594 all_collections/Multi-Class Imbalanced Learning  for Time Series Problem .pdf\n",
      "Found: References 87521\n",
      "595 all_collections/Short-term_stock_market_price_trend_prediction_using a comprehensive deep learning system .pdf\n",
      "Found: REFERENCES 14890\n",
      "596 all_collections/OPTIMISING TIME SERIES FORECASTS THROUGH LINEAR PROGRAMMING.pdf\n",
      "??????????\n",
      "597 all_collections/Predicting Stock Trends From News Articles.pdf\n",
      "??????????\n",
      "598 all_collections/Anomaly Detection with Time Series Forecasting _ Complete Guide.pdf\n",
      "Found: References 33600\n",
      "599 all_collections/Optimal VWAP Trading Strategy and.Relative Volume.pdf\n",
      "??????????\n",
      "600 all_collections/time-series-forecasting-with-python.pdf\n",
      "Found: References 35146\n",
      "601 all_collections/Information fusion in rough set theory _ An overview.pdf\n",
      "??????????\n",
      "602 all_collections/Estimize+Sales+Deck+October+2019.pdf\n",
      "Found: References 32530\n",
      "603 all_collections/A Survey of Neuromorphic Computing Based on Spiking Neural Networks.pdf\n",
      "Found: References 28185\n",
      "604 all_collections/Unsupervised Feature Learning from Time Series.pdf\n",
      "Found: References 36434\n",
      "605 all_collections/Learning to Utilize Shaping Rewards: A New Approach of Reward Shaping.pdf\n",
      "Found: References 37225\n",
      "606 all_collections/FinRL_Tutorials_June 09_2021.pdf\n",
      "Found: REFERENCES 5326\n",
      "607 all_collections/Fuzzy adaptive resonance theory_ Applications and extensions.pdf\n",
      "??????????\n",
      "608 all_collections/The Heatmap Technical Indicator. Creating the Heatmap Technical… | by Sofien Kaabar, CFA | Apr, 2022 | Medium.pdf\n",
      "Found: References 863\n",
      "609 all_collections/Frontiers _ QF-TraderNet_ Intraday Trading via Deep Reinforcement With Quantum Price Levels Based Profit-And-Loss Control _ Artificial Intelligence.pdf\n",
      "Found: REFERENCES 26608\n",
      "610 all_collections/Unsupervised Learning with Self Organizing Spiking Neural Networks.pdf\n",
      "??????????\n",
      "611 all_collections/OpenAi Gym and Evolutionary Models _ by Geoff Counihan _ Medium.pdf\n",
      "Found: REFERENCES 20687\n",
      "612 all_collections/Does the use of technical & fundamental analysis improve stock choice? : A data mining approach applied to the Australian stock market.pdf\n",
      "Found: REFERENCES 36610\n",
      "613 all_collections/K-Fold Cross-Validation is Superior to Split Sample Validation for Risk Adjustment Models .pdf\n",
      "??????????\n",
      "614 all_collections/INVESTIGATING_MACHINE_LEARNING_ALGORITHMS_WITH_IMBALANCED_BIG_DATA.pdf\n",
      "Found: References 13717\n",
      "615 all_collections/The Time Series Transformer _ by Theodoros Ntakouris _ Towards Data Science.pdf\n",
      "Found: References 5152\n",
      "616 all_collections/Financial Time Series Forecasting Using Spiking Neural Networks.pdf\n",
      "Found: REFERENCES 29849\n",
      "617 all_collections/Stock Market Trend Prediction using Supervised Machine Learning Algorithms.pdf\n",
      "Found: REFERENCES 95986\n",
      "618 all_collections/A_Hybrid_Multi-Task_Learning_Approach_for_Optimizing_Deep_Reinforcement_Learning_Agents.pdf\n",
      "??????????\n",
      "619 all_collections/Demark -- new-market-timing-techniques-innovative-studies-in-market-rhythm-and- price-exhaustion.pdf\n",
      "Found: REFERENCES 26410\n",
      "620 all_collections/Fuzzy Spiking Neural Network for Abnormality Detection in Cognitive Robot Life Supporting System.pdf\n",
      "??????????\n",
      "621 all_collections/Dynamic Optimisation of Technical Trading Rules Using Genetic Programming.pdf\n",
      "Found: References 80595\n",
      "622 all_collections/An Empirical Review of Automated Machine Learning.pdf\n",
      "Found: References 47632\n",
      "623 all_collections/New approaches for heuristic search: A bilateral linkage with artificial intelligence  .pdf\n",
      "??????????\n",
      "624 all_collections/Deep learning for portfolio management.pdf\n",
      "Found: References 65667\n",
      "625 all_collections/Machine Learning for Market Microstructure and High Frequency Trading.pdf\n",
      "??????????\n",
      "626 all_collections/Evolving Reinforcement Learning Algorithms .pdf\n",
      "Found: REFERENCES 41116\n",
      "627 all_collections/Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks.pdf\n",
      "Found: REFERENCES 39617\n",
      "628 all_collections/Stock Market Forecasting Using Deep Learning and Technical Analysis: A Systematic Review.pdf\n",
      "Found: References 93382\n",
      "629 all_collections/The Crowding Approach to Niching in Genetic Algorithms.pdf\n",
      "Found: REFERENCES 30708\n",
      "630 all_collections/The GMI Bond Market System by Dennis Meyers, Ph.D_.pdf\n",
      "Found: References 35141\n",
      "631 all_collections/Time Series Forecasting With Deep Learning_ Survey.pdf\n",
      "Found: REFERENCES 39740\n",
      "632 all_collections/Implementation of Artificial Intelligence and Machine learning in Financial services.pdf\n",
      "Found: References 37458\n",
      "633 all_collections/Layered TPOT Speeding up Tree-based Pipeline Optimization.pdf\n",
      "Found: References 56387\n",
      "634 all_collections/Predicting Trend of Stock Prices by Developing Data Mining Techniques with the Aim of Gaining Profit.pdf\n",
      "Found: References 17952\n",
      "635 all_collections/Evolving Trading Strategies With Genetic Programming - Data · Fabian Kostadinov.pdf\n",
      "Found: References 64871\n",
      "636 all_collections/Deep Reinforcement Learning for Trading—A Critical Survey.pdf\n",
      "Found: References 79347\n",
      "637 all_collections/Stock Market Analysis: A Review and Taxonomy of Prediction Techniques.pdf\n",
      "??????????\n",
      "638 all_collections/7 Winning Strategies for Trading Forex.pdf\n",
      "Found: References 45442\n",
      "639 all_collections/Multi-Transformer: A New Neural Network-Based Architecture for Forecasting S&P Volatility.pdf\n",
      "Found: References 28598\n",
      "640 all_collections/Data_Mining_for_Imbalanced_Datasets_An_Overview.pdf\n",
      "Found: REFERENCES 32509\n",
      "641 all_collections/Classification and Clustering of Stocks, using Genetic Algorithms and Fundamental Analysis.pdf\n",
      "??????????\n",
      "642 all_collections/drlearner _ Deep Reinforcement Learning.pdf\n",
      "Found: REFERENCES 59678\n",
      "643 all_collections/SmartMoney_Dumb_Money_And_Equity_Return.pdf\n",
      "??????????\n",
      "644 all_collections/Recreating AlphaZero Chess Engine.pdf\n",
      "Found: References 35751\n",
      "645 all_collections/An Overview of Evolutionary Computation.pdf\n",
      "Found: References 9640\n",
      "646 all_collections/The Adaptive Resonance Theory network : (clustering-)behaviour in relation with Brainstem Auditory Evoked Potential patterns.pdf\n",
      "??????????\n",
      "647 all_collections/Automated Trading Systems_ The Pros and Cons.pdf\n",
      "Found: References 29951\n",
      "648 all_collections/Classification-based Financial Markets Prediction using Deep Neural Networks.pdf\n",
      "Found: References 52191\n",
      "649 all_collections/Deep Reinforcement Learning in Quantitative Algorithmic Trading: A Review.pdf\n",
      "??????????\n",
      "650 all_collections/Dow Theory.pdf\n",
      "Found: References 67740\n",
      "651 all_collections/An Overview of Deep Learning Based Methods for Unsupervised and Semi-Supervised Anomaly Detection in Videos.pdf\n",
      "??????????\n",
      "652 all_collections/Reinforcement Learning: The Multi-Player Case.pdf\n",
      "??????????\n",
      "653 all_collections/Simulated Annealing_ Theory and Applications.pdf\n",
      "Found: References 7677\n",
      "654 all_collections/Deep Reinforcement Learning (DRL) for portfolio allocation.pdf\n",
      "??????????\n",
      "655 all_collections/ElegantRL_ Mastering PPO Algorithms _ by Xiao-Yang Liu _ Towards Data Science.pdf\n",
      "Found: References 40734\n",
      "656 all_collections/ENCODING CANDLESTICKS AS IMAGES FOR PATTERN CLASSIFICATION USING CONVOLUTIONAL NEURAL NETWORKS.pdf\n",
      "??????????\n",
      "657 all_collections/Deep learning.pdf\n",
      "Found: References 33206\n",
      "658 all_collections/Deep Reinforcement Learning for Trading.pdf\n",
      "Found: REFERENCES 14012\n",
      "659 all_collections/Neuroengineering of Clustering Algorithms .pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: REFERENCES 48125\n",
      "660 all_collections/Price-Trailing-for-Financial-Trading-using-Deep-Reinforcement-Learning-Transactions-on-Neural-Networks-and-Learning-Systems - 2019.pdf\n",
      "Found: References 18251\n",
      "661 all_collections/Stocks’ Trading System Based on the Particle Swarm Optimization Algorithm .pdf\n",
      "Found: REFERENCES 17980\n",
      "662 all_collections/stock-market-prediction-approach-an-analysis.pdf\n",
      "Found: References 30818\n",
      "663 all_collections/Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting.pdf\n",
      "Found: REFERENCES 13746\n",
      "664 all_collections/HEURISTIC BASED TRADING SYSTEM ON FOREX DATA USING TECHNICAL INDICATOR RULES.pdf\n",
      "??????????\n",
      "665 all_collections/Repeated Median Velocity Strategy, Part 2 by Dennis Meyers, PhD.pdf\n",
      "??????????\n",
      "666 all_collections/Improving Q-learning agent trading stock by adding recurrency and reward shaping _ by Alexey Burnakov _ Medium.pdf\n",
      "??????????\n",
      "667 all_collections/Algorithmic Trading Model for Manifold Learning in FX.pdf\n",
      "Found: References 12202\n",
      "668 all_collections/Evolving Trading Strategies With Genetic Programming - GP Parameters and Operators · Fabian Kostadinov.pdf\n",
      "Found: REFERENCES 15212\n",
      "669 all_collections/A Survey on Methods to Handle Imbalance Dataset.pdf\n",
      "Found: References 6168\n",
      "670 all_collections/Stock Trend Prediction Using Deep Learning Approach on Technical Indicator and Industrial Specific Information.pdf\n",
      "??????????\n",
      "671 all_collections/Algorithms in Nature .pdf\n",
      "Found: References 42787\n",
      "672 all_collections/A Deterministic Algorithm for Global Optimization.pdf\n",
      "??????????\n",
      "673 all_collections/High Frequency Exchange Rate Forecasting using Deep Learning on Cryptocurrency Markets.pdf\n",
      "??????????\n",
      "674 all_collections/Reinforcement learning in financial markets - a Survey.pdf\n",
      "??????????\n",
      "675 all_collections/Financial Time Series Forecasting with Deep Learning – The Data Exchange.pdf\n",
      "Found: REFERENCES 187895\n",
      "676 all_collections/DEEP REINFORCEMENT LEARNING: AN OVERVIEW.pdf\n",
      "??????????\n",
      "677 all_collections/A Comparison of Stock Trend Prediction Using Accuracy Driven Neural Network Variants.pdf\n",
      "??????????\n",
      "678 all_collections/Project Proposal.docx.pdf\n",
      "??????????\n",
      "679 all_collections/Algorithmic trading system requirements.pdf\n",
      "Found: REFERENCES 49705\n",
      "680 all_collections/An Introduction to Evolutionary Computing.pdf\n",
      "Found: REFERENCES 49182\n",
      "681 all_collections/AlphaStock- A Buying-Winners-and-Selling-Losers Investment Strategy using Interpretable Deep Reinforcement Attention Networks 2.pdf\n",
      "Found: REFERENCES 28853\n",
      "682 all_collections/Explainable Deep Reinforcement Learning for Portfolio Management: An Empirical Approach.pdf\n",
      "Found: References 87671\n",
      "683 all_collections/Artificial intelligence techniques in finance and financial markets: A survey of the literature.pdf\n",
      "Found: REFERENCES 68867\n",
      "684 all_collections/Artificial_Intelligence_Applied_to_Stock_Market_Trading_A_Review.pdf\n",
      "Found: REFERENCES 63163\n",
      "685 all_collections/Codes -- Hybrid evolutionary intelligent system and hybrid time series econometric model.pdf\n",
      "Found: REFERENCES 26352\n",
      "686 all_collections/Stock Prediction Based on Genetic Algorithm Feature Selection and Long Short-Term Memory Neural Network.pdf\n",
      "Found: REFERENCES 52271\n",
      "687 all_collections/DeepLOB: Deep Convolutional Neural Networks .pdf\n",
      "Found: References 30520\n",
      "688 all_collections/Imaging Time-Series to Improve Classification and Imputation.pdf\n",
      "Found: REFERENCES 3962\n",
      "689 all_collections/Residual_Capsule_Network_Shruthi_Bhamidi_Thesis.pdf\n",
      "Found: References 14173\n",
      "690 all_collections/Feature selection and deep neural networks for stock price direction forecasting using technical analysis indicators.pdf\n",
      "Found: REFERENCES 85443\n",
      "691 all_collections/Deep Reinforcement Learning Overview of the State of the Art.pdf\n",
      "Found: References 17838\n",
      "692 all_collections/Comparison of Min-Max normalization and Z-Score Normalization in the K-nearest neighbor (kNN) Algorithm to Test the Accuracy of Types of Breast Cancer.pdf\n",
      "Found: References 156573\n",
      "693 all_collections/On Monte Carlo Tree Search and Reinforcement Learning.pdf\n",
      "Found: References 27885\n",
      "694 all_collections/DATA MINING FOR IMBALANCED DATASETS: AN OVERVIEW.pdf\n",
      "??????????\n",
      "695 all_collections/Replicating Financial Markets using Reinforcement Learning .pdf\n",
      "Found: References 27986\n",
      "696 all_collections/Multi-scale Two-way Deep Neural Network for Stock Trend Prediction.pdf\n",
      "Found: References 59024\n",
      "697 all_collections/The Fuzzy Logic Method for Simpler Forecasting .pdf\n",
      "??????????\n",
      "698 all_collections/estimize_post_earnings_signal_strategy.pdf\n",
      "Found: REFERENCES 35146\n",
      "699 all_collections/A Survey on Machine Learning for Stock Price Prediction: Algorithms and Techniques .pdf\n",
      "??????????\n",
      "700 all_collections/Unsupervised Machine Learning_ Algorithms, Types with Example.pdf\n",
      "Found: References 18224\n",
      "701 all_collections/Neural-Symbolic Learning and Reasoning: Contributions and Challenges.pdf\n",
      "Found: References 113445\n",
      "702 all_collections/A Genetic Algorithm Tutorial.pdf\n",
      "Found: REFERENCES 18543\n",
      "703 all_collections/An Efficient and Simple Under-sampling Technique for Imbalanced Time Series Classification.pdf\n",
      "Found: REFERENCES 21160\n",
      "704 all_collections/Improving Deep Reinforcement Learning for Financial Trading Using Neural Network Distillation.pdf\n",
      "Found: REFERENCES 52271\n",
      "705 all_collections/DeepLOB: Deep Convolutional Neural Networks for Limit Order Books.pdf\n",
      "Found: References 45996\n",
      "706 all_collections/Optimization by Simulated Annealing.pdf\n",
      "Found: References 36446\n",
      "707 all_collections/AdaNet: Adaptive Structural Learning of Artificial Neural Networks.pdf\n",
      "Found: References 123541\n",
      "708 all_collections/Nature-Inspired Heuristics: Overview and Critique.pdf\n",
      "Found: References 23473\n",
      "709 all_collections/Analysis and implementation of realtime stock prediction using reinforcement frameworks .pdf\n",
      "Found: References 20190\n",
      "710 all_collections/Learning Sentiment-aware Trading Strategies for Bitcoin leveraging Deep Learning-based Financial News Analysis.pdf\n",
      "Found: REFERENCES 46730\n",
      "711 all_collections/Competitive Algorithms for VWAP and Limit Order Trading.pdf\n",
      "??????????\n",
      "712 all_collections/Efficient Evolution of Neural Networks.pdf\n",
      "??????????\n",
      "713 all_collections/Forex_Trading_Strategies.pdf\n",
      "Found: References 67402\n",
      "714 all_collections/Comparison of machine learning methods for financial time series forecasting at the examples of over 10 years of daily and hourly data of DAX 30 and S&P 500.pdf\n",
      "??????????\n",
      "715 all_collections/Evolving Probabilistic Spiking Neural Networks (Nuttapod Nuntalid) (z-lib.org).pdf\n",
      "Found: REFERENCES 56699\n",
      "716 all_collections/Networks of Spiking Neurons: The Third Generation of Neural Network Models .pdf\n",
      "??????????\n",
      "717 all_collections/Rough Set Theory and Stock Market Analysis - 14808 Words _ Essay Example.pdf\n",
      "Found: References 22645\n",
      "718 all_collections/Evolving Deep Unsupervised Convolutional Networks for .pdf\n",
      "??????????\n",
      "719 all_collections/Smart money, dumb money, and capital market anomalies$.pdf\n",
      "??????????\n",
      "720 all_collections/How to Calculate Volatility Using VWAP Price.pdf\n",
      "??????????\n",
      "721 all_collections/Fuzzy Sets and Rough Sets.pdf\n",
      "Found: References 338\n",
      "722 all_collections/auto-ml-whitepaper (1).pdf\n",
      "Found: REFERENCES 6688\n",
      "723 all_collections/Deep Q Learning Applied to Stock Trading.pdf\n",
      "Found: References 11326\n",
      "724 all_collections/Deep Reinforcement Learning For Forex Trading.pdf\n",
      "Found: References 30307\n",
      "725 all_collections/Generating trading rules on the stock markets with genetic programming.pdf\n",
      "Found: References 44508\n",
      "726 all_collections/Generative Adversarial Networks for Stock Market prediction Report.pdf\n",
      "??????????\n",
      "727 all_collections/Automated_time_series_model_discovery.pdf\n",
      "Found: References 69371\n",
      "728 all_collections/Forecasting a Stock Trend Using Genetic Algorithm and Random Forest.pdf\n",
      "??????????\n",
      "729 all_collections/Reinforcement Learning_ Risks and Challenges for for Financial Institutions.pdf\n",
      "Found: References 25760\n",
      "730 all_collections/Data Mining and Machine Learning for Financial Analysis.pdf\n",
      "Found: REFERENCES 43176\n",
      "731 all_collections/Learning Multiple Stock Trading Patterns with Temporal Routing Adaptor and Optimal Transport.pdf\n",
      "Found: REFERENCES 12043\n",
      "732 all_collections/Hierarchical reinforcement learning_ A comprehensive survey.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: REFERENCES 103106\n",
      "733 all_collections/Mid-Price Movement Prediction in Limit Order Book using Feature Enginerring and Machine Learning.pdf\n",
      "??????????\n",
      "734 all_collections/FUNDAMENTAL ANALYSIS AND EQUITY VOLATILITY.pdf\n",
      "Found: References 67078\n",
      "735 all_collections/Implementing algorithms of rough set theory and fuzzy rough set theory in the R package ‘‘RoughSets’’.pdf\n",
      "Found: REFERENCES 42634\n",
      "736 all_collections/A_Survey_on_Meta_Heuristic_Global_Optimi.pdf\n",
      "Found: References 18499\n",
      "737 all_collections/Time series prediction using the adaptive resonance theory algorithm ART-2.pdf\n",
      "??????????\n",
      "738 all_collections/Intro-to-Machine-Learning-techniques-used-in-the-financial-industry-and-a-case-study-V1.pdf\n",
      "Found: References 39870\n",
      "739 all_collections/A Robust Regression-Based Stock Exchange Forecasting and Determination of Correlation between Stock Markets.pdf\n",
      "Found: References 10601\n",
      "740 all_collections/deepFX.pdf\n",
      "Found: REFERENCES 46235\n",
      "741 all_collections/Multi-Scale Convolutional Neural Networks for Time Series Classification.pdf\n",
      "??????????\n",
      "742 all_collections/LOSS FUNCTIONS AND RISK.pdf\n",
      "Found: References 62065\n",
      "743 all_collections/Time-driven feature-aware jointly deep reinforcement learning for financial signal representation and algorithmic trading.pdf\n",
      "Found: References 28405\n",
      "744 all_collections/Hierarchical Multi-Scale Gaussian Transformer for Stock Movement Prediction.pdf\n",
      "Found: References 73731\n",
      "745 all_collections/Deep Learning Networks for Stock Market Analysis and Prediction- Methodology, Data Representations, and Case Studies.pdf\n",
      "Found: References 22712\n",
      "746 all_collections/Feature Selection.pdf\n",
      "Found: References 37106\n",
      "747 all_collections/DeepTrader: A Deep Reinforcement Learning Approach for Risk-Return Balanced Portfolio Management with Market Conditions Embedding.pdf\n",
      "Found: References 13829\n",
      "748 all_collections/Genetic algorithms and darwinian approaches in financial applications: A survey.pdf\n",
      "??????????\n",
      "749 all_collections/Event-Driven Asset Pricing Prediction.pdf\n",
      "Found: References 58405\n",
      "750 all_collections/Review 03 - Deep Reinforcement Learning For Trading - A Critical Survey.pdf\n",
      "??????????\n",
      "751 all_collections/Sentiment Alanysis of Company Earnings Conference Calss with Long Short-Term Memory.pdf\n",
      "Found: References 39750\n",
      "752 all_collections/A SURVEY ON MACHINE LEARNING TECHNIQUES FOR AUTO LABELING OF VIDEO, AUDIO, AND TEXT DATA .pdf\n",
      "Found: REFERENCES 19119\n",
      "753 all_collections/Development of Artificial Intelligence and Effects on Financial System.pdf\n",
      "Found: References 116719\n",
      "754 all_collections/A Comparative Study of Common Nature-Inspired Algorithms for Continuous Function Optimization.pdf\n",
      "Found: References 17196\n",
      "755 all_collections/applications-of-data-mining-in-stock-market.pdf\n",
      "??????????\n",
      "756 all_collections/The Candlestick Trading Bible.pdf\n",
      "Found: References 23770\n",
      "757 all_collections/Optimization of a Trading System using Global Search Techniques and Local Optimization.pdf\n",
      "Found: References 56936\n",
      "758 all_collections/Predicting the daily return direction of the stock market using hybrid machine learning.pdf\n",
      "??????????\n",
      "759 all_collections/Final report.pdf\n",
      "Found: REFERENCES 55189\n",
      "760 all_collections/An evolutionary algorithm that constructs recurrent neural networks.pdf\n",
      "??????????\n",
      "761 all_collections/Intelligent Algorithmic Trading Systems.pdf\n",
      "Found: References 70164\n",
      "762 all_collections/Determinants of Stock Market Development: A Review of the Literature .pdf\n",
      "Found: References 72546\n",
      "763 all_collections/Computational Intelligence for Evolving Trading Rules.pdf\n",
      "Found: References 22956\n",
      "764 all_collections/Building Technical Trading System with Genetic Programming: A New Method to Test the Efficiency of Chinese Stock Markets.pdf\n",
      "Found: References 76375\n",
      "765 all_collections/Smart “Predict, then Optimize”.pdf\n",
      "Found: References 6089\n",
      "766 all_collections/Fuzzy rough sets.pdf\n",
      "Found: References 19363\n",
      "767 all_collections/TPOT: A Tree-based Pipeline Optimization Tool for Automating Machine Learning.pdf\n",
      "Found: References 31573\n",
      "768 all_collections/Robust Market Making via Adversarial Reinforcement Learning.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid FloatObject b'0.00-2547933'\n",
      "Invalid FloatObject b'0.00-11111111'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "769 all_collections/NLP Tutorial for Text Classification in Python _ by Vijaya Rani _ Analytics Vidhya _ Medium.pdf\n",
      "Found: References 83168\n",
      "770 all_collections/Automated Reinforcement Learning (AutoRL):A Survey and Open Problems.pdf\n",
      "??????????\n",
      "771 all_collections/Evolving Reinforcement  .pdf\n",
      "Found: References 33449\n",
      "772 all_collections/Evolution Strategies as a Scalable Alternative to Reinforcement Learning.pdf\n",
      "Found: References 8230\n",
      "773 all_collections/Introduction to K-fold Cross validation _ by Little Dino _ Towards Dev.pdf\n",
      "??????????\n",
      "774 all_collections/Stock Price Predictions from News Headline Embeddings.pdf\n",
      "Found: References 45914\n",
      "775 all_collections/NeurIPS-2021-continuous-vs-discrete-optimization-of-deep-neural-networks-Paper.pdf\n",
      "Found: REFERENCES 43057\n",
      "776 all_collections/Integrated_Long-Term_Stock_Selection_Models_Based_on_Feature_Selection_and_Machine_Learning_Algorithms_for_China_Stock_Market (1).pdf\n",
      "Found: REFERENCES 26628\n",
      "777 all_collections/Algorithmic Trading Using Genetic Algorithms in the Brazilian Stock Exchange.pdf\n",
      "??????????\n",
      "778 all_collections/A Beginner_s Guide to Deep Reinforcement Learning _ Pathmind.pdf\n",
      "Found: References 26572\n",
      "779 all_collections/Reinforcement Learning Applications in Real Time Trading.pdf\n",
      "Found: REFERENCES 29492\n",
      "780 all_collections/Trading via Image Classification.pdf\n",
      "Found: REFERENCES 36907\n",
      "781 all_collections/New approaches to robotics.pdf\n",
      "??????????\n",
      "782 all_collections/Reinforcement Model for automated stock trading.pdf\n",
      "Found: References 93584\n",
      "783 all_collections/An insight into classification with imbalanced data: Empirical results and current trends on using data intrinsic characteristics.pdf\n",
      "Found: References 30314\n",
      "784 all_collections/Temporal Logistic Neural Bag-of-Features for Financial Time.pdf\n",
      "Found: REFERENCES 68425\n",
      "785 all_collections/AutoML to Date and Beyond: Challenges and Opportunities.pdf\n",
      "Found: References 18812\n",
      "786 all_collections/Trading rule extraction in stock market using the rough set approach.pdf\n",
      "Found: REFERENCES 22946\n",
      "787 all_collections/Insight on Stock Market using Data Mining.pdf\n",
      "Found: REFERENCES 29521\n",
      "788 all_collections/Loss Functions in Financial Sector- An Overview.pdf\n",
      "Found: References 42951\n",
      "789 all_collections/Predicting the Distribution of Stock Returns: Model Formulation, Statistical Evaluation, VaR Analysis and Economic Significance.pdf\n",
      "Found: REFERENCES 25737\n",
      "790 all_collections/Anomaly Detection in Multivariate Non-stationary Time Series for Automatic DBMS Diagnosis.pdf\n",
      "Found: REFERENCES 40756\n",
      "791 all_collections/An overview on the evolution and adoption of deep learning applications used in the industry.pdf\n",
      "Found: REFERENCES 39351\n",
      "792 all_collections/D EEP LEARNING FOR SYMBOLIC MATHEMATICS.pdf\n",
      "Found: REFERENCES 36410\n",
      "793 all_collections/IBM, Cubed by Dennis Meyers, Ph.D_.pdf\n",
      "??????????\n",
      "794 all_collections/Introduction to spiking neural networks: Information processing, learning and applications.pdf\n",
      "Found: References 39669\n",
      "795 all_collections/Federated Class-Incremental Learning.pdf\n",
      "Found: References 45786\n",
      "796 all_collections/Trend following algorithms in automated derivatives market trading.pdf\n",
      "Found: References 61517\n",
      "797 all_collections/Natural Language Based Financial Forecasting: A Survey.pdf\n",
      "Found: References 235774\n",
      "798 all_collections/Adaptive Resonance Theory: How a brain learns to consciously attend, learn, and recognize a changing world.pdf\n",
      "??????????\n",
      "799 all_collections/How (not) to use Machine Learning for time series forecasting_ Avoiding the pitfalls _ by Vegard Flovik _ Towards Data Science.pdf\n",
      "Found: References 22645\n",
      "800 all_collections/Evolving Deep Unsupervised Convolutional Networks for Vision-Based Reinforcement Learning.pdf\n",
      "Found: References 26311\n",
      "801 all_collections/Algorithmic Trading Using Deep Neural Networks on High Frequency Data.pdf\n",
      "??????????\n",
      "802 all_collections/2017 - Deep Direct Reinforcement Learning for Financial Signal Representation and Trading.pdf\n",
      "Found: REFERENCES 38667\n",
      "803 all_collections/Paper_106-Predicting_Stock_Closing_Prices_in_Emerging_Markets.pdf\n",
      "Found: REFERENCES 45138\n",
      "804 all_collections/NEURO-SYMBOLIC PROGRAM SYNTHESIS.pdf\n",
      "Found: REFERENCES 5065\n",
      "805 all_collections/STOCK MARKET FORECASTING BASED ON  ARTIFICIAL INTELLIGENCE TECHNOLOGY.pdf\n",
      "Found: References 14650\n",
      "806 all_collections/Twitter Sentiment Analysis for Predicting Stock Price Movements.pdf\n",
      "Found: References 7728\n",
      "807 all_collections/Manifold Learning Python _ Introduction to Python Manifold Learning algorithms.pdf\n",
      "Found: REFERENCES 18119\n",
      "808 all_collections/Survey of stock market prediction using machine learning approach.pdf\n",
      "Found: References 35828\n",
      "809 all_collections/Towards global optimization with adaptive simulated annealing.pdf\n",
      "Found: References 52113\n",
      "810 all_collections/A review on classification of imbalanced data for wireless sensor networks.pdf\n",
      "Found: References 35940\n",
      "811 all_collections/An automated FX trading system using adaptive reinforcement learning.pdf\n",
      "Found: References 100488\n",
      "812 all_collections/REVIEW OF AUTOMATED TIME SERIES FORECASTING PIPELINES.pdf\n",
      "Found: References 106266\n",
      "813 all_collections/Machine Learning Methods in Finance Recent Applications and Prospects.pdf\n",
      "Found: References 24328\n",
      "814 all_collections/Encoding Temporal Markov Dynamics in Graph for Visualizing and Mining Time Series.pdf\n",
      "Found: References 52024\n",
      "815 all_collections/Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting.pdf\n",
      "??????????\n",
      "816 all_collections/Stock price prediction using feature engineering and machine learning Techniques.pdf\n",
      "Found: REFERENCES 22300\n",
      "817 all_collections/A Survey on Stock Market Prediction.pdf\n",
      "Found: References 27799\n",
      "818 all_collections/An Effective Method for Imbalanced Time Series Classification: Hybrid Sampling.pdf\n",
      "Found: References 87861\n",
      "819 all_collections/Heuristic Methods for Evolutionary Computation Techniques.pdf\n",
      "Found: References 4721\n",
      "820 all_collections/Data Normalization and Standardization A Technical Report.pdf\n",
      "Found: References 10080\n",
      "821 all_collections/Tpot AutoML - GeeksforGeeks.pdf\n",
      "Found: References 60813\n",
      "822 all_collections/The Likelihood of Various Stock Market Return Distributions, Part 2: Empirical Results.pdf\n",
      "Found: References 55793\n",
      "823 all_collections/Pattern Learning and Recognition on Statistical Manifolds: An Information-Geometric Review.pdf\n",
      "Found: REFERENCES 36934\n",
      "824 all_collections/An Introduction to Genetic Algorithms and  Evolution Strategies.pdf\n",
      "??????????\n",
      "825 all_collections/A Daily A-D New High- New Low Market System.pdf\n",
      "Found: References 73451\n",
      "826 all_collections/Machine learning advances for time series.pdf\n",
      "Found: References 94256\n",
      "827 all_collections/An overview on the roles of fuzzy set techniques in big data processing: Trends, challenges and opportunities .pdf\n",
      "??????????\n",
      "828 all_collections/Text Classification with Python and Scikit-Learn.pdf\n",
      "Found: References 160\n",
      "829 all_collections/Financial Market Randomness.pdf\n",
      "??????????\n",
      "830 all_collections/Cross-validation and the Bootstrap.pdf\n",
      "??????????\n",
      "831 all_collections/Agent-based Computational Economic Models.pdf\n",
      "Found: References 69613\n",
      "832 all_collections/A Comparative Study of Technical Trading Strategies  Using Genetic Algorithm.pdf\n",
      "??????????\n",
      "833 all_collections/Time Series Data Wrangling • timetk.pdf\n",
      "??????????\n",
      "834 all_collections/New Concepts in Technical Trading Systems (Welles J. Wilder).pdf\n",
      "??????????\n",
      "835 all_collections/Evolving Reinforcement Learning Agents Using Genetic Algorithms _ by Mohammad Abdin _ Level Up Coding.pdf\n",
      "??????????\n",
      "836 all_collections/UDPrice Change Indicator by Dennis Meyers.pdf\n",
      "Found: REFERENCES 52137\n",
      "837 all_collections/Deep Reinforcement Learning for Portfolio Optimization using Latent Feature State Space (LFSS) Module.pdf\n",
      "??????????\n",
      "838 all_collections/Computational intelligence and financial markets: A survey and future directions.pdf\n",
      "Found: References 34327\n",
      "839 all_collections/Stock Market Trend Prediction Model Using Data Mining Techniques.pdf\n",
      "Found: References 42784\n",
      "840 all_collections/Robust subspace segmentation via nonconvex low rank representation.pdf\n",
      "??????????\n",
      "841 all_collections/Create custom gym environments from scratch — A stock market example _ by Adam King _ Towards Data Science.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: References 34349\n",
      "842 all_collections/Learning Transferable Architectures for Scalable Image Recognition.pdf\n",
      "??????????\n",
      "843 all_collections/Predicting Stock Price Trend Using Candlestick Chart Blending Technique_2018.pdf\n",
      "Found: References 70195\n",
      "844 all_collections/Embodied intelligence via learning and evolution.pdf\n",
      "Found: REFERENCES 46720\n",
      "845 all_collections/Trading with the Momentum Transformer: An Intelligent and Interpretable Architecture.pdf\n",
      "Found: References 18925\n",
      "846 all_collections/Evolving Trading Strategies With Genetic Programming - Data.pdf\n",
      "Found: References 13818\n",
      "847 all_collections/Nature-Inspired Algorithms as a Part of the Biomimetic Architecture: A Brief Discussion.pdf\n",
      "Found: References 111862\n",
      "848 all_collections/On the Automated, Evolutionary Design of Neural Networks-Past, Present, and Future.pdf\n",
      "Found: References 73388\n",
      "849 all_collections/A Machine Learning Approach to Automated Trading.pdf\n",
      "Found: References 38779\n",
      "850 all_collections/Machine learning approaches for financial time series forecasting.pdf\n",
      "??????????\n",
      "851 all_collections/A Review of Stock Market Prediction Using Neural Network.pdf\n",
      "??????????\n",
      "852 all_collections/TASC Issue February 2022 Traders Tips - Elegant Oscillator.pdf\n",
      "??????????\n",
      "853 all_collections/Fuzzy adaptive learning control network with policy and another adaptive resonance theory (FALCON‑PAART) embedded deep structure with applications in stock market prediction and analysis.pdf\n",
      "Found: References 19991\n",
      "854 all_collections/Comparison of Stock Price Prediction Models using Pre-trained Neural Networks.pdf\n",
      "??????????\n",
      "855 all_collections/Automated Machine Learning (AutoML) Libraries for Python.pdf\n",
      "Found: REFERENCES 65161\n",
      "856 all_collections/Anomaly Detection of Time Series With Smoothness-Inducing Sequential Variational Auto-Encoder .pdf\n",
      "Found: REFERENCES 57678\n",
      "857 all_collections/Unsupervised Classification and Network Analysis of the Reddit Communities with Spiking Neural Network and Exponential-Family Random Graph Model.pdf\n",
      "??????????\n",
      "858 all_collections/Attentive Neural Models for Algorithmic Trading.pdf\n",
      "??????????\n",
      "859 all_collections/Predicting class-imbalanced business risk using resampling, regularization, and model ensembling algorithms .pdf\n",
      "Found: REFERENCES 72722\n",
      "860 all_collections/High-frequency Trading new realities for traders markets and regulators.pdf\n",
      "Found: References 87747\n",
      "861 all_collections/A real-time adaptive trading system using genetic programming.pdf\n",
      "??????????\n",
      "862 all_collections/Can Reinforcement learning be applied for time series forecasting_ - Data Science Stack Exchange.pdf\n",
      "Found: References 34535\n",
      "863 all_collections/LSTM-DDPG for Trading with Variable Positions.pdf\n",
      "Found: References 33273\n",
      "864 all_collections/A Survey of Machine Learning Approaches and Techniques for Student Dropout Prediction.pdf\n",
      "??????????\n",
      "865 all_collections/Using Deep Learning to Predict the Stock Market.pdf\n",
      "Found: References 32852\n",
      "866 all_collections/CARTMAP: a neural network method for automated feature selection.pdf\n",
      "Found: References 112375\n",
      "867 all_collections/Deep Learning for Financial Applications : A Survey.pdf\n",
      "Found: REFERENCES 43697\n",
      "868 all_collections/ART 2-A: An adaptive resonance algorithm for rapid category learning and recognition.pdf\n",
      "??????????\n",
      "869 all_collections/An Automatic Stock Trading System using.pdf\n",
      "??????????\n",
      "870 all_collections/Stock Prediction with ML_ Feature Engineering — The Alpha Scientist.pdf\n",
      "??????????\n",
      "871 all_collections/ROUGH SETS - Theoretical Aspects of Reasoning about Data .pdf\n",
      "Found: REFERENCES 24459\n",
      "872 all_collections/Improving Deep Reinforcement learning for financial trading using deep adaptive group-based nomalization.pdf\n",
      "Found: References 31140\n",
      "873 all_collections/Representation Learning with Deconvolution for Multivariate Time Series Classification and Visualization.pdf\n",
      "??????????\n",
      "874 all_collections/CRAN Task View_ Machine Learning & Statistical Learning.pdf\n",
      "Found: References 51132\n",
      "875 all_collections/COSMOS trader - Chaotic Neuro-oscillatory multiagent financial prediction and trading system.pdf\n",
      "Found: REFERENCES 29867\n",
      "876 all_collections/Deep Adaptive Input Normalization for Time Series Forecasting.pdf\n",
      "Found: References 22334\n",
      "877 all_collections/An ART-Based Fuzzy Adaptive Learning Control Network.pdf\n",
      "Found: REFERENCES 117991\n",
      "878 all_collections/a-tutorial-survey-of-architectures-algorithms-and-applications-for-deep-learning.pdf\n",
      "??????????\n",
      "879 all_collections/Project Proposal.pdf\n",
      "Found: REFERENCES 41317\n",
      "880 all_collections/Predicting Stock Market Trends Using Machine.pdf\n",
      "??????????\n",
      "881 all_collections/100 to 1 in the stock market_ A distinguished security analyst tells how to make more of your investment opportunities.pdf\n",
      "Found: REFERENCES 24917\n",
      "882 all_collections/Imbalanced Time Series Data Classification Using  Oversampling Technique .pdf\n",
      "Found: References 15205\n",
      "883 all_collections/A Financial Trading System using  Rough set Classifier.pdf\n",
      "Found: References 22264\n",
      "884 all_collections/Compound Reinforcement Learning: Theory and An Application to Finance.pdf\n",
      "??????????\n",
      "885 all_collections/Portfolio Optimization using Particle Swarm Optimization.pdf\n",
      "Found: REFERENCES 35818\n",
      "886 all_collections/Selective oversampling approach for strongly imbalanced data .pdf\n",
      "Found: References 911\n",
      "887 all_collections/Frontiers _ BindsNET_ A Machine Learning-Oriented Spiking Neural Networks Library in Python _ Frontiers in Neuroinformatics.pdf\n",
      "Found: References 54217\n",
      "888 all_collections/Review of Meta-Heuristic Optimization based Artificial Neural Networks and its Applications.pdf\n",
      "??????????\n",
      "889 all_collections/Artificial intelligence and machine learning in financial services.pdf\n",
      "Found: References 43675\n",
      "890 all_collections/A systematic study of the class imbalance problem in convolutional neural networks.pdf\n",
      "??????????\n",
      "891 all_collections/Monte Carlo K-Means Clustering of Countries.pdf\n",
      "??????????\n",
      "892 all_collections/On the Structure of Rough Sets.pdf\n",
      "??????????\n",
      "893 all_collections/Paper_42-A_New_Particle_Swarm_Optimization_Based_Stock_Market_Prediction_Technique.pdf\n",
      "Found: References 25679\n",
      "894 all_collections/The use of technical analysis in the foreign exchange market.pdf\n",
      "??????????\n",
      "895 all_collections/Capsule Networks or CNNs_ Which is best for stock predictions_ — Neuravest.pdf\n",
      "Found: References 413\n",
      "896 all_collections/Biomimetic algorithms.pdf\n",
      "Found: References 33103\n",
      "897 all_collections/A TSK type fuzzy rule based system for stock price prediction.pdf\n",
      "Found: REFERENCES 57743\n",
      "898 all_collections/Stock Trend Prediction Using Candlestick Charting and Ensemble Machine Learning Techniques with a Novelty Feature Engineering Scheme.pdf\n",
      "Found: REFERENCES 48320\n",
      "899 all_collections/Structured Manifold Broad Learning System: A Manifold Perspective for Large-Scale Chaotic Time Series Analysis and Prediction.pdf\n",
      "Found: References 74467\n",
      "900 all_collections/Predicting Stock Market.pdf\n",
      "??????????\n",
      "901 all_collections/The Optimization Process- An example of portfolio optimization.pdf\n",
      "Found: References 56284\n",
      "902 all_collections/Volume weighted volatility: empirical evidence for a new realised volatility measure.pdf\n",
      "Found: REFERENCES 43818\n",
      "903 all_collections/Deep-Reinforcement-Learning-for-Trading.pdf\n",
      "??????????\n",
      "904 all_collections/4 Python AutoML Libraries Every Data Scientist Should Know _ by Andre Ye _ Towards Data Science.pdf\n",
      "Found: REFERENCES 32597\n",
      "905 all_collections/deep-learning-for-the-prediction-of-stockmarket-trends.pdf\n",
      "??????????\n",
      "906 all_collections/Clustering using Ant Colony Optimization.pdf\n",
      "Found: REFERENCES 32509\n",
      "907 all_collections/Classification and Clustering of Stocks, using Genetic Algorithms and .pdf\n",
      "Found: REFERENCES 93668\n",
      "908 all_collections/News sensitive stock market prediction: literature review and suggestions.pdf\n",
      "Found: References 31383\n",
      "909 all_collections/Transformer-Based Capsule Network For Stock Movements Prediction.pdf\n",
      "??????????\n",
      "910 all_collections/Neural networks for algorithmic trading. Volatility forecasting and custom loss functions _ by Alexandr Honchar _ codeburst.pdf\n",
      "Found: REFERENCES 59590\n",
      "911 all_collections/Financial Data Scicence.pdf\n",
      "Found: REFERENCES 40047\n",
      "912 all_collections/ST_Norm__Spatial_and_Temporal_Normalization_for_Multi_variate_Time_Series_Forecasting_camera ready version.pdf\n",
      "Found: References 26736\n",
      "913 all_collections/Reinforcement Learning Algorithms: Survey and Classifications.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: REFERENCES 41744\n",
      "914 all_collections/FinRL-Podracer: High Performance and Scalable Deep Reinforcement Learning for Quantitative Finance.pdf\n",
      "??????????\n",
      "915 all_collections/Introduction to Deep Reinforcement Learning _ by Nimish Sanghi _ Geek Culture _ Medium.pdf\n",
      "Found: REFERENCES 46794\n",
      "916 all_collections/Online Traffic Prediction in the Cloud.pdf\n",
      "Found: References 65120\n",
      "917 all_collections/Model‑free detection of unique  event time series.pdf\n",
      "Found: REFERENCES 39441\n",
      "918 all_collections/EMPIRICAL DISTRIBUTION OF STOCK .pdf\n",
      "Found: References 12871\n",
      "919 all_collections/FinRL-Meta: A Universe of Near-Real Market Environments for Data-Driven Deep Reinforcement Learning in Quantitative Finance.pdf\n",
      "Found: References 2893\n",
      "920 all_collections/Deep learning-based feature engineering for stock price movement prediction.pdf\n",
      "Found: References 30683\n",
      "921 all_collections/Neurons and Symbols: A Manifesto.pdf\n",
      "Found: REFERENCES 47536\n",
      "922 all_collections/Evaluating Temporal Bias in Time Series Event Detection Methods.pdf\n",
      "??????????\n",
      "923 all_collections/TPOT_ Automating Machine Learning Process _ by Himanshu Sharma _ MLearning.ai _ Medium.pdf\n",
      "Found: References 9826\n",
      "924 all_collections/Improving Reinforcement Learning Function Approximators via Neuroevolution.pdf\n",
      "Found: References 17365\n",
      "925 all_collections/Cross-validation.pdf\n",
      "Found: References 24701\n",
      "926 all_collections/A Sliding Window Filter for Time Series Streams.pdf\n",
      "Found: References 32890\n",
      "927 all_collections/Big self-supervised models are strong semi-supervised learners.pdf\n",
      "Found: References 46682\n",
      "928 all_collections/Machine Learning for Trading - What Does it Really Look Like_.pdf\n",
      "Found: References 16017\n",
      "929 all_collections/Multivariate time series prediction of high dimensional data based on deep reinforcement learning.pdf\n",
      "Found: References 40717\n",
      "930 all_collections/Machine learning techniques and data for stock market forecasting: A literature review .pdf\n",
      "??????????\n",
      "931 all_collections/HANDBOOK of Robust Low-rank and Sparse Matrix Decomposition.pdf\n",
      "Found: References 9373\n",
      "932 all_collections/Instance Normalization: The Missing Ingredient for Fast Stylization.pdf\n",
      "Found: References 31128\n",
      "933 all_collections/Machine Learning Approaches in Stock Price Prediction: A Systematic Review.pdf\n",
      "Found: REFERENCES 29670\n",
      "934 all_collections/Adaptive Normalization in Streaming Data.pdf\n",
      "??????????\n",
      "935 all_collections/Effective Approaches for Time Series Anomaly Detection _ by Aditya Bhattacharya _ Towards Data Science.pdf\n",
      "??????????\n",
      "936 all_collections/Natural Language Processing and Event-driven Stock Prediction.pdf\n",
      "Found: REFERENCES 16223\n",
      "937 all_collections/ADAPTIVE RESONANCE THEORY.pdf\n",
      "Found: REFERENCES 34167\n",
      "938 all_collections/A COLLABORATIVE ATTENTION ADAPTIVE NETWORK FOR FINANCIAL MARKET FORECASTING.pdf\n",
      "Found: REFERENCES 14873\n",
      "939 all_collections/Stock Market Prediction Using Data Mining Techniques.pdf\n",
      "Found: References 52187\n",
      "940 all_collections/Applications of Genetic Programming to Finance and Economics: Past, Present, Future.pdf\n",
      "??????????\n",
      "941 all_collections/Stock Market Trend Prediction Using High-order Information of Time Series.pdf\n",
      "??????????\n",
      "942 all_collections/Multivariate Time Series Forecasting with Transformers _ by Jake Grigsby _ Towards Data Science.pdf\n",
      "Found: REFERENCES 28506\n",
      "943 all_collections/Application of SVM-KNN using SVR as feature selection on stock analysis for Indonesia stock exchange.pdf\n",
      "??????????\n",
      "944 all_collections/Neuroevolution for Deep Reinforcement Learning Problems 2018.pdf\n",
      "Found: REFERENCES 18671\n",
      "945 all_collections/VLSTM: VERY LONG SHORT-TERM MEMORY NETWORKS FOR HIGH-FREQUENCY TRADING.pdf\n",
      "Found: References 33944\n",
      "946 all_collections/NONLINEAR DYNAMICS AND THE DISTRIBUTION OF DAILY STOCK INDEX RETURNS.pdf\n",
      "??????????\n",
      "947 all_collections/A Study of the ISOMAP Algorithm and Its Applications in Machine Learning.pdf\n",
      "??????????\n",
      "948 all_collections/A Study On Financial Time Series Forecasting And Symbolic Regression By Means Of A Hybrid Probabilistic Model-Building Cartesian Genetic Programming Methodology.pdf\n",
      "??????????\n",
      "949 all_collections/Provable Algorithms for Scalable and Robust Low-Rank Matrix Recovery.pdf\n",
      "??????????\n",
      "950 all_collections/Algorithmic Trading with Stochastic Oscillator in Python _ by Nikhil Adithyan _ CodeX _ Medium.pdf\n",
      "Found: REFERENCES 60072\n",
      "951 all_collections/Point Pattern Search in Big Data.pdf\n",
      "Found: References 31550\n",
      "952 all_collections/Discovering Stock Price Prediction Rules Using Rough Sets.pdf\n",
      "??????????\n",
      "953 all_collections/Analysis of the Predictive Ability of Time Delay Neural networks applied to the S&P 500 time series.pdf\n",
      "??????????\n",
      "954 all_collections/The Composite Index Strategy. Creating a Strategy on the S&P500 Using… | by Sofien Kaabar, CFA | Apr, 2022 | Medium.pdf\n",
      "Found: References 513364\n",
      "955 all_collections/Every Man a Speculator.pdf\n",
      "Found: References 37319\n",
      "956 all_collections/Adaptive Structure Learning for Low-rank Supervised Feature Selection.pdf\n",
      "??????????\n",
      "957 all_collections/Using LSTM Network to Predict Stock Prices.pdf\n",
      "??????????\n",
      "958 all_collections/Stock Price Prediction with Deep Learning Framework.pdf\n",
      "Found: References 27199\n",
      "959 all_collections/A Fuzzy Logic based Trend Impact Analysis method.pdf\n",
      "Found: REFERENCES 35191\n",
      "960 all_collections/A Review on Data Mining Applications to the Performance of Stock Marketing.pdf\n",
      "Found: REFERENCES 100262\n",
      "961 all_collections/Artificial Intelligence and Deep Reinforcement Learning Stock Market Predictions.pdf\n",
      "Found: References 40147\n",
      "962 all_collections/Genetic Algorithms on Technical Trading Rules.pdf\n",
      "Found: References 12276\n",
      "963 all_collections/TRADING MECHANISMS FOR FINANCIAL EXCHANGES.pdf\n",
      "Found: REFERENCES 41781\n",
      "964 all_collections/FinRL_ Deep Reinforcement Learning Framework to Automate Trading in Quantitative Finance.pdf\n",
      "Found: References 27059\n",
      "965 all_collections/Latent Segmentation of Stock Trading Strategies Using Multi-Modal Imitation Learning.pdf\n",
      "Found: REFERENCES 79428\n",
      "966 all_collections/DATA_MINING_A_CONCEPTUAL_OVERVIEW.pdf\n",
      "Found: References 8311\n",
      "967 all_collections/Evolving Trading Strategies With Genetic Programming - Punishing Complexity · Fabian Kostadinov.pdf\n",
      "??????????\n",
      "968 all_collections/Structure-Constrained Low-Rank Representation.pdf\n",
      "??????????\n",
      "969 all_collections/5 Frameworks for Reinforcement Learning on Python _ by Mauricio Fadel Argerich _ Towards Data Science.pdf\n",
      "Found: REFERENCES 6463\n",
      "970 all_collections/Less is more_ Beating the market with recurrent reinforcement learning.pdf\n",
      "Found: References 34307\n",
      "971 all_collections/Recent Advances in Deep Reinforcement Learning Applications.pdf\n",
      "??????????\n",
      "972 all_collections/Artificial Intelligence Innovation in Financial Services.pdf\n",
      "Found: References 28136\n",
      "973 all_collections/Using Deep Learning Neural Networks and Candlestick Chart Representation to Predict Stock Market.pdf\n",
      "Found: References 32952\n",
      "974 all_collections/Comprehensive Review of Deep Reinforcement Learning Methods and Applications in Economics.pdf\n",
      "??????????\n",
      "975 all_collections/Technical Analysis of Stock Trends Explained An Easy-to-Understand System for Successful Trading (Michael Thomsett).pdf\n",
      "Found: References 56016\n",
      "976 all_collections/THE DISTRIBUTION OF STOCK MARKET RETURNS AND THE MARKET MODEL*.pdf\n",
      "Found: REFERENCES 24866\n",
      "977 all_collections/A rough set theory based predictive model for stock prices.pdf\n",
      "Found: References 12763\n",
      "978 all_collections/Financial_time_series_forecasting_with_machine_learning_techniques.pdf\n",
      "Found: REFERENCES 7141\n",
      "979 all_collections/OPTIMIZATION OF TECHNICAL TRADING RULES IN FOREX MARKET USING GENETIC ALGORITHM.pdf\n",
      "Found: References 48633\n",
      "980 all_collections/Introduction to Fuzzy Systems, Neural Networks, and Genetic Algorithms (Hideyuki T.) (z-lib.org).pdf\n",
      "Found: References 26566\n",
      "981 all_collections/Threshold Recurrent Reinforcement Learning.pdf\n",
      "Found: References 68707\n",
      "982 all_collections/Self-Supervised ARTMAP.pdf\n",
      "??????????\n",
      "983 all_collections/rough set-based neuro-fuzzy approach.pdf\n",
      "Found: References 2250\n",
      "984 all_collections/Arti!cial Intelligence in Finance.pdf\n",
      "Found: REFERENCES 45412\n",
      "985 all_collections/Designing safe, profitable automated stock trading agents using evolutionary algorithms.pdf\n",
      "Found: References 40488\n",
      "986 all_collections/A Novel Deep Reinforcement Learning Based Stock Direction Prediction using Knowledge Graph and Community Aware Sentiments .pdf\n",
      "Found: REFERENCES 37026\n",
      "987 all_collections/Cost-Sensitive Deep Learning with Layer-Wise Cost Estimation.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "988 all_collections/Support-Vector-Based Fuzzy Neural Network for Pattern Classification.pdf\n",
      "??????????\n",
      "989 all_collections/The future of algo trading_ Using deep learning to more accurately predict equity market volumes - WatersTechnology.com.pdf\n",
      "??????????\n",
      "990 all_collections/Sharpen Your Trading with the Fisher Transform.pdf\n",
      "Found: References 9412\n",
      "991 all_collections/Transfer Learning in Natural Language Processing Tutorial.pdf\n",
      "Found: References 10285\n",
      "992 all_collections/Technical and Fundamental Features’ analysis for Stock Market Prediction with Data Mining Methods .pdf\n",
      "Found: References 41867\n",
      "993 all_collections/Deep+Learning+and+Time+Series-to-Image+Encoding+for+Financial+Forecasting.pdf\n",
      "Found: References 48212\n",
      "994 all_collections/Deep Learning Based Anomaly Detection for Muti-dimensional Time Series: A Survey.pdf\n",
      "??????????\n",
      "995 all_collections/Deep Learning for Time Series Forecasting_ A Survey _ Big Data.pdf\n",
      "Found: References 45558\n",
      "996 all_collections/Game Theory-Inspired Evolutionary Algorithm for Global Optimization.pdf\n",
      "Found: References 36194\n",
      "997 all_collections/Multiscaled Cross-Correlation Dynamics in Financial Time-Series.pdf\n",
      "Found: References 17612\n",
      "998 all_collections/Feature Selection for Stock Market Analysis .pdf\n",
      "??????????\n",
      "999 all_collections/Overview of Neural Architecture Search _ Paperspace Blog.pdf\n",
      "??????????\n",
      "1000 all_collections/7 Applications of Reinforcement Learning in Finance and Trading - neptune.ai.pdf\n",
      "Found: REFERENCES 31893\n",
      "1001 all_collections/Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy.pdf\n",
      "Found: References 16183\n",
      "1002 all_collections/Application of Deep Convolutional networks applied to Portfolio Optimization.pdf\n",
      "??????????\n",
      "1003 all_collections/Genetic Algorithms in Search, Optimization, and Machine Learning.pdf\n",
      "Found: References 61412\n",
      "1004 all_collections/COSMOS Trader – Chaotic Neuro-oscillatory Multiagent Financial Prediction and Trading System.pdf\n",
      "??????????\n",
      "1005 all_collections/Technical Analysis of the Financial Markets A Comprehensive Guide to Trading Methods and Applications (John J. Murphy).pdf\n",
      "Found: REFERENCES 39608\n",
      "1006 all_collections/Stock Market Prediction Using Machine Learning Algorithms.pdf\n",
      "Found: References 48586\n",
      "1007 all_collections/A Novel Trading Strategy Framework Based on Reinforcement Deep Learning for Financial Market Predictions.pdf\n",
      "Found: References 83322\n",
      "1008 all_collections/Deep learning in the stock market—a systematic survey.pdf\n",
      "Found: References 54145\n",
      "1009 all_collections/Impact_of_Data_Normalization_on_Stock_Index_Forecasting.pdf\n",
      "Found: References 71601\n",
      "1010 all_collections/Technical analysis based on high and low stock prices forecasts: evidence for Brazil using a fractionally cointegrated VAR model.pdf\n",
      "??????????\n",
      "1011 all_collections/Using Genetic Algorithms to Build Trading Strategies _ by Victor Sim _ Towards Data Science.pdf\n",
      "??????????\n",
      "1012 all_collections/Z Misc -- Predicting Stock Prices using Reinforcement Learning.pdf\n",
      "Found: REFERENCES 28788\n",
      "1013 all_collections/A survey of Game Theory using Evolutionary Algorithms.pdf\n",
      "Found: References 25314\n",
      "1014 all_collections/Deep Reinforcement Learning with Spiking Q-learning.pdf\n",
      "Found: REFERENCES 58833\n",
      "1015 all_collections/AlphaStock_ A Buying-Winners-and-Selling-Losers Investment Strategy using Interpretable Deep Reinforcement Attention Networks.pdf\n",
      "Found: References 65321\n",
      "1016 all_collections/A Survey on Spiking Neural Networks.pdf\n",
      "Found: References 5717\n",
      "1017 all_collections/Rough Set.pdf\n",
      "Found: References 34093\n",
      "1018 all_collections/Using Rough Set to Support Investment Strategies of Rule-Based Trading with Real-Time Data in Futures Market.pdf\n",
      "??????????\n",
      "1019 all_collections/Time Series_ An Overview and a Quick History - Practical Time Series Analysis [Book].pdf\n",
      "Found: References 42161\n",
      "1020 all_collections/Deep_Learning_and_Time_Series_to_Image_Encoding for Financial Forecasting.pdf\n",
      "Found: REFERENCES 23203\n",
      "1021 all_collections/Stock Market Prediction and Investment using Deep Reinforcement Learning- a Continuous  .pdf\n",
      "Found: REFERENCES 16863\n",
      "1022 all_collections/Clustering Analysis of Stocks of CSI 300 Index Based on Manifold Learning.pdf\n",
      "Found: REFERENCES 22424\n",
      "1023 all_collections/Using Reinforcement Learning in the Algorithmic Trading Problem.pdf\n",
      "Found: References 9322\n",
      "1024 all_collections/Artificial-intelligence-machine-learning-big-data-in-finance.pdf\n",
      "??????????\n",
      "1025 all_collections/Sparse Coding with Overcomplete Basis Set.pdf\n",
      "??????????\n",
      "1026 all_collections/Machine Learning for Trading_ Part 2 - Robot Wealth.pdf\n",
      "Found: References 61633\n",
      "1027 all_collections/A Systematic Literature Review of the Successors of “NeuroEvolution of Augmenting Topologies”.pdf\n",
      "Found: REFERENCES 63021\n",
      "1028 all_collections/Cost-Sensitive Learning of Deep Feature Representations from Imbalanced Data.pdf\n",
      "Found: References 11508\n",
      "1029 all_collections/Market Forecasting and Trading Rules  Based on Soft Computing Technologies .pdf\n",
      "Found: References 31132\n",
      "1030 all_collections/Deep Learning for Portfolio Optimization 2.pdf\n",
      "??????????\n",
      "1031 all_collections/Measures of Risk-adjusted Return.pdf\n",
      "Found: REFERENCES 24654\n",
      "1032 all_collections/Particle Swarm Optimization.pdf\n",
      "Found: REFERENCES 35128\n",
      "1033 all_collections/A Review on Data Mining Applications to the .pdf\n",
      "Found: References 25119\n",
      "1034 all_collections/DECISION-MAKING MODEL FOR STOCK MARKETS BASED ON PARTICLE SWARM OPTIMIZATION ALGORITHM.pdf\n",
      "Found: References 859\n",
      "1035 all_collections/Time-Series Forecasting_ NeuralProphet vs AutoML _ Towards Data Science.pdf\n",
      "??????????\n",
      "1036 all_collections/Stock Market Forecasting using Machine Learning Algorithms.pdf\n",
      "Found: References 13689\n",
      "1037 all_collections/On Generalizing Rough Set Theory.pdf\n",
      "??????????\n",
      "1038 all_collections/Hands-On Reinforcement Learning with Python_ Master reinforcement and deep reinforcement learning using OpenAI Gym and TensorFlow.pdf\n",
      "Found: References 43884\n",
      "1039 all_collections/Using Deep Learning for price prediction by exploiting stationary limit order book features.pdf\n",
      "??????????\n",
      "1040 all_collections/Using Data Mining to Study Upstream and Downstream Causal Relationship in Stock Market.pdf\n",
      "Found: References 89027\n",
      "1041 all_collections/Hyper-Heuristics based on Reinforcement Learning, Balanced Heuristic Selection and Group Decision Acceptance.pdf\n",
      "Found: References 37106\n",
      "1042 all_collections/DeepTrader_ A Deep Reinforcement Learning Approach for Risk-Return Balanced Portfolio Management with Market Conditions Embedding.pdf\n",
      "Found: REFERENCES 23156\n",
      "1043 all_collections/Deterministic Column-Based Matrix Decomposition.pdf\n",
      "Found: References 9922\n",
      "1044 all_collections/Against the Norm: Modeling Daily Stock.pdf\n",
      "??????????\n",
      "1045 all_collections/First steps before applying reinforcement learning for trading _ by Alexandr Honchar _ Geek Culture _ Medium.pdf\n",
      "Found: References 36902\n",
      "1046 all_collections/An LSTM and GRU based trading strategy adapted to the Moroccan market.pdf\n",
      "Found: References 35141\n",
      "1047 all_collections/Time-series forecasting with deep learning: a survey.pdf\n",
      "Found: References 29663\n",
      "1048 all_collections/Attention Is All You Need.pdf\n",
      "??????????\n",
      "1049 all_collections/Fidelity Learning Center_ Technical Analysis Indicator Guide -002.pdf\n",
      "??????????\n",
      "1050 all_collections/The use of heuristics to speedup Reinforcement Learning.pdf\n",
      "Found: REFERENCES 21067\n",
      "1051 all_collections/Mining_the_stock_market_Which_measure_is_best.pdf\n",
      "Found: REFERENCES 44083\n",
      "1052 all_collections/Journal of Financial Data Science - Winter 2019.pdf\n",
      "Found: References 19825\n",
      "1053 all_collections/Prediction Models for Indian Stock Market.pdf\n",
      "Found: References 31123\n",
      "1054 all_collections/Dynamic Routing Between Capsules.pdf\n",
      "Found: REFERENCES 38147\n",
      "1055 all_collections/Simpful: A User-Friendly Python Library for Fuzzy Logic.pdf\n",
      "Found: References 28878\n",
      "1056 all_collections/Poisson Model of Spike Generation.pdf\n",
      "Found: References 63183\n",
      "1057 all_collections/A Reversible Automatic Selection Normalization (RASN) Deep Network for Predicting in the Smart Agriculture System.pdf\n",
      "??????????\n",
      "1058 all_collections/Spike timing-dependent plasticity- A hebbian learning rule.pdf\n",
      "Found: REFERENCES 43455\n",
      "1059 all_collections/DeepLine: AutoML Tool for Pipelines Generation using Deep Reinforcement Learning and Hierarchical Actions Filtering.pdf\n",
      "Found: References 28106\n",
      "1060 all_collections/Deep Deterministic Portfolio Optimization.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "1061 all_collections/Create custom gym environments from scratch — A stock market example _ by Adam King _ Towards Data Science (1).pdf\n",
      "Found: References 54487\n",
      "1062 all_collections/Continuous Control with Stacked Deep Dynamic Recurrent Reinforcement Learning for Portfolio Optimization.pdf\n",
      "Found: References 16629\n",
      "1063 all_collections/Evolving Trading Strategies With Genetic Programming - Fitness Functions · Fabian Kostadinov.pdf\n",
      "Found: References 24766\n",
      "1064 all_collections/Instance Selection Using Genetic Algorithms for an Intelligent Ensemble Trading System .pdf\n",
      "Found: References 112471\n",
      "1065 all_collections/Qualities, challenges and future of genetic algorithms: a literature review.pdf\n",
      "Found: References 33076\n",
      "1066 all_collections/Deep Adaptive Group-based Input Normalization for Financial Trading.pdf\n",
      "Found: REFERENCES 45478\n",
      "1067 all_collections/Surfing The Linear Regression Curve . . . by Dennis Meyers, Ph.D_.pdf\n",
      "Found: References 42570\n",
      "1068 all_collections/A novel ensemble deep learning model for stock prediction based on stock prices and news.pdf\n",
      "Found: REFERENCES 75151\n",
      "1069 all_collections/Ebola_Optimization_Search_Algorithm_A_New_Nature-Inspired_Metaheuristic_Optimization_Algorithm.pdf\n",
      "??????????\n",
      "1070 all_collections/Automated stock trading using Deep Reinforcement Learning with Fundamental Indicators _ by Mariko Sawada _ Medium.pdf\n",
      "Found: References 33713\n",
      "1071 all_collections/Direct Training for Spiking Neural Networks: Faster, Larger, Better.pdf\n",
      "Found: References 22521\n",
      "1072 all_collections/An Introduction to Natural Computing in Finance.pdf\n",
      "??????????\n",
      "1073 all_collections/Overview of Machine Learning in Finance Applications.pdf\n",
      "Found: References 30278\n",
      "1074 all_collections/Stock Prediction on Japanese Candlestick Data.pdf\n",
      "Found: References 33397\n",
      "1075 all_collections/Sliding Window Algorithms for k-Clustering Problems.pdf\n",
      "Found: References 60382\n",
      "1076 all_collections/Transformers in Time-series Analysis: A Tutorial.pdf\n",
      "??????????\n",
      "1077 all_collections/My Dream Team of Technical Indicators _ by Sofien Kaabar, CFA _ Apr, 2022 _ Medium.pdf\n",
      "??????????\n",
      "1078 all_collections/Weekly Report.pdf\n",
      "Found: References 31704\n",
      "1079 all_collections/Optimizing Cost-Sensitive SVM for Imbalanced Data: Connecting Cluster to Classification.pdf\n",
      "Found: REFERENCES 37207\n",
      "1080 all_collections/Knowledge-Driven Stock Trend Prediction and Explanation via Temporal Convolutional Network.pdf\n",
      "??????????\n",
      "1081 all_collections/Articles by Sofien Kaabar’s Profile _ Medium, The Startup, Towards Data Science Journalist _ Muck Rack.pdf\n",
      "Found: References 87545\n",
      "1082 all_collections/Learning To Predict By The Methods Of  Temporal Differences.pdf\n",
      "Found: References 25513\n",
      "1083 all_collections/Risk, Reward & Reinforcement.pdf\n",
      "??????????\n",
      "1084 all_collections/Predicting Stock Movements Using LSTM.pdf\n",
      "Found: REFERENCES 24221\n",
      "1085 all_collections/Stock volatility forecasting using Swarm optimized Hybrid Network.pdf\n",
      "Found: REFERENCES 44736\n",
      "1086 all_collections/An Adaptive Financial Trading System Using Deep Reinforcement Learning with Candlestick.pdf\n",
      "Found: References 120962\n",
      "1087 all_collections/Deep Reinforcement Learning: A State-of-the-Art Walkthrough.pdf\n",
      "Found: REFERENCES 10890\n",
      "1088 all_collections/Predicting the Movement Direction of OMXS30 Stock Index Using XGBoost and Sentiment Analysis.pdf\n",
      "??????????\n",
      "1089 all_collections/Stock Trading With Recurrent Reinforcement Learning.pdf\n",
      "Found: References 29136\n",
      "1090 all_collections/Evolutionary_Tournament-Based_Comparison_of_Learni.pdf\n",
      "??????????\n",
      "1091 all_collections/Dynamic Routing between Capsules - A Study of Digit Recognition and Application to Time-Serie Classification Problem in Finance · selimamrouni.github.io.pdf\n",
      "??????????\n",
      "1092 all_collections/_ DB-201409-Seven_Sins_of_Quantitative_Investing.pdf\n",
      "Found: References 31627\n",
      "1093 all_collections/Machine Learning Strategies for Time Series Forecasting.pdf\n",
      "Found: References 17061\n",
      "1094 all_collections/Reinforcement Learning in Stock Trading.pdf\n",
      "??????????\n",
      "1095 all_collections/Neuroevolution_ A different kind of deep learning – O’Reilly.pdf\n",
      "Found: References 80497\n",
      "1096 all_collections/The Distribution of Returns.pdf\n",
      "Found: References 12742\n",
      "1097 all_collections/A Modified Particle Swarm Optimizer .pdf\n",
      "Found: References 166810\n",
      "1098 all_collections/Reinforcement Learning in Robotics.pdf\n",
      "Found: References 57252\n",
      "1099 all_collections/Predicting stock and stock price index movement using Trend Deterministic Data Preparation and machine learning techniques.pdf\n",
      "Found: References 88200\n",
      "1100 all_collections/Technological Links and Predictable Returns.pdf\n",
      "Found: References 105848\n",
      "1101 all_collections/Practical Machine Learning with H2O.pdf\n",
      "??????????\n",
      "1102 all_collections/Computational Learning Techniques for Intraday FX Trading Using Popular Technical Indicators.pdf\n",
      "Found: REFERENCES 30151\n",
      "1103 all_collections/PyGAD: An Intuitive Genetic Algorithm Python Library.pdf\n",
      "Found: REFERENCES 93668\n",
      "1104 all_collections/News sensitive stock market prediction:literature review and suggestions.pdf\n",
      "Found: REFERENCES 38667\n",
      "1105 all_collections/Predicting_Stock_Closing_Prices_in_Emerging_Markets Markets with Transformer Neural Networks: The Saudi Stock Exchange Case.pdf\n",
      "Found: REFERENCES 39872\n",
      "1106 all_collections/Library for Evolutionary Algorithms in Python (LEAP).pdf\n",
      "Found: References 21527\n",
      "1107 all_collections/A Data Organization Method for LSTM and Transformer When Predicting Chinese Banking Stock Prices.pdf\n",
      "Found: REFERENCES 30239\n",
      "1108 all_collections/An overview over Capsule Networks.pdf\n",
      "Found: References 22264\n",
      "1109 all_collections/Compound Reinforcement Learning:Theory and An Application to Finance.pdf\n",
      "Found: REFERENCES 39454\n",
      "1110 all_collections/TOWARD GLOBAL OPTIMIZATION OF NEURAL NETWORKS: A COMPARISON OF THE GENETIC ALGORITHM AND BACKPROPAGATION.pdf\n",
      "Found: REFERENCES 38334\n",
      "1111 all_collections/Deep Reinforcement Learning for Active High Frequency Trading.pdf\n",
      "??????????\n",
      "1112 all_collections/Basic Guide to Spiking Neural Networks for Deep Learning _ cnvrg.io.pdf\n",
      "Found: References 37808\n",
      "1113 all_collections/An Exploration of Simple Optimized Technical Trading  Strategies.pdf\n",
      "??????????\n",
      "1114 all_collections/Reinforcement Learning for Algorithm Trading.pdf\n",
      "Found: REFERENCES 27854\n",
      "1115 all_collections/Automated Machine Learning in Practice: State of the Art and Recent Results.pdf\n",
      "??????????\n",
      "1116 all_collections/Deep Reinforcement Learning for Trading_ Strategy Development & AutoML.pdf\n",
      "??????????\n",
      "1117 all_collections/Reinforcement learning in financial markets - a surve.pdf\n",
      "Found: REFERENCES 32378\n",
      "1118 all_collections/Beating the Stock Market with a Deep Reinforcement Learning Day Trading System.pdf\n",
      "Found: REFERENCES 41438\n",
      "1119 all_collections/Cost-sensitive Deep Learning for Early Readmission Prediction at A Major Hospital.pdf\n",
      "??????????\n",
      "1120 all_collections/Evolving Artificial Neural Networks.pdf\n",
      "Found: REFERENCES 14391\n",
      "1121 all_collections/Triumph of the Empiricists: The Birth of Financial Data Science.pdf\n",
      "Found: References 91792\n",
      "1122 all_collections/Recent Advances in Stock Market Prediction Using Text Mining: A Survey.pdf\n",
      "Found: References 39315\n",
      "1123 all_collections/Combination Method between Fuzzy Logic and  Neural Network Models to Predict Amman Stock Exchange.pdf\n",
      "??????????\n",
      "1124 all_collections/Foundations of Reinforcement Learning withApplications in Finance.pdf\n",
      "Found: References 33572\n",
      "1125 all_collections/Transformers in Time Series: A Survey.pdf\n",
      "Found: References 19681\n",
      "1126 all_collections/A Global Geometric Framework for Nonlinear Dimensionality Reduction.pdf\n",
      "Found: References 22042\n",
      "1127 all_collections/Advanced visualization techniques for time series analysis _ by Michaël HOARAU _ Towards Data Science.pdf\n",
      "Found: References 98253\n",
      "1128 all_collections/Scaling laws for autoregressive generative modeling.pdf\n",
      "Found: References 72425\n",
      "1129 all_collections/Machine Learning Classification and Regression Models for Predicting Directional Changes Trend Reversal in FX Markets.pdf\n",
      "Found: References 27144\n",
      "1130 all_collections/NEW APPROACHES OF INVERSE SOFT ROUGH SETS AND THEIR APPLICATIONS IN A DECISION MAKING PROBLEM.pdf\n",
      "Found: References 18641\n",
      "1131 all_collections/Fuzzy ARTMAP Based Neural Networks on the GPU for High-Performance Pattern Recognition.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: REFERENCES 52358\n",
      "1132 all_collections/Candlestick Charting and Trading Volume: Evidence from Bursa Malaysia.pdf\n",
      "Found: References 120962\n",
      "1133 all_collections/Deep Reinforcement Learning: A State-of-the-Art Walkthrough .pdf\n",
      "??????????\n",
      "1134 all_collections/Towards a Unified Approach to Learning and Towards a Unified Approach to Learning and Adoptation.pdf\n",
      "Found: References 6249\n",
      "1135 all_collections/The Application of the Genetic Algorithm in Promoting Stock Trading Performances.pdf\n",
      "Found: References 14581\n",
      "1136 all_collections/An Overview of Particle Swarm Optimization Variants.pdf\n",
      "Found: REFERENCES 19845\n",
      "1137 all_collections/Evolutionary Method Combining Particle Swarm Optimization and Genetic Algorithms using Fuzzy Logic for Decision Making.pdf\n",
      "Found: References 61153\n",
      "1138 all_collections/Machine learning for stock selection.pdf\n",
      "??????????\n",
      "1139 all_collections/Stock forecasting using Deep Learning.pdf\n",
      "Found: References 35147\n",
      "1140 all_collections/Robusta: Robust AutoML for Feature Selection via Reinforcement Learning.pdf\n",
      "??????????\n",
      "1141 all_collections/Learning_the_Limit_Order_Book_a_comprehensive_mix_between_stochastic_and_machine_learning_models_for_generation_and_prediction.pdf\n",
      "Found: REFERENCES 21536\n",
      "1142 all_collections/Modelling Stock-market Investors as Reinforcement Learning Agents.pdf\n",
      "??????????\n",
      "1143 all_collections/Reinforcement Learning algorithms — an intuitive overview _ by SmartLab AI _ Medium.pdf\n",
      "??????????\n",
      "1144 all_collections/Integrating  Machine Learning and Discrete Optimization.pdf\n",
      "Found: References 27901\n",
      "1145 all_collections/Nature Inspired Computing: An Overview and Some Future Directions.pdf\n",
      "Found: REFERENCES 20379\n",
      "1146 all_collections/Understanding Imbalanced Datasets and techniques for handling them.pdf\n",
      "Found: References 59143\n",
      "1147 all_collections/An intelligent hybrid trading system for discovering trading rules for the futures market using rough sets and genetic algorithms.pdf\n",
      "Found: References 66945\n",
      "1148 all_collections/Designing neural networks through neuroevolution.pdf\n",
      "??????????\n",
      "1149 all_collections/Competitive learning: From interactive activation to adaptive resonance.pdf\n",
      "??????????\n",
      "1150 all_collections/Time Series Forecasting With Deep Learning_ A Survey.pdf\n",
      "Found: REFERENCES 16083\n",
      "1151 all_collections/Data Mining: An AI Perspective .pdf\n",
      "Found: REFERENCES 42999\n",
      "1152 all_collections/Forecasting Stock Market Trends Using Rough Set.pdf\n",
      "??????????\n",
      "1153 all_collections/Generative Adversarial Networks for Stock Market prediction Summary.pdf\n",
      "Found: REFERENCES 26142\n",
      "1154 all_collections/A deep reinforcement learning approach for early classification of time series.pdf\n",
      "??????????\n",
      "1155 all_collections/hands-on-artificial-intelligence-on-google-cloud-platform-build-intelligent-applications-powered-by-tensorflow-cloud-automl-bigquery-and-dialogflow.pdf\n",
      "Found: REFERENCES 27457\n",
      "1156 all_collections/Forecasting financial time series volatility using Particle Swarm Optimization trained Quantile Regression Neural Network.pdf\n",
      "Found: REFERENCES 33942\n",
      "1157 all_collections/Designing Neural Network Architectures using Reinforcement Learning.pdf\n",
      "Found: References 61758\n",
      "1158 all_collections/iCVI-ARTMAP: Accelerating and improving clustering using adaptive resonance theory predictive mapping and incremental cluster validity indices.pdf\n",
      "Found: References 74925\n",
      "1159 all_collections/Short-term stock market price trend prediction using a comprehensive deep learning system | Journal of Big Data | Full Text.pdf\n",
      "Found: REFERENCES 32482\n",
      "1160 all_collections/The Distribution of Stock Returns: New Evidence Against the Stable Model.pdf\n",
      "Found: References 125143\n",
      "1161 all_collections/Forecasting Financial Time Series Movements with.pdf\n",
      "Found: References 15757\n",
      "1162 all_collections/A Hybrid Weighted Nearest Neighbor Approach to Mine Imbalanced Data .pdf\n",
      "Found: REFERENCES 67694\n",
      "1163 all_collections/Deep learning in spiking neural networks. .pdf\n",
      "Found: References 24516\n",
      "1164 all_collections/Neural Architecture Search: A Survey.pdf\n",
      "Found: References 11032\n",
      "1165 all_collections/Generative Adversarial Network for Stock Market price Prediction.pdf\n",
      "??????????\n",
      "1166 all_collections/AI Pioneers in Investment Management.pdf\n",
      "Found: References 84260\n",
      "1167 all_collections/Evolutionary learning of interpretable decision trees.pdf\n",
      "Found: REFERENCES 40419\n",
      "1168 all_collections/Differentiable_Neural_Architecture_Search_for_High-Dimensional_Time_Series_Forecasting.pdf\n",
      "Found: References 45192\n",
      "1169 all_collections/Comparison of Genetic Algorithm, Particle Swarm Optimization and Biogeography-based Optimization for Feature Selection to Classify Clusters of Microcalcifications.pdf\n",
      "Found: REFERENCES 35193\n",
      "1170 all_collections/Comparative Study of FOREX Trading Systems Built with SVR+GHSOM and Genetic Algorithms Optimization of Technical Indicators.pdf\n",
      "Found: REFERENCES 38775\n",
      "1171 all_collections/Multi-Element_Hierarchical_Attention_Capsule_Network_for_Stock_Prediction.pdf\n",
      "??????????\n",
      "1172 all_collections/GA-MSSR: Genetic Algorithm Maximizing Sharpe and Sterling Ratio Method for RoboTrading  .pdf\n",
      "??????????\n",
      "1173 all_collections/Analysing Stock Market Trend Prediction using Machine & Deep Learning Models: A Comprehensive Review .pdf\n",
      "Found: References 45283\n",
      "1174 all_collections/Evolutionary reinforcement learning of artificial neural networks.pdf\n",
      "??????????\n",
      "1175 all_collections/Neural-Symbolic Learning Systems: Foundations and Applications.pdf\n",
      "??????????\n",
      "1176 all_collections/Measuring Accuracy of of Trading Strategies.pdf\n",
      "??????????\n",
      "1177 all_collections/Hedge Fund History.pdf\n",
      "Found: References 53566\n",
      "1178 all_collections/Genetic algorithms for modelling and optimisation.pdf\n",
      "Found: References 19450\n",
      "1179 all_collections/Price Trend Prediction Using Data Mining Algorithm.pdf\n",
      "Found: References 65647\n",
      "1180 all_collections/Stacked Generalizations in Imbalanced Fraud Data Sets using Resampling Methods.pdf\n",
      "Found: REFERENCES 70114\n",
      "1181 all_collections/Forecast_Methods_for_Time_Series_Data_A_Survey.pdf\n",
      "??????????\n",
      "1182 all_collections/Dynamic Vision and Learning_ Recent trends in Automated Machine Learning (AutoML) (IN2107, IN4954).pdf\n",
      "Found: References 12167\n",
      "1183 all_collections/The applications of genetic algorithms in stock market data mining optimisation .pdf\n",
      "Found: References 35346\n",
      "1184 all_collections/ETSformer: Exponential Smoothing Transformers for Time-series Forecasting.pdf\n",
      "??????????\n",
      "1185 all_collections/Genetic Algorithms. How human evolution paved the way for… _ by Amit Naik _ DataDrivenInvestor.pdf\n",
      "Found: References 129076\n",
      "1186 all_collections/Reinforcement Learning- A Survey.pdf\n",
      "Found: REFERENCES 18781\n",
      "1187 all_collections/Stock price prediction using reinforcement learning.pdf\n",
      "??????????\n",
      "1188 all_collections/Portfolio Optimization using Reinforcement Learning _ by Noufal Samsudin _ Analytics Vidhya _ Medium.pdf\n",
      "Found: References 18626\n",
      "1189 all_collections/MTSS-GAN- Multivariate Time Series Simulation Generative Adversarial Networks.pdf\n",
      "Found: References 19019\n",
      "1190 all_collections/A Brief Review on Spiking Neural Network - A Biological Inspiration.pdf\n",
      "Found: References 85590\n",
      "1191 all_collections/Particle swarm optimization algorithm: an overview.pdf\n",
      "Found: References 151637\n",
      "1192 all_collections/Survey on deep learning with class imbalance.pdf\n",
      "Found: REFERENCES 150964\n",
      "1193 all_collections/A Comprehensive Survey on Transfer Learning.pdf\n",
      "Found: REFERENCES 28515\n",
      "1194 all_collections/Effect of Normalization Techniques on Univariate Time Series Forecasting using Evolutionary Higher Order Neural Network.pdf\n",
      "Found: REFERENCES 64860\n",
      "1195 all_collections/Performance functions and reinforcement learning for trading systems and portfolios.pdf\n",
      "Found: References 75622\n",
      "1196 all_collections/Using Convolutional Neural Network and Candlestick Representation to Predict Sports Match Outcomes.pdf\n",
      "Found: References 10792\n",
      "1197 all_collections/How to optimise machine learning pipelines with TPOT_.pdf\n",
      "Found: References 25429\n",
      "1198 all_collections/Deep Learning for Time-Series Analysis.pdf\n",
      "??????????\n",
      "1199 all_collections/A Random Walk Through Stock Market.pdf\n",
      "Found: REFERENCES 52850\n",
      "1200 all_collections/Is Image Encoding Beneficial for Deep Learning in Finance.pdf\n",
      "Found: References 29629\n",
      "1201 all_collections/QuantNet: Transferring Learning Across Trading Strategies.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: REFERENCES 59948\n",
      "1202 all_collections/A deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series.pdf\n",
      "Found: REFERENCES 24132\n",
      "1203 all_collections/Predicting future trends in stock market by decision tree rough-set based hybrid system with HHMM .pdf\n",
      "Found: References 28270\n",
      "1204 all_collections/Testing different Reinforcement Learning configurations for financial trading_ Introduction and applications.pdf\n",
      "Found: References 26057\n",
      "1205 all_collections/Challenges and Approaches to Time series forecasting: A Survey.pdf\n",
      "Found: References 3622\n",
      "1206 all_collections/Spiking Neural Networks Learning, Applications, and Analysis.pdf\n",
      "??????????\n",
      "1207 all_collections/Stock Market Prices Do Not Follow Random Walks.pdf\n",
      "Found: REFERENCES 62214\n",
      "1208 all_collections/IFROWANN Imbalanced Fuzzy-Rough Ordered Weighted Average Nearest Neighbor Classification.pdf\n",
      "Found: REFERENCES 31247\n",
      "1209 all_collections/The Advance-Decline, New-High, New-Low Market System by Dennis Meyers, Ph.D_.pdf\n",
      "Found: References 148017\n",
      "1210 all_collections/Neurosymbolic Programming.pdf\n",
      "??????????\n",
      "1211 all_collections/STOCK TREND PREDICTION USING NEWS  SENTIMENT ANALYSIS.pdf\n",
      "??????????\n",
      "1212 all_collections/High Performance Data Mining in Time Series: Techniques and Case Studies.pdf\n",
      "Found: References 42906\n",
      "1213 all_collections/DeepLearningandTimeSeries-to-ImageEncodingforFinancialForecasting.pdf\n",
      "??????????\n",
      "1214 all_collections/Intraday FX Trading_ An Evolutionary Reinforcement Learning.pdf\n",
      "Found: References 77764\n",
      "1215 all_collections/Stock returns, quantile autocorrelation, and volatility forecasting.pdf\n",
      "Found: References 12756\n",
      "1216 all_collections/Stable-Baselines3: Reliable Reinforcement Learning.pdf\n",
      "??????????\n",
      "1217 all_collections/Can reinforcement learning be used to forecast time series_ - Quora.pdf\n",
      "Found: References 93478\n",
      "1218 all_collections/TRAINING SPIKING NEURAL NETWORKS USING LESSONS FROM DEEP LEARNING.pdf\n",
      "Found: References 30046\n",
      "1219 all_collections/Artificial Counselor System for Stock Investment.pdf\n",
      "??????????\n",
      "1220 all_collections/EXPLOITING STOCK DATA: A SURVEY OF STATE OF THE ART  COMPUTATIONAL TECHNIQUES AIMED AT PRODUCING BELIEFS REGARDING INVESTMENT PORTFOLIOS  .pdf\n",
      "Found: REFERENCES 46369\n",
      "1221 all_collections/A_Hybrid_System_Integrating_a_Wavelet_and_TSK_Fuzz.pdf\n",
      "??????????\n",
      "1222 all_collections/Faster AutoML with TPOT and RAPIDS _ by Nick Becker _ RAPIDS AI _ Medium.pdf\n",
      "Found: REFERENCES 97806\n",
      "1223 all_collections/A Comprehensive Survey of Neural Architecture Search: Challenges and Solutions.pdf\n",
      "Found: References 55342\n",
      "1224 all_collections/Exploiting Multi-Channels Deep Convolutional Neural Networks for Multivariate Time Series Classification.pdf\n",
      "Found: References 53620\n",
      "1225 all_collections/****Stock Price Movement Prediction Based on a Deep Factorization Machine and the Attention Mechanism.pdf\n",
      "Found: References 71625\n",
      "1226 all_collections/Structured Low-Rank Algorithms.pdf\n",
      "Found: References 23047\n",
      "1227 all_collections/Reinforcement Learning for Trading Systems and Portfolios .pdf\n",
      "Found: References 61626\n",
      "1228 all_collections/A review of unsupervised feature learning and deep learning for time-series modeling.pdf\n",
      "Found: References 59659\n",
      "1229 all_collections/Deep learning in finance and banking_ A literature review and classification.pdf\n",
      "Found: References 60737\n",
      "1230 all_collections/Dumb money: Mutual fund flows and the cross-section of stock returns.pdf\n",
      "Found: References 20754\n",
      "1231 all_collections/Time Series Model for Stock Market Prediction Utilising Prophet.pdf\n",
      "Found: References 81411\n",
      "1232 all_collections/A Survey of Forex and Stock Price Prediction UsingDeep Learning.pdf\n",
      "??????????\n",
      "1233 all_collections/Developing High Performing Trading Strategies with Genetic Programming.pdf\n",
      "Found: References 21966\n",
      "1234 all_collections/Neuro-Fuzzy Systems: A Survey.pdf\n",
      "??????????\n",
      "1235 all_collections/States, Observation and Action Spaces in Reinforcement Learning _ by #Cban2020 _ The Startup _ Medium.pdf\n",
      "Found: References 56463\n",
      "1236 all_collections/ART 2: Self-organization of stable category recognition codes for analog input patterns.pdf\n",
      "Found: References 26876\n",
      "1237 all_collections/Accelerating reinforcement learning by reusing abstract policies.pdf\n",
      "Found: REFERENCES 73001\n",
      "1238 all_collections/ART 3: Hierarchical search using chemical transmitters in self-organizing pattern recognition architectures.pdf\n",
      "Found: References 14610\n",
      "1239 all_collections/Swarm intelligence.pdf\n",
      "??????????\n",
      "1240 all_collections/ON INCREASING THE SCOPE OF GENETIC PROGRAMMING TRADING AGENTS.pdf\n",
      "Found: References 36931\n",
      "1241 all_collections/Long-Range Transformers for Dynamic Spatiotemporal Forecasting.pdf\n",
      "??????????\n",
      "1242 all_collections/Deep Reinforcement Learning for Trading_ Strategy Development _ AutoML.pdf\n",
      "Found: References 28094\n",
      "1243 all_collections/Stock Market Prediction Using Machine Learning Techniques.pdf\n",
      "Found: REFERENCES 38250\n",
      "1244 all_collections/Stock Market Prediction using Novel Deep Learning Approaches: A Review .pdf\n",
      "Found: References 15203\n",
      "1245 all_collections/genetic algorithms and evolutionary computation.pdf\n",
      "??????????\n",
      "1246 all_collections/The distribution of stock market returns Returns with the Laplace Distribution.pdf\n",
      "??????????\n",
      "1247 all_collections/TPOT for Automated Machine Learning in Python.pdf\n",
      "Found: References 56566\n",
      "1248 all_collections/A multi-layer and multi-ensemble stock trader using deep learning.pdf\n",
      "Found: References 42882\n",
      "1249 all_collections/Deep Learning and Time Series-to-Image Encoding for Financial Forecasting.pdf\n",
      "??????????\n",
      "1250 all_collections/Automatic design and manufacture of robotic.pdf\n",
      "??????????\n",
      "1251 all_collections/williamsBarrett-Fast-Fourier-Transform-Predicting-Financial-Securities-Prices.pdf\n",
      "??????????\n",
      "1252 all_collections/ROUGH SETS, SIMILARITY, AND OPTIMAL APPROXIMATIONS.pdf\n",
      "Found: References 18780\n",
      "1253 all_collections/Practical Deep Reinforcement Learning Approach for Stock Trading 2.pdf\n",
      "Found: References 46334\n",
      "1254 all_collections/Embodied artificial evolution.pdf\n",
      "??????????\n",
      "1255 all_collections/The training dilemma_ loss vs profit function_ _ by Haris (Chariton) Chalvatzis _ Analytics Vidhya _ Medium.pdf\n",
      "??????????\n",
      "1256 all_collections/AI in Finance_ how to finally start to believe your backtests [3_3] _ by Alexandr Honchar _ Towards Data Science.pdf\n",
      "Found: References 52030\n",
      "1257 all_collections/InTech-Rough_set_theory_151_fundamental_concepts_principals_data_extraction_and_applications.pdf\n",
      "Found: References 26930\n",
      "1258 all_collections/Evolving Stock Market Prediction Models Using Multi-gene Symbolic Regression Genetic Programming.pdf\n",
      "Found: References 65667\n",
      "1259 all_collections/Machine Learning for Market Microstructure and High Frequency Trading .pdf\n",
      "Found: References 44852\n",
      "1260 all_collections/GENETIC ALGORITHMS Genetic algorithms.pdf\n",
      "Found: REFERENCES 28370\n",
      "1261 all_collections/Systematic Literature Review: Stock Price Prediction Using Machine Learning and Deep  Learning.pdf\n",
      "Found: References 8712\n",
      "1262 all_collections/Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning .pdf\n",
      "??????????\n",
      "1263 all_collections/A_D Volume, New-High, New-Low System by Dennis Meyers, Ph.D_.pdf\n",
      "??????????\n",
      "1264 all_collections/An Introductory Review of Spiking Neural Network and Artificial Neural Network: From Biological Intelligence to Artificial Intelligence.pdf\n",
      "Found: References 45572\n",
      "1265 all_collections/Adaptive sliding windows for improved estimation of data center resource utilization.pdf\n",
      "Found: References 18242\n",
      "1266 all_collections/An_Attention-Based_LSTM_Model_for_Stock_Price_Trend.pdf\n",
      "Found: REFERENCES 54088\n",
      "1267 all_collections/MODERN PERSPECTIVES ON REINFORCEMENT LEARNING IN FINANCE.pdf\n",
      "??????????\n",
      "1268 all_collections/Reinforcement Learning For Multiple Time Series.pdf\n",
      "??????????\n",
      "1269 all_collections/An Experimental Review on Deep Learning Architectures for Time Series Forecasting.pdf\n",
      "Found: References 65585\n",
      "1270 all_collections/Reinforcement Learning Through Modulation of Spike-Timing-Dependent Synaptic Plasticity.pdf\n",
      "??????????\n",
      "1271 all_collections/Google AI Blog_ Introducing AdaNet_ Fast and Flexible AutoML with Learning Guarantees.pdf\n",
      "??????????\n",
      "1272 all_collections/Generating Long-Term Trading System Rules Using a Genetic Algorithm Based on Analyzing Historical Data.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: References 122779\n",
      "1273 all_collections/Fundamental Analysis and the Cross-Section of Stock Returns: A Data-Mining Approach.pdf\n",
      "Found: References 10258\n",
      "1274 all_collections/Financial Data Modeling by Using Asynchronous Parallel Evolutionary Algorithms.pdf\n",
      "Found: References 15409\n",
      "1275 all_collections/Long Short Term Memory Networks for Anomaly Detection in Time Series.pdf\n",
      "Found: References 17707\n",
      "1276 all_collections/Optimization of Association Rule Mining using Improved  Genetic Algorithms .pdf\n",
      "Found: REFERENCES 16251\n",
      "1277 all_collections/Stock Price Prediction using Reinforcement Learning and Feature Extraction.pdf\n",
      "Found: REFERENCES 18989\n",
      "1278 all_collections/Effects of Time Normalization on the Accuracy of Dynamic Time Warping.pdf\n",
      "??????????\n",
      "1279 all_collections/Evolving Artificial Neural Networks through Complexification.pdf\n",
      "??????????\n",
      "1280 all_collections/THE DOW THEORY AND THE MANAGEMENT OF INVESTMENTS.pdf\n",
      "Found: References 49510\n",
      "1281 all_collections/Mitigating Metaphors: A Comprehensible Guide to Recent Nature-Inspired Algorithms.pdf\n",
      "??????????\n",
      "1282 all_collections/Genetic Algorithms and their Applications 1999.pdf\n",
      "??????????\n",
      "1283 all_collections/ESSAYS ON FINANCIAL MARKET STRUCTURE AND DESIGN.pdf\n",
      "??????????\n",
      "1284 all_collections/Co-evolved Genetic Program for Stock Market Trading.pdf\n",
      "Found: References 70756\n",
      "1285 all_collections/MACHINE LEARNING AND SPEED IN HIGH-FREQUENCY TRADING.pdf\n",
      "Found: References 34780\n",
      "1286 all_collections/Online Forecasting and Anomaly Detection Based on the Arima Model.pdf\n",
      "Found: References 5985\n",
      "1287 all_collections/Capsule Networks – A survey.pdf\n",
      "??????????\n",
      "1288 all_collections/genetic algorithms.pdf\n",
      "Found: References 44200\n",
      "1289 all_collections/Deep Neuroevolution: Genetic Algorithms are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning .pdf\n",
      "Found: References 550\n",
      "1290 all_collections/PypeCast-A-framework-for-time-series-forecasting-with-artificial-neural-networks-and-uncertainty-modelling.pdf\n",
      "Found: References 84979\n",
      "1291 all_collections/Market Timing: A Myth or a Possibility? .pdf\n",
      "??????????\n",
      "1292 all_collections/Capsule Networks_ Deep Learning Computer Vision for Stock Forecasting_ — Neuravest.pdf\n",
      "Found: References 47464\n",
      "1293 all_collections/TI-Capsule: Capsule Network for Stock Exchange Prediction .pdf\n",
      "Found: REFERENCES 41075\n",
      "1294 all_collections/Development of a stock trading system based on a neural network using highly volatile stock price patterns.pdf\n",
      "Found: References 31320\n",
      "1295 all_collections/Genetic-Based Trading Rules - A New Tool to Beat the Market With? - First Empirical Results - .pdf\n",
      "??????????\n",
      "1296 all_collections/AutoML for time series_ definitely a good idea _ by Mikhail Sarafanov _ Towards Data Science.pdf\n",
      "Found: References 93511\n",
      "1297 all_collections/Neuroevolutionary reinforcement learning for generalized control of simulated helicopters.pdf\n",
      "Found: REFERENCES 22872\n",
      "1298 all_collections/Stock Prediction Overview and a Simple LSTM based Prediction Model.pdf\n",
      "Found: References 29025\n",
      "1299 all_collections/Deep Learning for Event-Driven Stock Prediction.pdf\n",
      "Found: REFERENCES 58194\n",
      "1300 all_collections/DeepAnT_A_Deep_Learning_Approach_for_Unsupervised_Anomaly_Detection_in_Time_Series.pdf\n",
      "Found: References 10886\n",
      "1301 all_collections/Evolving Trading Strategies With Genetic Programming - An Overview · Fabian Kostadinov.pdf\n",
      "Found: References 53076\n",
      "1302 all_collections/Reinforcement learning combined with a fuzzy adaptive learning control network (FALCON-R) for pattern classification.pdf\n",
      "??????????\n",
      "1303 all_collections/Application of Deep Reinforcement Learning in Time Series Data Compression - ICDE 2020 Paper - Alibaba Cloud Community.pdf\n",
      "??????????\n",
      "1304 all_collections/A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem .pdf\n",
      "Found: REFERENCES 43644\n",
      "1305 all_collections/Reinforcement Learning and its Relationship to Supervised Learning.pdf\n",
      "Found: References 77792\n",
      "1306 all_collections/Optimal VWAP Tracking.pdf\n",
      "Found: REFERENCES 21750\n",
      "1307 all_collections/An enabling technique analysis in Data Mining for Stock Market  trend by Approaching Genetic Algorithm.pdf\n",
      "??????????\n",
      "1308 all_collections/A NOVEL TIME SERIES FORECASTING METHOD USING FUZZY INFORMATION RETRIEVAL SYSTEM.pdf\n",
      "Found: REFERENCES 14012\n",
      "1309 all_collections/Neuroengineering of Clustering Algorithms.pdf\n",
      "Found: References 26824\n",
      "1310 all_collections/Stock predictions with Transformer and Time Embeddings _ Towards Data Science.pdf\n",
      "??????????\n",
      "1311 all_collections/Computational Decision Making Methods.pdf\n",
      "??????????\n",
      "1312 all_collections/GAN base 7-minute prediction in stock market.pdf\n",
      "Found: REFERENCES 29567\n",
      "1313 all_collections/Financial Forecasting With α-RNNs- A Time Series Modeling Approach.pdf\n",
      "Found: References 65405\n",
      "1314 all_collections/Machine Learning for Quantitative Finance Applications: A Survey.pdf\n",
      "Found: References 44200\n",
      "1315 all_collections/Deep Neuroevolution: Genetic Algorithms are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning.pdf\n",
      "Found: References 83543\n",
      "1316 all_collections/Evolving Neural Networks through Augmenting Topologies.pdf\n",
      "Found: REFERENCES 47313\n",
      "1317 all_collections/An Effective Approach for Obtaining a Group Trading Strategy Portfolio Using Grouping Genetic Algorithm.pdf\n",
      "Found: References 16217\n",
      "1318 all_collections/Benchmarking Nonstationary Time Series Prediction.pdf\n",
      "Found: References 54987\n",
      "1319 all_collections/An Overview of Genetic Algorithms: Part 2, Research Topics.pdf\n",
      "Found: REFERENCES 32027\n",
      "1320 all_collections/STATE AGGREGATION FOR REINFORCEMENT LEARNING USING NEUROEVOLUTION.pdf\n",
      "??????????\n",
      "1321 all_collections/Literature Review on Data Normalization and clustering.pdf\n",
      "??????????\n",
      "1322 all_collections/AutoML_ An Introduction Using Auto-Sklearn and Auto-PyTorch.pdf\n",
      "Found: REFERENCES 209215\n",
      "1323 all_collections/Calibrating an Adaptive Farmer-Joshi Agent-Based Model for Financial Markets.pdf\n",
      "??????????\n",
      "1324 all_collections/Order Flow Imbalance - A High Frequency Trading Signal _ juliabloggers.com.pdf\n",
      "Found: References 51078\n",
      "1325 all_collections/Time-series forecasting of Bitcoin prices using high-dimensional features: a machine learning approach.pdf\n",
      "??????????\n",
      "1326 all_collections/K-Fold Cross Validation Technique and its Essentials - Analytics Vidhya.pdf\n",
      "??????????\n",
      "1327 all_collections/Patterns that detect stock market reversals by Bill Ohama and Melanie Bowman.pdf\n",
      "Found: References 3331\n",
      "1328 all_collections/A Python Package for Optimal Mean Reversion Trading _ by Tim Leung, Ph.D. _ Quantitative Investing _ Medium.pdf\n",
      "Found: References 23293\n",
      "1329 all_collections/Forecasting_stock_market_prices.pdf\n",
      "Found: REFERENCES 45761\n",
      "1330 all_collections/Auto-keras: An efficient neural architecture search system.pdf\n",
      "??????????\n",
      "1331 all_collections/Applications of ANNs in Stock Market Prediction: A Survey  .pdf\n",
      "??????????\n",
      "1332 all_collections/Introduction to Genetic Algorithms.pdf\n",
      "Found: References 60410\n",
      "1333 all_collections/A survey of the development of biomimetic intelligence and robotics.pdf\n",
      "Found: References 75514\n",
      "1334 all_collections/Particle swarm optimization.pdf\n",
      "Found: References 151725\n",
      "1335 all_collections/A Comprehensive Survey on Particle Swarm Optimization.pdf\n",
      "??????????\n",
      "1336 all_collections/Framework.pdf\n",
      "Found: References 40706\n",
      "1337 all_collections/GloVe: Global Vectors for Word Representation.pdf\n",
      "Found: References 68057\n",
      "1338 all_collections/Machine Learning and Fuzzy Logic in Electronics: Applying Intelligence in Practice.pdf\n",
      "??????????\n",
      "1339 all_collections/Attention for time series forecasting and classification _ by Isaac Godfried _ Towards Data Science.pdf\n",
      "Found: References 72921\n",
      "1340 all_collections/An Application of Deep Reinforcement Learning to Algorithmic Trading.pdf\n",
      "??????????\n",
      "1341 all_collections/AI in Finance_ how to finally start to believe your backtests [1_3] _ by Alexandr Honchar _ Towards Data Science.pdf\n",
      "Found: References 42220\n",
      "1342 all_collections/Heuristic-Guided Reinforcement Learning.pdf\n",
      "Found: References 46020\n",
      "1343 all_collections/An Introduction to Genetic Algorithms.pdf\n",
      "Found: References 73691\n",
      "1344 all_collections/Metaheuristic research: a comprehensive survey.pdf\n",
      "??????????\n",
      "1345 all_collections/Foreword: special issue on computational finance and economics 2016.pdf\n",
      "??????????\n",
      "1346 all_collections/Trading with Reinforcement Learning in Python Part II_ Application _ Teddy Koker.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: References 36344\n",
      "1347 all_collections/Financial Time Series Prediction using Spiking Neural Networks .pdf\n",
      "??????????\n",
      "1348 all_collections/Fuzzy Logic Tutorial_ What is, Architecture, Application, Example.pdf\n",
      "Found: References 35826\n",
      "1349 all_collections/Automated trading systems statistical andmachine learning methods and hardware implementation: a survey.pdf\n",
      "Found: References 12697\n",
      "1350 all_collections/Evaluation of Fitness Functions for Evolved Stock Market Forecasting.pdf\n",
      "Found: References 49311\n",
      "1351 all_collections/Reinforcement_Learning_for_Systematic_FX Trading.pdf\n",
      "Found: REFERENCES 20578\n",
      "1352 all_collections/Rough set with Effective Clustering Method.pdf\n",
      "??????????\n",
      "1353 all_collections/Predicting Tesla Stocks (TSLA) using Python & PyCaret _ by Muneeb Ahmad _ Dev Genius.pdf\n",
      "Found: REFERENCES 16390\n",
      "1354 all_collections/TURNOVER PREDICTION OF SHARES USING DATA MINING TECHNIQUES: A CASE STUDY.pdf\n",
      "??????????\n",
      "1355 all_collections/Parallel Evolutionary Algorithms.pdf\n",
      "??????????\n",
      "1356 all_collections/Using Genetic Algorithms to Find Technical Trading Rules.pdf\n",
      "Found: REFERENCES 17787\n",
      "1357 all_collections/Reinforcement Learning Driven Heuristic Optimization.pdf\n",
      "Found: REFERENCES 29268\n",
      "1358 all_collections/The Distribution of Stock Returns.pdf\n",
      "Found: REFERENCES 74530\n",
      "1359 all_collections/Pay Attention to Evolution_ Time Series Forecasting with Deep Graph-Evolution Learning.pdf\n",
      "Found: REFERENCES 20467\n",
      "1360 all_collections/Review of Unsupervised Adaptive Resonance Theory.pdf\n",
      "Found: REFERENCES 23401\n",
      "1361 all_collections/Stock Market Prediction: A Survey and Evaluation.pdf\n",
      "??????????\n",
      "1362 all_collections/Reinforcement learning without gradients_ evolving agents using Genetic Algorithms _ by Paras Chopra _ Towards Data Science.pdf\n",
      "Found: References 51688\n",
      "1363 all_collections/A Survey on Deep Learning.pdf\n",
      "Found: REFERENCES 62078\n",
      "1364 all_collections/Evaluation of current research on stock return predictability.pdf\n",
      "Found: References 118294\n",
      "1365 all_collections/Applications of deep learning in stock market prediction: recent progress.pdf\n",
      "??????????\n",
      "1366 all_collections/Reviving Threshold-Moving: a Simple Plug-in Bagging Ensemble for Binary and Multiclass Imbalanced Data.pdf\n",
      "??????????\n",
      "1367 all_collections/Handling imbalanced dataset using SVM and k-NN approach.pdf\n",
      "Found: References 48503\n",
      "1368 all_collections/Forecasting daily conditional volatility and h-step-ahead short and long Value-at-Risk accuracy_ Evidence from financial data.pdf\n",
      "Found: References 85301\n",
      "1369 all_collections/Short‑term stock market price trend prediction using a comprehensive deep learning system.pdf\n",
      "Found: References 6510\n",
      "1370 all_collections/Evolutionary Algorithms in Optimization of Technical Rules for Automated Stock Trading.pdf\n",
      "Found: References 36723\n",
      "1371 all_collections/An_automated_FX_trading_system_using_adaptive_reinforcement learning.pdf\n",
      "Found: References 33719\n",
      "1372 all_collections/CTS_ Time Series Smoothing with Constrained Reinforcement Learning.pdf\n",
      "Found: References 28299\n",
      "1373 all_collections/Financial Trading as a Game_ A Deep Reinforcement Learning Approach.pdf\n",
      "??????????\n",
      "1374 all_collections/A novel data-driven stock price trend prediction system.pdf\n",
      "Found: References 54536\n",
      "1375 all_collections/Forecasting-Financial-Time-Series-using-Robust-Deep-Adaptive-Input-Normalization.pdf\n",
      "??????????\n",
      "1376 all_collections/Reinforcement Learning Applied to Forex Trading.pdf\n",
      "Found: References 41819\n",
      "1377 all_collections/Evolving spiking neural network – A survey.pdf\n",
      "Found: References 40396\n",
      "1378 all_collections/Generic Neural Architecture Search via Regression.pdf\n",
      "??????????\n",
      "1379 all_collections/2_1_cashpenalty_alt.pdf\n",
      "??????????\n",
      "1380 all_collections/Rough Set Theory – Fundamentals and an Overview of its Main  Applications.pdf\n",
      "Found: References 65565\n",
      "1381 all_collections/Enhancement of Cross Validation Using Hybrid Visual and Analytical Means with Shannon Function.pdf\n",
      "??????????\n",
      "1382 all_collections/DeMark on day-trading options.pdf\n",
      "Found: REFERENCES 43795\n",
      "1383 all_collections/A_Survey_on_Meta-Heuristic_Global_Optimization_Alg.pdf\n",
      "Found: REFERENCES 37997\n",
      "1384 all_collections/UNSUPERVISED REPRESENTATION LEARNING FOR TIME SERIES WITH TEMPORAL NEIGHBORHOOD CODING.pdf\n",
      "Found: REFERENCES 37043\n",
      "1385 all_collections/A_Survey_on_Stock_Market_Price_Predictio.pdf\n",
      "Found: REFERENCES 58392\n",
      "1386 all_collections/Unsupervised Learning of a Hierarchical Spiking Neural Network for Optical Flow Estimation:From Events to Global Motion Perception.pdf\n",
      "Found: References 142456\n",
      "1387 all_collections/Financial Time Series Forecasting with Deep Learning _ A Systemic Literature Review 2005-2019.pdf\n",
      "Found: References 47476\n",
      "1388 all_collections/A Volume-Weighted-Average-Price (VWAP) Method for Estimating Beta in the Context of Reference-Day Risk..pdf\n",
      "Found: References 94666\n",
      "1389 all_collections/EVOLUTIONARY COMPUTATION.pdf\n",
      "??????????\n",
      "1390 all_collections/Google AI Blog_ Evolving Reinforcement Learning Algorithms.pdf\n",
      "Found: References 23166\n",
      "1391 all_collections/Stock Index Prices Prediction via Temporal Pattern Attention and.pdf\n",
      "Found: REFERENCES 16372\n",
      "1392 all_collections/Making the Titanic Fly by Dennis Meyers.pdf\n",
      "Found: References 35694\n",
      "1393 all_collections/Deep Reinforcement Learning in Agent Based Financial Market Simulation .pdf\n",
      "Found: References 65937\n",
      "1394 all_collections/Genetic- Algorithm Programming Environments.pdf\n",
      "??????????\n",
      "1395 all_collections/20 Key Examples Of AI In Finance You Should Know 2022 _ Built In.pdf\n",
      "??????????\n",
      "1396 all_collections/Profitable Strategy Design by Using Deep Reinforcement Learning for Trades on Cryptocurrency Markets.pdf\n",
      "??????????\n",
      "1397 all_collections/Time Series Analysis for Business Forecasting.pdf\n",
      "Found: REFERENCES 19134\n",
      "1398 all_collections/Deep Reinforcement Learning for Financial Trading using Price Trailing.pdf\n",
      "??????????\n",
      "1399 all_collections/Neuroevolution for Deep Reinforcement Learning Problems 2019.pdf\n",
      "Found: References 78031\n",
      "1400 all_collections/Reinforcement Learning in Economics and Finance.pdf\n",
      "??????????\n",
      "1401 all_collections/Time Series Modeling with Genetic Programming Prediction of Stock Market Index Using Genetic Algorithm .pdf\n",
      "??????????\n",
      "1402 all_collections/Machine Learning for Irregular Time Series (ML4ITS) - Research.pdf\n",
      "Found: References 30705\n",
      "1403 all_collections/Artificial Neural Networks architectures for stock price prediction: comparisons and applications.pdf\n",
      "Found: REFERENCES 36063\n",
      "1404 all_collections/NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING.pdf\n",
      "??????????\n",
      "1405 all_collections/Combinatorial PurgedKFold Cross-Validation for Deep Reinforcement Learning _ by Berend _ Apr, 2022 _ Towards AI.pdf\n",
      "Found: REFERENCES 21950\n",
      "1406 all_collections/Analyzing and Predicting Stock Market Using Data Mining Techniques – A Review .pdf\n",
      "Found: References 18890\n",
      "1407 all_collections/The Best Deep Learning Models for Time Series Forecasting _ by Nikos Kafritsas _ Towards Data Science.pdf\n",
      "??????????\n",
      "1408 all_collections/Simple_Trading_strategies.pdf\n",
      "??????????\n",
      "1409 all_collections/Manifold-Learning-Based Feature Extraction for Classification of Hyperspectral Data.pdf\n",
      "??????????\n",
      "1410 all_collections/Machine Learning in Finance Applications of Continuous Depth and Randomized Neural Networks.pdf\n",
      "Found: References 3709\n",
      "1411 all_collections/Nature-Inspired Optimization Algorithms.pdf\n",
      "Found: REFERENCES 63027\n",
      "1412 all_collections/Enhancing Time-Series.pdf\n",
      "??????????\n",
      "1413 all_collections/Encyclopedia_of_Chart_Patterns.pdf\n",
      "Found: References 25157\n",
      "1414 all_collections/A New Methodology Based on Imbalanced Classification for Predicting Outliers in Electricity Demand Time Series.pdf\n",
      "Found: REFERENCES 70294\n",
      "1415 all_collections/The Great Time Series Classification Bake Off: An Experimental Evaluation of Recently Proposed Algorithms. Extended Version.pdf\n",
      "Found: REFERENCES 19977\n",
      "1416 all_collections/Deep Learning Techniques for Stock Market Prediction in the European Union: A Systematic Review.pdf\n",
      "Found: References 31530\n",
      "1417 all_collections/Data-mining-techniques-and-applications.pdf\n",
      "Found: References 17226\n",
      "1418 all_collections/A Survey on Stock Market Prediction Using Machine Learning Techniques.pdf\n",
      "Found: REFERENCES 23953\n",
      "1419 all_collections/VWAP Strategies.pdf\n",
      "??????????\n",
      "1420 all_collections/Using Genetic Alglorithms to Find Technical Trading Rules.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "1421 all_collections/Time Series Simulation by Conditional Generative Adversarial Net.pdf\n",
      "Found: References 19237\n",
      "1422 all_collections/einforcement-learning-for-trading-Paper.pdf\n",
      "Found: References 81411\n",
      "1423 all_collections/A Survey of Forex and Stock Price Prediction Using Deep Learning.pdf\n",
      "Found: References 29374\n",
      "1424 all_collections/New Interpretations of Normalization Methods in Deep Learning.pdf\n",
      "Found: References 13324\n",
      "1425 all_collections/Alexandros Iosifidis - Time-series data analysis.pdf\n",
      "??????????\n",
      "1426 all_collections/The \"Liquid Computer\": A Nevel Strategy for Real-Time Computing on Time Series.pdf\n",
      "Found: REFERENCES 18132\n",
      "1427 all_collections/Discovering Patterns in Sentimental Analysis.pdf\n",
      "Found: References 30335\n",
      "1428 all_collections/Computational Finance.pdf\n",
      "Found: REFERENCES 30860\n",
      "1429 all_collections/Implementation of a Type-2 Fuzzy Logic Based Prediction System for the Nigerian Stock Exchange.pdf\n",
      "Found: REFERENCES 23203\n",
      "1430 all_collections/Stock Market Prediction and Investment using Deep Reinforcement Learning- a Continuous Training Pipeline  .pdf\n",
      "??????????\n",
      "1431 all_collections/Impact of Data Normalization on Deep Neural Network for Time Series Forecasting.pdf\n",
      "??????????\n",
      "1432 all_collections/30 RULES TO MASTER SWING TRADING.pdf\n",
      "Found: References 20971\n",
      "1433 all_collections/Using fast adaptive neural network classifier for mutual fund performance evaluation.pdf\n",
      "Found: References 81742\n",
      "1434 all_collections/An empirical survey of data augmentation for time series classification with neural networks.pdf\n",
      "Found: References 75967\n",
      "1435 all_collections/The Distribution of Stock Return Volatility.pdf\n",
      "Found: References 25321\n",
      "1436 all_collections/Predicting break-points in trading strategies with Twitter .pdf\n",
      "Found: References 42077\n",
      "1437 all_collections/Evolutionary_Computation_from_Genetic_Algorithms_to_Genetic_Programming Algorithms for Data Science.pdf\n",
      "Found: REFERENCES 19860\n",
      "1438 all_collections/Using Deep Learning to Detect Price Change Indications in Financial Markets.pdf\n",
      "Found: References 36973\n",
      "1439 all_collections/Adaptive Quantitative Trading: An Imitative Deep Reinforcement Learning Approach.pdf\n",
      "Found: References 34596\n",
      "1440 all_collections/Cost Sensitive Time-series Classification.pdf\n",
      "??????????\n",
      "1441 all_collections/Andre Bush -- The Swiss trading champion who earned 4537.8% in 4 months - Andre Bush's investment strategy and theory - iNEWS.pdf\n",
      "Found: REFERENCES 26921\n",
      "1442 all_collections/Stocks & Commodities V17_4 (151-159)_ The Discrete Fourier Transform Illusion by Dennis Meyers, Ph.D_.pdf\n",
      "??????????\n",
      "1443 all_collections/Working Towards Explainable and Data-efficient Machine Learning Models via Symbolic Reasoning.pdf\n",
      "Found: References 45365\n",
      "1444 all_collections/A Few Useful Things to Know About Machine Learning.pdf\n",
      "??????????\n",
      "1445 all_collections/4 Ways to Predict Market Performance.pdf\n",
      "Found: REFERENCES 24282\n",
      "1446 all_collections/Introducing Fuzzy Layers for Deep Learning.pdf\n",
      "Found: References 43009\n",
      "1447 all_collections/Stock Trend Prediction Algorithm Based on Deep Recurrent Neural Network .pdf\n",
      "Found: REFERENCES 32615\n",
      "1448 all_collections/Multi-Objective reward generalization: Improving performance of Deep Reinforcement Learning for selected applications in stock and cryptocurrency trading.pdf\n",
      "??????????\n",
      "1449 all_collections/Genetic Algorithms: Genesis of Stock Evaluation.pdf\n",
      "Found: References 47120\n",
      "1450 all_collections/Survey on the application of deep learning in algorithmic trading.pdf\n",
      "Found: References 93512\n",
      "1451 all_collections/HANDBOOK OF GLOBAL OPTIMIZATION.pdf\n",
      "Found: REFERENCES 70665\n",
      "1452 all_collections/Technical Analysis in the Foreign Exchange Market.pdf\n",
      "Found: References 58779\n",
      "1453 all_collections/Reinforcement Learning in Financial Markets.pdf\n",
      "Found: References 30520\n",
      "1454 all_collections/Imaging time-series to improve classification and imputation.pdf\n",
      "??????????\n",
      "1455 all_collections/STOCK TREND PREDICTION USING NEWS SENTIMENT ANALYSIS .pdf\n",
      "Found: References 95461\n",
      "1456 all_collections/Time series momentum.pdf\n",
      "Found: REFERENCES 42852\n",
      "1457 all_collections/TIME SERIES CLASSIFICATION USING IMBALANCED LEARNING FOR 2 REAL-TIME SAFETY ASSESSMENT.pdf\n",
      "??????????\n",
      "1458 all_collections/List of Technical Indicators _ Trading Technologies.pdf\n",
      "Found: REFERENCES 16046\n",
      "1459 all_collections/Applications of artificial neural networks in financial economics: A Survey.pdf\n",
      "Found: References 122728\n",
      "1460 all_collections/Multi-agent Deep Reinforcement Learning.pdf\n",
      "Found: REFERENCES 11524\n",
      "1461 all_collections/Neuro-symbolic approaches in artificial intelligence .pdf\n",
      "Found: REFERENCES 48720\n",
      "1462 all_collections/An Efficient and Accurate Rough Set for Feature Selection, Classification and Knowledge Representation.pdf\n",
      "??????????\n",
      "1463 all_collections/Short Book Reviews.pdf\n",
      "Found: REFERENCES 25552\n",
      "1464 all_collections/MULTIVARIATE ANOMALY DETECTION ON STOCK MARKET.pdf\n",
      "Found: References 86837\n",
      "1465 all_collections/Nature-Inspired Metaheuristic Techniques for Combinatorial Optimization Problems: Overview and Recent Advances .pdf\n",
      "Found: References 32652\n",
      "1466 all_collections/Cost-Aware Pre-Training for Multiclass Cost-Sensitive Deep Learning.pdf\n",
      "Found: REFERENCES 144134\n",
      "1467 all_collections/Deep Learning for Limit Order Book Trading and Mid-Price Movement Prediction.pdf\n",
      "Found: References 36748\n",
      "1468 all_collections/An_automated_FX_trading_system_using_adaptive_reinforcement.pdf\n",
      "??????????\n",
      "1469 all_collections/Identifying Candlestick Patterns using Deep Learning _ by Shaan Shah _ Towards Data Science.pdf\n",
      "Found: References 43009\n",
      "1470 all_collections/A Transformer Self-Attention Model for Time Series Forecasting.pdf\n",
      "??????????\n",
      "1471 all_collections/estimize_signal_strategy.pdf\n",
      "??????????\n",
      "1472 all_collections/Time Series in Finance- the array database approach .pdf\n",
      "Found: References 59534\n",
      "1473 all_collections/Neuroevolution strategies for episodic reinforcement learning.pdf\n",
      "Found: References 68827\n",
      "1474 all_collections/Evolutionary Design of Convolutional Neural Networks for Human Activity Recognition in Sensor-Rich Environments.pdf\n",
      "Found: References 33263\n",
      "1475 all_collections/Fastformer: Additive Attention Can Be All You Need.pdf\n",
      "Found: References 51831\n",
      "1476 all_collections/Nonlinear system control using self-evolving neural fuzzy inference networks with reinforcement evolutionary learning.pdf\n",
      "Found: References 57347\n",
      "1477 all_collections/An Empirical Analysis of Data Requirements for Financial Forecasting with Neural Networks.pdf\n",
      "??????????\n",
      "1478 all_collections/Multi-Agent Deep Reinforcement Learning in 13 Lines of Code Using PettingZoo _ by J K Terry _ Towards Data Science.pdf\n",
      "Found: References 38152\n",
      "1479 all_collections/Rough Set Theory with Applications to Data  Mining.pdf\n",
      "Found: References 23129\n",
      "1480 all_collections/Recurrence and Self-Attention vs the Transformer for Time-Series Classification: A Comparative Study.pdf\n",
      "Found: References 37721\n",
      "1481 all_collections/Multi-Horizon Forecasting for Limit Order Books: Novel Deep Learning Approaches and Hardware Acceleration using Intelligent Processing Units.pdf\n",
      "??????????\n",
      "1482 all_collections/An overview of time-aware cross-validation techniques _ by Matthias Ramirez (ELCA) _ ELCA IT.pdf\n",
      "Found: REFERENCES 29281\n",
      "1483 all_collections/GA-DRL_Genetic_Algorithm-Based_Function_Optimizer_.pdf\n",
      "Found: REFERENCES 43524\n",
      "1484 all_collections/Attention-based Neural Bag-of-Features Learning.pdf\n",
      "Found: REFERENCES 78015\n",
      "1485 all_collections/Deep Learning With Spiking Neurons: Opportunities and Challenges.pdf\n",
      "Found: References 86425\n",
      "1486 all_collections/***Short term stock market price trend prediction using a comprehensive deep learning system.pdf\n",
      "Found: References 35863\n",
      "1487 all_collections/Reinforcement Learning with Neuroevolution: Final Report.pdf\n",
      "??????????\n",
      "1488 all_collections/Introduction to Technical Indicators and Oscillators [ChartSchool].pdf\n",
      "Found: References 43190\n",
      "1489 all_collections/Surveying stock market forecasting techniques Part II: Soft computing methods.pdf\n",
      "Found: REFERENCES 40670\n",
      "1490 all_collections/FinRL: Deep Reinforcement Learning Framework to Automate Trading in Quantitative Finance.pdf\n",
      "Found: REFERENCES 103275\n",
      "1491 all_collections/A Survey on Modern Deep Neural Network for Traffic Prediction: Trends, Methods and Challenges.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????\n",
      "1492 all_collections/Time Forecast with TPOT. a Python Automated Machine Learning… _ by Susan Li _ Towards Data Science.pdf\n",
      "Found: References 32483\n",
      "1493 all_collections/Convolutional Nonlinear Neighbourhood Components Analysis for Time Series Classification.pdf\n",
      "Found: References 36909\n",
      "1494 all_collections/On Using Genetic Algorithms to Search Program Spaces.pdf\n",
      "Found: References 33572\n",
      "1495 all_collections/Transformers in Time Series- A Survey.pdf\n",
      "Found: References 19935\n",
      "1496 all_collections/Optimal Ratio for Data Splitting.pdf\n",
      "Found: References 39571\n",
      "1497 all_collections/Forecasting Volatility of Stock Index- Deep Learning Model with Likelihood-Based Loss Function.pdf\n",
      "??????????\n",
      "1498 all_collections/DeMark -- technical analysis_ TD Waldo Patterns _ LiteFinance (ex. LiteForex).pdf\n",
      "Found: References 33578\n",
      "1499 all_collections/Hierarchical Adaptive Temporal-Relational Modeling for Stock Trend Prediction.pdf\n",
      "Found: References 37773\n",
      "1500 all_collections/Absolute exponential stability of recurrent neural networks with Lipschitz-continuous activation functions and time delays.pdf\n",
      "Found: References 99003\n",
      "1501 all_collections/Deep Reinforcement Trading with Predictable Returns.pdf\n",
      "Found: References 67517\n",
      "1502 all_collections/Machine Learning for Forecasting Mid Price Movement using Limit Order Book Data.pdf\n",
      "Found: REFERENCES 163488\n",
      "1503 all_collections/Anomaly Detection.pdf\n",
      "Found: References 26808\n",
      "1504 all_collections/Parameter tuning in trading algorithms using ASTA.pdf\n",
      "Found: References 38760\n",
      "1505 all_collections/Unsupervised Learning of Digit Recognition Using Spike-Timing-Dependent Plasticity.pdf\n",
      "??????????\n",
      "1506 all_collections/Introduction and Trends to Fuzzy Logic and Fuzzy Databases.pdf\n",
      "??????????\n",
      "1507 all_collections/Fidelity Learning Center_ Technical Analysis Indicator Guide-001.pdf\n",
      "Found: References 43461\n",
      "1508 all_collections/Spike-timing dependent plasticity.pdf\n",
      "Found: REFERENCES 29346\n",
      "1509 all_collections/Optimization of the Trading Rule in Foreign Exchange using Genetic Algorithm.pdf\n",
      "Found: References 34343\n",
      "1510 all_collections/EFFECTIVE AND EFFICIENT COMPUTATION WITH MULTIPLE-TIMESCALE SPIKING RECURRENT NEURAL NETWORKS .pdf\n",
      "??????????\n",
      "1511 all_collections/Unsupervised Learning.pdf\n",
      "Found: References 38525\n",
      "1512 all_collections/Neuromorphic Data Augmentation for Training Spiking Neural Networks.pdf\n",
      "Found: REFERENCES 59004\n",
      "1513 all_collections/Generative_Adversarial_Networks_for_Financial_Trade.pdf\n",
      "??????????\n",
      "1514 all_collections/LARG: Loss avoidance technical trading rules using genetic algorithm.pdf\n",
      "Found: REFERENCES 38988\n",
      "1515 all_collections/Meta Optimization and its Application to Portfolio Selection.pdf\n",
      "Found: References 39624\n",
      "1516 all_collections/Which Daily Price Is Less Noisy?.pdf\n",
      "Found: References 2618\n",
      "1517 all_collections/Cross-ValidationInClassHO.pdf\n",
      "Found: References 46726\n",
      "1518 all_collections/Deep learning for Stock Market Prediction.pdf\n",
      "Found: References 25832\n",
      "1519 all_collections/Deepbots: A Webots-Based Deep Reinforcement Learning Framework for Robotics.pdf\n",
      "Found: References 60471\n",
      "1520 all_collections/A Comprehensive Analysis of Nature‑Inspired Meta‑Heuristic Techniques for Feature Selection Problem.pdf\n",
      "Found: References 42974\n",
      "1521 all_collections/Predicting the price movement from candlestick charts: a CNN-based approach.pdf\n",
      "Found: References 47979\n",
      "1522 all_collections/Hierarchical Temporal Memory Theory Approach to Stock Market Time Series Forecasting Long-Short-Term Memory.pdf\n",
      "Found: References 24563\n",
      "1523 all_collections/FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance .pdf\n",
      "Found: REFERENCES 5326\n",
      "1524 all_collections/Fuzzy adaptive resonance theory: Applications and extensions .pdf\n",
      "??????????\n",
      "1525 all_collections/Review 02 --A review of Reinforcement learning for financial time series prediction and portfolio optimization _ by Nick Smith _ Journal of Quantitative finance _ Medium.pdf\n",
      "??????????\n",
      "1526 all_collections/Trends of Inference Considering Extended Fuzzy Logic.pdf\n",
      "Found: References 109938\n",
      "1527 all_collections/A Novel Meta-Heuristic Optimization Algorithm Inspired by the Spread of Viruses.pdf\n",
      "Found: References 45826\n",
      "1528 all_collections/Evolutionary algorithm optimization of biological learning parameters in a biomimetic neuroprosthesis.pdf\n",
      "Found: REFERENCES 88565\n",
      "1529 all_collections/Automated Machine Learning: State-of-The-Art and Open Challenges.pdf\n",
      "??????????\n",
      "1530 all_collections/Transformers in Time Series_ A Survey.pdf\n",
      "Found: References 28094\n",
      "1531 all_collections/Stock Market Prediction Using Machine Learning Techniques: A Decade Survey on Methodologies, Recent Developments, and Future Directions.pdf\n",
      "??????????\n",
      "1532 all_collections/Technical Indicators and Overlays [ChartSchool].pdf\n",
      "Found: References 22308\n",
      "1533 all_collections/Parallel genetic algorithms for stock market trading rules.pdf\n",
      "Found: References 82289\n",
      "1534 all_collections/Fast and slow arbitrage: Smart money, dumb money and mispricing in the frequency domain.pdf\n",
      "Found: References 114081\n",
      "1535 all_collections/The Bio-Inspired Optimization of Trading Strategies and Its Impact on the Efficient Market Hypothesis and Sustainable Development Strategies.pdf\n"
     ]
    }
   ],
   "source": [
    "skipped = ['all_collections/Fuzzy Based Modified SHL algorithm for Spiking Neural  Network.pdf', \n",
    "           'all_collections/A Survey on Unsupervised Machine Learning Algorithms for Automation, Classification and Maintenance.pdf',\n",
    "          'all_collections/Evolutionary Function Approximation for Reinforcement Learning.pdf',\n",
    "          'all_collections/Purified sentiment indicators for the stock market5.04.09.pdf',\n",
    "           'all_collections/Time Series Analysis by State Space Methods (2ed).pdf',\n",
    "           'all_collections/Machine Learning for Time Series Anomaly Detection.pdf',\n",
    "           'all_collections/AI-and-Financial-Markets.pdf',\n",
    "           'all_collections/normalize-time-series-and-forecast-using-evolutionary-neural-network.pdf',\n",
    "           'all_collections/Rough Sets.pdf',\n",
    "           'all_collections/Deep reinforcement learning stock market trading, utilizing a CNN with candlestick images.pdf',\n",
    "            'all_collections/Genetic Algorithm- An Application to Technical Trading System Design.pdf',\n",
    "            'all_collections/GA_an_application_to_technical_trading_system_design.pdf',\n",
    "           'all_collections/Action-specialized expert ensemble trading system with extended discrete action space using deep reinforcement learning.pdf',\n",
    "           'all_collections/Deep reinforcement learning stock market trading, utilizing a CNN with candlestick.pdf',\n",
    "           'all_collections/Multi-DQN: An ensemble of Deep Q-learning agents for stock  market forecasting.pdf',\n",
    "           'all_collections/Monte-Carlo Evaluation of Trading Systems.pdf',\n",
    "           'all_collections/New developments in time series econometrics: An overview.pdf',\n",
    "           'all_collections/Search and Reasoning in Problem Solving.pdf',\n",
    "           'all_collections/DPP: Deep predictor for price movement from candlestick charts.pdf',\n",
    "           'all_collections/Building Reliable Trading Systems.pdf',\n",
    "           'all_collections/Effects of Time Normalization on the Accuracy of the Success of Artificial Neural Network Model.pdf',  \n",
    "           'all_collections/Impact of chart image characteristics on stock price prediction with a convolutional neural network.pdf',\n",
    "           'all_collections/A Comprehensive Survey of Time Series Anomaly Detection in Online Social Network Data.pdf',\n",
    "           'all_collections/A Comprehensive Survey of Time Series Anomaly Detection in Online Social Network Data.pdf',\n",
    "           'all_collections/Selection of the optimal trading model for stock investment in different industries.pdf',\n",
    "           'all_collections/The Effect of the Normalization Method Used in Different Sample Sizes on.pdf',\n",
    "           'all_collections/Genetic Algorithm: An Application to Technical Trading System Design.pdf',\n",
    "          'all_collections/Improving stock trading decisions based on pattern recognition using machine learning technology.pdf']\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "tot_ref = ''\n",
    "\n",
    "for fn in glob.glob('all_collections/*.pdf'):\n",
    "        \n",
    "    if fn in skipped:\n",
    "        continue\n",
    "    \n",
    "    if cnt >= 0:\n",
    "        reader = PdfReader(fn)\n",
    "\n",
    "        text = \"\"\n",
    "\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "\n",
    "        idx1 = text.find('REFERENCES')\n",
    "        idx2 = text.find('References')\n",
    "\n",
    "        if idx1 != -1:\n",
    "            print ('Found: REFERENCES', idx1)\n",
    "            tot_ref += text[idx1:]\n",
    "        elif idx2 != -1:\n",
    "            print ('Found: References', idx2)\n",
    "            tot_ref += text[idx2:]\n",
    "        else:\n",
    "            print('??????????')\n",
    "\n",
    "        tot_ref += '\\n\\n ********************\\n\\n'\n",
    "        print(cnt, fn)\n",
    "    \n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eff5e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Reference_Org.txt\", \"a\")\n",
    "f.write(tot_ref)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d55e365d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REFERENCES\\n[1] T. Yigitcanlar, L. Butler, E. Windle, K. C. Desouza, R. Mehmood,\\nand J. M. Corchado, “Can Building “Artificially Intelligent Cities”\\nSafeguard Humanity from Natural Disasters, Pandemics, and Other\\nCatastrophes? An Urban Scholar’s Perspective,” Sensors, vol. 20, no. 10,\\np. 2988, may 2020. [Online]. Available: https://www.mdpi.com/1424-\\n8220/20/10/2988\\n[2] T. Yigitcanlar, N. Kankanamge, M. Regona, A. Maldonado, B. Rowan,\\nA. Ryu, K. C. Desouza, J. M. Corchado, R. Mehmood, and R. Y. M.\\nLi, “Artificial Intelligence Technologies and Related Urban Planning\\nand Development Concepts: How Are They Perceived and Utilized\\nin Australia?”Journal of Open Innovation: Technology, Market, and\\nComplexity, vol. 6, no. 4, p. 187, dec 2020. [Online]. Available:\\nhttps://www.mdpi.com/2199-8531/6/4/187\\n[3] E. Alomari, I. Katib, A. Albeshri, and R. Mehmood, “COVID-19:\\nDetecting Government Pandemic Measures and Public Concerns from\\nTwitter Arabic Data Using Distributed Machine Learning,” International\\nJournal of Environmental Research and Public Health , vol. 18, no. 1,\\np. 282, jan 2021. [Online]. Available: https://www.mdpi.com/1660-\\n4601/18/1/282\\n[4] S. Alotaibi, R. Mehmood, I. Katib, O. Rana, and A. Albeshri, “Sehaa:\\nA Big Data Analytics Tool for Healthcare Symptoms and Diseases\\nDetection Using Twitter, Apache Spark, and Machine Learning,”\\nApplied Sciences, vol. 10, no. 4, p. 1398, feb 2020. [Online].\\nAvailable: https://www.mdpi.com/2076-3417/10/4/1398\\n[5] E. Alomari, I. Katib, A. Albeshri, T. Yigitcanlar, R. Mehmood, and\\nA. A. Sa, “Iktishaf+: A Big Data Tool with Automatic Labeling for\\nRoad Traffic Social Sensing and Event Detection Using Distributed\\nMachine Learning,”Sensors, vol. 21, no. 9, p. 2993, apr 2021.\\n[Online]. Available: https://www.mdpi.com/1424-8220/21/9/2993\\n[6] M. Aqib, R. Mehmood, A. Alzahrani, I. Katib, and A. Albeshri, “A\\nDeep Learning Model to Predict Vehicles Occupancy on Freeways\\nfor Traffic Management,”IJCSNS - International Journal of Computer\\nScience and Network Security, vol. 18, no. 12, pp. 246–254, 2018.\\n[7] S. Usman, R. Mehmood, and I. Katib, “Big data and hpc convergence\\nfor smart infrastructures: A review and proposed architecture,” in Smart\\nInfrastructure and Applications Foundations for Smarter Cities and\\nSocieties. Springer Cham, 2020, pp. 561–586.\\n[8] R. Mehmood, F. Alam, N. N. Albogami, I. Katib, A. Albeshri, and\\nS. M. Altowaijri, “UTiLearn: A Personalised Ubiquitous Teaching and\\nLearning System for Smart Societies,” IEEE Access, vol. 5, pp. 2615–\\n2635, 2017.\\n[9] M. Aqib, R. Mehmood, A. Alzahrani, and I. Katib, A smart disaster\\nmanagement system for future cities using deep learning, gpus, and\\nin-memory computing, 2020.\\n[10] A. Omar Alkhamisi and R. Mehmood, “An Ensemble Machine and\\nDeep Learning Model for Risk Prediction in Aviation Systems,”\\nin2020 6th Conference on Data Science and Machine Learning\\nApplications (CDMA). Riyadh, Saudi Arabia: Institute of Electrical\\nand Electronics Engineers (IEEE), mar 2020, pp. 54–59. [Online].\\nAvailable: https://ieeexplore.ieee.org/abstract/document/9044233\\n[11] H. Alotaibi, F. Alsolami, and R. Mehmood, “DNA Profiling: An\\nInvestigation of Six Machine Learning Algorithms for Estimating the\\nNumber of Contributors in DNA Mixtures,” International Journal of\\nAdvanced Computer Science and Applications (IJACSA) , vol. 12, pp.\\n130–137, 2021.\\n[12] R. Mehmood, S. See, I. Katib, and I. Chlamtac, Smart Infrastructure and\\nApplications: foundations for smarter cities and societies , R. Mehmood,\\nS. See, I. Katib, and I. Chlamtac, Eds. Springer International\\nPublishing, Springer Nature Switzerland AG, 2020.\\n[13] S. Alotaibi, R. Mehmood, and I. Katib, “Sentiment Analysis of Arabic\\nTweets in Smart Cities: A Review of Saudi Dialect,” in 2019 Fourth\\nInternational Conference on Fog and Mobile Edge Computing (FMEC) .\\nIEEE, 2019, pp. 330–335. [14] Z. Hu, Y. Zhao, and M. Khushi, “A Survey of Forex and Stock Price\\nPrediction Using Deep Learning,”Appl. Syst. Innov., vol. 4, no. 1, p. 9,\\nfeb 2021. [Online]. Available: https://www.mdpi.com/2571-5577/4/1/9\\n[15] J. Sirignano and R. Cont, “Universal features of price formation\\nin financial markets: perspectives from deep learning,” Quant.\\nFinanc., vol. 19, no. 9, pp. 1449–1459, 2019. [Online]. Available:\\nhttps://www.tandfonline.com/doi/abs/10.1080/14697688.2019.1622295\\n[16] E. Guresen, G. Kayakutlu, and T. U. Daim, “Using artificial neural\\nnetwork models in stock market index prediction,” Expert Syst.\\nAppl., vol. 38, no. 8, pp. 10 389–10 397, 2011. [Online]. Available:\\nhttps://www.researchgate.net/publication/220219343\\n[17] L. Takeuchi and Y. Lee, “Applying Deep Learning\\nto Enhance Momentum Trading Strategies in\\nStocks,” Tech. Rep. December 1989, 2013. [Online].\\nAvailable: http://cs229.stanford.edu/proj2013/TakeuchiLee-\\nApplyingDeepLearningToEnhanceMomentumTradingStrategiesInStocks.pdf\\n[18] M. Nikou, G. Mansourfar, and J. Bagherzadeh, “Stock price\\nprediction using DEEP learning algorithm and its comparison\\nwith machine learning algorithms,”Intell. Syst. Accounting, Financ.\\nManag., vol. 26, no. 4, pp. 164–174, 2019. [Online]. Available:\\nhttps://www.researchgate.net/publication/337735594\\n[19] H. Hewamalage, C. Bergmeir, and K. Bandara, “Recurrent neural net-\\nworks for time series forecasting: Current status and future directions,”\\nInt. J. Forecast., vol. 37, no. 1, pp. 388–427, 2021.\\n[20] S. Li, X. Jin, Y. Xuan, X. Zhou, W. Chen, Y.-X. Wang,\\nand X. Yan, “Enhancing the Locality and Breaking the Memory\\nBottleneck of Transformer on Time Series Forecasting,” Adv.\\nNeural Inf. Process. Syst., vol. 32, jun 2019. [Online]. Available:\\nhttp://arxiv.org/abs/1907.00235\\n[21] U. Khandelwal, H. He, P. Qi, and D. Jurafsky, “Sharp Nearby, Fuzzy\\nFar Away: How Neural Language Models Use Context,” in Proc. 56th\\nAnnu. Meet. Assoc. Comput. Linguist. (Volume 1 Long Pap. , vol. 1.\\nStroudsburg, PA, USA: Association for Computational Linguistics, may\\n2018, pp. 284–294. [Online]. Available: http://arxiv.org/abs/1805.04623\\nhttp://aclweb.org/anthology/P18-1027\\n[22] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\\nGomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in\\nAdv. Neural Inf. Process. Syst., vol. 2017-Decem. Neural information\\nprocessing systems foundation, jun 2017, pp. 5999–6009. [Online].\\nAvailable: https://arxiv.org/abs/1706.03762v5\\n[23] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai,\\nT. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly,\\nJ. Uszkoreit, and N. Houlsby, “An Image is Worth 16x16 Words:\\nTransformers for Image Recognition at Scale,” oct 2020. [Online].\\nAvailable: http://arxiv.org/abs/2010.11929\\n[24] R. J. Hyndman, “A brief history of forecasting\\ncompetitions,” Tech. Rep. 1, 2020. [Online]. Available:\\nhttp://monash.edu/business/ebs/research/publications\\n[25] S. Selvin, R. Vinayakumar, E. A. Gopalakrishnan, V. K. Menon,\\nand K. P. Soman, “Stock price prediction using LSTM, RNN and\\nCNN-sliding window model,”2017 Int. Conf. Adv. Comput. Commun.\\nInformatics, ICACCI 2017, vol. 2017-Janua, pp. 1643–1647, 2017.\\n[26] S. Hochreiter and J. Schmidhuber, “Long Short-Term\\nMemory,”Neural Comput., vol. 9, no. 8, pp. 1735–1780,\\nnov 1997. [Online]. Available: http://direct.mit.edu/neco/article-\\npdf/9/8/1735/813796/neco.1997.9.8.1735.pdf\\n[27] N. Naik and B. R. Mohan, “Study of stock return predictions using\\nrecurrent neural networks with LSTM,” in Commun. Comput. Inf.\\nSci., vol. 1000. Springer Verlag, may 2019, pp. 453–459. [Online].\\nAvailable: https://link.springer.com/chapter/10.1007/978-3-030-20257-\\n6\\n39\\n[28] T. Skehin, M. Crane, and M. Bezbradica, “Day ahead forecasting of\\nFAANG stocks using ARIMA, LSTM networks and wavelets,” in CEUR\\nWorkshop Proc., vol. 2259, 2018, pp. 186–197.\\n[29] D. M. Nelson, A. C. Pereira, and R. A. De Oliveira,\\n“Stock market’s price movement prediction with LSTM\\nneural networks,” inProc. Int. Jt. Conf. Neural Networks ,\\nvol. 2017-May, 2017, pp. 1419–1426. [Online]. Available:\\nhttps://www.researchgate.net/publication/318329563\\n\\nwww.ijacsa.thesai.org 885 |P a g e\\n (IJACSA) International Journal of Advanced Computer Science and Applications,\\nVol. 12, No. 12, 2021\\n[30] S. Y. Shih, F. K. Sun, and H. yi Lee, “Temporal pattern\\nattention for multivariate time series forecasting,” Mach. Learn.,\\nvol. 108, no. 8-9, pp. 1421–1441, sep 2019. [Online]. Available:\\nhttps://doi.org/10.1007/s10994-019-05815-0\\n[31] G. Lai, W. C. Chang, Y. Yang, and H. Liu, “Modeling long- and\\nshort-term temporal patterns with deep neural networks,” Tech. Rep.,\\n2018. [Online]. Available: https://doi.org/10.475/123\\n4\\n[32] M. U. Gudelek, S. A. Boluk, and A. M. Ozbayoglu, “A deep learning\\nbased stock trading model with 2-D CNN trend detection,” in 2017\\nIEEE Symp. Ser. Comput. Intell.IEEE, nov 2017, pp. 1–8. [Online].\\nAvailable: http://ieeexplore.ieee.org/document/8285188/\\n[33] L. Di Persio and O. Honchar, “Artificial neural networks architectures\\nfor stock price prediction: Comparisons and applications,” Tech. Rep.,\\n2016.\\n[34] D. Povey, H. Hadian, P. Ghahremani, K. Li, and S. Khudanpur, “A\\ntime-restricted self-attention layer for ASR,” in ICASSP, IEEE Int. Conf.\\nAcoust. Speech Signal Process. - Proc. , vol. 2018-April. Institute of\\nElectrical and Electronics Engineers Inc., sep 2018, pp. 5874–5878.\\n[35] N. Parmar, A. Vaswani, J. Uszkoreit, L. Kaiser, N. Shazeer, A. Ku,\\nand D. Tran, “Image transformer,” Tech. Rep., jul 2018. [Online].\\nAvailable: http://proceedings.mlr.press/v80/parmar18a.html\\n[36] G. Bertasius, H. Wang, and L. Torresani, “Is Space-Time Attention All\\nYou Need for Video Understanding?” feb 2021. [Online]. Available:\\nhttp://arxiv.org/abs/2102.05095\\n[37] J.-S. Chou, D.-N. Truong, and T.-L. Le, “Interval Forecasting\\nof Financial Time Series by Accelerated Particle Swarm-\\nOptimized Multi-Output Machine Learning System,” IEEE\\nAccess, vol. 8, pp. 14 798–14 808, 2020. [Online]. Available:\\nhttps://ieeexplore.ieee.org/document/8955860/\\n[38] V. Braverman, R. Ostrovsky, and C. Zaniolo, “Optimal sampling from\\nsliding windows,”J. Comput. Syst. Sci., vol. 78, no. 1, pp. 260–272, jan\\n2012. [Online]. Available: http://dx.doi.org/10.1016/j.jcss.2011.04.004 https://linkinghub.elsevier.com/retrieve/pii/S0022000011000493\\n[39] K. Bandara, C. Bergmeir, and S. Smyl, “Forecasting across time series\\ndatabases using recurrent neural networks on groups of similar series:\\nA clustering approach,”Expert Syst. Appl., vol. 140, p. 112896, feb\\n2020.\\n[40] S. Smyl and K. Kuber, “Data Preprocessing and Augmentation\\nfor Multiple Short Time Series Forecasting with Recurrent\\nNeural Networks,” Tech. Rep., 2016. [Online]. Available:\\nhttps://www.researchgate.net/publication/309385800\\n[41] K. Chen, Y. Zhou, and F. Dai, “A LSTM-based method for stock\\nreturns prediction: A case study of China stock market,” in 2015 IEEE\\nInt. Conf. Big Data (Big Data). IEEE, oct 2015, pp. 2823–2824. [On-\\nline]. Available: https://ieeexplore.ieee.org/abstract/document/7364089/\\nhttp://ieeexplore.ieee.org/document/7364089/\\n[42] M. Nabipour, P. Nayyeri, H. Jabani, S. S., and A. Mosavi, “Predicting\\nStock Market Trends Using Machine Learning and Deep Learning\\nAlgorithms Via Continuous and Binary Data; a Comparative Analysis,”\\nIEEE Access, vol. 8, pp. 150 199–150 212, 2020. [Online]. Available:\\nhttps://ieeexplore.ieee.org/document/9165760/\\n[43] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S.\\nCorrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow,\\nA. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur,\\nJ. Levenberg, D. Mane, R. Monga, S. Moore, D. Murray, C. Olah,\\nM. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker,\\nV. Vanhoucke, V. Vasudevan, F. Viegas, O. Vinyals, P. Warden,\\nM. Wattenberg, M. Wicke, Y. Yu, and X. Zheng, “TensorFlow: Large-\\nScale Machine Learning on Heterogeneous Distributed Systems,” mar\\n2016. [Online]. Available: http://arxiv.org/abs/1603.04467\\n[44] J. Huang, J. Chai, and S. Cho, “Deep learning in finance and\\nbanking: A literature review and classification,” Front. Bus. Res.\\nChina, vol. 14, no. 1, p. 13, dec 2020. [Online]. Available:\\nhttps://fbr.springeropen.com/articles/10.1186/s11782-020-00082-6\\n\\nwww.ijacsa.thesai.org 886 |P a g e\\n\\n\\n ********************REFERENCES\\n[1]Mart\\x13\\x10n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo,\\nZhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jef-\\nfrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow,\\nAndrew Harp, Geoﬀrey Irving, Michael Isard, Yangqing Jia,\\nRafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Lev-\\nenberg, Dandelion Man\\x13e, Rajat Monga, Sherry Moore, Derek\\nMurray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit\\nSteiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent\\nVanhoucke, Vijay Vasudevan, Fernanda Vi\\x13egas, Oriol Vinyals,\\nPete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and\\nXiaoqiang Zheng. TensorFlow: large-scale machine learning on\\nheterogeneous systems, 2015. URL:https://www.tensorflow.org/.\\nSoftware available from tensor\\row.org.\\n[2]Shumeet Baluja. Population-based incremental learning. a\\nmethod for integrating genetic search based function opti-\\nmization and competitive learning. Technical report, Carnegie-\\nMellon Univ Pittsburgh Pa Dept Of Computer Science, 1994.\\n[3]Antonio Bentez-Hidalgo, Antonio J. Nebro, Jos Garca-Nieto,\\nIzaskun Oregi, and Javier [Del Ser]. jMetalPy: a Python frame-\\nwork for multi-objective optimization with metaheuristics.\\nSwarm and Evolutionary Computation, 51:100598, 2019. URL:\\nhttp://www.sciencedirect.com/science/article/pii/S2210650219301397 .\\n[4]Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas\\nSchneider, John Schulman, Jie Tang, and Wojciech Zaremba.\\nOpenai gym. arXiv preprint arXiv:1606.01540, 2016.\\n[5]Fran\\x18cois Chollet et al. Keras.https://keras.io, 2015.\\n[6]M. Coletti, A. Fafard, and D. Page. Troubleshooting deep-\\nlearner training data problems using an evolutionary algorithm\\non summit. IBM Journal of Research and Development:1{1, in\\npress.\\n[7]Dask Development Team. Dask: Library for dynamic task\\nscheduling. 2016. URL:https://dask.org.\\n[8]Kenneth De Jong. Evolutionary Computation: A Uni\\x0ced Ap-\\nproach. The MIT Press, 2006.\\n[9]Kenneth De Jong. Learning with genetic algorithms: an\\noverview. Machine learning, 3(2-3):121{138, 1988.\\n[10]F\\x13elix-Antoine Fortin, Fran\\x18cois-Michel De Rainville, Marc-\\nAndr\\x13e Gardner, Marc Parizeau, and Christian Gagn\\x13e. DEAP:\\nevolutionary algorithms made easy. Journal of Machine Learn-\\ning Research, 13:2171{2175, 2012.\\n[11]A. Garrett. Inspyred: bio-inspired algorithms in python. 2017.\\nURL:http://aarongarrett.github.io/inspyred/.\\n[12]Nikolaus Hansen, Sibylle D M\\x7fuller, and Petros Koumoutsakos.\\nReducing the time complexity of the derandomized evolution\\nstrategy with covariance matrix adaptation (cma-es). Evolu-\\ntionary computation, 11(1):1{18, 2003.\\n[13]Yannick Hold-Geoﬀroy, Olivier Gagnon, and Marc Parizeau.\\nOnce you scoop, no need to fork. In Proceedings of the 2014\\nAnnual Conference on Extreme Science and Engineering Dis-\\ncovery Environment, page 60. ACM, 2014.\\n[14]June 2019jTOP500 supercomputer sites, 2019. URL:https:\\n//www.top500.org/lists/2019/06/.\\n[15]Maarten Keijzer, Juan J Merelo, Gustavo Romero, and Marc\\nSchoenauer. Evolving objects: a general purpose evolution-\\nary computation library. In International Conference on Arti\\x0c-\\ncial Evolution (Evolution Arti\\x0ccielle), pages 231{242. Springer,\\n2001.\\n[16]Mehdi Khoury et al. pySTEP or Python strongly typed genetic\\nprogramming.https://sourceforge.net/projects/pystep/.\\n[17]Sean Luke. ECJ evolutionary computation library, 1998. Avail-\\nable for free at http://cs.gmu.edu/\\x18eclab/projects/ecj/.\\n[18]ORNL Leadership Computing Facility. Summit: america\\'s\\nnewest and smartest supercomputer, 2019. URL:https://www.\\nolcf.ornl.gov/for-users/system-user-guides/summit/summit-user-guide/\\n#system-overview.\\n[19]Gary Pampar\\x12a and Andries P Engelbrecht. Evolutionary and\\nswarm-intelligence algorithms through monadic composition. In\\nProceedings of the Genetic and Evolutionary Computation Con-\\nference Companion, pages 1382{1390, 2019.\\n[20]Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James\\nBradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Na-\\ntalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas\\nKopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan\\nTejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Jun-\\njie Bai, and Soumith Chintala. Pytorch: an imperative style, high-performance deep learning library. In Advances in Neu-\\nral Information Processing Systems 32, pages 8024{8035. 2019.\\nURL:http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-\\nhigh-performance-deep-learning-library.pdf.\\n[21]Christian S Perone. Pyevolve: a python open-source framework\\nfor genetic algorithms. Acm Sigevolution, 4(1):12{20, 2009.\\n[22]Adrian M. Price-Whelan and Daniel Foreman-Mackey.\\nSchwimmbad: a uniform interface to parallel processing pools\\nin python. The Journal of Open Source Software, 2(17), 2017.\\nURL:https://doi.org/10.21105/joss.00357.\\n[23]Ayodeji Remi-Omosowon and Yasser Gonzalez. Pyeasyga: A\\nsimple and easy-to-use implementation of a Genetic Algorithm\\nlibrary in Python.https://github.com/remiomosowon/pyeasyga, 2014.\\n[24]Matthew Rocklin and John Jacobsen. Toolz. 2020. URL:https:\\n//toolz.readthedocs.io/en/latest/index.html.\\n[25]Ralf Salomon. Re-evaluating genetic algorithm performance un-\\nder coordinate rotation of benchmark functions. A survey of\\nsome theoretical and practical aspects of genetic algorithms.\\nBioSystems, 39(3):263{278, 1996.\\n[26]Eric O Scott and Kenneth A De Jong. Understanding simple\\nasynchronous evolutionary algorithms. In Proceedings of the\\n2015 ACM Conference on Foundations of Genetic Algorithms\\nXIII, pages 85{98, 2015.\\n[27]Eric O Scott and Sean Luke. Ecj at 20: toward a general meta-\\nheuristics toolkit. In Proceedings of the Genetic and Evolu-\\ntionary Computation Conference Companion, pages 1391{1398,\\n2019.\\n\\n\\n ********************References\\n[1] I. Goodfellow, Y. Bengio, and A. Courville,Deep Learning,\\nMIT Press, Cambridge, UK, 2016.\\n[2] A. Vaswani, “Attention is all you need,” inProceedings of the\\n31st Conference on Neural Information Processing Systems\\n(NIPS 2017), Long Beach, CA, USA, 2017.\\n[3] D.Shah,H.Isah,andF.Zulkernine,“Stockmarketanalysis:a\\nreviewandtaxonomyofpredictiontechniques,”International\\nJournal of Financial Studies, vol. 7, no. 2, pp. 1–22, 2019.\\n[4] O. Bustos and A. Pomares-Quimbaya, “Stock market\\nmovementforecast:asystematicreview,”ExpertSystemswith\\nApplications, vol. 156, pp. 1–15, 2020.\\n[5] M. R. Islam, M. Rashed-Al-Mahfuz, S. Ahmad, and\\nM.K.I.Molla,“Multibandpredictionmodelforﬁnancialtime\\nseries with multivariate empirical mode decomposition,”\\nDiscreteDynamicsinNatureandSociety,vol.2012,ArticleID\\n593018, 21 pages, 2012.\\n[6] Q. Chen, M. Tao, X. He, and L. Tao, “Fuzzy adaptive non-\\nsingular ﬁxed-time attitude tracking control of quadrotor\\nUAVs,”IEEE Transactions on Aerospace and Electronic Sys-\\ntems, vol. 57, no. 5, pp. 2864–2877, 2021.\\n[7] Q. Chen, S. Xie, and X. He, “Neural-network-based adaptive\\nsingularity-free ﬁxed-time attitude tracking control for\\nspacecrafts,”IEEETransactionsonCybernetics,vol.51,no.10,\\npp. 5032–5045, 2021.\\n[8] Q. Chen, Y. Ye, Z. Hu, J. Na, and S. Wang, “Finite-time\\napproximation-freeattitudecontrolofquadrotors:theoryand\\nexperiments,”IEEE Transactions on Aerospace and Electronic\\nSystems, vol. 57, no. 3, pp. 1780–1792.\\n[9] C. Wei, Z. Zhang, W. Qiao, and L. Qu, “Reinforcement-\\nlearning-based intelligent maximum power point tracking\\ncontrol for wind energy conversion systems,”IEEE Trans-\\nactions on Industrial Electronics, vol. 62, no. 10, pp. 6360–\\n6370, 2015.\\n[10] C.Wei,Z.Zhang,W.Qiao,andL.Qu,“Anadaptivenetwork-\\nbased reinforcement learning method for MPPT control of\\nPMSG wind energy conversion systems,”IEEE Transactions\\non Power Electronics, vol. 31, no. 11, pp. 7837–7848, 2016.\\n[11] C. Wei, Y. Zhao, Y. Zheng, L. Xie, and K. Smedley, “Analysis\\nand design of a non-isolated high step-down converter with\\ncoupled inductor and ZVS operation,”IEEE Transactions on\\nIndustrial Electronics, p. 1, 2021.\\n[12] Y. Xia, Y. Liu, and Z. Chen, “Support Vector Regression for\\nprediction of stock trend,” inProceedings of the 2013 6th\\nInternational Conference on Information Management, In-\\nnovation Management and Industrial Engineering, vol. 123-\\n126, 2013.\\n[13] Y. Liu, Z. Qin, P. Li, and T. Wan, “Stock volatility prediction\\nusing recurrent neural networks with sentiment analysis,” in\\nAdvances in Artiﬁcial Intelligence: From zT_heory to Practice,\\nS. Benferhat, K. Tabia, and M. Ali, Eds., Springer, Berlin,\\nGermany, 2017.\\n[14] Q. Ding, S. Wu, H. Sun, J. Guo, and J. Guo, “Hierarchical\\nmulti-scale Gaussian transformer for stock movement pre-\\ndiction,” inProceedings of the Twenty-Ninth International\\nJoint Conference on Artiﬁcial Intelligence Special Track on AI\\nin FinTech, pp. 4640–4646, Yokohama, Japan, January 2020.\\n[15] R. Akita, A. Yoshihara, and T. Matsubara, “Deeplearning for\\nstockpredictionusingnumericalandtextualinformation,”in\\nProceedings of the 2016 IEEE/ACIS 15th International Con-\\nference on Computer and Information Science (ICIS), June\\n2016.[16] S. Jain, R. Gupta, and A. Moghe, “Stock price prediction on\\ndailystockdatausingdeepneuralnetworks,”inProceedingsof\\nthe 2018 International Conference on Advanced Computation\\nand Telecommunication (ICACAT), Bhopal, India, December\\n2018.\\n[17] J. Qiu, B. Wang, and C. Zhou, “Forecasting stock prices with\\nlong-short term memory neural network based on attention\\nmechanism,”PLoS One, vol. 15, no. 1, Article ID e0227222,\\n2020.\\n[18] T. B. Shahi, A. Shrestha, A. Neupane, W. Guo, and S. Price,\\n“Stock price forecasting with deep learning: a comparative\\nstudy,”Mathematics, vol. 8, no. 9, p. 1441, 2020.\\n[19] S.-L. Lin and H.-W. Huang, “Improving deep learning for\\nforecasting accuracy in ﬁnancial data,”Discrete Dynamics in\\nNature and Society, vol. 2020, pp. 1–12, 2020.\\n[20] K. Chen, Y. Zhou, and F. Dai, “A LSTM-based method for\\nstockreturnsprediction:acasestudyofChinastockmarket,”\\ninProceedings of the 2015 IEEE International Conference on\\nBig Data (Big Data), Santa Clara, CA, USA, October-No-\\nvember 2015.\\n[21] Y.Peng,Y.Liu,andR.Zhang,“Modelingandanalysisofstock\\nprice forecasting based on lstm,”Computer Engineering and\\nApplications (in Chinese), vol. 55, no. 11, pp. 209–212, 2019.\\n[22] S. Hochreiter and J. Schmidhuber, “Long short-term mem-\\nory,”Neural Computation, vol. 9, no. 8, pp.1735–1780, 1997.\\n[23] A. Graves,Supervised Sequence Labelling, Springer, Berlin,\\nGermany, 2012.\\n[24] N. Leo,zT_he Sixth Kondratieﬀ: zT_he New Long Wave in the\\nGlobal Economy, CreateSpace Independent Publishing Plat-\\nform, Scotts Valley, CA, USA, 2017.8DiscreteDynamicsinNatureandSociety\\n\\n\\n ********************REFERENCES\\n[1] P. Afshar, A. Mohammadi, and K. N. Plataniotis.\\nBrain tumor type classiﬁcation via capsule networks.\\nCoRR, abs/1802.10200, 2018.\\n[2] Aphex34. Convolutional neural network - max pooling.\\nhttps://en.wikipedia.org/wiki/Convolutional_\\nneural_network#Max_pooling_shape ; last accessed on\\n2018/06/14.\\n[3] M. T. Bahadori. Spectral capsule networks. 2018.\\n[4] S. Garg. Demystifying “matrix capsules with em\\nrouting.”.https://towardsdatascience.com/\\ndemystifying-matrix-capsules-with-em-routing\\n-part-1-overview-2126133a8457; last accessed on\\n2018/06/14.\\n[5] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual\\nlearning for image recognition.CoRR, abs/1512.03385,\\n2015.\\n[6] G. Hinton, S. Sabour, and N. Frosst. Matrix capsules\\nwith em routing. 2018.\\n[7]G. E. Hinton. What is wrong with convolutional neural\\nnets? Talk recorded on youtube,\\nhttps://youtu.be/rTawFwUvnLE; last accessed on\\n2018/06/14.\\n[8] K.-Y. Ho. Capsules: Alternative to pooling.\\nhttps://datawarrior.wordpress.com/2017/11/14/\\ncapsules-alternative-to-pooling/; last accessed on\\n2018/08/18.\\n[9] T. Kothari. Uncovering the intuition behind capsule\\nnetworks and inverse graphics.\\nhttps://hackernoon.com/\\nuncovering-the-intuition-behind-capsule-networks\\n-and-inverse-graphics-part-i-7412d121798d ; last\\naccessed on 2018/06/14.\\n[10] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classiﬁcation with deep convolutional neural\\nnetworks. InAdvances in neural information processing\\nsystems, pages 1097–1105, 2012.\\n[11] S. Kullback and R. A. Leibler. On information and\\nsuﬃciency.The annals of mathematical statistics ,\\n22(1):79–86, 1951.\\n[12] R. LaLonde and U. Bagci. Capsules for Object\\nSegmentation.ArXiv e-prints, Apr. 2018.\\n[13] Y. LeCun, C. Cortes, and C. Burges. Mnist dataset,\\n1998.\\n[14] H. Lee, R. Grosse, R. Ranganath, and A. Y. Ng.\\nConvolutional deep belief networks for scalable\\nunsupervised learning of hierarchical representations. In\\nProceedings of the 26th annual international conference\\non machine learning, pages 609–616. ACM, 2009.\\n[15] Mathworks. Convolutional neural network. https:\\n//www.mathworks.com/solutions/deep-learning/\\nconvolutional-neural-network.html ; last accessed\\non 2018/06/14.\\n[16] D. G. Pelli. Crowding: A cortical constraint on object\\nrecognition.Current opinion in neurobiology,\\n18(4):445–451, 2008.\\n[17] S. S. R. Phaye, A. Sikka, A. Dhall, and D. Bathula.\\nDense and diverse capsule networks: Making the\\ncapsules learn better.arXiv preprint arXiv:1805.04001,\\n2018.\\n[18] D. Rawlinson, A. Ahmed, and G. Kowadlo. Sparse\\nunsupervised capsules generalize better. CoRR,\\nabs/1804.06094, 2018.\\n[19] O. Ronneberger, P. Fischer, and T. Brox. U-net:\\nConvolutional networks for biomedical image\\nsegmentation. InInternational Conference on Medical\\nimage computing and computer-assisted intervention ,\\npages 234–241. Springer, 2015.\\n[20] S. Sabour, N. Frosst, and G. E. Hinton. Dynamic\\nrouting between capsules. InAdvances in Neural\\nInformation Processing Systems, pages 3859–3869,\\n2017.\\n[21] A. Shahroudnejad, A. Mohammadi, and K. N.\\nPlataniotis. Improved explainability of capsule\\nnetworks: Relevance path by agreement. CoRR,\\nabs/1802.10204, 2018.\\n[22] soskek. Capsnets tensorﬂow implementation.\\nhttps://github.com/soskek/dynamic_routing_\\nbetween_capsules; last accessed on 2018/06/14.\\n[23] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,\\nD. Anguelov, D. Erhan, V. Vanhoucke, and\\nA. Rabinovich. Going deeper with convolutions. InThe\\nIEEE Conference on Computer Vision and Pattern\\nRecognition (CVPR), June 2015.\\n[24]D. Wang and Q. Liu. An optimization view on dynamic\\nrouting between capsules. 2018.\\n[25] Y. Wang, A. Sun, J. Han, Y. Liu, and X. Zhu.\\nSentiment analysis by capsules. In Proceedings of the\\n2018 World Wide Web Conference on World Wide\\nWeb, pages 1165–1174. International World Wide Web\\nConferences Steering Committee, 2018.\\n[26] E. Xi, S. Bing, and Y. Jin. Capsule Network\\nPerformance on Complex Data.ArXiv e-prints, Dec.\\n2017.Seminars FI / IITM SS 18,\\nNetwork Architectures and Services, September 2018 95 doi: 10.2313/NET-2018-11-1_12\\n\\n\\n ********************References\\n1.Arnab Basu, Tirthankar Bhattacharyya, and Vivek S. Borkar. A learning algorithm for risk-\\nsensitive cost.Mathematics of Operations Research , 33(4):880–898, 2008.\\n2.Vivek S. Borkar. Q-learning for risk-sensitive control. Mathematics of Operations Research ,\\n27(2):294–311, 2002.\\n3.John Y. Campbell, Andrew W. Lo, and A. Graig MacKinlay. The Econometrics of Financial\\nMarkets. Princeton University Press, 1997.\\n4.CMA. Global sovereign credit risk report, 4th quarter 2010. Credit Market Analysis, Ltd.\\n(CMA), 2011.\\n5.Peter Geibel and Fritz Wysotzki. Risk-sensitive reinforcement learning applied to control\\nunder constraints.Journal of Artiﬁcial Intelligence Research , 24:81–108, 2005.\\n6.Abhijit Gosavi. A reinforcement learning algorithm based on policy iteration for average\\nreward: Empirical results with yield management and convergence analysis. Machine Learn-\\ning, 55(1):5–29, 2004.\\n7.Matthias Heger. Consideration of risk in reinforcement learning. In Proc. of ICML 1994,\\npages 105–111, 1994.\\n8.John Larry Kelly, Jr. A new interpretaion of information rate. Bell System Technical Journal,\\n35:917–26, 1956.\\n9.Oliver Mihatsch and Ralph Neuneier. Risk-sensitive reinforcement learning. Machine Learn-\\ning, 49(2–3):267–290, 2002.\\n10.William Poundstone.Fortune’s Formula: The untold story of the scientiﬁc betting system\\nthat beat the casinos and wall street . Hill and Wang, 2005.\\n11.Makoto Sato and Shigenobu Kobayashi. Average-reward reinforcement learning for variance\\npenalized markov decision problems. In Proc. of ICML 2001, pages 473–480, 2001.\\n12.Anton Schwartz. A reinforcement learning method for maximizing undiscounted rewards.\\nInProc. of ICML 1993, pages 298–305, 1993.\\n13.Satinder P. Singh. Reinforcement learning algorithms for average-payoff markovian decision\\nprocesses. InProc. of AAAI 1994, volume 1, pages 700–705, 1994.\\n14.Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction . The\\nMIT Press, 1998.\\n15.John N. Tsitsiklis and Benjamin Van Roy. On average versus discounted reward temporal-\\ndifference learning.Machine Learning, 49:179–191, 2002.\\n16.Ralph Vince.Portfolio management formulas: mathematical trading methods for the futures,\\noptions, and stock markets. Wiley, 1990.\\n17.Christopher J. C. H. Watkins and Peter Dayan. Technical note: Q-learning. Machine Learn-\\ning, 8(3/4):279–292, 1992.\\n\\n\\n ********************REFERENCES\\n[1]  Coats, P. K., Fant, F. L. (1993).  “Recognizing financial distress patterns using a neural\\nnetwork tool,” Financial Management, 22(3), 142-156.\\n[2]  Demuth, Mark and Beale, Mark, (1994).   Neural Network Toolbox, Users Guide , Natick,\\nMass: The Math Works, Inc.\\n[3]  Dorsey, R.E. and Mayer W.J., (1995).  \"Genetic Algorithms for Estimation Problems with\\nMultiple Optima, Non-Differentiability, and Other Irregular Features,\" Journal of Business\\nand Economic Statistics, 13(1), 53-66.\\n 21\\n[4]  Dorsey, R. E. and Mayer, W. J. (1994).  “Optimization Using Genetic Algorithms,”  Advanc-\\nes in Artificial Intelligence in Economics, Finance, and Management (J. D. Johnson and A.\\nB. Whinston, eds.). Vol. 1. Greenwich, CT: JAI Press Inc., 69-91.\\n[5]  Dorsey, R. E., Johnson, J. D. And Mayer, W. J.  (1992).  “The Genetic Adaptive Neural\\nNetwork Training (GANNT) for Generic Feedforard Artificial Neural Systems,” School of\\nBusiness Administration Working Paper, available at http://www.bus.olemiss.edu/johnson/\\ncompress/compute.htm.\\n[6]  Dorsey, R. E., Johnson, J. D. And Mayer, W. J.  (1994).  “A Genetic Algorithm for the\\nTraining of Feedforward Neural Networks,”  Advances in Artificial Intelligence in\\nEconomics, Finance, and Management  (J. D. Johnson and A. B. Whinston, eds., 93-111). \\nVol. 1. Greenwich, CT: JAI Press Inc.\\n[7]  Dorsey, R. E., Johnson, J. D. And Van Boening, M. V.  (1994).  “The Use of Artificial\\nNeural Networks for Estimation of Decision Surfaces in First Price Sealed Bib Auctions,”\\nIn W.W. Cooper and A.B. Whinston (eds.),  New Direction in Computational Economics,\\nNetherlands:Kluwer Academic Publishers, 19-40.\\n[8]  Fahlman, S. E., And Lebiere, C. (1990).  “The Cascade-Correlation learning architecture. \\nAdvances in Neural Information Processing Systems,” Vol. II, Morgan Kaufmann, San\\nMateo, CA, 524-532.\\n[9]  Funahashi, K.-I. (1989).  “On the Approximate Realization of Continuous Mappings by\\nNeural Networks,”  Neural Networks 2(3): 183-192.\\n[10] Hand, D.J. (1981), Discrimination and Classification , John Wiley and Sons, Chichester.\\n[11] Hornik, K., Stinchcombe, M. and White, H. (1989).  “Multilayer Feed-forward Networks are\\nUniversal Approximators,” Neural Networks 2(5): 359-366.\\n[12] Huang, C.S., R.E. Dorsey and M.A. Boose. (1995), \"Life Insurer Financial Distress\\nPrediction: A Neural Network Model,\" Journal of Insurance Regulation, 13(2), 131-167.\\n[13] Lacher, R. C., Coats, P. K., Sharma, S. C., And Fant, F. L. (1995).  “A Neural Network for\\nClassifying the Financial Health of a Firm,” European Jouranal of Operatiional Research,\\n85(1), 53-66. \\n 22\\n[14] LeCun, Y. (1986).  “Learning Processes in an Asymmetric Threshold Network”,  Disordered\\nSystems and Biological Organization (pp. 233-240).  Berlin: Springer Verlag.\\n[15]  Lee, T. -H., White, H. and Granger, C. W. J. (1993).  “Testing for Neglected Nonlinearity in\\nTime Series Model: A Comparison of Neural Network Methods and Alternative Tests,” \\nJournal of Econometrics 56(1), 269-290.\\n[16]  Miller, G.F., Todd, P.M., and S.U. Hedge, (1989).   “Designing Neural Networks Using\\nGenetic Algorithms,\" Proc. 3rd International Conference on Genetic Algorithms, San\\nMateo, Calf: Morgan Kaufmann.\\n[17] Montana, D. J., and L. Davis, 1989, “Training Feedforward Neural Networks Using Genetic\\nAlgorithms,” BBN Systems and Technologies Technical Report. \\n[18]  Parker, D. (1985).  “Learning Logic,”  Technical Report TR-87.  Cambridge, MA: Center\\nfor Computational Research in Economics and Management Science, MIT.\\n[19]  Rumelhart, D. E., Hinton, G. G. and Williams, R. J. (1986a).  “Learning Internal\\nRepresentations by Error Propagation”,  Parallel Distributed Processing: Exploration in\\nthe Microstructure of Cognition (pp. 318-362).  Cambridge MA: MIT Press.\\n[20]  Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986b).  “Learning Representations by\\nBack propagating Errors,”  Nature 323, 533-536.\\n[21]  Salchenberger, L. M., Cinar, E. M. And Lash, N. A. (1992).  “Neural Networks: A New\\nTool for Predicting Thrift Failures,”  Decision Sciences 23, 899-916.\\n[22]  Todd, P.M., (1988), \"Evolutionary Methods for Connectionists Architectures,\" Psychology\\nDept. Stanford University, unpublished Manuscript.\\n[23]  Wang, Shouhong, (1995).  “The Unpredictability of Standard Back Propagation Neural\\nNetworks in Classification Applications,” Management Science 41(3), March 1995,  555-\\n559.\\n[24]  Werbos, P. (1974).  “Beyond Regression: New Tool for Prediction and Analysis in the\\nBehavioral Sciences,” Unpublished Ph.D.  Thesis.  Harvard University.\\n[25] Whitley, Darrell and T. Hansen, 1989, “The GENITOR Algorithm: Using Genetic\\nRecombination to Optimize Neural Networks,” Working Paper, Computer Science\\nDepartment, Colorado State University.\\n 23\\n[26] Whitley, Darrell, Starkweather, Timothy, and Christopher Bogart, 1990, “Genetic\\nAlgorithms and Neural Networks: Optimizing Connections and Connectivity,”  Parallel\\nComputing, 14, pp. 347-361. \\n[27]  Wilensky, G and Manukian, N. (1992).  “The Projection Neural Network,”  International\\nJoint Conference on Neural Networks (358-367).  Vol II.\\n 24\\nTable 1: Alternate Backpropagation Training Parameters\\n                                                                       Learning Rate\\n                                                          .5                                       1\\nLogicon         Test           Momentum       Momentum\\n             Size\\nAlgorithm      .3                  .9       .3             .9\\n          OFF           1 10 rep 10 rep 10 rep 10 rep\\n                50\\n      \\n          \\n         ON  10 rep    10 rep 10 rep 10 rep\\n       1     10 rep10 rep10 rep10 rep\\n      50 10 rep10 rep10 rep10 rep\\n  \\n 25\\nTable 2 - Optimal Training Parameters for Back Propagation\\nPROBLEMLEARNING MOMENTUM   TESTLOGICON\\n    RATE     SIZE\\n11.91OFF\\n2 1.91OFF\\n31.91OFF\\n4.5.91OFF\\n51.91OFF\\n6.5.91OFF\\n71.91OFF\\n 26\\nTable 3 - Comparisons of In-Sample RMS Error for BP and GA Trained NNs\\nProb P valueBPGABPGABPGABPGA\\nBestBest WorstWorstMeanMeanStdevStdev\\n14.11E-014.16E-0717.638.46E-068.562.61E-065.864.02E-06.00\\n211.651.27E-02337.905.07E-01164.271.15E-0186.451.22E-01.00\\n35.311.82E-0115.301.2910.375.22E-012.516.13E-01.00\\n4178.704.09E-023,253.782.201,023.463.50-01942.712.33.00\\n58459.913.06E-02201,0631.09102,7072.56E-0155719.385.60E-01.00\\n61.33E-012.53E-025.19E-011.29E-013.83E-017.91E-021.05E-015.34E-03.00\\n74.793.47E-0113.502.4910.561.322.502.29.00\\n 27\\nTable 4 - Out-of-Sample Comparisons RMS errors\\nInterpolation Comparison Extrapolation Comparison\\nMean RMS Error forStandard DeviationMean RMS Error forStandard Deviation\\n10 Data Setsfor 10 Data Sets10 Data Setsfor 10 Data Sets\\nProbBPGABPGABPGABPGA\\n11.894.06E-071.552.07E-088.451.42E-043.082.52E-05\\n220.201.56E-029.231.26E-03265.821.2923.737.32E-02\\n39.634.46E-014.343.73E-0226.307.101.81E-012.72E-01\\n4360.974.67E-02123.582.43E-037527.6810.47895.071.18\\n525692.832.10E-027574.863.09E-03183633.173681.3117278.26416.69\\n61.22E-013.36E-021.38E-021.37E-03N/AN/AN/AN/A\\n75.951.955.97E-013.87E-0131.771.03E-011.663.16E-03\\n 28\\nTable 5 - In-Sample Training Comparisons\\n   *Number of Epochs **Execution Time in\\nseconds \\nProbBPGABPGA\\n1  1,000,000100,0001,250343\\n2  1,000,000   100,0001,250343\\n3  1,000,000100,0001,250343\\n41,000,000 100,0001,250343\\n51,000,000   100,0001,100317\\n61,000,000100,0001,350508\\n71,000,000100,0001,250494\\n* One epoch is a complete pass through the data \\n** Time in seconds based on execution time on a Pentium\\n83MHz PC\\nPC version for BP NeuralWorks Professional II/PLUS \\nNeuralWare, Inc.\\n 29\\nTable 6 - Wilcoxon Matched Pairs Ranks Test\\nNumber of Test Sets out of 10 where the GA\\nTrained NN found Superior Solutions to the BP\\nTrained NN at the 0.99 Level of  Significance\\nProblemInterpolationExtrapolation\\n11010\\n21010\\n31010\\n41010\\n51010\\n610NA\\n71010\\n 30\\nTable 7 - RMS Comparison for Functions including Error\\nParameters\\nfrom\\nTraining\\nRun                   X+X+e*                    X*X+e**1 2 12\\nInterpolationExtrapolationInterpolationExtrapolation\\n     BPGABPGABPGABPGA\\n  1  4.141.2736.653.47  16.021.661303.618.58\\n  2  2.851.5632.243.89215.971.752037.618.97\\n  3  2.821.8234.285.12  49.271.671460.358.67\\n  4  2.931.4830.734.15  50.821.881399.338.84\\n  5  6.951.5734.279.38  30.561.641479.328.50\\n  6  2.901.3038.373.70  15.962.001321.459.52\\n  7  2.802.0334.595.87  19.732.131317.339.80\\n  8  3.111.4733.434.17  21.351.851322.689.79\\n  9  2.991.5034.333.50  29.861.751348.109.24\\n10  2.711.6034.023.69  19.481.651307.228.48\\n  *error was drawn from a normal distribution    [µ=0,  s=5]2\\n**error was drawn from a normal distribution    [µ=0,  s=10]2\\n \\n-1000 \\n-500 \\n0 \\n500 \\n1000 \\n1500 \\n\\n-1000 \\n-500 \\n0 \\n500 \\n1000 \\n1500 \\n\\nTrue ValuesFigure 1 - BP Interpolation Forecasts\\nLine Indicates Problem 4 Actual Values 31\\n-1000 \\n-500 \\n0 \\n500 \\n1000 \\n1500 \\n\\n-1000 \\n-500 \\n0 \\n500 \\n1000 \\n1500 \\n\\nTrue Values\\nFigure 2  - GA Interpolation Forecasts\\nLine Indicates Problem 4 Actual Values 32\\n0 \\n5 \\n10 \\n15 \\n20 \\n25 \\n30 \\n\\n2 \\n4 \\n6 \\n8 \\n10 \\n12 \\n14 \\n16 \\n18 \\nTrue Values\\nThousands\\nFigure 3 - BP Extrapolation Forecasts\\n\\nLine Indicates Problem 4 Actual Values 33\\n0 \\n5 \\n10 \\n15 \\n20 \\n25 \\n30 \\n\\n2 \\n4 \\n6 \\n8 \\n10 \\n12 \\n14 \\n16 \\n18 \\nTrue Values\\nThousands\\nFigure 4 - GA Extrapolation Forecasts\\nLine Indicates Problem 4 Actual Values 34\\n    \\n012345678910\\n0246810\\nln (type 1 units)ln (type 2 units)\\n\\n012345678910\\n0246810\\nln (type 1 units)ln (type 2 units)\\n\\n012345678910\\n0246810\\nln (type 1 units)ln (type 2 units)\\n 35\\nNon Parametric Classification from\\nHand(1981) Monotonic NN from Wang (1995)\\nUnconstrained Neural Network\\n 36\\nFigure 6 - Partitions of Classification Problem  \\n                  \\n       \\n                     \\nFigure 5- Four levels of Magnification of the GA and BP solutions to the X *X12\\nProblem.  The vertical axis is the sum of squared errors.  The horizontal axes\\ncorrespond to two of the NN weights.  The optimal values are centered on the axes and\\nresult in the smallest SSE.  Four levels of magnification are shown.  The least\\nmagnification is in the upper left, and then increasing to the lower left, upper right and\\nfinally lower right.   In each pair the GA solution is on the left and the BP solution is on\\nthe right.    \\n\\n\\n ********************REFERENCES\\n[1] J. Kober, J. A. Bagnell, and J. Peters, “Reinforcement learning in\\nrobotics: A survey,”The International Journal of Robotics Research ,\\nvol. 32, no. 11, pp. 1238–1274, 2013.\\n[2] M. Deisenroth and C. E. Rasmussen, “Pilco: A model-based and\\ndata-efﬁcient approach to policy search,” in Proceedings of the 28th\\nInternational Conference on machine learning (ICML-11) , 2011, pp.\\n465–472.\\n[3] Y. Ling, S. A. Hasan, V. Datla, A. Qadir, K. Lee, J. Liu, and O. Farri,\\n“Diagnostic inferencing via improving clinical concept extraction with\\ndeep reinforcement learning: A preliminary study,” in Machine Learning\\nfor Healthcare Conference, 2017, pp. 271–285.\\n[4] Y. Li, “Deep reinforcement learning: An overview,” arXiv preprint\\narXiv:1701.07274, 2017.\\n[5] C. Comerton-Forde and T. J. Putnin¸ ˇs, “Dark trading and price discovery,”\\nJournal of Financial Economics, vol. 118, no. 1, pp. 70–92, 2015.\\n[6] M. O’Hara, “High frequency market microstructure,” Journal of Finan-\\ncial Economics, vol. 116, no. 2, pp. 257–270, 2015.\\n[7] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, “Prox-\\nimal policy optimization algorithms,”arXiv preprint arXiv:1707.06347,\\n2017.\\n[8] F. Hutter, H. H. Hoos, and K. Leyton-Brown, “Sequential model-\\nbased optimization for general algorithm conﬁguration,” in International\\nconference on learning and intelligent optimization . Springer, 2011,\\npp. 507–523.\\n[9] A. Briola, J. Turiel, and T. Aste, “Deep learning modeling of limit order\\nbook: a comparative perspective,”arXiv preprint arXiv:2007.07319,\\n2020.\\n[10] A. Hill, A. Rafﬁn, M. Ernestus, A. Gleave, A. Kanervisto, R. Traore,\\nP. Dhariwal, C. Hesse, O. Klimov, A. Nichol, M. Plappert, A. Radford,\\nJ. Schulman, S. Sidor, and Y. Wu, “Stable baselines,” https://github.com/\\nhill-a/stable-baselines, 2018.\\n[11] J.-P. Bouchaud, J. Bonart, J. Donier, and M. Gould, Trades, Quotes\\nand Prices: Financial Markets Under the Microscope . Cambridge\\nUniversity Press, 2018.\\n[12] R. S. Sutton and A. G. Barto,Reinforcement learning: An introduction .\\nMIT press, 2018.\\n[13] K. Arulkumaran, M. P. Deisenroth, M. Brundage, and A. A. Bharath,\\n“Deep reinforcement learning: A brief survey,” IEEE Signal Processing\\nMagazine, vol. 34, no. 6, pp. 26–38, 2017.\\n[14] P. Abbeel and J. Schulman, “Deep reinforcement learning through policy\\noptimization,”Tutorial at Neural Information Processing Systems , 2016.\\n[15] M. Kearns and Y. Nevmyvaka, “Machine learning for market mi-\\ncrostructure and high frequency trading,” High Frequency Trading: New\\nRealities for Traders, Markets, and Regulators , 2013.\\n[16] A. Tsantekidis, N. Passalis, A. Tefas, J. Kanniainen, M. Gabbouj, and\\nA. Iosiﬁdis, “Forecasting stock prices from the limit order book using\\nconvolutional neural networks,” in2017 IEEE 19th Conference on\\nBusiness Informatics (CBI), vol. 1. IEEE, 2017, pp. 7–12.\\n[17] J. Sirignano and R. Cont, “Universal features of price formation in ﬁ-\\nnancial markets: perspectives from deep learning,” Quantitative Finance,\\nvol. 19, no. 9, pp. 1449–1459, 2019.\\n[18] Z. Zhang, S. Zohren, and S. Roberts, “Bdlob: Bayesian deep con-\\nvolutional neural networks for limit order books,” arXiv preprint\\narXiv:1811.10041, 2018.\\n[19] ——, “Extending deep learning models for limit order books to quantile\\nregression,”arXiv preprint arXiv:1906.04404, 2019.\\n[20] J. Moody and M. Saffell, “Learning to trade via direct reinforcement,”\\nIEEE transactions on neural Networks , vol. 12, no. 4, pp. 875–889,\\n2001.\\n[21] J. E. Moody and M. Saffell, “Reinforcement learning for trading,” in\\nAdvances in Neural Information Processing Systems , 1999, pp. 917–\\n923.\\n[22] J. Moody, L. Wu, Y. Liao, and M. Saffell, “Performance functions and\\nreinforcement learning for trading systems and portfolios,” Journal of\\nForecasting, vol. 17, no. 5-6, pp. 441–470, 1998.\\n[23] R. Neuneier, “Optimal asset allocation using adaptive dynamic program-\\nming,” inAdvances in Neural Information Processing Systems , 1996, pp.\\n952–958.\\n[24] O. Mihatsch and R. Neuneier, “Risk-sensitive reinforcement learning,”\\nMachine learning, vol. 49, no. 2-3, pp. 267–290, 2002. [25] J. Moody, M. Saffell, W. L. Andrew, Y. S. Abu-Mostafa, B. LeBaraon,\\nand A. S. Weigend, “Minimizing downside risk via stochastic dynamic\\nprogramming,”Computational Finance, pp. 403–415, 1999.\\n[26] T. L. Meng and M. Khushi, “Reinforcement learning in ﬁnancial\\nmarkets,”Data, vol. 4, no. 3, p. 110, 2019.\\n[27] D. Byrd, M. Hybinette, and T. H. Balch, “Abides: Towards high-ﬁdelity\\nmarket simulation for ai research,”arXiv preprint arXiv:1904.12066,\\n2019.\\n[28] M. Karpe, J. Fang, Z. Ma, and C. Wang, “Multi-agent reinforcement\\nlearning in a realistic limit order book market simulation,” arXiv preprint\\narXiv:2006.05574, 2020.\\n[29] F. Bertoluzzo and M. Corazza, “Testing different reinforcement learn-\\ning conﬁgurations for ﬁnancial trading: Introduction and applications,”\\nProcedia Economics and Finance, vol. 3, pp. 68–77, 2012.\\n[30] L. Chen and Q. Gao, “Application of deep reinforcement learning on\\nautomated stock trading,” in2019 IEEE 10th International Conference\\non Software Engineering and Service Science (ICSESS) . IEEE, 2019,\\npp. 29–33.\\n[31] Q.-V. Dang, “Reinforcement learning in stock trading,” in International\\nConference on Computer Science, Applied Mathematics and Applica-\\ntions. Springer, 2019, pp. 311–322.\\n[32] Y. Deng, F. Bao, Y. Kong, Z. Ren, and Q. Dai, “Deep direct rein-\\nforcement learning for ﬁnancial signal representation and trading,” IEEE\\ntransactions on neural networks and learning systems , vol. 28, no. 3,\\npp. 653–664, 2016.\\n[33] G. Jeong and H. Y. Kim, “Improving ﬁnancial trading decisions using\\ndeep q-learning: Predicting the number of shares, action strategies, and\\ntransfer learning,”Expert Systems with Applications, vol. 117, pp. 125–\\n138, 2019.\\n[34] Y. Kim, W. Ahn, K. J. Oh, and D. Enke, “An intelligent hybrid trading\\nsystem for discovering trading rules for the futures market using rough\\nsets and genetic algorithms,”Applied Soft Computing, vol. 55, pp. 127–\\n140, 2017.\\n[35] Z. Zhang, S. Zohren, and S. Roberts, “Deep reinforcement learning for\\ntrading,”The Journal of Financial Data Science, vol. 2, no. 2, pp. 25–40,\\n2020.\\n[36] T. Th´eate and D. Ernst, “An application of deep reinforcement learning\\nto algorithmic trading,”arXiv preprint arXiv:2004.06627, 2020.\\n[37] H. Yang, X.-Y. Liu, S. Zhong, and A. Walid, “Deep reinforcement\\nlearning for automated stock trading: An ensemble strategy,” Available\\nat SSRN, 2020.\\n[38] Z. Jiang and J. Liang, “Cryptocurrency portfolio management with\\ndeep reinforcement learning,” in2017 Intelligent Systems Conference\\n(IntelliSys). IEEE, 2017, pp. 905–913.\\n[39] Z. Zhang, S. Zohren, and S. Roberts, “Deep learning for portfolio\\noptimisation,”arXiv preprint arXiv:2005.13665, 2020.\\n[40] Y.-J. Hu and S.-J. Lin, “Deep reinforcement learning for optimizing\\nﬁnance portfolio management,” in2019 Amity International Conference\\non Artiﬁcial Intelligence (AICAI). IEEE, 2019, pp. 14–20.\\n[41] Y.-S. Lim and D. Gorse, “Reinforcement learning for high-frequency\\nmarket making.” inESANN, 2018.\\n[42] Y. Wang, “Electronic market making on large tick assets,” Ph.D.\\ndissertation, The Chinese University of Hong Kong (Hong Kong), 2019.\\n[43] R. Huang and T. Polak, “Lobster: Limit order book reconstruction\\nsystem,”Available at SSRN 1977207, 2011.\\n[44] T. H. Balch, M. Mahfouz, J. Lockhart, M. Hybinette, and D. Byrd, “How\\nto evaluate trading strategies: Single agent market replay or multiple\\nagent interactive simulation?”arXiv preprint arXiv:1906.12010, 2019.\\n[45] M. Bibinger, C. Neely, and L. Winkelmann, “Estimation of the discon-\\ntinuous leverage effect: Evidence from the nasdaq order book,” Journal\\nof Econometrics, vol. 209, no. 2, pp. 158–184, 2019.\\n[46] M. Bibinger, M. Jirak, M. Reiss et al., “Volatility estimation under\\none-sided errors with applications to limit order books,” The Annals\\nof Applied Probability, vol. 26, no. 5, pp. 2754–2790, 2016.\\n[47] B. Shahriari, K. Swersky, Z. Wang, R. P. Adams, and N. De Freitas,\\n“Taking the human out of the loop: A review of bayesian optimization,”\\nProceedings of the IEEE, vol. 104, no. 1, pp. 148–175, 2015.\\n[48] P. I. Frazier, “Bayesian optimization,” in Recent Advances in Optimiza-\\ntion and Modeling of Contemporary Problems . INFORMS, 2018, pp.\\n255–278.\\n[49] F. Archetti and A. Candelieri,Bayesian Optimization and Data Science .\\nSpringer, 2019.\\n[50] A. Candelieri and F. Archetti, “Global optimization in machine learning:\\nthe design of a predictive analytics application,” Soft Computing, vol. 23,\\nno. 9, pp. 2969–2977, 2019.\\n[51] C. E. Rasmussen, “Gaussian processes in machine learning,” in Summer\\nSchool on Machine Learning. Springer, 2003, pp. 63–71.\\n[52] J. Moˇckus, “On bayesian methods for seeking the extremum,” in\\nOptimization techniques IFIP technical conference . Springer, 1975,\\npp. 400–404.\\n[53] D. R. Jones, M. Schonlau, and W. J. Welch, “Efﬁcient global optimiza-\\ntion of expensive black-box functions,” Journal of Global optimization,\\nvol. 13, no. 4, pp. 455–492, 1998.\\n\\n\\n ********************\\n\\n ********************References \\n\\n \\nAlexander, S. \\n(1961). “Price movements in speculative markets: Trends or random walks.” \\n\\nIndustrial Management Review\\n. Vol 2, No. 2, pp. 7\\n–\\n26. \\n \\n\\nAllen and Karjalainen (1993). “Using Genetic Algorithms to Find Technical Trading Rules.” \\n\\nRodney L. White Center for Financial Research. Wharton School of Business \\npublications.  \\n \\n\\nBreiman, (2001). “Random Forests”. Machine\\n  Learning. Vol 45, No. 1, pp 5 -32. \\n\\n \\n\\nBrock, Lakonishok, and LeBaron (1992). “\\n Simple technical trading rules and the stochastic \\nproperties of stock returns\\n.” Journal of Finance. Vol. 47, No. 5, pp 1731\\n -1764. \\n \\n\\nFama (1970). “\\nEfficient capital markets: A review  of theory and empirical work\\n.” Journal of \\n\\nFinance. Vol 25, No. 2, pp 383 -417. \\n \\n\\nFama, E., Blume, M. (1966). “Filter Rules and Stock\\n -\\nMarket Trading.”The Journal of Business. \\n\\nVol. 39, No. 1, pp 226-241. \\n \\nFernandez-\\nRodrıguez, Martel, and Rivero (2000). “On th\\ne Profitability of Technical Trading \\n\\nRules Based on Artificial Neural Networks: Evidence from the Madrid stock market.” \\n\\nEconomic Letters. Vol 69, No. 1, pp 89 -94. \\n \\n\\nGrossman and Stiglitz (1980). “On the Impossibility of Informationally Efficient Markets.” T\\n he \\nAmerican Economic Review. Vol. 70, No. 3, pp 393 -408. \\n \\n\\nGunasekarage and Power (2001). “\\n The profitability of moving average trading rules in South \\nAsian stock markets\\n” Emerging Markets Review. Vol 2, No. 1, pp 17\\n -33. \\n \\n\\nHo, T.K. (1995). “Random Decision Forests.” \\nDocument Analysis and Recognition, 1995., \\nProceedings of the Third International Conference on . Vol. 1, pp 278-282. \\n \\n\\nIsakov and Hollistein (1999). “\\n Application of simple technical trading rules to Swiss stock \\nprices: Is it profitable?\\n” Social Scien\\nce Research Network. Working Papers.   \\n \\n\\nJS Liao and PY Chen (2001). “\\n Dynamic trading strategy learning model using learning classifier \\nsystems\\n” Evolutionary Computing: Proceedings of the 2011 Congress on Evolutionary \\n\\nComputation. Vol. 2, pp 783 -789.  \\n \\nLukac and Brorsen (1989)\\n. “The Usefulness of Historical Data in Selecting Parameters for \\ntechnical trading systems.” Journal of Futures Markets. Vol 9, No. 1, pp 55\\n -65. \\n \\n\\nNelder,J., Mead, R. (1965). “A Simplex Method for Function Minimization.” The Computer \\n\\nJournal. Vol 7, No. 4, pp 308-313. \\n \\n Charoenwong 24 \\n \\n\\nO’Neill, Brabazon, Ryan and Collins (2001). “\\n Evolving Market Index Trading Rules Using \\n\\nGrammatical Evolution.” Applications of Evolutionary Compu\\n ting. Vol 2037/2001, pp \\n343-352.\\n \\n\\nPotvin, Soriano and Vallee (2004). “\\n Generating trading rules on the stock markets with genetic \\nprogramming\\n” Computers & Operations Research. Vol 31, No. 7, pp 1033\\n -1047. \\n \\n\\nRatner and Leal (1999). “\\n Tests of technical trading strategies in the emerging equity markets of \\nLatin America and Asia\\n” Journal of\\n Banking & Finance. Vol 23, No. 12, pp 1887 -1905. \\n \\n\\nSamuelson, P. (1965). “Proof that Properly Anticipated Prices Fluctuate Randomly.” \\n Industrial \\nManagement Review. Vol 6, No. 2, pp 41-49. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n Charoenwong 25 \\n \\n\\nAppendix 1: R Code \\n\\n########################################  \\n# Ben Charoenwong \\n# Technical Trading Strategies  \\n########################################  \\n \\n#setwd(\"M:\\\\\\\\Desktop\\\\\\\\Thesis\"); \\n#setwd(\"H:\\\\\\\\Desktop\\\\\\\\Thesis\"); \\nlist.files();  #Check to see if it\\'s there!  \\n \\n#Load the Data \\nprice=as.matrix(read.csv(\"SP500.csv\")[,7]);  \\ndates=as.matrix(read.csv(\"SP500.csv\")[,1]);  \\nn=nrow(price); \\nreturns=matrix(0,n,1);  \\nreturns[1]=0; \\nreturns[2:n]=price[2:n] -price[1:(n-1)]; \\n \\n#Getting returns for a set of holdings:  \\ngetprofits=function(holdings)  \\n{ \\n   profits=0; \\n   #Be Careful of the start index!  \\n   for(i in 1:nrow(holdings)) {  \\n      if (holdings[i]>0) {profits=profits+returns[i];}  \\n      else               {profits=profits -returns[i];} \\n   } \\n   return(profits); \\n} \\n \\ngetideal=function(cost) {     #Ex post ideal holdings  \\n ideal=matrix(0,n); \\n for(i in 2:n) { \\n  ideal[i]=ideal[i-1]; \\n  if(returns[i]>=cost) {ideal[i]=1;}  \\n  if(returns[i]<cost) {ideal[i]=0;}  \\n } \\n return(ideal); \\n} \\n \\nnumTrades=function(holdings) {  \\n   trades=0; \\n   for(i in 2:nrow(holdings)) {  \\n      if(holdings[i]!=holdi ngs[i-1]) \\n         trades=trades+1; \\n   } \\n   return(trades); \\n} \\n \\n#Function for checking predictability  \\n Charoenwong 26 \\n \\ngetacc=function(holding,ideal)  \\n{ \\n   return(sum(holding==ideal)/n);  \\n} \\n \\n#Function for getting annualized returns  \\ngetret=function(profits,days)  \\n{ \\n return(profits/price[1]/days*365);  \\n} \\n \\n##################STRATEGIES###########################  \\n \\n#Benchmark: Buy and Hold Strategy  \\nbasic=function() { \\n series=price; \\n holdings=matrix(1,nrow=nrow(series));  \\n #return(getprofits(holdings));  \\n return(holdings); \\n} \\n#Fama and Blume tested 0.5 percent to 50% price change.  \\n \\nfilter=function(percent,cost)  \\n{ \\n series=price; \\n n=nrow(series); \\n holdings=matrix(0,n);  \\n for(i in 2:n) { \\n  holdings[i]=holdings[i -1]; \\n  diff=series[i]/series[i-1]-1; \\n  if(diff>=percent/100) {holdings[i]=1;}  \\n       if(diff<=-percent/100) {holdings[i]=0;}  \\n } \\n #return(getprofits(holdings) -numTrades(holdings)*cost);  \\n return(holdings); \\n} \\n \\n#Simple Moving Average: 1% filter  \\nma=function(days,cost)  \\n{ \\n am=function(series,days)  \\n { \\n m=nrow(series); \\n a=matrix(0,nrow=m);  \\n for(i in days:m) { \\n  a[i]=mean(series[(i-days+1):i]); \\n  } \\n return(a); \\n } \\n \\n short=floor(days[1]);long=floor(days[2]);  \\n Charoenwong 27 \\n \\n if(short<2 || long<2) {return( -99999)}; \\n series=price; \\n sma=am(series,short);  \\n lma=am(series,long);  \\n holdings=matrix(0,n);  \\n for(i in max(short,long):n) { \\n  holdings[i]=holdings[i -1]; \\n  if(sma[i]>lma[i]*1.01) {holdings[i]=1;}  \\n  if(sma[i]<lma[i]*1.01) {holdings[i]=0;}  \\n } \\n #return(getprofits(holdings) -numTrades(holdings)*cost);  \\n return(holdings); \\n} \\n \\n#Arithmetic-Harmonic Mean Difference:  \\nhmstrat=function(theta,cost) { \\n am=function(series,days)  \\n { \\n m=nrow(series); \\n am=matrix(rep(0,m),nrow=m);  \\n for(i in days:m) { \\n  am[i]=mean(series[(i-days+1):i]); \\n } \\n return(am); \\n } \\n \\n hm=function(series, days)  \\n { \\n m=nrow(series); \\n hm=matrix(rep(0,m),nrow=m);  \\n for(i in days:m) { \\n  hm[i]=1/mean(1/series[(i -days+1):i]); \\n } \\n return(hm); \\n } \\n days=floor(theta[2]);percent=theta[1];  \\n percent=percent/100; \\n series=price; \\n hm1=hm(series,days);  \\n am1=am(series,days); \\n crit=(am1-hm1)/am1*100;   #scaled up arbitrarily  \\n holdings=matrix(0,nrow(series));  \\n for(i in days:nrow(series))  #days >=2  \\n { \\n  holdings[i]=holdings[i -1]; \\n  if(crit[i] > percent) {holdings[i]=1;}  \\n  if(crit[i] < percent) {holdings[i]=0;}  \\n }  \\n #return(getprofits(holdings,returns) -cost*numTrades(holdings));  \\n return(holdings); \\n} \\n Charoenwong 28 \\n \\n \\n \\n##################NO TRADING COST ENVIRONMENT###########  \\n \\nbenchmark=basic(); \\nprofits.benchmark=getprofits(benchmark);  \\nreturns.benchmark=getret(profits.benchmark,n);  \\nacc.benchmark=getacc(benchmark,ideal0);  \\n \\nideal0=getideal(0); \\nprofits.ideal0=getprofits(ideal0);  \\nreturns.ideal0=getret(profits.ideal0,n);  \\nacc.ideal0=getacc(ideal0,ideal0);  \\n \\n#From past optimization: for 0 TC, parameter is: perc=0.0009765625  \\nfilter0=filter(0.0009765625,0);  \\nprofits.filter0=getprofits(filter0);  \\nreturns.filter0=getret(profits.filter0,n);  \\nacc.filter0=getacc(filter0,ideal0);  \\n \\n#From past optimization: for 0 TC, parameter is: days=c(2,19)  \\nma0=ma(c(2,19),0); \\nprofits.ma0=getprofits(ma0);  \\nreturns.ma0=getret(profits.ma0,n);  \\nacc.ma0=getacc(ma0,ideal0);  \\n \\n#From past optimization: for 0 TC, parameter is: days=82, perc=1.835567046  \\nhmstrat0=hmstrat(c(1.835567046,82),0);  \\nprofits.hmstrat0=getprofits(hmstrat0);  \\nreturns.hmstrat0=getret(profits.hmstrat0,n);  \\nacc.hmstrat0=getacc(hmstrat0,ideal0);  \\n \\n##################$8 TRADING COST EN VIRONMENT###########  \\ncost=8; \\n \\nbenchmark=basic(); \\nprofits.benchmark=getprofits(benchmark) -numTrades(benchmark)*cost;  \\nreturns.benchmark=getret(profits.benchmark,n);  \\nacc.benchmark=getacc(benchmark,ideal8);  \\n \\nideal8=getideal(cost);  \\nprofits.ideal8=getprofits(ide al8); \\nreturns.ideal8=getret(profits.ideal8,n);  \\nacc.ideal8=getacc(ideal8,ideal8);  \\n \\n#From past optimization: for 0 TC, parameter is: perc=0.918175814  \\nfilter8=filter(0.918175814,0);  \\nprofits.filter8=getprofits(filter8);  \\nreturns.filter8=getret(profits.filter8,n ); \\nacc.filter8=getacc(filter8,ideal8);  \\n \\n Charoenwong 29 \\n \\n#From past optimization: for 0 TC, parameter is: days=c(41,360)  \\nma8=ma(c(41,360),0);  \\nprofits.ma8=getprofits(ma8) -numTrades(ma8)*cost;  \\nreturns.ma8=getret(profits.ma8,n);  \\nacc.ma8=getacc(ma8,ideal8);  \\n \\n#From past optimization: for 0 TC, parameter is: days=136, perc= -10.58583745 \\nhmstrat8=hmstrat(c(-10.58583745,136),0); \\nprofits.hmstrat8=getprofits(hmstrat8);  \\nreturns.hmstrat8=getret(profits.hmstrat8,n);  \\nacc.hmstrat8=getacc(hmstrat8,ideal8);  \\n \\n \\n \\n \\n\\n\\n ********************\\n\\n ********************REFERENCES\\n[1] M. Braschler, K. Stockinger, and T. Stadelmann (Eds.), Applied Data\\nScience—Lessons Learned for the Data-Driven Business . Springer\\nInternational Publishing, 2019.\\n[2] B. B. Meier, I. Elezi, M. Amirian, O. D ¨urr, and T. Stadelmann,\\n“Learning neural models for end-to-end clustering,” in IAPR Workshop\\non Artiﬁcial Neural Networks in Pattern Recognition , pp. 126–138,\\nSpringer, 2018.\\n[3] F. Hutter, L. Kotthoff, and J. Vanschoren, “Automatic machine learn-\\ning: methods, systems, challenges,”Challenges in Machine Learning,\\n2019.\\n[4] C. Thornton, F. Hutter, H. H. Hoos, and K. Leyton-Brown, “Auto-\\nweka: Combined selection and hyperparameter optimization of clas-\\nsiﬁcation algorithms,” inProceedings of the 19th ACM SIGKDD\\ninternational conference on Knowledge discovery and data mining ,\\npp. 847–855, ACM, 2013.\\n[5] G. A. Susto, A. Schirru, S. Pampuri, S. McLoone, and A. Beghi,\\n“Machine learning for predictive maintenance: A multiple classiﬁer\\napproach,”IEEE Transactions on Industrial Informatics , vol. 11, no. 3,\\npp. 812–820, 2015.\\n[6] H. Li, D. Parikh, Q. He, B. Qian, Z. Li, D. Fang, and A. Hampapur,\\n“Improving rail network velocity: A machine learning approach to\\npredictive maintenance,”Transportation Research Part C: Emerging\\nTechnologies, vol. 45, pp. 17–26, 2014.\\n[7] E. Figueiredo, G. Park, C. R. Farrar, K. Worden, and J. Figueiras,\\n“Machine learning algorithms for damage detection under operational\\nand environmental variability,”Structural Health Monitoring, vol. 10,\\nno. 6, pp. 559–572, 2011.\\n[8] E. St¨uhler, S. Braune, F. Lionetto, Y. Heer, P. Kassraian-Fard, E. Jules,\\nC. Westermann, A. Bergmann, P. van Hvell, and N. S. Group, “Frame-\\nwork for personalized prediction of treatment response in relapsing\\nremitting multiple sclerosis,”BMC medical research methodology,\\nsubmitted.\\n[9] M. Handzic, F. Tjandrawibawa, and J. Yeo, “How neural networks\\ncan help loan ofﬁcers to make better informed application decisions,”\\nInforming Science, vol. 6, pp. 97–109, 2003.\\n[10] S. Viaene, G. Dedene, and R. A. Derrig, “Auto claim fraud detec-\\ntion using bayesian learning neural networks,” Expert Systems with\\nApplications, vol. 29, no. 3, pp. 653–666, 2005.\\n[11] J. M. P´erez, J. Muguerza, O. Arbelaitz, I. Gurrutxaga, and J. I. Mart ´ın,\\n“Consolidated tree classiﬁer learning in a car insurance fraud detection\\ndomain with class imbalance,” inInternational Conference on Pattern\\nRecognition and Image Analysis, pp. 381–389, Springer, 2005.\\n[12] G. Tsoumakas, “A survey of machine learning techniques for food\\nsales prediction,”Artiﬁcial Intelligence Review, pp. 1–7, 2018.\\n[13] L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar,\\n“Hyperband: A novel bandit-based approach to hyperparameter opti-\\nmization,”The Journal of Machine Learning Research , vol. 18, no. 1,\\npp. 6765–6816, 2017.\\n[14] J. Duan, Z. Zeng, A. Oprea, and S. Vasudevan, “Automated generation\\nand selection of interpretable features for enterprise security,” in 2018\\nIEEE International Conference on Big Data (Big Data) , pp. 1258–\\n1265, IEEE, 2018.\\n[15] M. Andrychowicz, M. Denil, S. Gomez, M. W. Hoffman, D. Pfau,\\nT. Schaul, B. Shillingford, and N. De Freitas, “Learning to learn\\nby gradient descent by gradient descent,” in Advances in Neural\\nInformation Processing Systems, pp. 3981–3989, 2016.\\n[16] B. Zoph and Q. V. Le, “Neural architecture search with reinforcement\\nlearning,” inProceedings of International Conference on Learning\\nRepresentations (ICLR), 2017.\\n[17] M. Feurer, A. Klein, K. Eggensperger, J. Springenberg, M. Blum,\\nand F. Hutter, “Efﬁcient and robust automated machine learning,” in\\nAdvances in Neural Information Processing Systems , pp. 2962–2970,\\n2015.\\n[18] R. Gaudel and M. Sebag, “Feature selection as a one-player game,” in\\nInternational Conference on Machine Learning , pp. 359–366, 2010.\\n[19] G. Katz, E. C. R. Shin, and D. Song, “Explorekit: Automatic feature\\ngeneration and selection,” inData Mining (ICDM), 2016 IEEE 16th\\nInternational Conference on, pp. 979–984, IEEE, 2016.\\n[20] F. Nargesian, H. Samulowitz, U. Khurana, E. B. Khalil, and D. Turaga,\\n“Learning feature engineering for classiﬁcation,” in Proceedings of the\\nTwenty-Sixth International Joint Conference on Artiﬁcial Intelligence,\\nIJCAI, vol. 17, pp. 2529–2535, 2017.\\n[21] A. Kaul, S. Maheshwary, and V. Pudi, “Autolearnautomated feature\\ngeneration and selection,” inData Mining (ICDM), 2017 IEEE Inter-\\nnational Conference on, pp. 217–226, IEEE, 2017.\\n[22] N. Meinshausen and P. B¨uhlmann, “Stability selection,”Journal of the\\nRoyal Statistical Society: Series B (Statistical Methodology) , vol. 72,\\nno. 4, pp. 417–473, 2010.\\n[23] B. Pfahringer, H. Bensusan, and C. G. Giraud-Carrier, “Meta-learning\\nby landmarking various learning algorithms.,” in ICML, pp. 743–750,\\n2000.\\n[24] A. Klein, S. Falkner, J. T. Springenberg, and F. Hutter, “Learning curve\\nprediction with bayesian neural networks,” 2016.\\n[25] K. Eggensperger, M. Lindauer, and F. Hutter, “Neural networks for\\npredicting algorithm runtime distributions.,” in IJCAI, pp. 1442–1448,\\n2018.\\n[26] P. B. Brazdil and C. Soares, “A comparison of ranking methods for\\nclassiﬁcation algorithm selection,” inEuropean conference on machine\\nlearning, pp. 63–75, Springer, 2000. [27] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural\\ncomputation, vol. 9, no. 8, pp. 1735–1780, 1997.\\n[28] Y. Chen, M. W. Hoffman, S. G. Colmenarejo, M. Denil, T. P. Lillicrap,\\nM. Botvinick, and N. de Freitas, “Learning to learn without gradient\\ndescent by gradient descent,” inProceedings of the 34th International\\nConference on Machine Learning-Volume 70 , pp. 748–756, JMLR.\\norg, 2017.\\n[29] C. Cortes and V. Vapnik, “Support-vector networks,” Machine learn-\\ning, vol. 20, no. 3, pp. 273–297, 1995.\\n[30] T. Elsken, J.-H. Metzen, and F. Hutter, “Simple and efﬁcient archi-\\ntecture search for convolutional neural networks,” in Proceedings of\\nInternational Conference on Learning Representations (ICLR) , 2018.\\n[31] E. Real, S. Moore, A. Selle, S. Saxena, Y. L. Suematsu, J. Tan,\\nQ. V. Le, and A. Kurakin, “Large-scale evolution of image classiﬁers,”\\ninProceedings of the 34th International Conference on Machine\\nLearning(D. Precup and Y. W. Teh, eds.), vol. 70 of Proceedings\\nof Machine Learning Research, (International Convention Centre,\\nSydney, Australia), pp. 2902–2911, PMLR, 06–11 Aug 2017.\\n[32] Y. He, J. Lin, Z. Liu, H. Wang, L.-J. Li, and S. Han, “Amc:\\nAutoml for model compression and acceleration on mobile devices,” in\\nProceedings of the European Conference on Computer Vision (ECCV) ,\\npp. 784–800, 2018.\\n[33] I. Guyon, L. Sun-Hosoya, M. Boull ´e, H. Escalante, S. Escalera, Z. Liu,\\nD. Jajetic, B. Ray, M. Saeed, M. Sebag, et al., “Analysis of the automl\\nchallenge series 2015-2018,” 2017.\\n[34] E. Brochu, V. M. Cora, and N. De Freitas, “A tutorial on bayesian\\noptimization of expensive cost functions, with application to active\\nuser modeling and hierarchical reinforcement learning,” arXiv preprint\\narXiv:1012.2599, 2010.\\n[35] F. Hutter, H. H. Hoos, and K. Leyton-Brown, “Sequential model-based\\noptimization for general algorithm conﬁguration,” in International\\nConference on Learning and Intelligent Optimization , pp. 507–523,\\nSpringer, 2011.\\n[36] M. Feurer, J. T. Springenberg, and F. Hutter, “Using meta-learning to\\ninitialize bayesian optimization of hyperparameters,” in Proceedings\\nof the 2014 International Conference on Meta-learning and Algorithm\\nSelection-Volume 1201, pp. 3–10, Citeseer, 2014.\\n[37] K. Jamieson and A. Talwalkar, “Non-stochastic best arm identiﬁca-\\ntion and hyperparameter optimization,” in Artiﬁcial Intelligence and\\nStatistics, pp. 240–248, 2016.\\n[38] M. Jaderberg, V. Dalibard, S. Osindero, W. M. Czarnecki, J. Don-\\nahue, A. Razavi, O. Vinyals, T. Green, I. Dunning, K. Simonyan,\\net al., “Population based training of neural networks,” arXiv preprint\\narXiv:1711.09846, 2017.\\n[39] D. Maclaurin, D. Duvenaud, and R. Adams, “Gradient-based hyper-\\nparameter optimization through reversible learning,” in International\\nConference on Machine Learning, pp. 2113–2122, 2015.\\n[40] W. Banzhaf, P. Nordin, R. E. Keller, and F. D. Francone, Genetic pro-\\ngramming: an introduction, vol. 1. Morgan Kaufmann San Francisco,\\n1998.\\n[41] B. Sch¨olkopf, “The kernel trick for distances,” in Advances in neural\\ninformation processing systems, pp. 301–307, 2001.\\n[42] T. Swearingen, W. Drevo, B. Cyphers, A. Cuesta-Infante, A. Ross,\\nand K. Veeramachaneni, “Atm: A distributed, collaborative, scalable\\nsystem for automated machine learning,” in IEEE International Con-\\nference on Big Data, 2017.\\n[43] M. Feurer, K. Eggensperger, S. Falkner, M. Lindauer, and F. Hutter,\\n“Practical automated machine learning for the automl challenge 2018,”\\ninInternational Workshop on Automatic Machine Learning at ICML ,\\n2018.\\n[44] T. Stadelmann, M. Amirian, I. Arabaci, M. Arnold, G. F. Duivesteijn,\\nI. Elezi, M. Geiger, S. L¨orwald, B. B. Meier, K. Rombach,et al.,\\n“Deep learning in the wild,” inIAPR Workshop on Artiﬁcial Neural\\nNetworks in Pattern Recognition, pp. 17–38, Springer, 2018.\\n[45] R. S. Olson, R. J. Urbanowicz, P. C. Andrews, N. A. Lavender, J. H.\\nMoore,et al., “Automating biomedical data science through tree-based\\npipeline optimization,” inEuropean Conference on the Applications of\\nEvolutionary Computation, pp. 123–137, Springer, 2016.\\n[46] J. Vanschoren, J. N. van Rijn, B. Bischl, and L. Torgo, “Openml: Net-\\nworked science in machine learning,”SIGKDD Explorations, vol. 15,\\nno. 2, pp. 49–60, 2013.\\n[47] K. Li and J. Malik, “Learning to optimize,” arXiv preprint\\narXiv:1606.01885, 2016.\\n\\n\\n ********************\\n\\n ********************\\n\\n ********************REFERENCES\\n[1] M. de Prado, “Advances in Financial Machine Learning,” Wiley Pub-\\nlishin, 1st. edition, 2018.\\n[2] J. Heaton, N. Polson, and Jan Witte, “Deep learning for ﬁnance: deep\\nportfolios,” Applied Stochastic Models in Business and Industry, 2016.\\n[3] G. Atsalakis and K. Valavanis, “Surveying stock market forecasting\\ntechniques - part ii: Soft computing methods,” Expert Systems with\\nApplications, vol. In Press, Corrected Proof, 2008.\\n[4] Reﬁnitiv, “Smarter Humans. Smarter Machines. Insights from the\\nReﬁnitiv 2019 Artiﬁcial Intelligence / Machine Learning Global\\nStudy,” 2019, https://www.reﬁnitiv.com/content/dam/marketing/enus/\\ndocuments/reports/reﬁnitiv-ai-ml-survey-report.pdf, visited in January\\n2020.\\n[5] D. Britz, “Introduction to Learning to Trade with Reinforcement Learn-\\ning,” 2018, https://www.cnblogs.com/DjangoBlog/p/9285956.html, vis-\\nited in January 2020.\\n[6] M. Morales, “Grokking Deep Reinforcement Learning,” Manning Pub-\\nlications, 2020.\\n[7] R. Sutton and A. Barto, “Introduction to Reinforcement Learning,” MIT\\nPress, 2nd edition, 2018.\\n[8] B3, http://www.b3.com.br, visited in January 2020.\\n[9] SmarttBot, www.smarttbot.com, in Portuguese, visited in January 2020.\\n978-1-7281-6926-2/20/$31.00 ©2020 IEEE\\n[10] L. Martinez, D. da Hora, J. Palotti, W. Meira Jr. and G. Pappa, “From\\nan artiﬁcial neural network to a stock market day-trading system: a\\ncase study on the BM&F BOVESPA”, International Joint Conference\\non Neural Networks (IJCNN), 2009.\\n[11] S. Niaki and S. Hoseinzade, “Forecasting SP 500 index using artiﬁcial\\nneural networks and design of experiments”, Journal of Industrial\\nEngineering International, Vol. 9(1), pp. 1, 2013.\\n[12] Y. LeCun, Y. Bengio and G. Hinton, “Deep learning”, Nature, Vol. 521,\\npp.436—444, 2015. Lee,\\n[13] J. Schmidhuber, “Deep learning in neural networks: An overview”,\\nNeural Networks, Vol. 61, pp. 85—117, 2015.\\n[14] I. Goodfellow, Y. Bengio, and A. Courville, “Deep learning”, The MIT\\nPress, Vol. 1, 2016.\\n[15] D. Silver and D. Hassabis, “AlphaGo: mastering the ancient game of\\nGo with Machine Learning”, Research Blog, 2016.\\n[16] D Silver, T. Hubert, J. Schrittwieser, I. Antonoglou, M. Lai, A. Guez, M.\\nLanctot, L. Sifre, D. Kumaran, T. Graepel, T. Lillicrap, K. Simonyan,\\nD. Hassabis, “A general reinforcement learning algorithm that masters\\nchess, shogi, and Go through self-play”, Science, Vol. 362, pp. 1140—\\n1144, 2018.\\n[17] S. Almahdi and S. Yang, “An adaptive portfolio trading system: A risk-\\nreturn portfolio optimization using recurrent reinforcement learning with\\nexpected maximum drawdown,” Expert Systems With Applications, vol.\\n87, pp. 267–279, 2017.\\n[18] S. Almahdi and S. Yang, “A constrained portfolio trading system us- ing\\nparticle swarm algorithm and recurrent reinforcement learning”, Expert\\nSystems With Applications, Vol. 130, pp. 145–156, 2019.\\n[19] F. Bertoluzzo and M. Corazza, “Testing different Reinforcement Learn-\\ning conﬁgurations for ﬁnancial trading: Introduction and applications”,\\nProcedia Economics and Finance, Vol. 3, pp. 68–77, 2012.\\n[20] P. Casqueiro and A. Rodrigues, “Neuro-dynamic trading methods”,\\nEuropean Journal of Operational Research, Vol. 175, pp. 1400–1412,\\n2006.\\n[21] M. Dempster and V. Leemans, “An automated FX trading system using\\nadaptive reinforcement learning”, Expert Systems With Applications,\\nVol. 30, pp. 543–552, 2006.\\n[22] Y. Deng, B. Feng, Y. Kong, Z. Ren and Q. Dai, “Deep direct rein-\\nforcement learning for ﬁnancial signal representation and trading”, IEEE\\nTransactions on Neural Networks and Learning Systems, Vol. 28 pp.\\n653—664, 2016.\\n[23] D. Eilers, C. Dunis, H. Mettenheim, and M. Breitner, “Intelligent trading\\nof seasonal effects: A decision support algorithm based on reinforcement\\nlearning”, Decision Support Systems, Vol. 64, pp. 100–108, 2014.\\n[24] G. Jeong and H. Kim, “Improving ﬁnancial trading decisions using\\ndeep Q-learning: Predicting the number of shares, action strategies, and\\ntransfer learning”, Expert system with applications, Vol. 117, pp.125—\\n138, 2019.\\n[25] Z. Jiang, D. Xu, and J. Liang. A deep reinforcement learning frame-\\nwork for the ﬁnancial portfolio management problem. arXiv preprint\\narXiv:1706.10059, 2017.\\n[26] J. Moody and M. Saffell, “Learning to trade via Direct Reinforcement”,\\nIEEE Transactions On Neural Networks, Vol. 12, pp.875–889, 2001.\\n[27] J. Moody, L. Wu, Y. Liao and M. Saffell, “Performance Functions and\\nReinforcement Learning for Trading Systems and Portfolios”, Journal\\nof Forecasting, Vol. 17, pp. 441–470, 1998.\\n[28] R. Neuneier, “Optimal Asset Allocation using Adaptive Dynamic\\nProgram- ming”, Advances in Neural Information Processing Systems,\\npp. 952–958, 1996.\\n[29] R. Neuneier, “Enhancing Q-Learning for Optimal Asset Allocation”, Ad-\\nvances in Neural Information Processing Systems, pp. 936–942, 1998.\\n[30] J. O, J. Lee, J. Lee, and B. Zhang, “Adaptive stock trading with\\ndy- namic asset allocation using reinforcement learning”, Information\\nSciences, Vol. 176, pp. 2121–2147, 2006.\\n[31] P. Pendharkar and P. Cusatis, “Trading ﬁnancial indices with reinforce-\\nment learning agents”, Expert Systems with Applications, Vol. 103,\\npp.1–13, 2018.\\n[32] X. Zhang, Y. Hu, K. Xie, W. Zhang, L. Su, and M. Liu, “An evolutionary\\ntrend reversion model for stock trading rule discovery. Knowledge-Based\\nSystems”, Vol. 79, pp. 27–5, 2015.\\n[33] J. Cumming, “An investigation into the use of reinforcement learn-\\ning techniques within the algorithmic trading domain”, Master’s thesis,\\nImperial College London, United Kiongdoms, 2015. http://www.doc.\\nic.ac.uk/teaching/distinguished-projects/2015/j.cumming.pdf, visited in\\nJanuary 2020. [34] Y. Deng, F. Bao, Y. Kong, Z. Ren and Q. Dai, “Deep Direct Reinforce-\\nment Learning for Financial Signal Representation and Trading”, IEEE\\nTransactions on Neural Networks and Learning Systems, Vol. 28, no. 3,\\npp. 653–664, 2017.\\n[35] T. Lillicrap, J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Silver\\nand D. Wierstra, “Continuous control with deep reinforcement learning”.\\narXiv preprint arXiv:1509.02971, 2015.\\n[36] A. Filos, “Reinforcement Learning for Portfolio Management”, MEng\\nDissertation, 2018.\\n[37] Z. Liang, H. Chen, J. Zhu, K. Jiang and Y. Li, “Adversarial\\ndeep reinforcement learning in portfolio management”, arXiv preprint\\narXiv:1808.09940, 2018.\\n[38] J. Schulman, F. Wolski, P. Dhariwal, A. Radford and O Klimov,\\n“Proximal Policy Optimization Algorithms”, ArXiv:1707.06347, 2017.\\n[39] B3, “Equities and Investment Funds Fees“. http://www.b3.com.br/en\\nus/products-and-services/fee-schedules/listed-equities-and-derivatives/\\nequities/equities-and-investment-funds-fees/spot/, visited in January\\n2020.\\n[40] C. Kirkpatrick II and J. Dahlquist, “Technical analysis: The complete\\nresource for ﬁnancial market technician”, FT Press, 2010.\\n[41] A. Lo, H. Mamaysky and J. Wang, “Foundations of technical analysis:\\nComputational algorithms, statistical inference, and empirical implemen-\\ntation”, The Journal of Finance, Vol. 55(4), pp. 1705-–1770, 2000.\\n[42] D. Silver, G. Lever, N. Heess, T. Degris, D. Wierstra and M. Ried-miller,\\n“Deterministic Policy Gradient Algorithms”, Proceedings of the 31st\\nInternational Conference on Machine Learning (ICML-14), pp. 387–\\n395, 2014.\\n[43] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D.\\nWierstra and M Riedmiller, “Playing Atari with deep reinforcement\\nlearning”, pp. 1–9, 2013.\\n[44] V. Mnih, K. Kavukcuoglu, D. Silver, A. Rusu, J. Veness, M. Bellemare,\\nA. Graves, M. Riedmiller, A. Fidjeland, G. Ostrovski, S. Petersen, C.\\nBeattie, A. Sadik, I. Antonoglou, H. King, D. Kumaran, D. Wierstra, S.\\nLegg and D. Hassabis, “Human-level control through deep reinforcement\\nlearning”, Nature, Vol. 518, no. 7540, pp. 529–533, 2015.\\n[45] C. Zhang, L. Zhang and C. Chen, “Deep Reinforcement Learning for\\nPortfolio Management”, 2017.\\n[46] J. Chen (Investopedia), “Liquidity”, https://www.investopedia.com/\\nterms/l/liquidity.asp, visited in January 2020.\\n[47] J. Chen (Investopedia), “Slippage”, https://www.investopedia.com/terms/\\ns/slippage.asp, visited in January 2020.\\n[48] J. Chen (Investopedia), “Odd Lot”, https://www.investopedia.com/terms/\\no/oddlot.asp, visited in January 2020.\\n[49] W. Kenton (Investopedia), “Round Lot”, https://www.investopedia.com/\\nterms/r/roundlot.asp, visited in January 2020.\\n[50] Black Rock, www.blackrock.com, visited in January 2020.\\n[51] Carteira Valor, https://valor.globo.com/valor-data/carteira-valor/, in Por-\\ntuguese, visited in January 2020.\\n[52] Valor Economico, https://valor.globo.com/, in Portuguese, visited in\\nJanuary 2020.\\n[53] Corretora Toro Investimentos, https://www.toroinvestimentos.com.br/, in\\nPortuguese, visited in January 2020.\\n[54] Corretora Warren, https://warrenbrasil.com.br/, in Portuguese, visited in\\nJanuary 2020.\\n[55] Corretora Clear, https://clear.com.br/, in Portuguese, visited in January\\n2020.\\n[56] Inter DTVM, https://www.bancointer.com.br/inter-dtvm/, in Portuguese,\\nvisited in January 2020.\\n[57] CM Capital Markets, https://www.cmcapital.com.br/, in Portuguese,\\nvisited in January 2020.\\n978-1-7281-6926-2/20/$31.00 ©2020 IEEE\\n\\n\\n ********************REFERENCES\\n[1]MM Al Rahhal, Yakoub Bazi, Haikel AlHichri, Naif Alajlan, Farid\\nMelgani, and RR Yager. 2016. Deep learning approach for active\\nclassi\\x0ccation of electrocardiogram signals.Information Sciences\\n345 (2016), 340{354.\\n[2]Waheeda Almayyan. 2016. Lymph Diseases Prediction Using\\nRandom Forest and Particle Swarm Optimization.Journal of\\nIntelligent Learning Systems and Applications8, 03 (2016), 51.\\n[3]Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc\\nSturm, and Noemie Elhadad. 2015. Intelligible models for health-\\ncare: Predicting pneumonia risk and hospital 30-day readmis-\\nsion. InProceedings of the 21th ACM SIGKDD International\\nConference on Knowledge Discovery and Data Mining. ACM,\\n1721{1730. [4]Edward Choi, Mohammad Taha Bahadori, Jimeng Sun, Joshua\\nKulas, Andy Schuetz, and Walter Stewart. 2016. RETAIN: An\\nInterpretable Predictive Model for Healthcare using Reverse Time\\nAttention Mechanism. InAdvances in Neural Information Pro-\\ncessing Systems. 3504{3512.\\n[5]Edward Choi, Andy Schuetz, Walter F Stewart, and Jimeng Sun.\\n2016. Using recurrent neural network models for early detection of\\nheart failure onset.Journal of the American Medical Informatics\\nAssociation(2016), ocw112.\\n[6]Shahid A Choudhry, Jing Li, Darcy Davis, Cole Erdmann, Rishi\\nSikka, and Bharat Sutariya. 2013. A public-private partnership\\ndevelops and externally validates a 30-day hospital readmission\\nrisk prediction model.Online journal of public health informatics\\n5, 2 (2013), 219.\\n[7]Zhicheng Cui, Wenlin Chen, and Yixin Chen. 2016. Multi-scale\\nconvolutional neural networks for time series classi\\x0ccation.arXiv\\npreprint arXiv:1603.06995(2016).\\n[8]Joseph Futoma, Jonathan Morris, and Joseph Lucas. 2015. A\\ncomparison of models for predicting early hospital readmissions.\\nJournal of biomedical informatics56 (2015), 229{238.\\n[9]John Cristian Borges Gamboa. 2017. Deep Learning for Time-\\nSeries Analysis.arXiv preprint arXiv:1701.01887(2017).\\n[10]Danning He, Simon C Mathews, Anthony N Kalloo, and Susan\\nHut\\ress. 2014. Mining high-dimensional administrative claims\\ndata to predict early hospital readmissions.Journal of the Amer-\\nican Medical Informatics Association21, 2 (2014), 272{279.\\n[11]Stephen F Jencks, Mark V Williams, and Eric A Coleman. 2009.\\nRehospitalizations among Patients in the Medicare Fee-for-Service\\nProgram.N Engl J Med360 (2009), 1418{28.\\n[12]Sujin Kim, Woojae Kim, and Rae Woong Park. 2011. A compari-\\nson of intensive care unit mortality prediction models through the\\nuse of data mining techniques.Healthcare informatics research\\n17, 4 (2011), 232{243.\\n[13]Eun Whan Lee. 2012. Selecting the Best Prediction Model for\\nReadmission.Journal of Preventive Medicine and Public Health\\n45, 4 (2012), 259.\\n[14]Xu-Ying Liu, Jianxin Wu, and Zhi-Hua Zhou. 2009. Exploratory\\nundersampling for class-imbalance learning.IEEE Transactions\\non Systems, Man, and Cybernetics, Part B (Cybernetics)39, 2\\n(2009), 539{550.\\n[15]Yi Mao, Wenlin Chen, Yixin Chen, Chenyang Lu, Marin Kollef,\\nand Thomas Bailey. 2012. An integrated data mining approach\\nto real-time clinical monitoring and deterioration warning. In\\nProceedings of the 18th ACM SIGKDD international conference\\non Knowledge discovery and data mining. ACM, 1140{1148.\\n[16]Sriram Somanchi, Samrachana Adhikari, Allen Lin, Elena Eneva,\\nand Rayid Ghani. 2015. Early prediction of cardiac arrest (code\\nblue) using electronic medical records. InProceedings of the\\n21th ACM SIGKDD International Conference on Knowledge\\nDiscovery and Data Mining. ACM, 2119{2126.\\n[17]Shanu Sushmita, Garima Khulbe, Aftab Hasan, Stacey Newman,\\nPadmashree Ravindra, Senjuti Basu Roy, Martine De Cock, and\\nAnkur Teredesai. 2016. Predicting 30-day risk and cost of\" all-\\ncause\" hospital readmissions. InWorkshops at the Thirtieth\\nAAAI Conference on Arti\\x0ccial Intelligence.\\n[18]Christian Szegedy. 2016. An Overview of Deep Learning.AITP\\n2016(2016).\\n[19]Yujin Tang, Jianfeng Xu, Kazunori Matsumoto, and Chihiro\\nOno. 2016. Sequence-to-Sequence Model with Attention for Time\\nSeries Classi\\x0ccation. InData Mining Workshops (ICDMW),\\n2016 IEEE 16th International Conference on. IEEE, 503{510.\\n[20]Haishuai Wang and Jun Wu. 2017. Boosting for Real-Time\\nMultivariate Time Series Classi\\x0ccation.. InAAAI. 4999{5000.\\n[21]Haishuai Wang, Peng Zhang, Xingquan Zhu, Ivor Wai-Hung\\nTsang, Ling Chen, Chengqi Zhang, and Xindong Wu. 2017. Incre-\\nmental subgraph feature selection for graph classi\\x0ccation.IEEE\\nTransactions on Knowledge and Data Engineering29, 1 (2017),\\n128{142.\\n[22]Yi Zheng, Qi Liu, Enhong Chen, Yong Ge, and J Leon Zhao. 2014.\\nTime series classi\\x0ccation using multi-channels deep convolution-\\nal neural networks. InInternational Conference on Web-Age\\nInformation Management. Springer, 298{310.\\n\\n\\n ********************\\n\\n ********************REFERENCES\\nBoland, L. A. “Reading and Misreading Friedman’s 1953 \\nMethodology Essay.” In Milton Friedman: Contributions to Eco-\\nnomics and Public Policy, edited by R. Cord and D. Hammond, \\npp. 541–560. Oxford: Oxford University Press, 2016.\\nBurns, A., and W. Mitchell. Measuring Business Cycles. \\nNew York: National Bureau of Economic Research, 1946.\\nDewey, J. Essays in Experimental Logic. Chicago: The Univer-\\nsity of Chicago Press, 1916.\\n——. Logic: The Theory of Inquiry. Oxford: Holt, 1938.\\nDuhem, P. The Aim and Structure of Physical Theory. Translated \\nfrom the second edition by P. P. Wiener. Princeton: Princeton \\nUniversity Press, 1914 (1954).\\nEdge, R. M., and R. S. Gurkaynak. 2010. “How Useful \\nAre Estimated DSGE Model Forecasts for Central Bankers?” \\nBrookings Papers on Economic Activity 41 (2): 209–259.\\nEdge, R. M., M. T. Kiley, and J. Laforte. 2010. “A Com-\\nparison of Forecast Performance Between Federal Reserve \\nStaff Forecasts, Simple Reduced Form Models, and a DSGE \\nModel.” Journal of Applied Econometrics 25 (4): 720–754.\\nFriedman, M. “The Methodology of Positive Economics.” \\nIn Essays in Positive Economics, pp. 3–43. Chicago: University \\nof Chicago Press, 1953.Granger, C. W. J. 1969. “Investigating Causal Relations by \\nEconometric Models and Cross-Spectral Methods.” Econo-\\nmetrica 37 (3): 424–438.\\nHaavelmo, T. 1943. “The Statistical Implications of a System \\nof Simultaneous Equations.” Econometrica 11 (1): 1–12.\\n——. 1944. “The Probability Approach in Econometrics.” \\nEconometrica 12 (supplement).\\nHicks, J. Causality in Economics. Oxford: Basil Blackwell, 1979.\\nHoover, K. D. Causality in Macroeconomics. Cambridge: Cam-\\nbridge University Press, 2001.\\nKoopmans, T. C. 1947. “Measurement Without Theory.” The \\nReview of Economics and Statistics 29 (3): 161–172.\\nLópez de Prado, M., and R. Israel. 2019. “Beyond Econo-\\nmetrics: A Roadmap Towards Financial Machine Learning.” \\nThe Journal of Financial Data Science 1 (1): 99–110.\\nRobertson, H. P. 1949. “Postulate versus Observation in \\nthe Special Theory of Relativity.” Reviews of Modern Physics \\n21 (3): 378–382.\\nRosenberg, A. 1983. “If Economics Isn’t Science, What Is \\nIt?” Philosophical Forum 14 (3/4): 296–314.\\nSimon, H. “Causal Ordering and Identifiability.” In Studies in \\nEconometric Method, edited by W. C. Hood and T. C. Koop-\\nmans. New Haven, CT: Yale University Press, 1953.\\nSummers, L. H. 1991. “The Scientific Illusion in Empirical \\nMacroeconomics.” The Scandinavian Journal of Economics 93 \\n(2): 129–148.\\nTor retti, R. The Philosophy of Physics. Cambridge: Cambridge \\nUniversity Press, 1999.\\nDisclaimer\\nThis editorial reflects the current opinions of the authors, which are not \\nthose of Natixis Investment Managers.\\nTo order reprints of this article, please contact David Rowe at \\nd.rowe@pageantmedia.com or 646-891-2157.\\n\\n\\nJFDS-Simonian.indd   13JFDS-Simonian.indd   1305/01/19   10:21 am05/01/19   10:21 am\\n\\n\\n ********************References\\n31\\nRecent Advances in Stock Market Prediction Using Text Mining: A Survey\\nDOI: http://dx.doi.org/10.5772/intechopen.92253\\n\\narticles. In: 2017 IEEE International \\nConference on Computational \\nIntelligence and Virtual Environments for \\nMeasurement Systems and Applications \\n(CIVEMSA). IEEE; 2017. pp.\\xa060-65\\n[18] Khedr AE, Yaseen N.\\xa0Predicting \\nstock market behavior using data \\nmining technique and news sentiment \\nanalysis. International Journal of \\nIntelligent Systems and Applications. \\n2017;9(7):22\\n[19] Mudinas A, Zhang D, Levene M.  \\nMarket trend prediction using \\nsentiment analysis: Lessons learned \\nand paths forward. 2019. arXiv preprint \\narXiv:1903.05440\\n[20] Granger CW.\\xa0Investigating causal \\nrelations by econometric models and \\ncross-spectral methods. Econometrica: \\nJournal of the Econometric Society. \\n1969;1:424-438\\n[21] Checkley MS, Higón DA, Alles H. \\nThe hasty wisdom of the mob: How \\nmarket sentiment predicts stock \\nmarket behavior. Expert Systems with \\nApplications. 2017;77:256-263\\n[22] Souza TT, Aste T.\\xa0Predicting \\nfuture stock market structure by \\ncombining social and financial network \\ninformation. Physica A: Statistical \\nMechanics and its Applications. \\n2019;535:122343\\n[23] Wu GG, Hou TC, Lin JL.\\xa0Can \\neconomic news predict Taiwan \\nstock market returns? Asia Pacific \\nManagement Review. 2019;24(1):54-59\\n[24] Bujari A, Furini M, Laina N.\\xa0On \\nusing cashtags to predict companies \\nstock trends. In: 2017 14th IEEE \\nAnnual Consumer Communications & \\nNetworking Conference (CCNC). IEEE; \\n2017. pp.\\xa025-28\\n[25] Dumais S, Platt J, Heckerman D,  \\nSahami M.\\xa0Inductive learning \\nalgorithms and representations for text categorization. In: Proceedings of \\nthe Seventh International Conference \\non Information and Knowledge \\nManagement; 1998. pp.\\xa0148-155\\n[26] Joachims T.\\xa0Text categorization with \\nsupport vector machines: Learning with \\nmany relevant features. In: European \\nconference on machine learning. Berlin/\\nHeidelberg: Springer; 1998. pp.\\xa0137-142\\n[27] Xie Y, Jiang H.\\xa0Stock market \\nforecasting based on text mining \\ntechnology: A support vector machine \\nmethod. 2019. arXiv preprint \\narXiv:1909.12789\\n[28] Li X, Xie H, Chen L, Wang J, \\nDeng X.\\xa0News impact on stock price \\nreturn via sentiment analysis. \\nKnowledge-Based Systems. \\n2014;69:14-23\\n[29] Loughran T, McDonald B.\\xa0When is a \\nliability not a liability? Textual analysis, \\ndictionaries, and 10-Ks. The Journal of \\nFinance. 2011;66(1):35-65\\n[30] Long W, Song L, Tian Y.\\xa0A new \\ngraphic kernel method of stock price \\ntrend prediction based on financial \\nnews semantic and structural similarity. \\nExpert Systems with Applications. \\n2019;118:411-424\\n[31] Porshnev A, Redkin I, \\nShevchenko A. Machine learning in \\nprediction of stock market indicators \\nbased on historical data and data from \\ntwitter sentiment analysis. In: 2013 \\nIEEE 13th International Conference on \\nData Mining Workshops. IEEE; 2013. \\npp.\\xa0440-444\\n[32] Xu F, Keelj V.\\xa0Collective sentiment \\nmining of microblogs in 24-hour stock \\nprice movement prediction. In: 2014 \\nIEEE 16th Conference on Business \\nInformatics, Vol. 2. IEEE; 2014. \\npp.\\xa060-67\\n[33] Uysal AK, Murphey YL.\\xa0Sentiment \\nclassification: Feature selection based \\nE-Business - Higher Education and Intelligence Applications\\n\\n32approaches versus deep learning. In: \\n2017 IEEE International Conference on \\nComputer and Information Technology \\n(CIT). IEEE; 2017. pp.\\xa023-30\\n[34] Sohangir S, Wang D, Pomeranets A, \\nKhoshgoftaar TM.\\xa0Big data: Deep \\nlearning for financial sentiment \\nanalysis. Journal of Big Data. 2018;5(1):3\\n[35] Singhal P, Bhattacharyya P. \\nSentiment Analysis and Deep Learning: \\nA Survey. Bombay: Center for Indian \\nLanguage Technology, Indian Institute \\nof Technology; 2016\\n[36] Martin V.\\xa0Predicting the French \\nstock market using social media \\nanalysis. In: 2013 8th International \\nWorkshop on Semantic and Social \\nMedia Adaptation and Personalization. \\nIEEE; 2013. pp.\\xa03-7\\n[37] Geva T, Zahavi J.\\xa0Empirical \\nevaluation of an automated intraday \\nstock recommendation system \\nincorporating both market data and \\ntextual news. Decision Support Systems. \\n2014;57:212-223\\n[38] Goldberg DE.\\xa0Genetic Algorithms \\nin Search, Optimization, and Machine \\nLearning. Reading, MA: Addison-\\nWesley; 1989\\n[39] Khatri SK, Srivastava A.\\xa0Using \\nsentimental analysis in prediction of \\nstock market investment. In: 2016 5th \\nInternational Conference on Reliability, \\nInfocom Technologies and Optimization \\n(Trends and Future Directions) \\n(ICRITO). IEEE; 2016. pp.\\xa0566-569\\n[40] Chen W, Zhang Y, Yeo CK, Lau CT, \\nLee BS.\\xa0Stock market prediction using \\nneural network through news on online \\nsocial networks. In: 2017 International \\nSmart Cities Conference (ISC2). IEEE; \\n2017. pp.\\xa01-6\\n[41] Shastri M, Roy S, Mittal M.\\xa0Stock \\nprice prediction using artificial neural \\nmodel: An application of big data. EAI Endorsed Transactions on Scalable \\nInformation Systems. 2019;6(20)\\n[42] Picasso A, Merello S, Ma Y, Oneto L, \\nCambria E.\\xa0Technical analysis and \\nsentiment embeddings for market \\ntrend prediction. Expert Systems with \\nApplications. 2019;135:60-70\\n[43] Cambria E, Fu J, Bisio F, Poria S. \\nAffectiveSpace 2: Enabling affective \\nintuition for concept-level sentiment \\nanalysis. In: Twenty-Ninth AAAI \\nConference on Artificial Intelligence; \\n2015\\n[44] Hochreiter S, Schmidhuber J.\\xa0Long \\nshort-term memory. Neural \\nComputation. 1997;9(8):1735-1780\\n[45] Rao G, Huang W, Feng Z,  \\nCong Q.\\xa0LSTM with sentence \\nrepresentations for document-\\nlevel sentiment classification. \\nNeurocomputing. 2018;308:49-57\\n[46] Siami-Namini S, Namin AS. \\nForecasting economics and financial \\ntime series: ARIMA vs. LSTM. 2018. \\narXiv preprint arXiv:1803.06386\\n[47] Huynh HD, Dang LM, Duong D.\\xa0A \\nnew model for stock price movements \\nprediction using deep neural \\nnetwork. In: Proceedings of the \\nEighth International Symposium on \\nInformation and Communication \\nTechnology; 2017. pp.\\xa057-62\\n[48] Mikolov T, Sutskever I, Chen K,  \\nCorrado GS, Dean J.\\xa0Distributed \\nrepresentations of words and phrases \\nand their compositionality. In: Advances \\nin Neural Information Processing \\nSystems; 2013. pp.\\xa03111-3119\\n[49] Wang Y, Huang M, Zhu X, \\nZhao L.\\xa0Attention-based LSTM for \\naspect-level sentiment classification. In: \\nProceedings of the 2016 Conference on \\nEmpirical Methods in Natural Language \\nProcessing; 2016. pp.\\xa0606-615\\n33\\nRecent Advances in Stock Market Prediction Using Text Mining: A Survey\\nDOI: http://dx.doi.org/10.5772/intechopen.92253\\n\\n[50] Liu H.\\xa0Leveraging financial news for \\nstock trend prediction with attention-\\nbased recurrent neural network. 2018. \\narXiv preprint arXiv:1811.06173\\n[51] Kraus M, Feuerriegel S.\\xa0Decision \\nsupport from financial disclosures with \\ndeep neural networks and transfer \\nlearning. Decision Support Systems. \\n2017;104:38-48\\n[52] Li J, Bu H, Wu J.\\xa0Sentiment-aware \\nstock market prediction: A deep \\nlearning method. In: 2017 International \\nConference on Service Systems and \\nService Management. IEEE; 2017. \\npp.\\xa01-6\\n[53] Collobert R, Weston J.\\xa0A unified \\narchitecture for natural language \\nprocessing: Deep neural networks with \\nmultitask learning. In: Proceedings of \\nthe 25th International Conference on \\nMachine Learning; 2008. pp.\\xa0160-167\\n[54] Ho CC, Baharim KN, Fatan AA, \\nAlias MS. Deep neural networks for \\ntext: A review. In: The 6th International \\nConference on Computer Science and \\nComputational Mathematics. Langkawi, \\nMalaysia; 2017\\n[55] Ding X, Zhang Y, Liu T, Duan J. \\nUsing structured events to predict stock \\nprice movement: An empirical \\ninvestigation. In: Proceedings of the \\n2014 Conference on Empirical Methods \\nin Natural Language Processing \\n(EMNLP); 2014. pp.\\xa01415-1425\\n[56] Vu TT, Chang S, Ha QT, Collier N. \\nAn experiment in integrating sentiment \\nfeatures for tech stock prediction in \\ntwitter. In: Proceedings of the Workshop \\non Information Extraction and Entity \\nAnalytics on Social Media Data; 2012. \\npp.\\xa023-38\\n[57] Moniz A, de Jong F.\\xa0Classifying the \\ninfluence of negative affect expressed \\nby the financial media on investor \\nbehavior. In: Proceedings of the 5th Information Interaction in Context \\nSymposium; 2014. pp.\\xa0275-278\\n[58] Bing L, Chan KC, Ou C.\\xa0Public \\nsentiment analysis in Twitter data \\nfor prediction of a company’s stock \\nprice movements. In: 2014 IEEE 11th \\nInternational Conference on e-Business \\nEngineering. IEEE; 2014. pp.\\xa0232-239\\n[59] Li X, Huang X, Deng X, Zhu S. \\nEnhancing quantitative intra-day stock \\nreturn prediction by integrating \\nboth market news and stock prices \\ninformation. Neurocomputing. \\n2014;142:228-238\\n[60] Shynkevich Y, McGinnity TM, \\nColeman S, Belatreche A.\\xa0Stock price \\nprediction based on stock-specific and \\nsub-industry-specific news articles. In: \\n2015 International Joint Conference on \\nNeural Networks (IJCNN). IEEE; 2015. \\npp.\\xa01-8\\n[61] Cakra YE, Trisedya BD.\\xa0Stock price \\nprediction using linear regression \\nbased on sentiment analysis. In: 2015 \\nInternational Conference on Advanced \\nComputer Science and Information \\nSystems (ICACSIS). IEEE; 2015. \\npp.\\xa0147-154\\n[62] Ghanavati M, Wong RK, Chen F,  \\nWang Y, Fong S.\\xa0A generic service \\nframework for stock market prediction. \\nIn: 2016 IEEE International Conference \\non Services Computing (SCC). IEEE; \\n2016. pp.\\xa0283-290\\n[63] Gálvez RH, Gravano A.\\xa0Assessing \\nthe usefulness of online message board \\nmining in automatic stock prediction \\nsystems. Journal of Computational \\nScienc. 2017;19:43-56\\n[64] Maqsood H, Mehmood I, \\nMaqsood M, Yasir M, Afzal S, Aadil F, \\net\\xa0al. A local and global event sentiment \\nbased efficient stock exchange \\nforecasting using deep learning. \\nInternational Journal of Information \\nManagement. 2020;50:432-451\\n\\n\\n ********************References \\n[1] Partha, R., Sanjay, S. and Kowar, M.K. (2012) Fuzzy Candlestick Approach to Trade \\nS & P CNX,\\n \\nNIFTY 50 Index Using Engulfing Patterns.  International Journal of \\nHybrid Information Technology\\n, 5, 57-66. \\n[2] Hiemstra, Y. (1994) A Stock Market Forecasting Support System Based on Fuzzy \\nLogic. \\nProceedings of the IEEE 27th Annual Hawaii International Conference on \\nSystem\\n, Sciences, Wailea, HI, 4-7 January 1994, 281-287.  \\nhttps://doi.org/10.1109/HICSS.1994.323343\\n\\n \\n\\n[3] Nicholis, S.C. and Sumpter, D.J.T. (2011) A Dynamical Approach to Stock Market \\nFluctuation. \\nInternational Journal of Bifurcation and Chaos , \\n21, 3557-564.  \\nhttps://doi.org/10.1142/S0218127411030726\\n\\n \\n[4] Preethi, G. and Santhi, B. (2012) Stock Market Forecasting Techniques: A Survey. \\nJournal of Theoretical and Applied Information Technology , \\n46, 24-30. \\n\\n[5] Chong, T. (2009) Financial Time Series Forecasting Using Improved Wavelet ANN. \\nMaster Thesis Report. (Not Published) \\n[6] Dhamija, A.K. (2010) Financial Time Series Forecasting: Comparison of ANN and \\nARCH Model.\\n International Research Journal of Finance, No. 49, 194-212. \\n[7] Zadeh, L.A. (1965) Fuzzy Sets. \\nInformation and Control , \\n8\\n, 338-353.  \\nhttps://doi.org/10.1016/S0019-9958(65)90241-X\\n \\n[8] Zadeh, L.A. (1975). The Concept of a Linguistic Variable and Its Application to \\nApproximate Reasoning I. \\nInformation Science, 8\\n, 199-249.  \\nhttps://doi.org/10.1016/0020-0255(75)90036-5\\n \\n[9] Abraham, A. and Nath, B. (2001) Hybrid Intelligent Systems Design—A Review of a \\nDecade of Research. Technical Report (5/2000), Gippsland School of Computing \\nand Information Technology, Monash University, Australia. \\n[10] Abraham, A. (2001) Neuro-Fuzzy Systems: State-Of-The-Art Modeling Techniques, \\nIn: Mira, J. and Prieto, A., Eds., \\nConnectionist Models of Neurons, Learning \\nProcesses\\n, and Artificial Intelligence, Springer-Verlag Germany, Granada, Spain, \\n269-276. https://doi.org/10.1007/3-540-45720-8_30\\n\\n \\n[11] Thammano, A. (1999) Neuro-Fuzzy Model for Stock Market Prediction. In: Dagli, \\nC.H., Buczak, A.L., Ghosh, J., Embrechts, M.J. and Ersoy, O., Eds., \\nSmart Engineer-\\nM. M. Alalaya et al. \\n \\n \\n\\nDOI: 10.4236/ojbm.2018.63048 650 Open Journal of Business and Management\\n  \\n\\n\\n \\n\\n ing System Design: Neural Networks , Fuzzy Logic, Evolutionary Programming, \\nData Mining, and Complex Systems , Proceedings of the Artificial Neural Networks \\nin Engineering Conference (ANNIE ‘99). ASME Press, New York, 587-591. \\n[12] Kim, K.-J. and Han, I. (2000) Genetic Algorithms Approach to Feature Discretiza-\\ntion in Artificial Neural Networks for the Prediction of Stock Price Index. \\nExpert \\nSystems with Applications\\n, \\n19, 125-132.  \\nhttps://doi.org/10.1016/S0957-4174(00)00027-0\\n \\n[13] Egeli, B., Ozturan, M. and Badur, B. (2003) Stock Market Prediction Using Artificial \\nNeural Networks. \\nProceedings of the 3rd International Conference on Business , \\nHawaii, 18-21 June 2003, 1-8. \\n[14] Singh, K.K., Dimri, P. and Singh, J.N. (2014) Green Data Base Management System \\nfor Intermediaries of the Indian Stock Market. IEEE Xplore Digital Library, 1-5. \\n[15] White, H. (2010) Economic Prediction Using Neural Networks: The Case of IBM \\nDaily Stock Returns. Department of Economics University of California, San Diego. \\n[16] Dashore, P. and Jain, S. (2010) Fuzzy Rule Based Expert System to Represent Un-\\ncertain Knowledge of E-Commerce. \\nInternational Journal of Computer Theory and \\nEngineering\\n, 2, 882-886. \\n[17] Huang, K.Y. and Jane, C.-J. (2009) A Hybrid Model for Stock Market Forecasting \\nand Portfolio Selection Based on ARX, Grey System and RS Theories. \\nExpert Sys-\\ntems with Applications\\n, \\n36, 5387-5392. https://doi.org/10.1016/j.eswa.2008.06.103\\n  \\n[18] Feng, L., Baowen, L., Boris, P., Tobias, P. and Eugene, H. (2012) Linking \\nAgent-Based Models and Stochastic Models of a Financial Market. \\nProceeding of \\nthe National Academy of Sciences of the United State of America\\n, \\n109, 8388-8393.  \\nhttps://doi.org/10.1073/pnas.1205013109\\n  \\n[19] Kim, M.J., Min, S.H. and Han, I.G. (2006) An Evolutionary Approach to the Com-\\nbination of Multiple Classifiers to Predict a Stock Price Index. \\nExpert Systems with \\nApplications\\n, \\n31, 241-247. https://doi.org/10.1016/j.eswa.2005.09.020\\n  \\n[20] Mate, A.A. (2014) Scheduling By Using Fuzzy Logic in Manufacturing. \\nInternation-\\nal Journal of Engineering Research and Applications\\n, 4, 104-111. \\n[21] Alejandro, E., Juliano, M. and Sebastian, M. (2013) A Technical Analysis Indicator \\nBased on Fuzzy Logic. \\nElectronic Notes on Theoretical Computer Science, \\n292, \\n27-37.\\n https://doi.org/10.1016/j.entcs.2013.02.003\\n  \\n \\n\\n\\n ********************\\n\\n ********************References\\n[Benidiset al., 2020]Konstantinos Benidis, Syama Sundar Ranga-\\npuram, Valentin Flunkert, Bernie Wang, Danielle Maddix, Caner\\nTurkmen, Jan Gasthaus, et al. Neural forecasting: Introduction\\nand literature overview.arXiv preprint arXiv:2004.10240, 2020.\\n[Bl´azquez-Garc´ıaet al., 2021]Ane Bl´azquez-Garc´ıa, Angel\\nConde, Usue Mori, and Jose A Lozano. A review on out-\\nlier/anomaly detection in time series data. ACM Computing\\nSurveys (CSUR), 54(3):1–33, 2021.\\n[Brownet al., 2020]Tom Brown, Benjamin Mann, Nick Ryder,\\nMelanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, et al. Lan-\\nguage models are few-shot learners. NeurIPS, 2020.\\n[Caiet al., 2020]Ling Cai, Krzysztof Janowicz, Gengchen Mai,\\nBo Yan, and Rui Zhu. Trafﬁc transformer: Capturing the conti-\\nnuity and periodicity of time series for trafﬁc forecasting. Trans-\\nactions in GIS, 24(3):736–755, 2020.\\n[Chaudhariet al., 2021]Sneha Chaudhari, Varun Mithal, Gungor\\nPolatkan, and Rohan Ramanath. An attentive survey of attention\\nmodels.ACM Transactions on Intelligent Systems and Technol-\\nogy (TIST), 12(5):1–32, 2021.\\n[Chenet al., 2021a]Hanting Chen, Yunhe Wang, Tianyu Guo,\\nChang Xu, Yiping Deng, Zhenhua Liu, Siwei Ma, Chunjing Xu,\\net al. Pre-trained image processing transformer. In CVPR, 2021.\\n[Chenet al., 2021b]Lili Chen, Kevin Lu, Aravind Rajeswaran,\\nKimin Lee, Aditya Grover, Misha Laskin, Pieter Abbeel, Aravind\\nSrinivas, and Igor Mordatch. Decision transformer: Reinforce-\\nment learning via sequence modeling. NeurIPS, 2021.\\n[Chenet al., 2021c]Minghao Chen, Houwen Peng, Jianlong Fu,\\nand Haibin Ling. AutoFormer: Searching transformers for vi-\\nsual recognition. InCVPR, 2021.\\n[Chenet al., 2021d]Zekai Chen, Dingshuo Chen, Xiao Zhang,\\nZixuan Yuan, and Xiuzhen Cheng. Learning graph structures\\nwith transformer for multivariate time series anomaly detection\\nin IoT.IEEE Internet of Things Journal, 2021.\\n[Choiet al., 2021]Kukjin Choi, Jihun Yi, Changhwa Park, and\\nSungroh Yoon. Deep learning for anomaly detection in time-\\nseries data: Review, analysis, and guidelines. IEEE Access, 2021.\\n[Clevelandet al., 1990]Robert B Cleveland, William S Cleveland,\\nJean E McRae, and Irma Terpenning. STL: A seasonal-trend de-\\ncomposition procedure based on loess. Journal of Ofﬁcial Statis-\\ntics, 6(1):3–73, 1990.\\n[Donget al., 2018]Linhao Dong, Shuang Xu, and Bo Xu. Speech-\\ntransformer: a no-recurrence sequence-to-sequence model for\\nspeech recognition. InICASSP, 2018.\\n[Dosovitskiyet al., 2021]Alexey Dosovitskiy, Lucas Beyer,\\nAlexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,\\nThomas Unterthiner, et al. An image is worth 16x16 words:\\nTransformers for image recognition at scale. In ICLR, 2021.\\n[Elskenet al., 2019]Elsken, Thomas, Jan Hendrik Metzen, and\\nFrank Hutter. Neural architecture search: A survey. Journal of\\nMachine Learning Research, 2019.\\n[Galassiet al., 2020]Andrea Galassi, Marco Lippi, and Paolo Tor-\\nroni. Attention in natural language processing. IEEE Transac-\\ntions on Neural Networks and Learning Systems , 2020.\\n[Gehringet al., 2017]Jonas Gehring, Michael Auli, David Grang-\\nier, Denis Yarats, and Yann N Dauphin. Convolutional sequence\\nto sequence learning. InICML, 2017. [Goodfellowet al., 2014]Ian Goodfellow, Jean Pouget-Abadie,\\nMehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,\\nAaron Courville, and Yoshua Bengio. Generative adversarial\\nnets.NeurIPS, 2014.\\n[Hanet al., 2020]Kai Han, Yunhe Wang, Hanting Chen, Xinghao\\nChen, Jianyuan Guo, Zhenhua Liu, Yehui Tang, An Xiao, Chun-\\njing Xu, Yixing Xu, et al. A survey on visual transformer. arXiv\\npreprint arXiv:2012.12556, 2020.\\n[Hanet al., 2021]Xu Han, Zhengyan Zhang, Ning Ding, Yuxian\\nGu, Xiao Liu, Yuqi Huo, Jiezhong Qiu, Liang Zhang, Wentao\\nHan, Minlie Huang, et al. Pre-trained models: Past, present and\\nfuture.AI Open, 2021.\\n[Ismail Fawazet al., 2019]Hassan Ismail Fawaz, Germain\\nForestier, Jonathan Weber, Lhassane Idoumghar, and Pierre-\\nAlain Muller. Deep learning for time series classiﬁcation: a\\nreview.Data mining and knowledge discovery , 2019.\\n[Keet al., 2020]Guolin Ke, Di He, and Tie-Yan Liu. Rethink-\\ning positional encoding in language pre-training. arXiv preprint\\narXiv:2006.15595, 2020.\\n[Kenton and Toutanova, 2019]Jacob Devlin Ming-Wei Chang\\nKenton and Lee Kristina Toutanova. BERT: Pre-training of\\ndeep bidirectional transformers for language understanding. In\\nNAACL-HLT, 2019.\\n[Khanet al., 2021]Salman Khan, Muzammal Naseer, Munawar\\nHayat, Syed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak\\nShah. Transformers in vision: A survey. arXiv preprint\\narXiv:2101.01169, 2021.\\n[Kingma and Welling, 2013]Diederik P Kingma and Max\\nWelling. Auto-encoding variational bayes. arXiv preprint\\narXiv:1312.6114, 2013.\\n[Liet al., 2019]Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou,\\nWenhu Chen, Yu-Xiang Wang, and Xifeng Yan. Enhancing the\\nlocality and breaking the memory bottleneck of transformer on\\ntime series forecasting. InNeurIPS, 2019.\\n[Liet al., 2021]Longyuan Li, Jian Yao, Li Wenliang, Tong He,\\nTianjun Xiao, Junchi Yan, David Wipf, and Zheng Zhang. Grin:\\nGenerative relation and intention network for multi-agent trajec-\\ntory prediction. InNeurIPS, 2021.\\n[Lim and Zohren, 2021]Bryan Lim and Stefan Zohren. Time-\\nseries forecasting with deep learning: a survey. Philosophical\\nTransactions of the Royal Society, 2021.\\n[Limet al., 2019]Bryan Lim, Sercan O Arik, Nicolas Loeff,\\nand Tomas Pﬁster. Temporal fusion transformers for inter-\\npretable multi-horizon time series forecasting. arXiv preprint\\narXiv:1912.09363, 2019.\\n[Limet al., 2021]Bryan Lim, Sercan¨O Arık, Nicolas Loeff, and\\nTomas Pﬁster. Temporal fusion transformers for interpretable\\nmulti-horizon time series forecasting. International Journal of\\nForecasting, 37(4):1748–1764, 2021.\\n[Linet al., 2021]Yang Lin, Irena Koprinska, and Mashud Rana.\\nSSDNet: State space decomposition neural network for time se-\\nries forecasting. InICDM, 2021.\\n[Liuet al., 2021]Minghao Liu, Shengqi Ren, Siyuan Ma, Jiahui\\nJiao, Yizhou Chen, Zhiguang Wang, and Wei Song. Gated trans-\\nformer networks for multivariate time series classiﬁcation. arXiv\\npreprint arXiv:2103.14438, 2021.\\n[Liuet al., 2022]Shizhan Liu, Hang Yu, Cong Liao, Jianguo Li,\\nWeiyao Lin, Alex X. Liu, and Schahram Dustdar. Pyraformer:\\nLow-complexity pyramidal attention for long-range time series\\nmodeling and forecasting. InICLR, 2022.\\n[Meiet al., 2022]Hongyuan Mei, Chenghao Yang, and Jason Eis-\\nner. Transformer embeddings of irregularly spaced events and\\ntheir participants. InICLR, 2022.\\n[Menget al., 2019]Hengyu Meng, Yuxuan Zhang, Yuanxiang Li,\\nand Honghua Zhao. Spacecraft anomaly detection via trans-\\nformer reconstruction error. InICASSE, 2019.\\n[Qiet al., 2021]Xinyuan Qi, Kai Hou, Tong Liu, Zhongzhong\\nYu, Sihao Hu, and Wenwu Ou. From known to unknown:\\nKnowledge-guided transformer for time-series sales forecasting\\nin Alibaba.arXiv preprint arXiv:2109.08381, 2021.\\n[Qiuet al., 2020]Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan\\nShao, Ning Dai, and Xuanjing Huang. Pre-trained models for\\nnatural language processing: A survey. Science China Techno-\\nlogical Sciences, pages 1–26, 2020.\\n[Ruffet al., 2021]Lukas Ruff, Jacob R Kauffmann, Robert A Van-\\ndermeulen, Gr´egoire Montavon, Wojciech Samek, Marius Kloft,\\nThomas G Dietterich, and Klaus-Robert M ¨uller. A unifying re-\\nview of deep and shallow anomaly detection. Proceedings of the\\nIEEE, 2021.\\n[Rußwurm and K¨orner, 2020]Marc Rußwurm and Marco K¨orner.\\nSelf-attention for raw optical satellite time series classiﬁca-\\ntion.ISPRS Journal of Photogrammetry and Remote Sensing ,\\n169:421–435, 11 2020.\\n[Selvaet al., 2022]Javier Selva, Anders S Johansen, Sergio Es-\\ncalera, Kamal Nasrollahi, Thomas B Moeslund, and Albert\\nClap´es. Video transformers: A survey. arXiv preprint\\narXiv:2201.05991, 2022.\\n[Shawet al., 2018]Peter Shaw, Jakob Uszkoreit, and Ashish\\nVaswani. Self-attention with relative position representations.\\narXiv preprint arXiv:1803.02155, 2018.\\n[Shchuret al., 2021]Oleksandr Shchur, Ali Caner T¨urkmen, Tim\\nJanuschowski, and Stephan G¨unnemann. Neural temporal point\\nprocesses: A review. InIJCAI, 2021.\\n[Soet al., 2019]David So, Quoc Le, and Chen Liang. The evolved\\ntransformer. InICML, 2019.\\n[Tang and Matteson, 2021]Binh Tang and David Matteson. Proba-\\nbilistic transformer for time series analysis. In NeurIPS, 2021.\\n[Tayet al., 2020]Yi Tay, Mostafa Dehghani, Dara Bahri, and Don-\\nald Metzler. Efﬁcient transformers: A survey. arXiv preprint\\narXiv:2009.06732, 2020.\\n[Torreset al., 2021]Jos´e F. Torres, Dalil Hadjout, Abderrazak Se-\\nbaa, Francisco Mart´ınez-´Alvarez, and Alicia Troncoso. Deep\\nlearning for time series forecasting: a survey. Big Data, 2021.\\n[Tuliet al., 2022]Shreshth Tuli, Giuliano Casale, and Nicholas R\\nJennings. TranAD: Deep transformer networks for anomaly de-\\ntection in multivariate time series data. In VLDB, 2022.\\n[Vaswaniet al., 2017]Ashish Vaswani, Noam Shazeer, Niki Par-\\nmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz\\nKaiser, and Illia Polosukhin. Attention is all you need. In\\nNeurIPS, 2017.\\n[Wanget al., 2020]Xiaoxing Wang, Chao Xue, Junchi Yan, Xi-\\naokang Yang, Yonggang Hu, and Kewei Sun. MergeNAS: Merge\\noperations into one for differentiable architecture search. In IJ-\\nCAI, 2020.\\n[Wanget al., 2022]Xixuan Wang, Dechang Pi, Xiangyan Zhang,\\nHao Liu, and Chang Guo. Variational transformer-based anomaly\\ndetection approach for multivariate time series. Measurement,\\npage 110791, 2022. [Wenet al., 2019]Qingsong Wen, Jingkun Gao, Xiaomin Song,\\nLiang Sun, Huan Xu, and Shenghuo Zhu. RobustSTL: A robust\\nseasonal-trend decomposition algorithm for long time series. In\\nAAAI, 2019.\\n[Wenet al., 2021a]Qingsong Wen, Kai He, Liang Sun, Yingying\\nZhang, Min Ke, and Huan Xu. RobustPeriod: Time-frequency\\nmining for robust multiple periodicities detection. In SIGMOD,\\n2021.\\n[Wenet al., 2021b]Qingsong Wen, Liang Sun, Fan Yang, Xiaomin\\nSong, Jingkun Gao, Xue Wang, and Huan Xu. Time series data\\naugmentation for deep learning: A survey. In IJCAI, 2021.\\n[Wuet al., 2020]Sifan Wu, Xi Xiao, Qianggang Ding, Peilin Zhao,\\nYing Wei, and Junzhou Huang. Adversarial sparse transformer\\nfor time series forecasting. InNeurIPS, 2020.\\n[Wuet al., 2021]Haixu Wu, Jiehui Xu, Jianmin Wang, and Ming-\\nsheng Long. Autoformer: Decomposition transformers with\\nauto-correlation for long-term series forecasting. In NeurIPS,\\n2021.\\n[Xuet al., 2020]Mingxing Xu, Wenrui Dai, Chunmiao Liu, Xing\\nGao, Weiyao Lin, Guo-Jun Qi, and Hongkai Xiong. Spatial-\\ntemporal transformer networks for trafﬁc ﬂow forecasting. arXiv\\npreprint arXiv:2001.02908, 2020.\\n[Xuet al., 2022]Jiehui Xu, Haixu Wu, Jianmin Wang, and Ming-\\nsheng Long. Anomaly Transformer: Time series anomaly detec-\\ntion with association discrepancy. In ICLR, 2022.\\n[Yanget al., 2021]Chao-Han Huck Yang, Yun-Yun Tsai, and Pin-\\nYu Chen. Voice2series: Reprogramming acoustic models for\\ntime series classiﬁcation. InICML, 2021.\\n[Yuet al., 2020]Cunjun Yu, Xiao Ma, Jiawei Ren, Haiyu Zhao, and\\nShuai Yi. Spatio-temporal graph transformer networks for pedes-\\ntrian trajectory prediction. InECCV, 2020.\\n[Yuan and Lin, 2020]Yuan Yuan and Lei Lin. Self-supervised pre-\\ntraining of transformers for satellite image time series classiﬁca-\\ntion.IEEE Journal of Selected Topics in Applied Earth Observa-\\ntions and Remote Sensing, 14:474–487, 2020.\\n[Zerveaset al., 2021]George Zerveas, Srideepika Jayaraman,\\nDhaval Patel, Anuradha Bhamidipaty, and Carsten Eickhoff. A\\ntransformer-based framework for multivariate time series repre-\\nsentation learning. InKDD, 2021.\\n[Zhanget al., 2020]Qiang Zhang, Aldo Lipani, Omer Kirnap, and\\nEmine Yilmaz. Self-attentive Hawkes process. In ICML, 2020.\\n[Zhanget al., 2021]Hongwei Zhang, Yuanqing Xia, Tijin Yan, and\\nGuiyang Liu. Unsupervised anomaly detection in multivariate\\ntime series through transformer-based variational autoencoder. In\\nCCDC, 2021.\\n[Zhouet al., 2021]Haoyi Zhou, Shanghang Zhang, Jieqi Peng,\\nShuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang. In-\\nformer: Beyond efﬁcient transformer for long sequence time-\\nseries forecasting. InAAAI, 2021.\\n[Zhouet al., 2022]Tian Zhou, Ziqing Ma, Qingsong Wen, Xue\\nWang, Liang Sun, and Rong Jin. FEDformer: Frequency en-\\nhanced decomposed transformer for long-term series forecasting.\\narXiv preprint arXiv:2201.12740, 2022.\\n[Zuoet al., 2020]Simiao Zuo, Haoming Jiang, Zichong Li, Tuo\\nZhao, and Hongyuan Zha. Transformer Hawkes process. In\\nICML, 2020.\\n\\n\\n ********************References and Notes\\n1. M. P. Young, S. Yamane,Science256, 1327 (1992).\\n2. R. N. Shepard,Science210, 390 (1980).\\n3. M. Turk, A. Pentland,J. Cogn. Neurosci.3, 71 (1991).\\n4. H. Murase, S. K. Nayar,Int. J. Comp. Vision14,5\\n(1995).\\n5. J. W. McClurkin, L. M. Optican, B. J. Richmond, T. J.\\nGawne,Science253, 675 (1991).\\n6. J. L. Elman, D. Zipser,J. Acoust. Soc. Am.83, 1615\\n(1988).\\n7. W. Klein, R. Plomp, L. C. W. Pols,J. Acoust. Soc. Am.\\n48, 999 (1970).\\n8. E. Bizzi, F. A. Mussa-Ivaldi, S. Giszter,Science253, 287\\n(1991).\\n9. T. D. Sanger,Adv. Neural Info. Proc. Syst.7, 1023\\n(1995).\\n10. J. W. Hurrell,Science269, 676 (1995).\\n11. C. A. L. Bailer-Jones, M. Irwin, T. von Hippel,Mon.\\nNot. R. Astron. Soc.298, 361 (1997).\\n12. P. Menozzi, A. Piazza, L. Cavalli-Sforza,Science201,\\n786 (1978).\\n13. K. V. Mardia, J. T. Kent, J. M. Bibby,Multivariate\\nAnalysis, (Academic Press, London, 1979).\\n14. A. H. Monahan,J. Clim., in press.\\n15. The scale-invariantKparameter is typically easier to\\nset thane, but may yield misleading results when thelocal dimensionality varies across the data set. When\\navailable, additional constraints such as the temporal\\nordering of observations may also help to determine\\nneighbors. In earlier work (36) we explored a more\\ncomplex method (37), which required an order of\\nmagnitude more data and did not support the theo-\\nretical performance guarantees we provide here for\\ne- andK-Isomap.\\n16. This procedure, known as FloydÕs algorithm, requires\\nO(N3\\n) operations. More efÞcient algorithms exploit-\\ning the sparse structure of the neighborhood graph\\ncan be found in (38).\\n17. The operatortis deÞned byt(D)52HSH/2, whereS\\nis the matrix of squared distances {S\\nij5D\\nij2}, andHis\\nthe Òcentering matrixÓ {H\\nij5d\\nij21/N}(13).\\n18. Our proof works by showing that for a sufÞciently\\nhigh density (a) of data points, we can always choose\\na neighborhood size (eorK) large enough that the\\ngraph will (with high probability) have a path not\\nmuch longer than the true geodesic, but small\\nenough to prevent edges that Òshort circuitÓ the true\\ngeometry of the manifold. More precisely, given ar-\\nbitrarily small values ofl\\n1,l\\n2, andm, we can guar-\\nantee that with probability at least 12m, estimates\\nof the form\\n~12l\\n1!d\\nM~i,j!#d\\nG~i,j!#~11l\\n2!d\\nM~i,j!\\nwill hold uniformly over all pairs of data pointsi,j. For\\ne-Isomap, we require\\ne#~2/p!r\\n0˛\\n24l\\n1,e,s\\n0,\\na.@log~V/mh\\nd~l\\n2e/16!d\\n!#/h\\nd~l\\n2e/8!d\\nwherer\\n0is the minimal radius of curvature of the\\nmanifoldMas embedded in the input spaceX,s\\n0is\\nthe minimal branch separation ofMinX,Vis the\\n(d-dimensional) volume ofM, and (ignoring boundary\\neffects)h\\ndis the volume of the unit ball in Euclidean\\nd-space. ForK-Isomap, we letebe as above and Þx\\nthe ratio (K11)/a5h\\nd(e/2)d\\n/2. We then require\\ne\\n2~K11!/4\\n#mh\\nd~e/4!d\\n/4V,\\n~e/4!\\n~K11!/2\\n#mh\\nd~e/8!d\\n/16V,\\na.@4 log~8V/mh\\nd~l\\n2e/32p!d\\n!#/h\\nd~l\\n2e/16p!d\\nThe exact content of these conditionsÑbut not their\\ngeneral formÑdepends on the particular technical\\nassumptions we adopt. For details and extensions to\\nnonuniform densities, intrinsic curvature, and bound-\\nary effects, see http://isomap.stanford.edu.\\n19. In practice, for Þnite data sets,d\\nG(i,j) may fail to\\napproximated\\nM(i,j) for a small fraction of points that\\nare disconnected from the giant component of the\\nneighborhood graphG. These outliers are easily de-\\ntected as having inÞnite graph distances from the\\nmajority of other points and can be deleted from\\nfurther analysis.\\n20. The Isomap embedding of the hand images is avail-\\nable atScienceOnline at www.sciencemag.org/cgi/\\ncontent/full/290/5500/2319/DC1. For additional\\nmaterial and computer code, see http://isomap.\\nstanford.edu.\\n21. R. Basri, D. Roth, D. Jacobs,Proceedings of the IEEE\\nConference on Computer Vision and Pattern Recog-\\nnition(1998), pp. 414Ð420.\\n22. C. Bregler, S. M. Omohundro,Adv.Neural Info.Proc.\\nSyst.7, 973 (1995).\\n23. G. E. Hinton, M. Revow, P. Dayan,Adv.Neural Info.\\nProc.Syst.7, 1015 (1995).\\n24. R. Durbin, D. Willshaw,Nature326, 689 (1987).\\n25. T. Kohonen,Self-Organisation and Associative Mem-\\nory(Springer-Verlag, Berlin, ed. 2, 1988), pp. 119Ð\\n157.\\n26. T. Hastie, W. Stuetzle,J.Am.Stat.Assoc.84, 502\\n(1989).\\n27. M. A. Kramer,AIChE J.37, 233 (1991).\\n28. D. DeMers, G. Cottrell,Adv.Neural Info.Proc.Syst.5,\\n580 (1993).\\n29. R. Hecht-Nielsen,Science269, 1860 (1995).\\n30. C. M. Bishop, M. Svense«n, C. K. I. Williams,Neural\\nComp.10, 215 (1998).\\n31. P. Comon,Signal Proc.36, 287 (1994).\\n32. A. J. Bell, T. J. Sejnowski,Neural Comp.7, 1129\\n(1995).\\n33. R. N. Shepard, S. A. Judd,Science191, 952 (1976).\\n34. M. Shiffrar, J. J. Freyd,Psychol.Science1, 257 (1990).Table 1.The Isomap algorithm takes as input the distancesd\\nX(i,j) between all pairsi,jfromNdata points\\nin the high-dimensional input spaceX, measured either in the standard Euclidean metric (as in Fig. 1A)\\nor in some domain-speciÞc metric (as in Fig. 1B). The algorithm outputs coordinate vectorsy\\niin a\\nd-dimensional Euclidean spaceYthat (according to Eq. 1) best represent the intrinsic geometry of the\\ndata. The only free parameter (eorK) appears in Step 1.\\n\\nStep\\n1 Construct neighborhood graph DeÞne the graphGover all data points by connecting\\npointsiandjif [as measured byd\\nX(i,j)] they are\\ncloser thane(e-Isomap), or ifiis one of theK\\nnearest neighbors ofj(K-Isomap). Set edge lengths\\nequal tod\\nX(i,j).\\n2 Compute shortest paths Initialized\\nG(i,j)5d\\nX(i,j)ifi,jare linked by an edge;\\nd\\nG(i,j)5‘otherwise. Then for each value ofk5\\n1, 2, . . .,Nin turn, replace all entriesd\\nG(i,j)by\\nmin{d\\nG(i,j),d\\nG(i,k)1d\\nG(k,j)}. The matrix of Þnal\\nvaluesD\\nG5{d\\nG(i,j)} will contain the shortest path\\ndistances between all pairs of points inG(16,19).\\n3 Constructd-dimensional embedding Letl\\npbe thep-th eigenvalue (in decreasing order) of\\nthe matrixt(D\\nG)(17), andv\\npibe thei-th\\ncomponent of thep-th eigenvector. Then set the\\np-th component of thed-dimensional coordinate\\nvectory\\niequal to=l\\np\\nv\\npi.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFig. 4.Interpolations along straight lines in\\nthe Isomap coordinate space (analogous to\\nthe blue line in Fig. 3C) implement perceptu-\\nally natural but highly nonlinear ÒmorphsÓ of\\nthe corresponding high-dimensional observa-\\ntions (43) by transforming them approxi-\\nmately along geodesic paths (analogous to\\nthe solid curve in Fig. 3A). (A) Interpolations\\nin a three-dimensional embedding of face\\nimages (Fig. 1A). (B) Interpolations in a four-\\ndimensional embedding of hand images (20)\\nappear as natural hand movements when\\nviewed in quick succession, eventhough no\\nsuch motions occurred in the observed data. (C)\\nInterpolations in a six-dimensional embedding of\\nhandwritten Ò2Ós (Fig. 1B) preserve continuity not\\nonly in the visual features of loop and arch artic-\\nulation, but also in the implied pen trajectories,\\nwhich are the true degrees of freedom underlying\\nthose appearances.REPORTS\\n22 DECEMBER 2000 VOL 290 SCIENCE www.sciencemag.org2322\\n  on July 25, 2012www.sciencemag.orgDownloaded from \\n35. R. N. Shepard,Psychon. Bull.Rev.1, 2 (1994).\\n36. J. B. Tenenbaum,Adv.Neural Info.Proc.Syst.10, 682\\n(1998).\\n37. T. Martinetz, K. Schulten,Neural Netw.7, 507 (1994).\\n38. V. Kumar, A. Grama, A. Gupta, G. Karypis,Introduc-\\ntion to Parallel Computing:Design and Analysis of\\nAlgorithms(Benjamin/Cummings, Redwood City, CA,\\n1994), pp. 257Ð297.\\n39. D. Beymer, T. Poggio,Science272, 1905 (1996).\\n40. Available at www.research.att.com/;yann/ocr/mnist.\\n41. P. Y. Simard, Y. LeCun, J. Denker,Adv.Neural Info.\\nProc.Syst.5, 50 (1993).\\n42. In order to evaluate the Þts of PCA, MDS, and Isomap\\non comparable grounds, we use the residual variance1ÐR2\\n(Dö\\nM,D\\nY).D\\nYis the matrix of Euclidean distanc-\\nes in the low-dimensional embedding recovered by\\neach algorithm.Dö\\nMis each algorithmÕs best estimate\\nof the intrinsic manifold distances: for Isomap, this is\\nthe graph distance matrixD\\nG; for PCA and MDS, it is\\nthe Euclidean input-space distance matrixD\\nX(except\\nwith the handwritten Ò2Ós, where MDS uses the\\ntangent distance).Ris the standard linear correlation\\ncoefÞcient, taken over all entries ofDö\\nMandD\\nY.\\n43. In each sequence shown, the three intermediate im-\\nages are those closest to the points 1/4, 1/2, and 3/4\\nof the way between the given endpoints. We can also\\nsynthesize an explicit mapping from input spaceXto\\nthe low-dimensional embeddingY, or vice versa, us-ing the coordinates of corresponding points {xi,y\\ni}in\\nboth spaces provided by Isomap together with stan-\\ndard supervised learning techniques (39).\\n44. Supported by the Mitsubishi Electric Research Labo-\\nratories, the Schlumberger Foundation, the NSF\\n(DBS-9021648), and the DARPA Human ID program.\\nWe thank Y. LeCun for making available the MNIST\\ndatabase and S. Roweis and L. Saul for sharing related\\nunpublished work. For many helpful discussions, we\\nthank G. Carlsson, H. Farid, W. Freeman, T. GrifÞths,\\nR. Lehrer, S. Mahajan, D. Reich, W. Richards, J. M.\\nTenenbaum, Y. Weiss, and especially M. Bernstein.\\n10 August 2000; accepted 21 November 2000\\nNonlinear Dimensionality\\nReduction by\\nLocally Linear Embedding\\nSam T. Roweis1\\nand Lawrence K. Saul2\\nMany areas of science depend on exploratory data analysis and visualization.\\nThe need to analyze large amounts of multivariate data raises the fundamental\\nproblem of dimensionality reduction: how to discover compact representations\\nof high-dimensional data. Here, we introduce locally linear embedding (LLE), an\\nunsupervised learning algorithm that computes low-dimensional, neighbor-\\nhood-preserving embeddings of high-dimensional inputs. Unlike clustering\\nmethods for local dimensionality reduction, LLE maps its inputs into a single\\nglobal coordinate system of lower dimensionality, and its optimizations do not\\ninvolve local minima. By exploiting the local symmetries of linear reconstruc-\\ntions, LLE is able to learn the global structure of nonlinear manifolds, such as\\nthose generated by images of faces or documents of text.\\nHow do we judge similarity? Our mental\\nrepresentations of the world are formed by\\nprocessing large numbers of sensory in-\\nputs—including, for example, the pixel in-\\ntensities of images, the power spectra of\\nsounds, and the joint angles of articulated\\nbodies. While complex stimuli of this form can\\nbe represented by points in a high-dimensional\\nvector space, they typically have a much more\\ncompact description. Coherent structure in the\\nworld leads to strong correlations between in-\\nputs (such as between neighboring pixels in\\nimages), generating observations that lie on or\\nclose to a smooth low-dimensional manifold.\\nTo compare and classify such observations—in\\neffect, to reason about the world—depends\\ncrucially on modeling the nonlinear geometry\\nof these low-dimensional manifolds.\\nScientists interested in exploratory analysis\\nor visualization of multivariate data (1) face a\\nsimilar problem in dimensionality reduction.\\nThe problem, as illustrated in Fig. 1, involves\\nmapping high-dimensional inputs into a low-\\ndimensional “description” space with as manycoordinates as observed modes of variability.\\nPrevious approaches to this problem, based on\\nmultidimensional scaling (MDS) (2), have\\ncomputed embeddings that attempt to preserve\\npairwise distances [or generalized disparities\\n(3)] between data points; these distances are\\nmeasured along straight lines or, in more so-\\nphisticated usages of MDS such as Isomap (4),along shortest paths confined to the manifold of\\nobserved inputs. Here, we take a different ap-\\nproach, called locally linear embedding (LLE),\\nthat eliminates the need to estimate pairwise\\ndistances between widely separated data points.\\nUnlike previous methods, LLE recovers global\\nnonlinear structure from locally linear fits.\\nThe LLE algorithm, summarized in Fig.\\n2, is based on simple geometric intuitions.\\nSuppose the data consist ofNreal-valued\\nvectorsWX\\ni, each of dimensionalityD, sam-\\npled from some underlying manifold. Pro-\\nvided there is sufficient data (such that the\\nmanifold is well-sampled), we expect each\\ndata point and its neighbors to lie on or\\nclose to a locally linear patch of the mani-\\nfold. We characterize the local geometry of\\nthese patches by linear coefficients that\\nreconstruct each data point from its neigh-\\nbors. Reconstruction errors are measured\\nby the cost function\\ne~W!5\\nO\\niUWX\\ni2S\\njW\\nijWX\\njU2\\n(1)\\nwhich adds up the squared distances between\\nall the data points and their reconstructions. The\\nweightsW\\nijsummarize the contribution of the\\njth data point to theith reconstruction. To com-\\npute the weightsW\\nij, we minimize the cost\\n\\n1\\nGatsby Computational Neuroscience Unit, Universi-\\nty College London, 17 Queen Square, London WC1N\\n3AR, UK.\\n2\\nAT&T LabÑResearch, 180 Park Avenue,\\nFlorham Park, NJ 07932, USA.\\nE-mail: roweis@gatsby.ucl.ac.uk (S.T.R.); lsaul@research.\\natt.com (L.K.S.)\\nFig. 1.The problem of nonlinear dimensionality reduction, as illustrated (10) for three-dimensional\\ndata (B) sampled from a two-dimensional manifold (A). An unsupervised learning algorithm must\\ndiscover the global internal coordinates of the manifold without signals that explicitly indicate how\\nthe data should be embedded in two dimensions. The color coding illustrates the neighborhood-\\npreserving mapping discovered by LLE; black outlines in (B) and (C) show the neighborhood of a\\nsingle point. Unlike LLE, projections of the data by principal component analysis (PCA) (28)or\\nclassical MDS (2) map faraway data points to nearby points in the plane, failing to identify the\\nunderlying structure of the manifold. Note that mixture models for local dimensionality reduction\\n(29), which cluster the data and perform PCA within each cluster, do not address the problem\\nconsidered here: namely, how to map high-dimensional data into a single global coordinate system\\nof lower dimensionality.REPORTS\\nwww.sciencemag.org SCIENCE VOL 290 22 DECEMBER 20002323\\n on July 25, 2012www.sciencemag.orgDownloaded from \\n\\n\\n ********************References\\nWang, Zhiguang; Oates, Tim (2015), \\nImaging Time-Series to Improve Classification and Imputation\\n, Arxiv.\\nLiu, Lu.; Wang, Zhiguang (2018) \\nEncoding temporal Markov dynamics in graph for visualizing and mining time series\\n Arxiv.\\nSign up for The Variable\\nBy Towards Data Science\\nEvery Thursday, the Variable delivers the very best of Towards Data Science: from hands-on tutorials and cutting-edge research to original features you don\\'t\\nwant to miss.\\n\\xa0\\nTake a look.\\nGet this newsletter\\nEmails will be sent to \\npalo2896@gmail.com\\n.\\nNot you?\\n\\nGet unlimited access\\nOpen in app\\n\\n\\n\\n ********************References\\n[BMR+20] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-\\nwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agar-\\nwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh,\\nDaniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler,\\nMateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCan-\\ndlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners,\\n2020, 2005.14165. 3, 5, 6, 7, 8, 10, 15, 18, 19, 20, 31, 32\\n[CGRS19] Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. Generating long sequences with\\nsparse transformers.CoRR, abs/1904.10509, 2019, 1904.10509. URL http://arxiv.org/\\nabs/1904.10509. 6, 7, 20\\n[CLH17] Patryk Chrabaszcz, Ilya Loshchilov, and Frank Hutter. A downsampled variant of imagenet\\nas an alternative to the CIFAR datasets. CoRR, abs/1707.08819, 2017, 1707.08819. URL\\nhttp://arxiv.org/abs/1707.08819 . 4, 14, 15\\n[CRC+20] Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and Ilya\\nSutskever. Generative pretraining from pixels. In Proceedings of Machine Learning and Systems\\n2020, pages 10466–10478. 2020. 3, 19\\n[DJP+20] Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, and Ilya\\nSutskever. Jukebox: A generative model for music, 2020, 2005.00341. 8\\n[HDMB19] Dieuwke Hupkes, Verna Dankers, Mathijs Mul, and Elia Bruni. Compositionality decomposed:\\nhow do neural networks generalise?, 2019, 1908.08351. 16\\n[HNA+17] Joel Hestness, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kia-\\nninejad, Md. Mostofa Ali Patwary, Yang Yang, and Yanqi Zhou. Deep learning scaling is\\npredictable, empirically, 2017, 1712.00409. 3, 19\\n[JGH18] Arthur Jacot, Franck Gabriel, and Clément Hongler. Neural tangent kernel: Convergence and\\ngeneralization in neural networks. In Advances in neural information processing systems , pages\\n8571–8580, 2018. 19\\n[KMH+20] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child,\\nScott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language\\nmodels, 2020, 2001.08361. 3, 4, 5, 6, 7, 9, 10, 11, 17, 18, 19, 20, 33\\n[Kom19] Aran Komatsuzaki. One epoch is all you need, 2019, arXiv:1906.06669. 19\\n[LBD+20] Aitor Lewkowycz, Yasaman Bahri, Ethan Dyer, Jascha Sohl-Dickstein, and Guy Gur-Ari. The\\nlarge learning rate phase of deep learning: the catapult mechanism, 2020, 2003.02218. 19\\n[LH17] Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. CoRR,\\nabs/1711.05101, 2017, 1711.05101. URL http://arxiv.org/abs/1711.05101 . 6\\n[LSP+18] Peter J. Liu, Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and\\nNoam Shazeer. Generating wikipedia by summarizing long sequences. arXiv:1801.10198 [cs],\\n2018, 1801.10198. URLhttp://arxiv.org/abs/1801.10198 . 3, 20\\n[LWS+20] Zhuohan Li, Eric Wallace, Sheng Shen, Kevin Lin, Kurt Keutzer, Dan Klein, and Joseph E.\\nGonzalez. Train large, then compress: Rethinking model size for efﬁcient training and inference\\nof transformers, 2020, 2002.11794. 3, 19\\n[LXS+19] Jaehoon Lee, Lechao Xiao, Samuel S. Schoenholz, Yasaman Bahri, Roman Novak, Jascha Sohl-\\nDickstein, and Jeffrey Pennington. Wide neural networks of any depth evolve as linear models\\nunder gradient descent, 2019, arXiv:1902.06720. 19\\n[MBB17] Siyuan Ma, Raef Bassily, and Mikhail Belkin. The power of interpolation: Understanding the\\neffectiveness of SGD in modern over-parametrized learning. CoRR, abs/1712.06559, 2017,\\n1712.06559. URLhttp://arxiv.org/abs/1712.06559 . 10\\n[MKAT18] Sam McCandlish, Jared Kaplan, Dario Amodei, and OpenAI Dota Team. An empirical model\\nof large-batch training, 2018, arXiv:1812.06162. 10\\n[RDG+20] Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu,\\nMyle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, and Jason Weston. Recipes for building\\nan open-domain chatbot, 2020, 2004.13637. 3, 19\\n36\\n[RFCS20] Jonathan S. Rosenfeld, Jonathan Frankle, Michael Carbin, and Nir Shavit. On the predictability\\nof pruning across scales, 2020, 2006.10621. 19\\n[RRBS19] Jonathan S. Rosenfeld, Amir Rosenfeld, Yonatan Belinkov, and Nir Shavit. A constructive\\nprediction of the generalization error across scales, 2019, 1909.12673. 3, 19\\n[SGHK19] David Saxton, Edward Grefenstette, Felix Hill, and Pushmeet Kohli. Analysing mathematical\\nreasoning abilities of neural models. CoRR, abs/1904.01557, 2019, 1904.01557. URL http:\\n//arxiv.org/abs/1904.01557 . 3, 8, 16, 20, 26, 27, 28, 29\\n[SK20] Utkarsh Sharma and Jared Kaplan. A neural scaling law from the dimension of the data mani-\\nfold, 2020, 2004.10802. 3, 19\\n[SSF+19] Imanol Schlag, Paul Smolensky, Roland Fernandez, Nebojsa Jojic, Jürgen Schmidhuber, and\\nJianfeng Gao. Enhancing the transformer with explicit relational encoding for math problem\\nsolving, 2019, 1910.06611. 20\\n[TBL+19] Yao-Hung Hubert Tsai, Shaojie Bai, Paul Pu Liang, J Zico Kolter, Louis-Philippe Morency, and\\nRuslan Salakhutdinov. Multimodal transformer for unaligned multimodal language sequences.\\nInProceedings of the conference. Association for Computational Linguistics. Meeting , volume\\n2019, page 6558. NIH Public Access, 2019. 3, 20\\n[TSF+15] Bart Thomee, David A. Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas\\nPoland, Damian Borth, and Li-Jia Li. The new data and new challenges in multimedia research.\\nCoRR, abs/1503.01817, 2015, 1503.01817. URL http://arxiv.org/abs/1503.01817 . 3,\\n4, 5, 7, 13, 34\\n[vdOKK16] Aäron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural net-\\nworks.CoRR, abs/1601.06759, 2016, 1601.06759. URL http://arxiv.org/abs/1601.\\n06759. 19\\n[vdOVK18] Aaron van den Oord, Oriol Vinyals, and Koray Kavukcuoglu. Neural discrete representation\\nlearning, 2018, 1711.00937. 6, 7, 8, 11\\n[VSP+17] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\\nŁ ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg,\\nS. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural\\nInformation Processing Systems 30 , pages 5998–6008. Curran Associates, Inc., 2017. URL\\nhttp://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf . 3\\n[WTU19] Dirk Weissenborn, Oscar Täckström, and Jakob Uszkoreit. Scaling autoregressive video models,\\n2019, 1906.02634. 3, 20\\n37\\n\\n\\n ********************References\\n[1] A. Brabazon, M. Kampouridis, M. O’Neill, Applications of genetic programming to ﬁnance and economics: past, present, future, Genetic\\nProgramming and Evolvable Machines. 21 (2020) 33–53.\\n[2] M. Kampouridis, E. Tsang, Investment opportunities forecasting: Extending the grammar of a gp-based tool, International Journal of Com-\\nputational Intelligence Systems 5 (3) (2012) 530–541.\\n[3] M. Kampouridis, A. Alsheddy, E. Tsang, On the investigation of hyper-heuristics on a ﬁnancial forecasting problem, Annals of Mathematics\\nand Artiﬁcial Intelligence 68 (2013) 225–246.\\n[4] M. Kampouridis, F. E. Otero, Heuristic procedures for improving the predictability of a genetic programming ﬁnancial forecasting algorithm,\\nSoft Computing (2015) 1–16.\\n[5] M. Kampouridis, S.-H. Chen, E. Tsang, Market fraction hypothesis: A proposed test, International Review of Financial Analysis 23 (2012)\\n41 – 54.\\n[6] M. Kampouridis, S.-H. Chen, E. Tsang, Microstructure dynamics and agent-based ﬁnancial markets: can dinosaurs return?, Advances in\\nComplex Systems 15 (supp02) (2012) 1250060.\\n[7] B. Mandelbrot, H. M. Taylor, On the distribution of stock price di \\x0berences, Operations research 15 (6) (1967) 1057–1062.\\n[8] R. C. Cavalcante, R. C. Brasileiro, V. L. Souza, J. P. Nobrega, A. L. Oliveira, Computational intelligence and ﬁnancial markets: A survey and\\nfuture directions, Expert Systems with Applications 55 (2016) 194–211.\\n[9] Y. Wan, X. Gong, Y.-W. Si, E\\x0bect of segmentation on ﬁnancial time series pattern matching, Applied Soft Computing 38 (2016) 346–359.\\n[10] T.-l. Chen, F.-y. Chen, An intelligent pattern recognition model for supporting investment decisions in stock market, Information Sciences\\n346 (2016) 261–274.\\n[11] F.-L. Chung, T. C. Fu, R. Luk, V. Ng, Flexible time series pattern matching based on perceptually important points, International Joint\\nConference on Artiﬁcial Intelligence Workshop on Learning from Temporal and Spatial Data (2001) 1–7.\\n[12] J. Yin, Y.-W. Si, Z. Gong, Financial time series segmentation based on turning points, in: Proceedings 2011 International Conference on\\nSystem Science and Engineering, IEEE, 2011, pp. 394–399.\\n[13] A. Azzini, C. da Costa Pereira, A. G. Tettamanzi, Modeling turning points in ﬁnancial markets with soft computing techniques, in: Natural\\nComputing in Computational Finance, Springer, 2010, pp. 147–167.\\n[14] M. O.¨Ozorhan,˙I. H. Toroslu, O. T. S¸ehito˘glu, Short-term trend prediction in ﬁnancial time series data, Knowledge and Information Systems\\n(2018) 1–33.\\n[15] J. Glattfelder, A. Dupuis, R. Olsen, Patterns in high-frequency FX data: discovery of 12 empirical scaling laws, Quantitative Finance 11 (4)\\n(2011) 599–614.\\n[16] E. Tsang, Directional changes, deﬁnitions, Working Paper WP050-10 Centre for Computational Finance and Economic Agents (CCFEA),\\nUniversity of Essex Revised 1, Tech. Rep.\\n[17] E. P. Tsang, R. Tao, A. Serguieva, S. Ma, Proﬁling high-frequency equity price movements in directional changes, Quantitative ﬁnance 17 (2)\\n(2017) 217–225.\\n[18] A. Adegboye, M. Kampouridis, C. G. Johnson, Regression genetic programming for estimating trend end in foreign exchange market, in:\\nComputational Intelligence (SSCI), 2017 IEEE Symposium Series on, IEEE, 2017, pp. 1–8.\\n[19] D. M. Guillaume, M. M. Dacorogna, R. R. Dav ´e, U. A. M¨uller, R. B. Olsen, O. V. Pictet, From the bird’s eye to the microscope: A survey of\\nnew stylized facts of the intra-daily foreign exchange markets, Finance and stochastics 1 (2) (1997) 95–129.\\n[20] M. Sewell, Characterization of ﬁnancial time series, Research Note, RN /11/01, UCL Department of Computer Science (2011).\\n[21] J. Glattfelder, A. Dupuis, R. Olsen, An extensive set of scaling laws and the FX coastline, Centre for Computational Finance and Economics\\nAgents, Working Paper Series WP025-08.\\n[22] M. Aloud, E. Tsang, R. B. Olsen, A. Dupuis, A directional-change events approach for studying ﬁnancial time series, Economics Discussion\\nPaper 2011-28.\\n33\\n[23] M. Aloud, M. Fasli, The impact of strategies on the stylized facts in the FX market, Technical Report, University of Essex, United Kingdom\\n(2013).\\n[24] M. E. Aloud, Time series analysis indicators under directional changes: The case of Saudi stock market, International Journal of Economics\\nand Financial Issues 6 (1).\\n[25] E. Tsang, J. Chen, Regime change detection using directional change indicators in the foreign exchange market to chart brexit, IEEE Trans-\\nactions on Emerging Topics in Computational Intelligence 2 (3) (2018) 185–193.\\n[26] J. Chen, E. Tsang, Classiﬁcation of normal and abnormal regimes in ﬁnancial markets, Algorithms 11 (12) (2018) 202.\\n[27] H. Ao, A directional changes based study on stock market, Ph.D. thesis, University of Essex (2018).\\n[28] T. Bisig, A. Dupuis, V. Impagliazzo, R. Olsen, The scale of market quakes, Quantitative Finance 12 (4) (2012) 501–508.\\n[29] V. Petrov, A. Golubb, Volatility seasonality of bitcoin prices.\\n[30] V. Petrov, A. Golub, R. Olsen, Instantaneous volatility seasonality of high-frequency markets in directional-change intrinsic time, Journal of\\nRisk and Financial Management 12 (2) (2019) 54.\\n[31] M. Aloud, E. Tsang, R. Olsen, Modeling the FX market traders behavior: An agent-based approach, Banking, Finance, and Accounting:\\nConcepts, Methodologies, Tools, and Applications (2014) 350.\\n[32] M. Aloud, Directional-change event trading strategy: Proﬁt-maximizing learning strategy, The Seventh International Conference on Advanced\\nCognitive Technology and Applications.\\n[33] M. E. Aloud, Proﬁtability of directional change based trading strategies: The case of Saudi stock market, International Journal of Economics\\nand Financial Issues 6 (1).\\n[34] A. Bakhach, E. Tsang, W. L. Ng, V. R. Chinthalapati, Backlash agent: A trading strategy based on directional change, in: 2016 IEEE\\nSymposium Series on Computational Intelligence (SSCI), IEEE, 2016, pp. 1–9.\\n[35] A. Bakhach, V. Chinthalapati, E. Tsang, A. El Sayed, Intelligent dynamic backlash agent: A trading strategy based on the directional change\\nframework, Algorithms 11 (11) (2018) 171.\\n[36] A. Kablan, W. L. Ng, Intraday high-frequency FX trading with adaptive neuro-fuzzy inference systems, International Journal of Financial\\nMarkets and Derivatives 2 (1-2) (2011) 68–87.\\n[37] A. Bakhach, E. Tsang, W. L. Ng, Forecasting directional changes in ﬁnancial markets, Working Paper WP075-15 Centre for Computational\\nFinance and Economic Agents (CCFEA), University of Essex, Tech. Rep.\\n[38] A. Bakhach, E. P. K. Tsang, H. Jalalian, Forecasting directional changes in FX markets, in: IEEE Symposium on Computational Intelligence\\nfor Financial Engineering & Economics (IEEE CIFEr’16), IEEE, Athens Greece, 2016, pp. 6–9.\\n[39] J. Gypteau, F. E. Otero, M. Kampouridis, Generating directional change based trading strategies with genetic programming, in: European\\nConference on the Applications of Evolutionary Computation, Springer, 2015, pp. 267–278.\\n[40] N. Alkhamees, M. Fasli, A directional change based trading strategy with dynamic thresholds, in: 2017 IEEE International Conference on\\nData Science and Advanced Analytics (DSAA), IEEE, 2017, pp. 283–292.\\n[41] N. Alkhamees, M. Fasli, Event detection from time-series streams using directional change and dynamic thresholds, in: 2017 IEEE Interna-\\ntional Conference on Big Data (Big Data), IEEE, 2017, pp. 1882–1891.\\n[42] A. Ye, V. R. Chinthalapati, A. Serguieva, E. Tsang, Developing sustainable trading strategies using directional changes with high frequency\\ndata, in: 2017 IEEE International Conference on Big Data (Big Data), IEEE, 2017, pp. 4265–4271.\\n[43] R. J. Almeida, N. Bas¸t¨urk, R. Golan, Intraday value-at-risk estimation for directional change events and investment strategies, in: 2017 IEEE\\nSymposium Series on Computational Intelligence (SSCI), IEEE, 2017, pp. 1–8.\\n[44] M. Kampouridis, F. E. Otero, Evolving trading strategies using directional changes, Expert Systems with Applications 73 (2017) 145–160.\\n[45] M. Kampouridis, A. Adegboye, C. Johnson, Evolving directional changes trading strategies with a new event-based indicator, in: Asia-Paciﬁc\\nConference on Simulated Evolution and Learning, Springer, 2017, pp. 727–738.\\n[46] C. Thornton, F. Hutter, H. H. Hoos, K. Leyton-Brown, Auto-weka: Combined selection and hyperparameter optimization of classiﬁcation\\nalgorithms, in: Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, 2013, pp.\\n34\\n847–855.\\n[47] M. L´opez-Ib´anez, J. Dubois-Lacoste, T. St¨utzle, M. Birattari, The irace package, iterated race for automatic algorithm conﬁguration, Tech.\\nrep., Citeseer (2011).\\n[48] M. Birattari, Z. Yuan, P. Balaprakash, T. St ¨utzle, F-race and iterated f-race: An overview, in: Experimental methods for the analysis of\\noptimization algorithms, Springer, 2010, pp. 311–336.\\n[49] J. Brookhouse, F. E. Otero, M. Kampouridis, Working with opencl to speed up a genetic programming ﬁnancial forecasting algorithm: initial\\nresults, in: Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation, 2014, pp.\\n1117–1124.\\n35\\n\\n\\n ********************References\\n1. H. Aktas and N. Cagman,Soft sets and soft groups, Inform. Sci.177(2007), 2726-2735.\\n2. K. Atanassov,Intuitionistic fuzzy sets, Fuzzy Sets and Systems20(1986), 87-96.\\n3. K. Atanassov,Operators over interval valued intuitionistic fuzzy sets , Fuzzy Sets and Sys-\\ntems64(1994), 159-174.\\n4. V. Cetkin, A. Aygunoglu and H. Aygun, A new approach in handling soft decision making\\nproblems, J. Nonlinear Sci. Appl.9(2016), 231-239.\\n5. F. Feng, C. Li, B. Davvaz and M.I. Ali, Soft sets combined with fuzzy sets and rough sets:\\na tentative approach, Soft Computing14(2016), 899-911.\\n6. F. Feng,Soft rough sets applied to multicriteria group decision making , Annals of Fuzzy\\nMathematics and Informatics2(2011), 69-80.\\n7. F. Feng, X. Liu, F.L. Violeta and J.B. Young, Soft sets and soft rough sets, Inform. Sci.\\n181(2011), 1125-1137.\\n8. G. Liu and W. Zhu,The algebraic structures of generalized rough set theory , Inform. Sci.\\n178(2008), 4105-4113.\\n9. G. Liu and Y. Sai,A comparison of two types of rough sets induced by coverings , Int. J.\\nApprox. Reason.50(2009), 521-528.\\n10. P.K. Maji, R. Biswas and A.R. Roy, Soft set theory, Comput. Math. Appl.45(2003),\\n555-562.\\n11. D. Molodtsov,Soft set theory \\x0crst results, Comput. Math. Appl.37(1999), 19-31.\\n12. Z. Pawlak and A. Skowron,Rudiments of rough sets, Inform. Sci.177(2007), 3-27.\\n13. Z. Pawlak,Rough sets, International Journal of Computer and Information Sciences 11\\n(1982), 341-356.\\n14. L.A. Zadeh,Fuzzy sets, Inform. Control.8(1965), 338-353.\\n15. W. Zhu and F. Wang,On three types of covering-based rough sets , IEEE Transactions on\\nKnowledge and Data Engineering19(2007), 1131-1143.\\n16. W. Zhu,Topological approaches to covering rough sets , Information Sciences177(2007),\\n1499-1508.\\nNaime Demirtasreceived M.Sc from Selcuk University and Ph.D. from Nigde Omer Hal-\\nisdemir University. She worked as a research assistant at Nigde Omer Halisdemir University\\nfrom 2011 to 2018 and since 2018 she has been at Mersin University. Her research interests\\nare topology, fuzzy set theory, rough set theory, soft set theory and their applications.\\nDepartment of Mathematics, Mersin University, Mersin 33110, Turkey.\\ne-mail: naimedemirtas@mersin.edu.tr\\nApproaches of Inverse Soft Rough Sets with Applications in Decision Making Problem 349\\nSabir Hussainis working as Full Professor in Department of Mathematics, College of Sci-\\nence, Qassim University Saudi Arabia. He published several research papers in leading and\\nwell reputed international journals. His research interests include General and Generalized\\nTopology especially operations on Topological Spaces, Structures in Soft Topological spaces\\nand Binary Soft Topological spaces, Fuzzy Topological space, Fuzzy Soft Topological spaces,\\nWeak and Strong Strucures in Topological spaces, Rough set Theory with applications and\\nMathematical Inequalities.\\nDepartment of Mathematics, College of Science, Qassim University, P. O. Box 6644, Bu-\\nraydah 51482, Saudi Arabia.\\ne-mail: sabiriub@yahoo.com; sh.hussain@qu.edu.sa\\nOrhan Dalkilicreceived M.Sc. from Mersin University. His research interests are topology,\\nfuzzy sets, rough sets, soft sets, decision making and their applications.\\nDepartment of Mathematics, Mersin University, Mersin 33110, Turkey.\\ne-mail: orhandlk952495@hotmail.com\\n\\n\\n ********************References\\n1. Amis, G.P., Carpenter, G.A.: Self-supervised artmap. Neural Networks 23(2),\\n265–282 (2010)\\n2. Ant´on-Rodr´ıguez, M., Pernas, F.J.D., Higuera, J.F.D., Mart´ınez-Zarzuela, M.,\\nOrtega, D.G., Boto-Giralda, D.: Recognition of coloured and textured images\\nthrough a multi-scale neural architecture with orientational ﬁltering and chromatic\\ndiﬀusion. Neurocomputing 72(16-18), 3713–3725 (2009)\\n3. Bernhard, F., Keriven, R.: Spiking neurons on gPUs. In: Alexandrov, V.N.,\\nvan Albada, G.D., Sloot, P.M.A., Dongarra, J. (eds.) ICCS 2006. LNCS, vol. 3994,\\npp. 236–243. Springer, Heidelberg (2006)\\n4. Campbell, A., Berglund, E., Streit, A.: Graphics hardware implementation of the\\nparameter-less self-organising map. In: Gallagher, M., Hogan, J.P., Maire, F. (eds.)\\nIDEAL 2005. LNCS, vol. 3578, pp. 343–350. Springer, Heidelberg (2005)\\n5. Carpenter, G.A., Grossberg, S., Markuzon, N., Reynolds, J.H., Rosen, D.B.: Fuzzy\\nARTMAP: A neural network architecture for incremental supervised learning of\\nanalog multidimensional maps. IEEE Trans. Neural Networks 3(5), 698–712 (1992)\\n6. Carpenter, G.A., Grossberg, S., Rosen, D.B.: Fuzzy ART: Fast stable learning\\nand categorization of analog patterns by an adaptive resonance system. Neural\\nNetworks 4(6), 759–771 (1991)\\n7. Greenspan, H.: Non-parametric texture learning (1996)\\n8. Grossberg, S., Williamson, J.: A self-organizing neural system for leaning to rec-\\nognize textured scenes. Vision Research (39), 1385–1406 (1999)\\n9. Harris, M.: Parallel preﬁx sum (scan) with cuda. In: Nguyen, H. (ed.) GPU Gems\\n3, ch. 39, pp. 851–876. Addison Wesley Professional, Reading (2007)\\n352 M. Mart´ınez-Zarzuela et al.\\n10. Ho, T.Y., Park, A., Jung, K.: Parallelization of cellular neural networks on gpu.\\nPattern Recogn. 41(8), 2684–2692 (2008)\\n11. Jang, H., Park, A., Jung, K.: Neural network implementation using cuda and\\nopenmp. In: DICTA 2008: Proceedings of the 2008 Digital Image Computing: Tech-\\nniques and Applications, pp. 155–161. IEEE Computer Society, Washington, DC,\\nUSA (2008)\\n12. Luo, Z., Liu, H., Wu, X.: Artiﬁcial neural network computation on graphic process\\nunit. In: IJCNN 2005: Proceedings of the 2005 IEEE International Joint Conference\\non Neural Networks, Montreal, Canada, pp. 622–626 (August 2005)\\n13. Mart´ınez-Zarzuela, M., D´ıaz Pernas, F.J., D´ıez Higuera, J.F., Rodr´ıguez, M.A.:\\nFuzzy ART neural network parallel computing on the GPU. In: Sandoval, F.,\\nPrieto, A.G., Cabestany, J., Gra˜na, M. (eds.) IWANN 2007. LNCS, vol. 4507,\\npp. 463–470. Springer, Heidelberg (2007)\\n14. Mart´ınez-Zarzuela, M., Pernas, F.J.D., de Pablos, A.T., Rodr´ıguez, M.A.,\\nHiguera, J.F.D., Giralda, D.B., Ortega, D.G.: Adaptative resonance theory fuzzy\\nnetworks parallel computation using CUDA. In: Cabestany, J., Sandoval, F.,\\nPrieto, A., Corchado, J.M. (eds.) IWANN 2009. LNCS, vol. 5517, pp. 149–156.\\nSpringer, Heidelberg (2009)\\n15. Oh, K., Jung, K.: Gpu implementation of neural networks. Pattern Recogni-\\ntion 37(6), 1311–1314 (2004)\\n16. VisTex: Vision texture database massachusetts institute of technology (1995),\\nhttp://vismod.media.mit.edu/vismod/imagery/VisionTexture/vistex.html\\n(last visit June 2010)\\n\\n\\n ********************REFERENCES\\n\\n\\nBrock, W., Lakonishok, J., LeBaron, B. (1992), Simple technical trading \\n\\n\\nrules and the stochastic properties of stock returns. Journal of \\n\\n\\nFinance, 47, 1731-1764.\\n\\nCaginalp, G., Laurent, H. (1998), The predictive power of price patterns. \\n\\nApplied Mathematical Finance, 5, 181-205.\\n\\n\\nDormeier, B.P. (2011), Investing with Volume Analysis: Identify, Follow, \\n\\n\\nand Profit from Trends. Unites States of America: FT Press.\\n\\n\\nFama, E. (1970), Efficient capital markets: A review of theory and \\n\\n\\nempirical work. Journal of Finance, 25, 383-417.\\n\\nHorton, M.J. (2009), Stars, crows, and doji: The use of candlesticks in \\n\\nstock selection. The Quarterly Review of Economics and Finance, \\n\\n49, 283-294.\\n\\n\\nLo, A.W., Mamaysky, H., Wang, J. (2000), Foundations of technical \\n\\n\\nanalysis: Computational algorithms, statistical inference, and \\n\\n\\nempirical implementation. Journal of Finance, 55, 1705-1765.\\n\\n\\nLu, T. (2014), The profitability of candlestick charting in the Taiwan stock \\n\\n\\nmarket. Pacific-Basin Finance Journal, 26, 65-78.\\n\\nLu, T., Chen, J. (2013), Candlestick charting in European stock markets. \\n\\nThe Finsia Journal of Applied Finance, 2, 20-25.\\n Lu, T., Huang, Y., Hsu, C. (2014), Can price anomalies been obtained \\n\\nby using candlestick patterns? Paper Presented at the 2014 Meeting \\n\\nof World Finance Conference, Venice, Italy. Available from: http://\\n\\nwww.mx.nthu.edu.tw/~ylihuang/pdf/Candle.pdf.\\n\\n\\nLu, T., Shiu, Y. (2012), Tests for two-day candlestick patterns in the \\n\\n\\nemerging equity market of Taiwan. Emerging Markets Finance and \\n\\nTrade, 48, 41-57.\\n\\nLu, T., Shiu, Y., Liu, T. (2012), Profitable candlestick trading strategies: \\n\\n\\nThe evidence from a new perspective. Review of Financial \\n\\n\\nEconomics, 21(2), 63-68.\\n\\n\\nMarshall, B.R., Young, M.R., Cahan, R. (2008), Are candlestick technical \\n\\n\\ntrading strategies profitable in the Japanese equity market? Review \\n\\nof Quantitative Finance and Accounting, 31, 191-207.\\n\\nMarshall, B.R., Young, M.R., Rose, L.C. (2006), Candlestick technical \\n\\ntrading strategies: Can they create value for investors? Journal of \\n\\nBanking and Finance, 30, 2303-2323.\\n\\n\\nMorris, G. (2006), Candlestick Charting Explained: Timeless Techniques \\n\\n\\nfor Trading and Futures. 3\\n rd\\n\\n ed. New York: McGraw-Hill.\\n\\n\\nMurphy, J.J. (1999), Technical Analysis of the Financial Markets: \\n\\n\\nA Comprehensive Guide to Trading Methods and Applications. \\n\\n\\nNew York: Penguin Putnam Inc.\\n\\nNeely, C.J., Rapach, D.E., Tu, J., Zhou, G. (2011), Forecasting the equity \\n\\npremium: The role of technical analysis. Journal of Management \\n\\nScience, 60(7), 1772-1791.\\n\\nNison, S. (1991), Japanese Candlestick Charting Techniques. New York: \\n\\nNew York Institute of Finance.\\n\\n\\nPrado, H.A., Ferneda, E., Morais, L.C.R., Luiz, A.J.B., Matsura, E. (2013), \\n\\n\\nOn the effectiveness of candlestick chart analysis for the Brazilian \\n\\nstock market. Procedia Computer Science, 22, 1136-1145.\\n\\n\\nShen, P. (2003), Market timing strategies that worked. Journal of Portfolio \\n\\n\\nManagement, 29, 57-68.\\n\\n\\nShiu, Y., Lu, T. (2011). Pinpoint and synergistic trading strategies of \\n\\n\\ncandlesticks. International Journal of Economics and Finance, 3(1), \\n\\n234-244.\\n\\n\\nTam, F.K.H. (2001), Investing in KLSE Stocks and Futures with Japanese \\n\\n\\nCandlestick Charting Techniques. Selangor Darul Ehsan, Malaysia: \\n\\nPelanduk Publications.\\n\\nZhu, M., Atri, S., Yegen, E. (2016), Are candlestick trading strategies \\n\\n\\neffective in certain stocks with distinct features? Pacific-Basin \\n\\n\\nFinance Journal, 37, 116-127.\\n\\nView publication stats\\nView publication stats\\n\\n\\n ********************References\\nAchiam, J., Edwards, H., Amodei, D., & Abbeel, P. (2018). Variational Option Discovery\\nAlgorithms.arXiv preprint arXiv:1807.10299 .\\nAhn, M., Zhu, H., Hartikainen, K., Ponte, H., Gupta, A., Levine, S., & Kumar, V. (2019).\\nROBEL: RObotics BEnchmarks for Learning with Low-Cost Robots. In Conference\\non Robot Learning.\\nAndrychowicz, M., Wolski, F., Ray, A., Schneider, J., Fong, R., Welinder, P., McGrew, B.,\\nTobin, J., Pieter Abbeel, O., & Zaremba, W. (2017). Hindsight Experience Replay.\\nAdvances in Neural Information Processing Systems ,30, 5048{5058.\\nArulkumaran, K., Deisenroth, M. P., Brundage, M., & Bharath, A. A. (2017). Deep Rein-\\nforcement Learning: A Brief Survey. IEEE Signal Processing Magazine ,34(6), 26{38.\\nBacon, P.-L., Harb, J., & Precup, D. (2017). The Option-Critic Architecture. In AAAI\\nConference on Arti\\x0ccial Intelligence .\\nBarth-Maron, G., Ho\\x0bman, M. W., Budden, D., Dabney, W., Horgan, D., Dhruva, T.,\\nMuldal, A., Heess, N., & Lillicrap, T. (2018). Distributed Distributional Deterministic\\nPolicy Gradients. InInternational Conference on Learning Representations .\\nBBC News (2019). Go Master Quits Because AI \\'Cannot Be Defeated\\'. https://www.bbc.\\ncom/news/technology-50573071/ .\\nBehzadan, V., & Munir, A. (2017). Vulnerability of Deep Reinforcement Learning to Pol-\\nicy Induction Attacks. In International Conference on Machine Learning and Data\\nMining in Pattern Recognition , pp. 262{275.\\nBellemare, M. G., Dabney, W., & Munos, R. (2017). A Distributional Perspective on\\nReinforcement Learning. In International Conference on Machine Learning , pp. 449{\\n458.\\nBellemare, M. G., Naddaf, Y., Veness, J., & Bowling, M. (2013). The Arcade Learning\\nEnvironment: An Evaluation Platform for General Agents. Journal of Arti\\x0ccial In-\\ntelligence Research,47, 253{279.\\nBellemare, M. G., Srinivasan, S., Ostrovski, G., Schaul, T., Saxton, D., & Munos, R. (2016).\\nUnifying Count-Based Exploration and Intrinsic Motivation. In Advances in Neural\\nInformation Processing Systems .\\nBellemare, M. G., Veness, J., & Talvitie, E. (2014). Skip Context Tree Switching. In\\nInternational Conference on Machine Learning , pp. 1458{1466.\\nBengio, S., Vinyals, O., Jaitly, N., & Shazeer, N. (2015). Scheduled Sampling for Sequence\\nPrediction with Recurrent Neural Networks. In Advances in Neural Information Pro-\\ncessing Systems, pp. 1171{1179.\\nBhatnagar, S., Precup, D., Silver, D., Sutton, R. S., Maei, H. R., & Szepesv\\x13ari, C. (2009a).\\nConvergent Temporal-Di\\x0berence Learning with Arbitrary Smooth Function Approxi-\\nmation. InAdvances in Neural Information Processing Systems , pp. 1204{1212.\\nBhatnagar, S., Sutton, R. S., Ghavamzadeh, M., & Lee, M. (2009b). Natural Actor-Critic\\nAlgorithms.Automatica,45(11), 2471{2482.\\n1458\\nDeep Reinforcement Learning: A State-of-the-Art Walkthrough\\nBloom, B. H. (1970). Space/Time Trade-O\\x0bs in Hash Coding with Allowable Errors. Com-\\nmunications of the ACM,13(7), 422{426.\\nBlundell, C., Cornebise, J., Kavukcuoglu, K., & Wierstra, D. (2015). Weight Uncertainty in\\nNeural Networks. InInternational Conference on Machine Learning , pp. 1613{1622.\\nBuckman, J., Hafner, D., Tucker, G., Brevdo, E., & Lee, H. (2018). Sample-E\\x0ecient Re-\\ninforcement Learning with Stochastic Ensemble Value Expansion. In Advances in\\nNeural Information Processing Systems , pp. 8224{8234.\\nBurda, Y., Edwards, H., Storkey, A., & Klimov, O. (2019). Exploration by Random Network\\nDistillation. InInternational Conference on Learning Representations .\\nCabi, S., Colmenarejo, S. G., Ho\\x0bman, M. W., Denil, M., Wang, Z., & Freitas, N. (2017).\\nThe Intentional Unintentional Agent: Learning to Solve Many Continuous Control\\nTasks Simultaneously. InConference on Robot Learning , pp. 207{216.\\nChalapathy, R., & Chawla, S. (2019). Deep Learning for Anomaly Detection: A Survey.\\narXiv preprint arXiv:1901.03407 .\\nCharikar, M. S. (2002). Similarity Estimation Techniques from Rounding Algorithms. In\\nACM symposium on Theory of computing , pp. 380{388.\\nChen, M., Beutel, A., Covington, P., Jain, S., Belletti, F., & Chi, E. H. (2019). Top-K O\\x0b-\\nPolicy Correction for a REINFORCE Recommender System. In ACM International\\nConference on Web Search and Data Mining , pp. 456{464.\\nChiappa, S., Racaniere, S., Wierstra, D., & Mohamed, S. (2017). Recurrent Environment\\nSimulators. InInternational Conference on Learning Representations .\\nChua, K., Calandra, R., McAllister, R., & Levine, S. (2018). Deep Reinforcement Learning\\nin a Handful of Trials Using Probabilistic Dynamics Models. In Advances in Neural\\nInformation Processing Systems , pp. 4754{4765.\\nClavera, I., Rothfuss, J., Schulman, J., Fujita, Y., Asfour, T., & Abbeel, P. (2018). Model-\\nBased Reinforcement Learning via Meta-Policy Optimization. In Conference on Robot\\nLearning, pp. 617{629.\\nCover, T. M. (1999).Elements of Information Theory . John Wiley & Sons.\\nDa Silva, F. L., & Costa, A. H. R. (2019). A Survey on Transfer Learning for Multiagent\\nReinforcement Learning Systems. Journal of Arti\\x0ccial Intelligence Research ,64, 645{\\n703.\\nDargan, S., Kumar, M., Ayyagari, M. R., & Kumar, G. (2019). A Survey of Deep Learning\\nand Its Applications: A New Paradigm to Machine Learning. Archives of Computa-\\ntional Methods in Engineering , 1{22.\\nDayan, P., & Hinton, G. E. (1992). Feudal Reinforcement Learning. In Neural Information\\nProcessing Systems, pp. 271{278.\\nDean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Mao, M., Ranzato, M., Senior,\\nA., Tucker, P., Yang, K., et al. (2012). Large Scale Distributed Deep Networks. In\\nAdvances in Neural Information Processing Systems , pp. 1223{1231.\\n1459\\n Lazaridis, Fachantidis, & Vlahavas\\nDeisenroth, M. P., Neumann, G., & Peters, J. (2013). A Survey on Policy Search for\\nRobotics.Foundations and Trends in Robotics ,2(1{2), 1{142.\\nDeisenroth, M. P., & Rasmussen, C. E. (2011). PILCO: A Model-Based and Data-E\\x0ecient\\nApproach to Policy Search. In International Conference on Machine Learning , pp.\\n465{472.\\nDuan, Y., Chen, X., Houthooft, R., Schulman, J., & Abbeel, P. (2016). Benchmarking\\nDeep Reinforcement Learning for Continuous Control. In International Conference\\non Machine Learning, pp. 1329{1338.\\nEspeholt, L., Soyer, H., Munos, R., Simonyan, K., Mnih, V., Ward, T., Doron, Y., Firoiu,\\nV., Harley, T., Dunning, I., et al. (2018). IMPALA: Scalable Distributed Deep-RL\\nwith Importance Weighted Actor-Learner Architectures. In International Conference\\non Machine Learning, pp. 1407{1416.\\nEysenbach, B., Gupta, A., Ibarz, J., & Levine, S. (2019). Diversity is All You Need: Learning\\nSkills without a Reward Function. In International Conference on Learning Repre-\\nsentations.\\nFeinberg, V., Wan, A., Stoica, I., Jordan, M. I., Gonzalez, J. E., & Levine, S. (2018). Model-\\nBased Value Estimation for E\\x0ecient Model-Free Reinforcement Learning. arXiv\\npreprint arXiv:1803.00101.\\nFernando, C., Banarse, D., Blundell, C., Zwols, Y., Ha, D., Rusu, A. A., Pritzel, A., &\\nWierstra, D. (2017). Pathnet: Evolution Channels Gradient Descent in Super Neural\\nNetworks.arXiv preprint arXiv:1701.08734 .\\nFernando, C., Vasas, V., Szathm\\x13ary, E., & Husbands, P. (2011). Evolvable Neuronal Paths:\\nA Novel Basis for Information and Search in the Brain. PloS one,6(8), e23534.\\nFinn, C., Abbeel, P., & Levine, S. (2017). Model-Agnostic Meta-Learning for Fast Adap-\\ntation of Deep Networks. In International Conference on Machine Learning , pp.\\n1126{1135.\\nFoerster, J., Assael, I. A., De Freitas, N., & Whiteson, S. (2016). Learning to Communicate\\nwith Deep Multi-Agent Reinforcement Learning. In Advances in Neural Information\\nProcessing Systems, pp. 2137{2145.\\nFoerster, J., Nardelli, N., Farquhar, G., Afouras, T., Torr, P. H., Kohli, P., & Whiteson, S.\\n(2017). Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning.\\nInInternational Conference on Machine Learning , pp. 1146{1155.\\nFortunato, M., Azar, M. G., Piot, B., Menick, J., Hessel, M., Osband, I., Graves, A., Mnih,\\nV., Munos, R., Hassabis, D., et al. (2018). Noisy Networks For Exploration. In\\nInternational Conference on Learning Representations .\\nFrancois-Lavet, V., Henderson, P., Islam, R., Bellemare, M. G., Pineau, J., et al. (2018). An\\nIntroduction to Deep Reinforcement Learning. Foundations and Trends®in Machine\\nLearning,11(3-4), 219{354.\\nFrans, K., Ho, J., Chen, X., Abbeel, P., & Schulman, J. (2018). Meta Learning Shared\\nHierarchies. InInternational Conference on Learning Representations .\\n1460\\nDeep Reinforcement Learning: A State-of-the-Art Walkthrough\\nFrench, R. M. (1994). Catastrophic Interference in Connectionist Networks: Can It Be\\nPredicted, Can It Be Prevented?. In Advances in Neural Information Processing\\nSystems, pp. 1176{1177.\\nFu, J., Co-Reyes, J., & Levine, S. (2017). EX2: Exploration with Exemplar Models for Deep\\nReinforcement Learning. In Advances in Neural Information Processing Systems , pp.\\n2577{2587.\\nFujimoto, S., Hoof, H., & Meger, D. (2018). Addressing Function Approximation Error in\\nActor-Critic Methods. InInternational Conference on Machine Learning , pp. 1587{\\n1596.\\nGaina, R. D., Lucas, S. M., & Perez-Liebana, D. (2019). Project Thyia: A Forever Game-\\nplayer. In2019 IEEE Conference on Games (CoG) , pp. 1{8.\\nGe\\x0bner, H. (2018). Model-Free, Model-Based, and General Intelligence. In International\\nJoint Conference on Arti\\x0ccial Intelligence , pp. 10{17.\\nGleave, A., Dennis, M., Wild, C., Kant, N., Levine, S., & Russell, S. (2020). Adversarial\\nPolicies: Attacking Deep Reinforcement Learning. In International Conference on\\nLearning Representations.\\nGoodfellow, I., Papernot, N., Huang, S., Duan, R., Abbeel, P., & Clark, J. (2017). At-\\ntacking Machine Learning with Adversarial Examples. https://openai.com/blog/\\nadversarial-example-research/ .\\nGraves, A. (2011). Practical Variational Inference for Neural Networks. In Advances in\\nNeural Information Processing Systems , pp. 2348{2356.\\nGraves, A. (2013). Generating Sequences with Recurrent Neural Networks. arXiv preprint\\narXiv:1308.0850.\\nGreensmith, E., Bartlett, P. L., & Baxter, J. (2004). Variance Reduction Techniques for Gra-\\ndient Estimates in Reinforcement Learning. Journal of Machine Learning Research ,\\n5, 1471{1530.\\nGregor, K., Danihelka, I., Graves, A., Rezende, D., & Wierstra, D. (2015). DRAW: A\\nRecurrent Neural Network For Image Generation. In International Conference on\\nMachine Learning, pp. 1462{1471.\\nGregor, K., Rezende, D. J., & Wierstra, D. (2017). Variational Intrinsic Control. In Inter-\\nnational Conference on Learning Representations .\\nGrondman, I., Busoniu, L., Lopes, G. A., & Babuska, R. (2012). A Survey of Actor-Critic\\nReinforcement Learning: Standard and Natural Policy Gradients. IEEE Transactions\\non Systems, Man, and Cybernetics ,42(6), 1291{1307.\\nGupta, J. K., Egorov, M., & Kochenderfer, M. (2017). Cooperative Multi-Agent Control\\nUsing Deep Reinforcement Learning. In International Conference on Autonomous\\nAgents and Multiagent Systems , pp. 66{83.\\nHa, D., & Eck, D. (2018). A Neural Representation of Sketch Drawings. In International\\nConference on Learning Representations .\\nHa, D., & Schmidhuber, J. (2018). Recurrent World Models Facilitate Policy Evolution. In\\nAdvances in Neural Information Processing Systems , pp. 2450{2462.\\n1461\\n Lazaridis, Fachantidis, & Vlahavas\\nHaarnoja, T., Tang, H., Abbeel, P., & Levine, S. (2017). Reinforcement Learning with\\nDeep Energy-Based Policies. In International Conference on Machine Learning , pp.\\n1352{1361.\\nHaarnoja, T., Zhou, A., Abbeel, P., & Levine, S. (2018a). Soft Actor-Critic: O\\x0b-Policy\\nMaximum Entropy Deep Reinforcement Learning with a Stochastic Actor. In Inter-\\nnational Conference on Machine Learning , pp. 1861{1870.\\nHaarnoja, T., Zhou, A., Hartikainen, K., Tucker, G., Ha, S., Tan, J., Kumar, V., Zhu, H.,\\nGupta, A., Abbeel, P., & Others (2018b). Soft Actor-Critic Algorithms and Applica-\\ntions.arXiv preprint arXiv:1812.05905 .\\nHafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D., Lee, H., & Davidson, J. (2019).\\nLearning Latent Dynamics for Planning from Pixels. In International Conference on\\nMachine Learning, pp. 2555{2565.\\nHansen, N. (2016). The CMA Evolution Strategy: A Tutorial. arXiv preprint\\narXiv:1604.00772.\\nHansen, N., & Ostermeier, A. (2001). Completely Derandomized Self-Adaptation in Evo-\\nlution Strategies.Evolutionary computation,9(2), 159{195.\\nHasselt, H. V. (2010). Double Q-Learning. In Advances in Neural Information Processing\\nSystems, pp. 2613{2621.\\nHausman, K., Springenberg, J. T., Wang, Z., Heess, N., & Riedmiller, M. (2018). Learning\\nan Embedding Space for Transferable Robot Skills. In International Conference on\\nLearning Representations.\\nHenderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D., & Meger, D. (2018). Deep\\nReinforcement Learning that Matters. In AAAI Conference on Arti\\x0ccial Intelligence .\\nHernandez-Garcia, J. F., & Sutton, R. S. (2019). Understanding Multi-Step Deep Re-\\ninforcement Learning: A Systematic Study of the DQN Target. arXiv preprint\\narXiv:1901.07510.\\nHessel, M., Modayil, J., Van Hasselt, H., Schaul, T., Ostrovski, G., Dabney, W., Horgan,\\nD., Piot, B., Azar, M., & Silver, D. (2018). Rainbow: Combining improvements in\\ndeep reinforcement learning. In AAAI Conference on Arti\\x0ccial Intelligence .\\nHessel, M., Soyer, H., Espeholt, L., Czarnecki, W., Schmitt, S., & van Hasselt, H. (2019a).\\nMulti-Task Deep Reinforcement Learning with PopArt. In AAAI Conference on Ar-\\nti\\x0ccial Intelligence, Vol. 33, pp. 3796{3803.\\nHessel, M., van Hasselt, H., Modayil, J., & Silver, D. (2019b). On Inductive Biases in Deep\\nReinforcement Learning.arXiv preprint arXiv:1907.02908 .\\nHiggins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M., Mohamed, S., &\\nLerchner, A. (2017). beta-VAE: Learning Basic Visual Concepts with a Constrained\\nVariational Framework. In International Conference on Learning Representations .\\nHinton, G. E. (2007). To Recognize Shapes, First Learn to Generate Images. Progress in\\nBrain Research,165, 535{547.\\nHochreiter, S. (2001). Gradient Flow in Recurrent Nets: the Di\\x0eculty of Learning Long-term\\nDependencies.A Field Guide to Dynamical Recurrent Neural Networks , 237{244.\\n1462\\nDeep Reinforcement Learning: A State-of-the-Art Walkthrough\\nHochreiter, S., & Schmidhuber, J. (1997). Long Short-Term Memory. Neural Computation,\\n9(8), 1735{1780.\\nHorgan, D., Quan, J., Budden, D., Barth-Maron, G., Hessel, M., van Hasselt, H., & Silver,\\nD. (2018). Distributed Prioritized Experience Replay. In International Conference on\\nLearning Representations.\\nHouthooft, R., Chen, X., Duan, Y., Schulman, J., De Turck, F., & Abbeel, P. (2016). VIME:\\nVariational Information Maximizing Exploration. In Advances in Neural Information\\nProcessing Systems, pp. 1109{1117.\\nHu, J., & Wellman, M. P. (2003). Nash Q-Learning for General-Sum Stochastic Games.\\nJournal of Machine Learning Research ,4, 1039{1069.\\nHuang, S., Papernot, N., Goodfellow, I., Duan, Y., & Abbeel, P. (2017). Adversarial Attacks\\non Neural Network Policies. In International Conference on Learning Representations .\\nIo\\x0be, S., & Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by\\nReducing Internal Covariate Shift. In International Conference on Machine Learning ,\\npp. 448{456.\\nJaakkola, T., Jordan, M. I., & Singh, S. P. (1994). Convergence of Stochastic Iterative\\nDynamic Programming Algorithms. In Advances in Neural Information Processing\\nSystems, pp. 703{710.\\nJaderberg, M., Czarnecki, W. M., Dunning, I., Marris, L., Lever, G., Castaneda, A. G.,\\nBeattie, C., Rabinowitz, N. C., Morcos, A. S., Ruderman, A., et al. (2019). Human-\\nLevel Performance in 3D Multiplayer Games with Population-Based Reinforcement\\nLearning.Science,364(6443), 859{865.\\nJaques, N., Lazaridou, A., Hughes, E., Gulcehre, C., Ortega, P., Strouse, D., Leibo, J. Z.,\\n& De Freitas, N. (2019). Social In\\ruence as Intrinsic Motivation for Multi-Agent\\nDeep Reinforcement Learning. In International Conference on Machine Learning , pp.\\n3040{3049.\\nJaynes, E. T. (2003).Probability Theory: The Logic of Science . Cambridge university press.\\nJordan, M. I., Ghahramani, Z., Jaakkola, T. S., & Saul, L. K. (1999). An Introduction to\\nVariational Methods for Graphical Models. Machine learning,37(2), 183{233.\\nJustesen, N., Bontrager, P., Togelius, J., & Risi, S. (2019). Deep Learning for Video Game\\nPlaying.IEEE Transactions on Games ,12(1), 1{20.\\nKaiser,  L., Babaeizadeh, M., Mi los, P., Osi\\x13nski, B., Campbell, R. H., Czechowski, K., Erhan,\\nD., Finn, C., Kozakowski, P., Levine, S., et al. (2019). Model-Based Reinforcement\\nLearning for Atari. InInternational Conference on Learning Representations .\\nKaiser,  L., & Bengio, S. (2018). Discrete Autoencoders for Sequence Models. arXiv preprint\\narXiv:1801.09797.\\nKempka, M., Wydmuch, M., Runc, G., Toczek, J., & Ja\\x13skowski, W. (2016). Vizdoom:\\nA Doom-Based AI Research Platform for Visual Reinforcement Learning. In IEEE\\nConference on Computational Intelligence and Games , pp. 1{8.\\nKingma, D. P., & Welling, M. (2013). Auto-Encoding Variational Bayes. arXiv preprint\\narXiv:1312.6114.\\n1463\\n Lazaridis, Fachantidis, & Vlahavas\\nKirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., Mi-\\nlan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et al. (2017). Overcoming\\nCatastrophic Forgetting in Neural Networks. Proceedings of the National Academy of\\nSciences,114(13), 3521{3526.\\nKlimov, O. (2016). CarRacing-v0. https://gym.openai.com/envs/CarRacing-v0/ .\\nKlyubin, A. S., Polani, D., & Nehaniv, C. L. (2005). Empowerment: A Universal Agent-\\nCentric Measure of Control. In IEEE Congress on Evolutionary Computation , Vol. 1,\\npp. 128{135.\\nKonda, V. R., & Tsitsiklis, J. N. (2000). Actor-Critic Algorithms. In Advances in Neural\\nInformation Processing Systems , pp. 1008{1014.\\nKulkarni, T. D., Narasimhan, K. R., Saeedi, A., & Tenenbaum, J. B. (2016). Hierarchical\\nDeep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Moti-\\nvation. InAdvances in Neural Information Processing Systems , pp. 3675{3683.\\nKullback, S., & Leibler, R. A. (1951). On Information and Su\\x0eciency. The Annals of\\nMathematical Statistics,22(1), 79{86.\\nKullback, S. (1959).Information Theory and Statistics . Wiley, New York.\\nKurutach, T., Clavera, I., Duan, Y., Tamar, A., & Abbeel, P. (2018). Model-Ensemble\\nTrust-Region Policy Optimization. In International Conference on Learning Repre-\\nsentations.\\nLauer, M., & Riedmiller, M. A. (2000). An Algorithm for Distributed Reinforcement Learn-\\ning in Cooperative Multi-Agent Systems. In International Conference on Machine\\nLearning, pp. 535{542.\\nLegg, S., & Hutter, M. (2007). Universal Intelligence: A De\\x0cnition of Machine Intelligence.\\nMinds and machines,17(4), 391{444.\\nLeibfried, F., Kushman, N., & Hofmann, K. (2017). A Deep Learning Approach for Joint\\nVideo Frame and Reward Prediction in Atari Games. In International Conference on\\nLearning Representations, pp. 1{17.\\nLevy, A., Platt, R., & Saenko, K. (2019). Learning Multi-Level Hierarchies with Hindsight.\\nInInternational Conference on Learning Representations .\\nLi, Y. (2018). Deep Reinforcement Learning. arXiv preprint arXiv:1810.06339 .\\nLi, Y. (2019). Reinforcement Learning Applications. arXiv preprint arXiv:1908.06973 .\\nLillicrap, T. P., Hunt, J. J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., & Wierstra,\\nD. (2016). Continuous Control with Deep Reinforcement Learning. In International\\nConference on Learning Representations .\\nLin, L.-J. (1992).Reinforcement Learning for Robots Using Neural Networks . Ph.D. thesis,\\nCarnegie Mellon University.\\nLittman, M. L. (1994). Markov Games as a Framework for Multi-Agent Reinforcement\\nLearning. InInternational Conference on Machine Learning , pp. 157{163.\\nLittman, M. L. (2001). Value-Function Reinforcement Learning in Markov Games. Cognitive\\nSystems Research,2(1), 55{66.\\n1464\\nDeep Reinforcement Learning: A State-of-the-Art Walkthrough\\nLowe, R., Wu, Y. I., Tamar, A., Harb, J., Abbeel, O. P., & Mordatch, I. (2017). Multi-\\nAgent Actor-Critic for Mixed Cooperative-Competitive Environments. In Advances\\nin Neural Information Processing Systems , pp. 6379{6390.\\nLuong, N. C., Hoang, D. T., Gong, S., Niyato, D., Wang, P., Liang, Y.-C., & Kim, D. I.\\n(2019). Applications of Deep Reinforcement Learning in Communications and Net-\\nworking: A Survey.IEEE Communications Surveys & Tutorials ,21(4), 3133{3174.\\nMacKay, D. J. C. (1992). Information-Based Objective Functions for Active Data Selection.\\nNeural Computation,21(4), 3133{3174.\\nMahmood, A. R., Van Hasselt, H., & Sutton, R. S. (2014). Weighted Importance Sampling\\nfor O\\x0b-Policy Learning with Linear Function Approximation. In Advances in Neural\\nInformation Processing Systems , pp. 3014{3022.\\nMahmud, M., Kaiser, M. S., Hussain, A., & Vassanelli, S. (2018). Applications of Deep\\nLearning and Reinforcement Learning to Biological Data. IEEE Transactions on\\nNeural Networks and Learning Systems ,29(6), 2063{2079.\\nMalisiewicz, T., Gupta, A., & Efros, A. A. (2011). Ensemble of Exemplar-SVMs for Object\\nDetection and Beyond. In IEEE International Conference on Computer Vision , pp.\\n89{96.\\nMarbach, P., & Tsitsiklis, J. N. (2003). Approximate Gradient Methods in Policy-Space\\nOptimization of Markov Reward Processes. Discrete Event Dynamic Systems: Theory\\nand Applications,13(1-2), 111{148.\\nMartens, J., & Grosse, R. (2015). Optimizing Neural Networks with Kronecker-Factored\\nApproximate Curvature. In International Conference on Machine Learning , pp. 2408{\\n2417.\\nMcGovern, A., Sutton, R. S., & Fagg, A. H. (1997). Roles of Macro-Actions in Accelerating\\nReinforcement Learning. In Grace Hopper Celebration of Women in Computing , Vol.\\n1317.\\nMerton, R. K. (1968). The Matthew E\\x0bect in Science: The Reward and Communication\\nSystems of Science are Considered. Science,159(3810), 56{63.\\nMinsky, M. (1961). Steps Toward Arti\\x0ccial Intelligence. Proceedings of the IRE,49(1),\\n8{30.\\nMnih, V., Badia, A. P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., Silver, D., &\\nKavukcuoglu, K. (2016). Asynchronous Methods for Deep Reinforcement Learning.\\nInInternational Conference on Machine Learning , pp. 1928{1937.\\nMnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., Graves,\\nA., Riedmiller, M., Fidjeland, A. K., Ostrovski, G., Petersen, S., Beattie, C., Sadik, A.,\\nAntonoglou, I., King, H., Kumaran, D., Wierstra, D., Legg, S., & Hassabis, D. (2015).\\nHuman-Level Control Through Deep Reinforcement Learning. Nature,518(7540),\\n529{533.\\nMoore, A. (1991).E\\x0ecient Memory-Based Learning for Robot Control . Ph.D. thesis, Uni-\\nversity of Cambridge.\\n1465\\n Lazaridis, Fachantidis, & Vlahavas\\nMunos, R., Stepleton, T., Harutyunyan, A., & Bellemare, M. (2016). Safe and E\\x0ecient\\nO\\x0b-Policy Reinforcement Learning. In Advances in Neural Information Processing\\nSystems, pp. 1054{1062.\\nMyerson, R. B. (2013).Game theory. Harvard University Press.\\nNachum, O., Lee, H., Gu, S., & Levine, S. (2018). Data-E\\x0ecient Hierarchical Reinforcement\\nLearning. InAdvances in Neural Information Processing Systems , pp. 3303{3313.\\nNagabandi, A., Kahn, G., Fearing, R. S., & Levine, S. (2018). Neural Network Dynamics for\\nModel-Based Deep Reinforcement Learning with Model-Free Fine-Tuning. In IEEE\\nInternational Conference on Robotics and Automation , pp. 7559{7566.\\nNair, A., Srinivasan, P., Blackwell, S., Alcicek, C., Fearon, R., De Maria, A., Panneershel-\\nvam, V., Suleyman, M., Beattie, C., Petersen, S., & Others (2015). Massively Parallel\\nMethods for Deep Reinforcement Learning. arXiv preprint arXiv:1507.04296 .\\nNguyen, T. T., Nguyen, N. D., & Nahavandi, S. (2020). Deep Reinforcement Learning for\\nMulti-Agent Systems: A Review of Challenges, Solutions, and Applications. IEEE\\nTransactions on Cybernetics.\\nNguyen, T. T., & Reddi, V. J. (2019). Deep Reinforcement Learning for Cyber Security.\\narXiv preprint arXiv:1906.05799 .\\nNosratabadi, S., Mosavi, A., Keivani, R., Ardabili, S., & Aram, F. (2020). State of the Art\\nSurvey of Deep Learning and Machine Learning Models for Smart Cities and Urban\\nSustainability. InEngineering for Sustainable Future , pp. 228{238.\\nOh, J., Guo, X., Lee, H., Lewis, R., & Singh, S. (2015). Action-Conditional Video Prediction\\nUsing Deep Networks in Atari Games. In Advances in Neural Information Processing\\nSystems, pp. 2863{2871.\\nOmidsha\\x0cei, S., Pazis, J., Amato, C., How, J. P., & Vian, J. (2017). Deep Decentral-\\nized Multi-task Multi-Agent Reinforcement Learning under Partial Observability. In\\nInternational Conference on Machine Learning , pp. 2681{2690.\\nOpenAI (2018). OpenAI Five. https://blog.openai.com/openai-five/ .\\nOroojlooyJadid, A., & Hajinezhad, D. (2019). A Review of Cooperative Multi-Agent Deep\\nReinforcement Learning.arXiv preprint arXiv:1908.03963 .\\nOsband, I., Van Roy, B., Russo, D., & Wen, Z. (2019). Deep Exploration via Randomized\\nValue Functions.Journal of Machine Learning Research ,20(124), 1{62.\\nOsband, I., Van Roy, B., & Wen, Z. (2016). Generalization and Exploration via Randomized\\nValue Functions. InInternational Conference on Machine Learning , Vol. 48, pp. 2377{\\n2386.\\nOstrovski, G., Bellemare, M. G., Van Den Oord, A., & Munos, R. (2017). Count-Based\\nExploration with Neural Density models. In International Conference on Machine\\nLearning, pp. 2721{2730.\\nOudeyer, P. Y., & Kaplan, F. (2009). What Is Intrinsic Motivation? A Typology of Com-\\nputational Approaches.Frontiers in Neurorobotics,1, 6.\\n1466\\nDeep Reinforcement Learning: A State-of-the-Art Walkthrough\\nPathak, D., Agrawal, P., Efros, A. A., & Darrell, T. (2017). Curiosity-Driven Exploration\\nby Self-Supervised Prediction. In International Conference on Machine Learning ,\\nVol. 70, pp. 2778{2787.\\nPeters, J., & Schaal, S. (2006). Policy Gradient Methods for Robotics. In IEEE International\\nConference on Intelligent Robots and Systems , pp. 2219{2225.\\nPinto, L., Davidson, J., Sukthankar, R., & Gupta, A. (2017). Robust Adversarial Reinforce-\\nment Learning. InInternational Conference on Machine Learning , pp. 2817{2826.\\nPrecup, D. (2000).Temporal Abstraction in Reinforcement Learning . Ph.D. thesis, Univer-\\nsity of Massachusetts Amherst.\\nPremack, D., & Woodru\\x0b, G. (1978). Does the Chimpanzee Have a Theory of Mind?.\\nBehavioral and Brain Sciences ,1(4), 515{526.\\nRabinowitz, N. C., Perbet, F., Song, H. F., Zhang, C., Eslami, S., & Botvinick, M. (2018).\\nMachine Theory of Mind. In International Conference on Machine Learning , pp.\\n4218{4227.\\nRacani\\x12ere, S., Weber, T., Reichert, D. P., Buesing, L., Guez, A., Rezende, D., Badia, A. P.,\\nVinyals, O., Heess, N., Li, Y., Pascanu, R., Battaglia, P., Hassabis, D., Silver, D., &\\nWierstra, D. (2017). Imagination-Augmented Agents for Deep Reinforcement Learn-\\ning. InAdvances in Neural Information Processing Systems , Vol. 30, pp. 5690{5701.\\nRatcli\\x0b, R. (1990). Connectionist Models of Recognition Memory: Constraints Imposed by\\nLearning and Forgetting Functions. Psychological Review,97(2), 285.\\nRezende, D. J., Mohamed, S., & Wierstra, D. (2014). Stochastic Backpropagation and\\nApproximate Inference in Deep Generative Models. In International Conference on\\nMachine Learning, pp. 1278{1286.\\nRichards, A. G. (2005).Robust Constrained Model Predictive Control . Ph.D. thesis, Mas-\\nsachusetts Institute of Technology.\\nRocha, F. M., Costa, V. S., & Reis, L. P. (2020). From Reinforcement Learning Towards\\nArti\\x0ccial General Intelligence. In World Conference on Information Systems and\\nTechnologies, pp. 401{413.\\nRoss, S., Gordon, G. J., & Bagnell, J. A. (2011). A Reduction of Imitation Learning and\\nStructured Prediction to No-Regret Online Learning. In International Conference on\\nArti\\x0ccial Intelligence and Statistics , pp. 627{635.\\nRubinstein, R. Y. (1997). Optimization of Computer Simulation Models with Rare Events.\\nEuropean Journal of Operational Research ,99(1), 89{112.\\nRusu, A. A., Rabinowitz, N. C., Desjardins, G., Soyer, H., Kirkpatrick, J., Kavukcuoglu,\\nK., Pascanu, R., & Hadsell, R. (2016). Progressive Neural Networks. arXiv preprint\\narXiv:1606.04671.\\nSalge, C., Glackin, C., & Polani, D. (2014). Empowerment { An Introduction. In Guided\\nSelf-Organization: Inception, pp. 89{112. Springer Berlin Heidelberg.\\nSalimans, T., Ho, J., Chen, X., Sidor, S., & Sutskever, I. (2017). Evolution Strategies as a\\nScalable Alternative to Reinforcement Learning. arXiv preprint arXiv:1703.03864 .\\n1467\\n Lazaridis, Fachantidis, & Vlahavas\\nSchaul, T., Horgan, D., Gregor, K., & Silver, D. (2015a). Universal Value Function Ap-\\nproximators. InInternational Conference on Machine Learning , pp. 1312{1320.\\nSchaul, T., Quan, J., Antonoglou, I., & Silver, D. (2015b). Prioritized Experience Replay.\\narXiv preprint arXiv:1511.05952 .\\nSchmidhuber, J. (2010). Formal Theory of Creativity, Fun, and Intrinsic Motivation (1990-\\n2010).IEEE Transactions on Autonomous Mental Development ,2(3), 230{247.\\nSchrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L., Schmitt, S., Guez, A.,\\nLockhart, E., Hassabis, D., Graepel, T., et al. (2019). Mastering Atari, Go, Chess and\\nShogi by Planning with a Learned Model. arXiv preprint arXiv:1911.08265 .\\nSchulman, J., Levine, S., Abbeel, P., Jordan, M., & Moritz, P. (2015). Trust Region Policy\\nOptimization. InInternational Conference on Machine Learning , pp. 1889{1897.\\nSchulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017). Proximal Policy\\nOptimization Algorithms.arXiv preprint arXiv:1707.06347 .\\nSehnke, F., Osendorfer, C., R\\x7fuckstiess, T., Graves, A., Peters, J., & Schmidhuber, J. (2010).\\nParameter-Exploring Policy Gradients. Neural Networks,23(4), 551{559.\\nShao, K., Tang, Z., Zhu, Y., Li, N., & Zhao, D. (2019). A Survey of Deep Reinforcement\\nLearning in Video Games. arXiv preprint arXiv:1912.10944 .\\nSilver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., & Riedmiller, M. (2014). Determin-\\nistic Policy Gradient Algorithms. In International Conference on Machine Learning ,\\npp. 387{395.\\nSilver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert,\\nT., Baker, L., Lai, M., Bolton, A., Chen, Y., Lillicrap, T., Hui, F., Sifre, L., Van Den\\nDriessche, G., Graepel, T., & Hassabis, D. (2017). Mastering the Game of Go Without\\nHuman Knowledge.Nature,550(7676), 354{359.\\nSilvia, P. J. (2012). Curiosity and Motivation. The Oxford Handbook of Human Motivation ,\\n550(7676), 354{359.\\nSkinner, G., & Walmsley, T. (2019). Arti\\x0ccial Intelligence and Deep Learning in Video\\nGames - A Brief Review. In IEEE International Conference on Computer and Com-\\nmunication Systems, pp. 404{408.\\nStrehl, A. L., & Littman, M. L. (2008). An Analysis of Model-Based Interval Estimation\\nfor Markov Decision Processes. Journal of Computer and System Sciences ,74(8),\\n1309{1331.\\nStylianou, N., & Vlahavas, I. (2019). A Neural Entity Coreference Resolution Review. arXiv\\npreprint arXiv:1910.09329.\\nSu, J., Vargas, D. V., & Sakurai, K. (2019). One Pixel Attack for Fooling Deep Neural\\nNetworks.IEEE Transactions on Evolutionary Computation ,23(5), 828{841.\\nSutton, R. S. (1988). Learning to Predict by the Methods of Temporal Di\\x0berences. Machine\\nLearning,3(1), 9{44.\\nSutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction . MIT press.\\n1468\\nDeep Reinforcement Learning: A State-of-the-Art Walkthrough\\nSutton, R. S., Precup, D., & Singh, S. (1999). Between MDPs and Semi-MDPs: A Frame-\\nwork for Temporal Abstraction in Reinforcement Learning. Arti\\x0ccial Intelligence,\\n112(1-2), 181{211.\\nSzegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., & Fergus,\\nR. (2014). Intriguing Properties of Neural Networks. In International Conference on\\nLearning Representations.\\nTai, L., Zhang, J., Liu, M., Boedecker, J., & Burgard, W. (2016). A Survey of Deep Network\\nSolutions for Learning Control in Robotics: From Reinforcement to Imitation. arXiv\\npreprint arXiv:1612.07139.\\nTang, H., Houthooft, R., Foote, D., Stooke, A., Chen, X., Duan, Y., Schulman, J., De Turck,\\nF., & Abbeel, P. (2017). Exploration: A Study of Count-Based Exploration for Deep\\nReinforcement Learning. In Advances in Neural Information Processing Systems , pp.\\n2753{2762.\\nTassa, Y., Doron, Y., Muldal, A., Erez, T., Li, Y., Casas, D. d. L., Budden, D., Abdolmaleki,\\nA., Merel, J., Lefrancq, A., et al. (2018). Deepmind Control Suite. arXiv preprint\\narXiv:1801.00690.\\nTodorov, E., Erez, T., & Tassa, Y. (2012). MuJoCo: A Physics Engine for Model-Based\\nControl. InIEEE International Conference on Intelligent Robots and Systems , pp.\\n5026{5033.\\nToromano\\x0b, M., Wirbel, E., & Moutarde, F. (2019). Is Deep Reinforcement Learning Really\\nSuperhuman on Atari?.arXiv preprint arXiv:1908.04683 .\\nTucker, G., Bhupatiraju, S., Gu, S., Turner, R., Ghahramani, Z., & Levine, S. (2018). The\\nMirage of Action-Dependent Baselines in Reinforcement Learning. In International\\nConference on Machine Learning , pp. 5015{5024.\\nUhlenbeck, G. E., & Ornstein, L. S. (1930). On the Theory of the Brownian Motion. Physical\\nreview,36(5), 823.\\nUther, W., & Veloso, M. (1997). Adversarial Reinforcement Learning. Tech. rep., Carnegie\\nMellon University. Unpublished.\\nVan Den Oord, A., Kalchbrenner, N., & Kavukcuoglu, K. (2016). Pixel Recurrent Neural\\nNetworks. InInternational Conference on Machine Learning , Vol. 48, pp. 1747{1756.\\nVan Hasselt, H., Guez, A., Hessel, M., Mnih, V., & Silver, D. (2016a). Learning Values\\nAcross Many Orders of Magnitude. In Advances in Neural Information Processing\\nSystems, pp. 4287{4295.\\nVan Hasselt, H., Guez, A., & Silver, D. (2016b). Deep Reinforcement Learning with Double\\nQ-Learning. InAAAI Conference on Arti\\x0ccial Intelligence , pp. 2094{2100.\\nVenkatraman, A., Capobianco, R., Pinto, L., Hebert, M., Nardi, D., & Bagnell, J. A. (2016).\\nImproved Learning of Dynamics Models for Control. In International Symposium on\\nExperimental Robotics, pp. 703{713.\\nVezhnevets, A., Mnih, V., Agapiou, J., Osindero, S., Graves, A., Vinyals, O., &\\nKavukcuoglu, K. (2016). Strategic Attentive Writer for Learning Macro-Actions. In\\nAdvances in Neural Information Processing Systems , Vol. 29, pp. 3486{3494.\\n1469\\n Lazaridis, Fachantidis, & Vlahavas\\nVezhnevets, A. S., Osindero, S., Schaul, T., Heess, N., Jaderberg, M., Silver, D., &\\nKavukcuoglu, K. (2017). Feudal networks for hierarchical reinforcement learning.\\nInInternational Conference on Machine Learning , pp. 3540{3549.\\nVinyals, O., Babuschkin, I., Chung, J., Mathieu, M., Jaderberg, M., Czarnecki, W., Dudzik,\\nA., Huang, A., Georgiev, P., Powell, R., Ewalds, T., Horgan, D., Kroiss, M., Dani-\\nhelka, I., Agapiou, J., Oh, J., Dalibard, V., Choi, D., Sifre, L., Sulsky, Y., Vezhnevets,\\nS., Molloy, J., Cai, T., Budden, D., Paine, T., Gulcehre, C., Wang, Z., Pfa\\x0b, T.,\\nPohlen, T., Yogatama, D., Cohen, J., McKinney, K., Smith, O., Schaul, T., Lillicrap,\\nT., Apps, C., Kavukcuoglu, K., Hassabis, D., & Silver, D. (2019). AlphaStar: Mas-\\ntering the Real-Time Strategy Game StarCraft II. https://deepmind.com/blog/\\nalphastar-mastering-real-time-strategy-game-starcraft-ii/ .\\nVon Neumann, J., & Morgenstern, O. (2007). Theory of Games and Economic Behavior .\\nPrinceton University Press.\\nWainwright, M. J., & Jordan, M. I. (2008). Graphical Models, Exponential Families, and\\nVariational Inference.Foundations and Trends in Machine Learning .\\nWang, Y., He, H., Tan, X., & Gan, Y. (2019). Trust Region-Guided Proximal Policy\\nOptimization. InAdvances in Neural Information Processing Systems , pp. 626{636.\\nWang, Z., Bapst, V., Heess, N., Mnih, V., Munos, R., Kavukcuoglu, K., & de Freitas,\\nN. (2017). Sample E\\x0ecient Actor-Critic with Experience Replay. In International\\nConference on Learning Representations .\\nWang, Z., Schaul, T., Hessel, M., & Lanctot, M. (2016). Dueling Network Architectures for\\nDeep Reinforcement Learning. In International Conference on Machine Learning , pp.\\n1995{2003.\\nWatkins, C. (1989).Learning from Delayed Rewards . Ph.D. thesis, University of Cambridge.\\nWen, Z. (2014).E\\x0ecient Reinforcement Learning with Value Function Generalization .\\nPh.D. thesis, Stanford University.\\nWhiteson, S. (2019). A Survey of Reinforcement Learning Informed by Natural Language.\\nInInternational Joint Conference on Arti\\x0ccial Intelligence , pp. 6309{6317.\\nWilliams, R. J. (1992). Simple Statistical Gradient-Following Algorithms for Connectionist\\nReinforcement Learning.Machine Learning,8(3-4), 229{256.\\nWu, C., Rajeswaran, A., Duan, Y., Kumar, V., Bayen, A. M., Kakade, S., Mordatch, I., &\\nAbbeel, P. (2018). Variance Reduction for Policy Gradient with Action-Dependent\\nFactorized Baselines. InInternational Conference on Learning Representations .\\nWu, Y., Mansimov, E., Grosse, R. B., Liao, S., & Ba, J. (2017a). Scalable Trust-Region\\nMethod for Deep Reinforcement Learning Using Kronecker-Factored Approximation.\\nInAdvances in Neural Information Processing Systems , pp. 5279{5288.\\nWu, Y., Mansimov, E., Liao, S., Radford, A., & Schulman, J. (2017b). OpenAI Baselines:\\nACKTR & A2C.https://openai.com/blog/baselines-acktr-a2c/ .\\nYang, X., & Sun, M. (2019). A Survey on Deep Learning in Crop Planting. IOP Conference\\nSeries: Materials Science and Engineering ,490(6), 062053.\\n1470\\nDeep Reinforcement Learning: A State-of-the-Art Walkthrough\\nYu, C., Liu, J., & Nemati, S. (2019). Reinforcement Learning in Healthcare: A Survey.\\narXiv preprint arXiv:1908.08796 .\\nZhang, K., Yang, Z., & Ba\\x18sar, T. (2019). Multi-Agent Reinforcement Learning: A Selective\\nOverview of Theories and Algorithms. arXiv preprint arXiv:1911.10635 .\\nZiebart, B. D., Maas, A., Bagnell, J. A., & Dey, A. K. (2008). Maximum Entropy Inverse\\nReinforcement Learning. In National Conference on Arti\\x0ccial Intelligence , Vol. 3, pp.\\n1433{1438.\\n1471\\n\\n\\n ********************\\n\\n ********************References:\\n \\n................................\\n................................\\n................................\\n..........................\\n \\n58\\n \\n\\nAppendix A \\n–\\n \\nRSI\\n, MACD and Bollinger Band\\n \\n................................\\n..............................\\n \\n64\\n \\n\\nAppendix B \\n–\\n \\nFigures\\n \\n................................\\n................................\\n................................\\n.........\\n \\n8\\n0\\n \\n\\nAppendix C \\n--\\n \\nTables\\n \\n................................\\n................................\\n................................\\n.........\\n \\n80\\n \\n\\n \\n\\n \\n iv\\n \\n\\n \\n List of \\nFigure\\ns\\n \\n\\n \\n\\nFigure\\n \\n1:\\n  \\nCumulative\\n \\nreturns of the hedged portfolio constructed by taking long positions \\n\\nof the top 10% CSI 300 index component stocks and short positions of the bottom 10% \\n\\nCSI 300 index component stocks over the period from 2010.06 to 2015.10.\\n  \\n..................\\n \\n25\\n \\n\\nFigure\\n \\n2:\\n \\nCumulative\\n \\nreturns of the hedged portfolio constructed by taking long positions \\n\\nof the top 10% CSI 300 index component stocks and short positions of the bottom 10% \\n\\nCSI 300 index component stocks over the\\n  \\nperiod from\\n \\n2010.06 to 2015.10\\n.\\n \\n..................\\n \\n25\\n \\n\\nFigure\\n \\n3:\\n \\nCumulative\\n \\nreturns of the hedged portfolio constructed by taking long positions \\n\\nof the top 10% CSI 300 index component stocks and short positions of the bottom 10% \\n\\nCSI 300 index component s\\n tocks over the\\n \\nperiod from 2010.06 to 2015.10\\n .\\n \\n..................\\n \\n25\\n \\n\\nFigure\\n \\n4: \\nCumulative\\n \\nreturns of the hedged portfolio constructed by taking long positions \\n\\nof the top 10% CSI 300 index component stocks and short positions of the bottom 10%\\n \\n\\nCSI 300 index component stocks over the period from 2010.06 to 2015.10.\\n  \\n..................\\n \\n25\\n \\n\\nFigure\\n \\n5:\\n \\nCSI 300 index from 2005.04 to 2015.11\\n  \\n................................\\n.........................\\n \\n4\\n1\\n \\n\\nFigure\\n \\n6:\\n \\nCumulative\\n \\ncontinuously compounding returns of buy\\n -\\nand\\n-\\nhold strategy of CSI \\n\\n300 index from 2005.04 to 2015.11\\n  \\n................................\\n................................\\n.................\\n \\n4\\n1\\n \\n\\nFigure\\n \\n7: \\n \\nIn\\n-\\nsample performances of 10 GA\\n-\\nbased technical trading rules in terms of \\n\\nexcess returns over buy\\n-\\nand\\n-\\nhold an\\nd the number of transactions for each strategy over \\n\\nthe period from 2005.04 to 2010.10.\\n ................................\\n................................\\n................\\n \\n43\\n \\n\\nFigure\\n \\n8: \\nOut\\n-\\nof\\n-\\nsample performances of 10 GA\\n-\\nbased technical trading rules in terms \\n\\nof excess returns over buy\\n -\\nand\\n-\\nhold and the num\\n ber of transactions for each strategy over \\n\\nthe period from 2010.11 to 2015.10.\\n ................................\\n................................\\n................\\n \\n4\\n4\\n \\n v\\n \\n\\n \\nFigure\\n \\n9:\\n \\nComparison between one GA\\n -\\nbased strategy and buy\\n -\\nand\\n-\\nhold strategy in terms \\n\\nof \\ncumulative\\n \\nreturn in the out\\n-\\nof\\n-\\nsample period from 2\\n010.11 to 2015.10.\\n \\n..................\\n \\n4\\n4\\n \\n\\nFigure\\n \\n10:\\n \\nTraining period performances of 10 GA\\n-\\nbased technical trading rules with \\n\\ndata over\\n-\\nfitting alleviation system in place in terms of excess returns over buy\\n -\\nand\\n-\\nhold \\n\\nand the number of transactions for each strategy over the period from 2005.04 to 2010.10.\\n\\n................................\\n................................\\n................................\\n................................\\n..........\\n \\n4\\n5\\n \\n\\nFigure\\n \\n11:\\n \\nEvaluation period performances of 10 GA\\n-\\nbased technical trading rules with \\n\\ndata over\\n-\\nfitting alleviation system in place in terms of excess returns over buy\\n -\\nand\\n-\\nhold \\n\\nand the number of transactions for each stra\\n tegy over the period from 2010.11 to 2014.10.\\n\\n................................\\n................................\\n................................\\n................................\\n..........\\n \\n45\\n \\n\\nFigure\\n \\n12:\\n \\nTesting period performances of 10 GA\\n -\\nbased technical trading rules with data \\n\\nover\\n-\\nfitting alleviation system in place in terms of excess returns over buy\\n-\\nand\\n-\\nhold \\nand \\n\\nthe number of transactions for each strategy over the period from 2014.11 to 2015.10.\\n  \\n45\\n \\n\\nFigure\\n \\n13:\\n  \\nComparison  between  the \\ncumulative\\n \\nreturns  of  the  top  three  GA\\n-\\nbased \\n\\ntechnical trading strategies and buy\\n -\\nand\\n-\\nhold over\\n \\ntesting period from 2014.11 to 2015.10.\\n\\n................................\\n................................\\n................................\\n................................\\n..........\\n \\n45\\n \\n\\nFigure\\n \\n14: \\n \\nscatter  plot  of  the  performances  of  these  18  GA\\n-\\nbased  technical  trading \\n\\nstrategies in terms of excess return over buy\\n-\\nand\\n-\\nhold and adjusted Sterling ratio in the \\n\\ntrain\\ning period from 2005.04 to 2010.10\\n  \\n................................\\n................................\\n.........\\n \\n46\\n \\n\\nFigure\\n \\n15: \\n \\nThe comparison between the \\ncumulative\\n \\nreturns of buy\\n-\\nand\\n-\\nhold and best \\n\\ntrading strategies from evaluation period in testing period (2014.10\\n -\\n2015.10)\\n \\n..............\\n \\n46\\n \\n\\nFigure\\n \\n16:\\n \\nCSI 300 index from 2010.01 to 2015.12\\n  \\n................................\\n.......................\\n \\n47\\n \\n vi\\n \\n\\n \\nFigure\\n \\n17: \\nCumulative\\n \\nreturn of buy\\n-\\nand\\n-\\nhold strategy on CSI 300 index from 2010.01 \\n\\nto 2015.12\\n \\n................................\\n................................\\n................................\\n........................\\n \\n4\\n8\\n \\n\\nFigure\\n \\n18\\n: \\ncomparisons  between  strategy  1  and  buy\\n-\\nand\\n-\\nhold  strategy  in  the  form  of \\n\\ncumulative\\n \\nreturns in training period from 2005.01 to 2008.04.\\n  \\n................................\\n.....\\n \\n50\\n \\n\\nFigure\\n \\n19: \\ncomparisons  between  strategy  1  and  buy\\n-\\nand\\n-\\nhold  strategy  in  the  form  of \\n\\ncumulative\\n \\nreturns in testing period from 2010.01 to 2015.12.\\n  \\n................................\\n.......\\n \\n50\\n \\n\\nFigure\\n \\n20:\\n \\nCumulative\\n \\nreturns of the long\\n-\\nposition portfolio constructed by taking long \\n\\npositions of the top 5% component stocks in CSI 300 index and the shor\\n t\\n-\\nposition portfolio \\n\\nconstructed by taking short positions of the bottom 5% component stocks in CSI 300 index.\\n\\n................................\\n................................\\n................................\\n................................\\n..........\\n \\n52\\n \\n\\nFigure\\n \\n21: \\nLong\\n-\\nshort signals released by one GA\\n-\\nbased technical trading strategy with \\n\\n“100” stands for takin\\ng long positions and “\\n-\\n100” for taking short positions\\n  \\n.................\\n \\n5\\n3\\n \\n\\nFigure\\n \\n22: \\nComparison between the long\\n-\\nposition portfolio, short\\n-\\nposition portfolio and \\n\\nthe combined portfolio according to GA\\n -\\nbased technical trading rules.\\n  \\n.........................\\n \\n53\\n \\n\\nFigure\\n \\n23:  \\nForecasted volatility based on GARCH model in out\\n-\\nof\\n-\\nsample period and \\n\\nthe  corresponding  threshold  point  GA  select  from  one  experiment  to  differentiate  the \\n\\nmarket regimes.\\n \\n................................\\n................................\\n................................\\n................\\n \\n54\\n \\n\\nFigure\\n \\n24: \\nPercentage of each regime from one GA\\n-\\nbased technical trading rules with \\n\\nregime switching taken into consideration.\\n  \\n................................\\n................................\\n.....\\n \\n54\\n \\n\\nFigure\\n \\n25: \\nCumulative\\n \\nreturns of technical trading strategies specific to regime 1, regime \\n\\n2 and th\\ne final trading strategy from one experiment.\\n  \\n................................\\n.....................\\n \\n55\\n \\n\\n \\n vii\\n \\n\\n \\n \\n\\nList of Tables\\n \\n\\n \\n\\nTable 1:\\n \\nDetail of Fama\\n-\\nMacBeth regressions on technical indicators RSI, MACD and \\n\\nBollinger  Band  to  identify  statuses  significantly  associated  with  positive  and  negative \\n\\nreturns over 120 days from 2013.03 to 2013. 06.\\n  \\n................................\\n............................\\n \\n24\\n \\n\\nTable 2:\\n \\nBasic facts of CSI 300 index over the period from 2005.04 to 2015.11 including \\n\\nnumber  of  days,  average  daily  return, \\ncumulative\\n \\nreturn,  return  volatility,  maximum \\n\\ndrawdown and Sharpe ratio.\\n  \\n................................\\n................................\\n............................\\n \\n41\\n \\n\\nTable 3: \\n \\nKey facts of the 10\\n \\nGA\\n-\\nbased technical trading strategies on CSI 300 index in \\n\\nout\\n-\\nof\\n-\\nsample  period  from  2010.01  to  2015.12.  Information  contained  includes  return \\n\\nattribution, holding period return, number of transaction, maximum drawdown and Sharpe \\n\\nratio for each strategy.\\n................................\\n................................\\n................................\\n......\\n \\n4\\n8\\n \\n\\nTable 4: \\nCategorization of the statuses for RSI, MACD and Bollinger Band and t\\n-\\nstats \\n\\nfor each of the statuses with regard to returns.\\n  \\n................................\\n................................\\n \\n51\\n \\n\\nTable  5:\\n \\nKey  facts  of  portfolio  1,  portfolio  2  and \\nportfolio  3.  Information  contained \\n\\nincludes return attribution, holding period return, maximum drawdown and Sharpe ratio.\\n\\n................................\\n................................\\n................................\\n................................\\n..........\\n \\n53\\n \\n\\nTable 6: \\n \\nKey facts of the 10 experiments with regime\\n -\\nswitching considered. Information \\n\\ncontained \\nincludes holding period return, maximum drawdown and Sharpe ratio.\\n  \\n........\\n \\n56\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n 1\\n \\n\\n \\n1.\\n \\nIntroduction\\n \\n\\n \\n\\nIn\\n \\nfinanc\\nial \\nresearch\\n,  there  are  two  alternative  approaches  of \\nscientific \\nreasoning\\n \\nin \\n\\nconducting research studies\\n, namely deductive reasoning and inductive reasoning. Deductive \\n\\nreasoning  takes  the  form  of  a  “top  down”  analysis  and  works  from  generalizations  to \\n\\nspecifications. Specifically, deductive reasoning starts with a theory \\n and pr\\noposes hypotheses \\n\\nrelated to the \\nobserved data\\n. After that, the original theory\\n \\non\\n \\nwhich the hypotheses are based \\n\\nis confirmed or \\nrejected\\n \\naccording to the test results of hypotheses. \\nIn\\n \\ncomparison, inductive \\n\\nreasoning works \\nthe opposite way\\n \\nas a kind of “\\nbottom up”\\n \\nanalysis. \\nM\\nore precise\\nly\\n, \\ninductive\\n \\n\\nreasoning  begins  with  specific \\ndata \\nobservations,  from  which  hypotheses  are  generated\\n. \\n\\nGenerated  hypotheses\\n \\nare  confirmed  or  rejected  in  following  tests \\nuntil  new  theories  or \\n\\ngeneralizations are reached.\\n  \\nIn \\nfinancial \\neconomics, market participants \\n are \\nassumed to \\nmodel \\n\\nexpectations  through  deductive  reasoning  and \\nbehave  with  full  rationality\\n \\nto  maximize\\n \\nthe\\n \\n\\nutilities.\\n \\n\\nHowever,\\n \\nmany  subsequent  studies  emerge\\n \\nand \\nchallenge\\n \\nthe \\nassumption  of \\ndeductive \\n\\nreasoning.\\n \\nSome  of  those  studies  reach  the  same  conclusion  that  when  facing  complicated \\n\\nproblems,  market  agents  turn  to  inductive  rather  than  deductive  reasoning\\n \\n(Arthur  (1992), \\n\\nArthur (1994), Arthur, Holland, LeBaron, Palmer and Tayler (1996)). Specifically, based o\\nn \\n\\ndata \\nobservations,  market  agents  seek  patterns  and  generate  hypotheses\\n \\nto  predict  market \\n\\nmovements\\n \\nfrom identified patterns. \\nAfter that, market agents \\nbehave\\n \\naccording to generated \\n\\nhypotheses  and \\nreceive  feedback\\ns  on\\n \\nthe  validation  of  the  hypotheses.  Con\\nsequently, \\n\\nhypotheses \\naccurately predicting market movements\\n \\nare maintained and strengthened while \\n\\nthose  with \\nimprecise  forecasts\\n \\nare  discarded.\\n \\nArthur  (1994)  defines  the  inductive  way  of \\n\\nreasoning as using simple models to fill the gaps in under\\nstanding \\nwhenever full reason or\\n \\n\\ndefinition of the problems are not achieved.\\n \\nIn this thesis, we attempt to leverage the GA to \\n\\nimitate inductive reasoning by seeking patterns in equity markets and to discover profitable \\n\\nfilter rules.\\n \\n\\n     \\nFilter rules in equity tra\\n ding are \\nthe direct results of the\\n  \\ninductive reasoning of market agents. \\n\\nTheoretically, there are infinite number of patterns \\nin stock markets and t\\nhe patterns can be \\n\\nrecognized based on prices, volumes, \\n volatilities and any other \\n information\\n \\nfrom\\n \\nstock tr\\nading\\n \\n\\nactivities\\n. Market agents observe and identify patterns\\n  \\nas potential filter rules\\n \\nand use them to \\n 2\\n \\n\\n \\npredict  market  movements.  Over  time, \\neach  filter  rule  is  evaluated  on  the  accuracy  of \\n\\npredictions. \\nAs the result, filter rules with high accuracy \\nare ke\\npt and become popular in the \\n\\nmarket while \\nthe\\n \\nnon\\n-\\nperforming \\nones\\n \\nare discarded or updated\\n.\\n \\nA\\nt the beginning, most of the \\n\\nfilter  rules  for  equity  trading  are  based  only  on  stock  closing  prices.  Later \\non, \\nwith  other \\n\\ninformation  such  as  volumes  and  volatilit\\nies  are  also  taken  into  consideration, \\nfilter  rules \\n\\nbecome \\nmore \\ndiversified\\n \\nand\\n \\nare presented in more complicated forms\\n .\\n \\nIn fact, due to the high \\n\\naccuracy  of  predictions,  s\\nome  filter  rules  become  popular  technical  indicators\\n \\nwhich\\n \\neven\\n \\n\\nextend their \\npractical values to now\\n.\\n \\n \\n\\nA\\nlthough many studies have covered the filter rules for stock trading, the \\nconsensus on the \\n\\nforms\\n \\nof profitable filter rules\\n \\nhas not been reached\\n, which brings discounted guidance to \\nthe \\n\\npractices  of  market  agents.  As  a  result,  in\\n \\nmany  cases \\ntechnical  analysis  fails  to  achieve \\n\\noutperformances over the benchmarks such as the buy\\n-\\nand\\n-\\nhold strategy. \\nDue to this reason, \\n\\nAllen and Karjalainen (1999) make the first attempt to\\n \\nverify whether the\\n \\nGenetic Algorithm \\n\\n(GA) \\ncan discover\\n \\nfilter \\nrules \\nthat consistently beat the\\n \\nbuy\\n-\\nand\\n-\\nhold strategy. \\nThe \\nGA was \\n\\nfirst discovered by John Holland in the 1960s to mimic the biological evolution in addressing \\n\\ncomputational problems\\n.\\n \\nIn \\nthe \\nGA, solutions are presented in the form of bit\\n -\\nstrings made up \\n\\nb\\ny “chromosomes” and the \\n biological evolution proceeds through\\n  \\ntransferring “chromosomes” \\n\\nby generations\\n. T\\nechnically, t\\nhe evolution \\nis \\nimplement\\ned\\n \\nby crossovers and mutations of the \\n\\nbit\\n-\\nstrings. \\nTherefore,  in  order  to  apply  the  GA  to  refine  filter  rules,  f\\nilter  rules \\nshould  be \\n\\nexpressed in the form of bit\\n-\\nstrings\\n. \\nIn other words\\n, each \\nfilter rule\\n \\nis\\n \\ntransformed into a bit\\n-\\n\\nstring, and each bit\\n -\\nstring can be \\n correspondingly \\ninterpreted\\n \\ninto one \\nfilter rule\\n. \\nThis feasibility\\n \\n\\nenables\\n \\nthe GA to refine \\nfilter rul\\nes\\n \\nbecause\\n, during the evolution, the\\n  \\n“good genes” of \\ntrading \\n\\nstrategies are\\n \\nmaintained while the “bad genes” are discarded. \\n  \\n\\n     \\nAs the first researchers attempting to use the GA to generate profitable filter rules, Allen \\n\\nand Karjalainen (1999) target \\ndaily trading on S&P 500 index\\n. The filter rules in the work of \\n\\nAllen and Karjalainen (1999) are based on\\n  \\nstock\\n \\nclosing prices, local extrema of \\n closing \\nprices \\n\\n(maximum  and  minimum)  and  averages  of  previous  closing  prices\\n.  The  GA  is\\n \\nutilize\\nd\\n \\nto \\n\\nprovide  the\\n \\nultimately  best  tradin\\ng  strategy  which \\nassists  trading  by  releasing\\n \\nbuy  and\\n \\nsell \\n\\nsignals.  However,  the  results  of \\nthe  work  of  Allen  and  Karjalainen  (1999) \\nshow  that\\n,  with \\n\\ntrading  costs  taken  into  consideration,  the  best\\n \\nfilter  rules\\n \\ngenerated  from\\n \\nthe  GA \\ndo  not \\n\\nconsistently earn excess returns over the buy\\n-\\nand\\n-\\nhold strategy in the out\\n-\\nof\\n-\\nsample\\n \\nperiods. \\n 3\\n \\n\\n \\nFrom the work of Allen and Karjalainen (1999), many studies on this topic follow up. Based \\n\\non  Australia  stock  market,  Pereira  (1999)  uses\\n \\nthe\\n \\nGA  to  refine \\nparameters  of  technical \\n\\nindicators\\n \\nover the in\\n-\\nsample period from 1982 to 1989. \\nAfter that, t\\nechnical indicators with \\n\\nrefined parameter are evaluated during the out\\n -\\nof\\n-\\nsample period from 1990 to 1997\\n . T\\nhe results\\n \\n\\nof the work of\\n \\nPereira (1999) \\nshow that\\n,\\n \\nth\\ne \\npositive \\nexcess returns of the optimal rules\\n \\nfrom \\n\\nthe GA\\n \\nvanish gradually. Dempster and Jones (2001) consider combinations of many technical \\n\\nindicators such as Adaptive Moving Average (AMA), Commodity Channel Index (CCI) and \\n\\nRelative Strength Index (RSI)\\n . By using the GA to initialize and update trading rules, they find \\n\\nthat the best \\ntrading \\nrules\\n \\nfrom the GA\\n \\nachieve significant profit trading US Dollar/British \\n\\nPound in the out\\n-\\nof\\n-\\nsample period\\ns\\n. \\n \\n\\nBecker  and  Seshadri\\n \\n(2003)  make  further  improvements  on  th\\ne  work  of  Allen  and \\n\\nKarjalainen  (1999)  by  introducing  a  complexity  penalizing  factor  to  the  objective  fitness \\n\\nfunction and assuming monthly instead of daily trading on \\nthe \\nS&P 500 index. The results of \\n\\nthe work of Becker and Seshadri (2003) show that sever\\nal trading rules are able to beat the \\n\\nbuy\\n-\\nand\\n-\\nhold strategy in out\\n -\\nof\\n-\\nsample periods from 1990 to 2002. Potvin, Soriano and Vallee \\n\\n(2004) target 14 Canadian listed companies on TSX and acquire GA\\n-\\nbased trading rules that \\n\\nare\\n \\nbeneficial when the market is s\\ntable or in downward trends.  Lohptch and Corne (2009) \\n\\nfurther investigate the work of Becker and Seshadri (2003) and find that the adopted technical \\n\\nstrategies for daily trading can achieve excess returns over the buy\\n-\\nand\\n-\\nhold strategy on the \\n\\nS&P 500 inde\\nx. However, their results are sensitive to the chosen data periods. In addition, \\n\\nthey also find that\\n , by\\n \\nutilizing shorter periods of time in \\n the \\ntestes\\n, we\\n \\ncan\\n \\ngenerate more robust \\n\\nresults.\\n \\nKapoor, Dey and Khurana (2011) use \\nthe \\nGA to refine parameters of technical \\nrules\\n \\n\\nfor stocks listed in National Stock Exchange in India and find that the optimized rule\\n s\\n \\nfrom the \\n\\nGA can significantly increase the profit as compared to traditional moving average trading \\n\\nrules. Shin, Kim and Han \\n(2015) take advantage of the GA to filter trading rules and find that \\n\\nthe best rules gained can consistently beat the buy\\n-\\nand\\n-\\nhold strategy for Korea Stock Price \\n\\nIndex 200 (KOSPI 200) futures. \\n However\\n, not every study on testing the GA’s ability to refine \\n\\ntrading rules\\n  \\nachieve consistent outperformances over benchmarks in the out\\n -\\nof\\n-\\nsample periods. \\n\\nIn  fact,  the  designs  of  experiments  vary  from  study  to  study.  For  example,  the  filter  rules \\n\\nconsidered by Allen and Karjalainen (1999) are made up by closing pri\\n ces, averages of closing \\n\\nprices and local extrema of closing prices. As a comparison, in the work of Dempster and Jones \\n 4\\n \\n\\n \\n(2001),  filter  rules  appear  in  the  form  of  complex  technical  indicators.  Another  noticeable \\n\\ndifference  on  experiment  designs  of  studies \\nis  about  the  trading  frequency.  Allen  and \\n\\nKarjalainen (1999) assume daily trading while Becker and Seshadri (2003) take on monthly \\n\\ntrading\\n \\nin their work\\n . In addition to these two differences existing in the designs of experiments, \\n\\nthere still are many aspe\\ncts from which previous literature can be differentiated. \\nStudies test \\n\\nGA\\n-\\nbased filter rules with specific forms in certain stock markets but \\n there is no \\nconclusion\\n \\non\\n \\n\\nwhether the experiment designs directly impact the results. \\n In fact\\n, most of previous li\\nterature \\n\\nhas tested GA\\n-\\nbased filter rules o\\nn S&P 500 index and\\n \\nDow Jones Industrial index (Allen and \\n\\nKarjalainen  (1999),  Yu  and  Tina  (2000),  Becker  and  Seshadri  (2003),  Potvin,  Soriano  and \\n\\nVallee (2004), Yu, Chen and Kuo (2005) etc.). Another field where l\\niterature on GA\\n-\\nbased \\n\\nfilter rules gather is\\n \\nforeign exchange\\n \\n(Levich and Thomas (1993), Neely, Weller and Dittmar \\n\\n(1997), Jones (1999), Dempster, Payne, Romahi and Thompson (2000), Dempster and Jones \\n\\n(2001) etc.).  In other studies, O’Neill,  Brabazon and R\\nyan  analyze  a  number  of  markets \\n\\nincluding UK’s FTSE, Japan’s Nikkei and the German DAX. In addition, Kapoor, Dey and \\n\\nKhurana (2011) test GA\\n -\\nbased filter rules on stocks listed in National Stock Exchange in India \\n\\nwhile Shin, Kim and Han (2015) target Korea \\n Stock Price Index 200 futures. \\n Overall\\n, \\nthe debate \\n\\non  the  effectiveness  of  GA  to\\n \\ndiscover  filter  rules  that\\n \\nconsistently  beat  the  buy\\n-\\nand\\n-\\nhold \\n\\nbenchmark is still on\\n-\\ngoing.\\n \\n\\n     \\nThe first objective of this thesis is to join the literature \\n debate \\nconcerning \\nthe effectiveness \\n\\nof the GA on discovering superior trading strategies by \\n providing an out\\n -\\nof\\n-\\nsample \\ntest \\nof \\nGA\\n-\\n\\nbased trading rules in the Chinese stock market. There have been many studies covering GA\\n -\\n\\nbased filter rules but few relevant literature has pai\\nd attention to \\nthe \\nChinese stock market. \\n\\nHowever\\n,\\n \\nChinese stock market is volatile \\nand \\nthe market climates switch frequently. Also, \\n\\nmarket speculations and manipulations are common in China’s stock market as a result of the \\n\\nunusual market structure\\n. In add\\nition, the Chinese stock market is greatly influenced by the \\n\\ngovernment.\\n \\nT\\nhe\\nse\\n \\nunique \\nfeatures of \\nthe Chinese \\nstock \\nmake it difficult to apply technical \\n\\nanalysis to discover profitable strategies\\n . \\nThus, by testing whether the GA is able to consistently \\n\\ndiscover profitable trading strategies in such a unique market environment, we can shed new \\n\\nlights to the \\neffectiveness of the GA method.\\n  \\n\\n     \\nThe second contribution of this thesis is that we \\n attempt\\n \\nto \\nopen up the black box of the GA \\n\\nby \\ntesting  the \\nstatistical \\nsignificance  of  profitable  trading  rules\\n.  More  precisely,  previous \\n 5\\n \\n\\n \\nstudies have tested GA\\n -\\nbased filter rules with different experiment designs on various financial \\n\\nmarkets.  However,  among  those\\n \\nstudies  that \\nfind\\n \\nconsistent  outperforming  rules,  no \\n\\nexplanation\\ns\\n \\nha\\nve\\n \\nbeen provided why certain technical strategies \\n are\\n \\nultimately selected by the \\n\\nGA  while  others  are  not.  Namely,  the  statistical  significance  of  the  generated  profitable \\n\\nstrategies \\nhas \\nn\\not been demonstrated.  In this thesis, in addition to test\\ning\\n \\nwhether the GA\\n-\\n\\nbased rules can consistently beat the benchmark in Chinese stock market, we also \\nperform \\n\\nstatistical  analysis  to  explain  why \\ncertain  strategies \\nare\\n \\nchosen  as  the  best  ones  during \\nthe \\n\\ntesting periods.\\n \\n\\n     \\nThird, this thesis makes a methodological contribution to the studies on GA\\n-\\nbased filter \\n\\nrules by connecting \\nthe \\nliterature on \\nregime switching to th\\nat on\\n \\nthe\\n \\nGA. When \\nreviewing\\n \\n\\nprevious literature on GA\\n -\\nbased trading rules, we fi\\n nd that the majority of studies are identical \\n\\nin  one  aspect  of  experiment  designs.  Namely,  the  GA  is  used  to  refine  trading  rules  by \\n\\nnarrowing  the  solution  space  to  one  ultimate  optimal  strategy.  Correspondingly,  in  each \\n\\nexperiment the conclusion about the\\n  \\neffectiveness of GA in discovering superior trading rules \\n\\nare  based  on  the  performance  of  the  single  adopted  strategy  in  the  out\\n-\\nof\\n-\\nsample  period. \\n\\nHowever, financial markets may go through significant changes and \\n display\\n \\ndifferent dynamics\\n , \\n\\nwhich  turns  pr\\neviously  performing\\n \\ntrading\\n \\nstrategies  into  losers\\n \\nas  the  result. \\nFor  instance, \\n\\nduring the global financial crisis in 2008, stock return pattern \\n experienced significant variation\\n s\\n \\n\\nwith regard to\\n  \\nthe\\n \\nmean,\\n \\nvolatility and correlation\\n .\\n \\nProfitable trading stra\\n tegies before the crisis \\n\\nend up with significant losses. Thus, for the sake of changed market dynamics\\n , it is not \\n optimal\\n \\n\\nto \\nstick with\\n \\none fixed strategy all the time\\n \\nin trading\\n. \\nActually\\n, some previous studies have \\n\\nverified  this  concern.  Pereira  (1999) \\ninvestigate\\ns\\n \\nGA\\n-\\nbased  trading  rules  and  evaluate\\ns\\n \\nthe \\n\\nsingle optimal rule in the out\\n-\\nof\\n-\\nsample\\n \\nperiod\\n \\nfrom 1990 to 1997. The results show that the \\n\\ntrading \\nrule cannot beat  the benchmark over the  entire out\\n-\\nof\\n-\\nsample period.  In  fact, when \\n\\nexamining  the  stra\\ntegy  performances  in  sub\\n-\\nperiods,  Pereira  finds  that  excess  returns  are \\n\\npositive first but decline over time and end up being negative during the last couple of years. \\n\\nIn other word\\ns\\n, the best trading rule from the GA works well at first but becomes inferi\\nor \\n\\ngradually. Dempster and Jones (2001) realize that GA\\n-\\nbased strategies may not persistently \\n\\ndeliver superior performances as the market changes its dynamics. Thus they \\n update filter rules \\n\\nregularly to make the trading strategy\\n \\nmore adaptive to the market\\n. Besides, Potvin, Soriano \\n\\nand Vallee (2004) target 14 Canadian listed companies on TSX and acquire GA\\n -\\nbased technical \\n 6\\n \\n\\n \\ntrading rules that \\nare\\n \\nbeneficial \\nonly \\nwhen the market is stable or in downward trends. From \\n\\nthese  three  studies,  we \\nconcern\\n \\nthat,  even  i\\nf  GA\\n-\\nbased  trading  rules  can  deliver  superior \\n\\nperformances than the benchmark\\n  \\nin some cases\\n, the \\ntrading \\nrules cannot handle every market \\n\\nclimate and their outperformances may not \\npersist over time\\n. \\nMaringer and Ramtohul (2012) \\n\\nconnect regime switching to \\n the recurrent reinforcement learning (RRL) algorithm to form the \\n\\nregime\\n-\\nswitching recurrent reinforcement learning (RSRRL) model a\\n nd apply it in the trading \\n\\nof component stocks of Dow Jones Industrial Average index. According to the out\\n-\\nof\\n-\\nsample \\n\\nresults, \\nthe  RSRRL  model  achieve  better  performances  than  the  RRL  model,  which \\n\\ndemonstrates the benefit of considering regime switching in the RRL algorithm. \\nThus \\nin this \\n\\nthesis, \\nwe are motivated to \\nconnect regime switching to the GA and test whether the regime\\n-\\n\\nswi\\ntching GA\\n \\n(RSGA)\\n \\ncan outperform the GA in discovering profitable trading strategies.\\n  \\n\\n     \\nIn order to test wh\\nether consistent outperforming \\n trading rules \\nin the Chinese stock market \\n\\ncan be discovered by the GA, we choose CSI 300 index as the data and our e\\n xperiments follow \\n\\nthe framework of the work of Allen and Karjalainen (1999) except for \\nforms\\n \\nof trading rules. \\n\\nMore precisely,\\n  \\nthe filter rules in the work of Allen and Karjalainen (1999) \\n are\\n \\nbased on current \\n\\nclosing prices, averages of previous closing pr\\nices and local extrema of closing prices. But in \\n\\nour experiments, we use refined technical indicators \\nsuch as Relative Strength Index (RSI), \\n\\nMoving Average Convergence Divergence (MACD) and Bollinger Band,\\n \\nwhich is similar to \\n\\nthe work of Dempster and Jones\\n \\n(2001). According to our experiment results, the \\noptimized \\n\\ntrading rules from the GA can consistently add value to both the buy\\n -\\nand\\n-\\nhold strategy and the \\n\\nactively managed portfolio.\\n  \\nSpecifically, \\ni\\nn the out\\n-\\nof\\n-\\nsample period from 2010.01 to 2015.11\\n , \\n\\nwhile \\nthe buy\\n-\\nand\\n-\\nhold strategy for CSI 300 index achieves an \\ncumulative\\n \\nreturn of 6.12% \\n\\nwith a Sharpe ratio of 0.0024, GA\\n -\\nbased strategies \\nobtain\\n \\nan \\ncumulative\\n \\nreturn\\n \\nof at least 106%\\n  \\n\\nwith \\nthe lowest Sharpe ratio \\n being\\n \\n1.00. \\nBesides,\\n \\nGA\\n-\\nbased strategies \\nalso\\n \\nbring \\nbenefits \\nto the \\n\\nactive\\nly\\n \\nmanaged portfolio\\n \\nby increasing\\n \\nthe original\\n \\ncumulative\\n \\nreturn by more than 100% \\n\\nduring the out\\n-\\nof\\n-\\nsample period \\nfrom 2010.01 to 2015.11.\\n \\nIn fact, we also find that the data \\n\\nover\\n-\\nfitting alleviation mechanism in the work of \\nAllen and Karjalainen (1999) is essential to \\n\\nthe consistent outperformances\\n  \\nachieved\\n. When splitting the data into\\n \\nthe\\n \\ntraining (in\\n-\\nsample) \\n\\nand \\nthe \\ntesting  (out\\n-\\nof\\n-\\nsample) \\nperiods\\n,  the\\nre  is  a  significant  discrepancy\\n \\nin  the  strategy \\n\\nperformances\\n \\nbetween \\nthe\\n \\nin\\n-\\nsample\\n \\nand t\\nhe out\\n-\\nof\\n-\\nsample\\n \\nperiods.\\n \\nHowever, if we instead \\n\\ndivide the data into training\\n \\n(in\\n-\\nsample)\\n, evaluation\\n \\n(in\\n-\\nsample)\\n,\\n \\nand testing periods (out\\n-\\nof\\n-\\n 7\\n \\n\\n \\nsample) and use the evaluation period to relieve the extent of data mining, trading strategies \\n\\na\\nchieve similar performances in \\n the in\\n-\\nsample and the out\\n-\\nof\\n-\\nsample\\n \\nperiods.\\n \\n\\n     \\nWith regard to the statistical tests\\n \\non\\n \\nGA\\n-\\nbased\\n \\ntrading strategies\\n,\\n \\nour rationale is to use \\n\\nanother approach to address the same problem solved by the GA. If two different methods \\n\\nexploring the identical solution space reach similar results, the effectiveness of \\neach method \\n\\non addressing the presented problem is verified by the other \\none\\n. In the\\n \\nstatistical \\nway, \\nwe \\n\\ndefine the market into several \\nstates\\n \\nbased on the technical indicators \\nrefined by the GA. \\nBy \\n\\nregress\\ning\\n \\ndaily realized returns on\\n \\nmarket \\nstate\\ns\\n \\nusing the\\n \\nFama\\n-\\nMacBeth regression\\ns (Fama\\n \\n\\nand MacBeth, \\n1973), we acquire the \\nnumerical assoc\\niation\\ns\\n \\nbetween each market sta\\nte\\ns and\\n \\n\\nthe\\n \\nrealized  returns\\n.  Then  conclusions  on  the\\n \\nsignificance  of \\neach\\n \\nassociation \\nare  obtained \\n\\nthrough t\\n-\\ntests\\n. \\nWe find that\\n,\\n \\nthe market states significantly related to positive realized returns \\n\\nmatch  the  buy\\n-\\nsignals  fro\\nm  GA\\n-\\nbased  trading  strategies\\n.  Besides,  the  market  states \\n\\nsignificantly related to negative realized returns  also match the sell\\n-\\nsignals from GA\\n-\\nbased \\n\\ntrading strategies. \\nTake\\n \\none\\n \\nGA\\n-\\nbased strategy\\n \\nfor example, \\nsignals for taking long position of \\n\\nCSI  300  i\\nndex  are  released  whenever  the  condition \\n“DIFF>DEA & \\nMACD  histogram  is\\n \\n\\nincreasing”\\n \\nis met during the period \\n from 2005.01 to 2009.12\\n . Over the same period, the market \\n\\nstate reflected by the condition \\n “DIFF>DEA & \\n MACD histogram is\\n  \\nincreasing”\\n \\nis significantl\\ny \\n\\nassociated with positive realized returns.\\n \\nSpecifically, the t\\n-\\nstatistic of this association is 2.89 \\n\\nin the Fama\\n -\\nMacBeth regression. \\nNamely, the GA and the statistical methods provide identical \\n\\ntrading  strategy  during  the  same  period  of  time.  Ther\\nefore,  on  the  one  hand,  through  the \\n\\ncomparisons \\nwe verify the effectiveness of the GA on finding profitable trading strategies\\n . On \\n\\nthe other hand, \\nwe open up the black box of the GA and explain why the GA \\n ultimately choose \\n\\ncertain trading strategies as the\\n  \\nbest ones\\n. \\n \\n\\n     \\nThe\\n \\nregime\\n-\\nswitching\\n \\nGA\\n \\n(RSGA)\\n \\nmodel is\\n \\nthe result of combining literature on GA\\n -\\nbased \\n\\ntrading strategy and that on regime switching.\\n \\nAng and Bekaert (\\n1999) concluded that high\\n-\\n\\nvolatility  regime\\n \\nand  low\\n-\\nvolatility  regime \\nexist  in  equity  m\\narket. \\nMaringer  and  Ramtohul \\n\\n(2\\n012) connect regime switching with\\n  \\nthe recurrent reinforcement learning (RRL) algorithm to \\n\\nform the regime\\n-\\nswitching recurrent reinforcement \\nlearning (RSRRL) model. In the\\n \\nwork\\n \\nof \\n\\nMaringer and Ramtohul (2012), the volatilitie\\n s are\\n \\nutilized to switch between regimes. \\n Due to \\n\\nthe frequent changes of dynamics in the Chinese stock market, the\\n  \\nvolatility is one of the most \\n\\nimportant  factor\\ns\\n \\nto  concern  when  trading  stocks.  Therefore\\n,\\n \\nin \\nthis  thesis\\n,  we  attempt\\n \\nto \\n 8\\n \\n\\n \\nidentify 2 market re\\ngimes \\nbased on\\n \\nvolatilities \\nand generate regime\\n-\\nspecific trading strategies \\n\\nfrom the GA method.\\n \\nMore precisely, based on the predicted volatilities from GARCH\\n \\n(1\\n, 1\\n) \\n\\nmodel in the out\\n-\\nof\\n-\\nsample period, the GA come\\n s\\n \\nup with a volatility threshold \\n and \\nsegregates \\n\\nthe market into two\\n \\nregimes accordingly. Then GA\\n-\\nbased trading \\nstrategie\\ns specific to each \\n\\nregime are generated and the exact strategy in effect is determined by the existing regimes. The \\n\\nexperiment outcomes show that, the optimal trading strate\\ngy\\n \\nfrom the RSGA model\\n \\nachieves\\n \\n\\na\\n \\ncumulative\\n \\nreturn  of  168%  with  a  Sharpe  ratio  of  1.17  in  the  out\\n-\\nof\\n-\\nsample  period  from \\n\\n2010.01 to 2015.11, compared to the GA\\n-\\nbased strategy \\nwhich obtain\\ns \\na\\n \\ncumulative\\n \\nreturn of \\n\\n106% with a Sharpe ratio around 1.00. \\n In sum\\nmary\\n, \\nconsidering\\n \\nregime switching makes GA\\n -\\n\\nbased rules more adaptive to the market and \\ndelivers significantly higher\\n \\nreturns \\nwith\\n \\nlower \\n\\nrisks.\\n \\n\\n     \\nOverall, this thesis contribute\\ns\\n \\nto the literature \\nalong three lines\\n. First, \\nwe provide \\nan out\\n-\\n\\nof\\n-\\nsample \\nte\\nst on the effectiveness of GA \\nbased on the framework of the work of Allen and \\n\\nKarjalainen (1999) \\n using\\n \\nthe \\nCSI 300 index from \\n the \\nChinese stock market, Second, we present \\n\\na clearer picture from statistical \\n analysis\\n \\nto explain why certain trading rules are \\n discovered by \\n\\nthe \\nGA \\nin testes.\\n \\nThird, we make a methodological contribution to\\n  \\nthe\\n \\nliterature on GA\\n-\\nbased \\n\\nfilter rules by connecting regime switching with the GA\\n \\nand use the regime\\n-\\nswitching GA\\n \\nto \\n\\ngenerate \\nbetter trading\\n \\nstrategies \\nthan those\\n \\nfrom the GA.\\n \\n \\n\\n     \\nThe remaining parts of the\\n  \\nthesis is \\norganized\\n \\nas follows. In section 2 we\\n  \\nconduct literature \\n\\nreview\\n. Section 3 \\n elaborate\\ns\\n \\non the \\nmethodology. Section 4 \\n describes\\n \\nthe data, experiments and \\n\\nresults. Section 5 presents conclusions and implications.\\n  \\n\\n2.\\n \\nLi\\nterature\\n \\nR\\neview\\n \\n\\n \\n\\n     \\nSection 2 presents the literature review of this thesis. There have been abundant studies \\n\\ncovering the topic of leveraging GA to identify superior technical trading rules. Since technical \\n\\nanalysis belongs to \\n the \\ninductive reasoning, l\\n iterature review starts by reviewing studies on \\n the \\n\\ninductive reasoning and \\nfilter rules\\n. After that, we go through some important researches on \\n\\nutilizing \\nthe \\nGA to discover technical trading rules\\n. Last but not least, we present studies on \\n\\nthe  regime\\n-\\nswit\\nching\\n \\nmodel\\n.  Specifically,  section  2.1  reviews  the  studies  on  inductive \\n\\nreasoning;\\n \\nsection 2.2 presents literature\\n \\non filter rules; section 2.3 displays literature on GA\\n-\\n 9\\n \\n\\n \\nbased  technical  trading  rules;  section  2.4  revi\\news  studies  on  regime  switching; \\nsection  2.5 \\n\\nidentify the gaps in literature and presents the contributions of this thesis.\\n  \\n\\n2.1\\n \\nInductive Reasoning\\n \\n\\n     \\nOver  time,  there  has  been  assumptions  of  the  nature  of  market  participants \\n–\\n \\neither \\n\\nhomogeneous or heterogeneous. On the one hand, if al\\n l the participants are homogeneous, there \\n\\nwill be one single, objective forecasting shared by everyone. In this case, participants resort to \\n\\ndeductive reasoning because this logic can reach a determinacy under homogeneity. On the \\n\\nother hand, heterogeneity \\neliminates such objective expectation and participants make their \\n\\nown prediction based on the information they have, which includes historical prices, volumes, \\n\\nestimation of others’ belief and so on. Due to the indeterminacy in forming expectations by \\n\\ndedu\\nctive reasoning, a more realistic assumption in the real world is that, market participants \\n\\nare heterogeneous and they turn to inductive reasoning in making prediction. (W. Brian Arthur, \\n\\nJohn H Holland et al. 1996). Even though all the participants share t\\nhe available information \\n\\nconsisting of historical prices, past trading volumes and previous dividends, different traders \\n\\nstill rely on different assumption and approach to take advantage of the shared information, \\n\\nwhich  will,  lead  to  the  lack  of  identical \\nforecasting  model  and  volatile  outcomes.  Besides, \\n\\nheterogeneous participants will never have an objective way to know the expectation models \\n\\nof each other. In this case, deductive reasoning ends up with indeterminacy. Instead of deducing \\n\\nthe  expectations, \\nmarket  participants  come  up  with  various  hypothesis  based  on  gathered \\n\\ninformation and verify the accuracy by corresponding performance in the real market (Blume \\n\\nand Easley, 1990). As a result of this, each participant constantly forms and updates “market \\n\\nh\\nypotheses”  subjectively \\n–\\n \\nthose  hypotheses  predicting  market  movements  well  will  be \\n\\nretained and used as trading signals and the underperforming ones will be discarded. From time \\n\\nto  time,  the  filter  mechanism  will  make  it  clear  which  hypotheses  work  well  a\\nnd  market \\n\\nparticipants learn and adapt during the whole process. Therefore, the inductive reasoning is \\n\\ndefined as the process where market participants generate, test and replace hypothetical models \\n\\non a continuing bases.\\n \\n\\n     \\nArthur (1992) argues that when dealing with complex or ill\\n-\\ndefined problems, economic \\n\\nagents move away from the standard notion of rationality and are forced to rely on inductive \\n\\nreasoning. Economic agents generate, monitor and update their internal models\\n  \\nand hypotheses \\n\\nof faced problems. Arthur (1992) also proposes that, in order for the deductive reasoning to get \\n 10\\n \\n\\n \\ninto a rational expectation equilibrium, several conditions must be met. First, each agent should \\n\\nhave full knowledge of the problem. Second, e\\nach agent has perfect ability to compute the \\n\\nsolution. Third, there is only one unique solution. Fourth, each agent is aware that other agents \\n\\nsatisfy the first and the second conditions. Furthermore, Arthur (1994) lists two reasons why \\n\\ndeductive  rationali\\nty  fails  to  work  under  complication.  First,  the  logic  apparatus  of  market \\n\\nagents cannot catch up once the complexity of faced problems exceed\\ns\\n \\ncertain level. Second, \\n\\nunder complication agents no longer get to be aware precisely of other agents’ beliefs. Fo\\n r the \\n\\nsake  of  these  two  reasons,  objective  and  shared  assumptions  do  not  apply  anymore  and \\n\\ncorrespondingly, the deductive reasoning which comes from perfect logic procedure cease to \\n\\napply.  As  a  result,  human  in  complicated  situations  are  considered  to  poss\\ness  bounded \\n\\nrationality and their behaviors are instead described by inductive reasoning. When considering \\n\\nthe operation of equity markets, we find that many previous literature has challenged the perfect \\n\\ndeductions of fully rational investors from efficie\\n nt market theory and defined the way market \\n\\nparticipants behave as one example of inductive reasoning with bounded rationality. Shiller \\n\\n(1989) shows that trading volume and volatilities in equity markets are large rather than being \\n\\nsmall or zero as propose\\n d by efficient market theory. Besides, O’Hara (1995) demonstrates that \\n\\ntrading volume and volatilities display significant autocorrelation as opposed to the conclusion \\n\\nof efficient market theory that neither trading volume nor volatilities are serially cor\\nrelated. \\n\\nArthur, Holland, LeBaron, Palmer and Tayler (1996) demonstrate that traders do not agree with \\n\\nthe efficient market theory which assumes market agents are identical in the sense that they \\n\\nshare rational expectations of financial assets and incorpor\\n ate all information into pricing assets \\n\\nand there is no way to achieve consistent speculative profit. By contrast, traders regard the \\n\\nmarket as imperfectly rational that the existence of “market psychology” makes speculative \\n\\nchances  possible.  Arthur,  Holla\\nnd,  LeBaron,  Palmer  and  Tayler  (1996)  also  show  that \\n\\ndeductive  reasoning  leads  to  an  indeterminacy  whenever  the  heterogeneity  of  agents  are \\n\\nintroduced  in.  As  the  result  of  failed  deductive  reasoning,  agents  must  turn  to  inductive \\n\\nreasoning to from their ex\\npectations. Specifically, market agents gathered observed data and \\n\\ncome up with several subjective hypotheses, which can be verified by only their corresponding \\n\\nperformances in the market.\\n  \\n\\n     \\nThere are some advantages of the inductive reasoning structure\\n. First of all, biases of any \\n\\nfixed  forecasting  model  will  be  avoided  through  the  competence  among  different  models. \\n 11\\n \\n\\n \\nSecondly, inductive reasoning enables heterogeneity to exist rather than having an identical \\n\\nexpectation. In addition, this structure bette\\nr reflects the real market, where volatile models \\n\\nwill be derived by participants as a results of the recognition differences among participants.\\n  \\n\\n2.\\n2\\n \\nFilter Rules\\n \\n\\n     \\nIn\\n \\nstock market, both individual and institutional investors have been broadly leveragin\\ng \\n\\ntechnical \\nanalysis\\n \\nin the investing process to construct, adjust and terminate the portfolio. \\n\\nHowever, the reality shows that, due to the complexity of stock market structure, investors \\n\\nperforming technical analysis manually frequently end up suffering f\\nrom losses. Therefore, \\n\\nover the years, the effectiveness of technical analysis in promoting stock trading performance \\n\\nhas always been a focus of research and many results show that, most of the trading patterns \\n\\nbased on these rules do not work well\\n ((Alexan\\nder, 1961), (Fama and Blume, 1966), Allen and \\n\\nKarjalainen, \\n1999)\\n)\\n.\\n \\nBasically, filter rules evolve by taking on more complicated forms and \\n\\nrequiring more information to make. Originally, filter rules are simply based on the maximum, \\n\\nminimum and average of c\\nlosing prices with some mark\\n-\\nups during certain period of time\\n \\n\\n((Alexander, 1961), (Fama and Blume, 1966), (William, Josef and Blake, \\n1992)\\n)\\n. Later on, \\n\\non the one hand, more complex considerations have been given to forming what are known \\n\\nby  market \\nparticipants  nowadays  as  technical  indicators  including  RSI  (Relative  Strength \\n\\nIndex), Bollinger Band and so on\\n((Dempster and Jones, 2001),\\n \\n(Boboc and Dinica, 2013), \\n\\n(Wiles and Enke, 2015))\\n.  On the other hand, information other than closing prices is used\\n  \\nin \\n\\nconstructing new technical indicators. For example, volumes of stocks are leveraged to form \\n\\nthe indicator VRSI (Volume Relative Strength Index). Standard deviations of returns of stocks \\n\\nare important inputs of the indicator Bollinger Band.\\n  \\n\\n \\n     \\nThe ma\\njority of this literature is performed on S&P and Dow Jones stock indices. During \\n\\nthe early periods, Alexander (1961) tests some ‘filter rules’ and finds that positive excess \\n\\nreturns over buy\\n -\\nand\\n-\\nhold are achievable, but the outperformance vanishes when tr\\n ading costs \\n\\nare taken into consideration.\\n \\nAlexander (1961) proposes an x\\n-\\npercent filter based on dail\\ny \\n\\nclosing prices of securities \\n in S&P Industrials and Dow Jones Industrials to test whether stock \\n\\nprices can incorporate new information on a gradually bas\\nis. The results of his experiments \\n\\nshow  that  this  proposition  is  valid  for  x  ranging  from  5  percent  to  30  percent.  However, \\n\\nAlexander (1964) find that when considering commissions of 2% for each round\\n-\\ntrip, only \\n\\nthe  largest  filter  (45.6%)  beat  the  buy\\n-\\nand\\n-\\nhold  by  a  great  margin  while  others  cannot \\n 12\\n \\n\\n \\noutperform the buy\\n-\\nand\\n-\\nhold after costs.\\n \\nSmidt (1965) tests 40 filter rules on May soybean \\n\\nfuture  contracts  and  finds  that  70%  of  tested  rules  are  able  to  bring  positive  returns  after \\n\\ncommissions. Fama and Blume (\\n1966) extend the work of Alexander (1964) by testing 24 \\n\\nfilter rules with parameters ranging from 0.5% to 50% on 30 individual stocks of the DJIA \\n\\nbut only to find 4 of 30 stocks can deliver average positive returns after costs per filter. Besides, \\n\\nmost  of \\nthe  filter  rules  are  not  superior  to  the  buy\\n-\\nand\\n-\\nhold  strategy  before  commission. \\n\\nNamely\\n, Fama and Blume (1966) fail to identify any profitable trading rules on 30 Dow Jones \\n\\nstocks.\\n \\nXiao\\n-\\nMing  Li  and  Kong\\n-\\nJun Chen (2006) used eight years’ daily stock price \\nand \\n\\ntrading volume data of 39 corporations listed on the Shenzhen Stock exchange, but only to \\n\\nfind extremely weak evidence for the predictability of technical analysis in China’s stock \\n\\nmarket. \\n \\n\\nOn the other hand, there still are some \\nsupport for technical \\nanalysis. William, Josef and \\n\\nBlake (1992) test two of the simplest filter rules\\n  \\n(\\nmoving average and trading range break\\n ) on \\n\\nDow Jones Index from 1897 to 1986 and provide strong support for technical analysis. \\n Choi \\n\\net al. (1995) ended up generating predicti\\n ons of 62.5% accuracy for in\\n -\\nsample data and 63.8% \\n\\nfor the entire data set. Levy (1966) reports testing results of 68 filter rules with few of them \\n\\nbased only on past prices and finds that all of them are able to provide higher returns than \\n\\nbuy\\n-\\nand\\n-\\nhold st\\nrategy. Van Horne and Parker (1967), James (1968), test the filter rules in the \\n\\nform of moving averages of previous prices but still fail to discover any rule beating buy\\n -\\nand\\n-\\n\\nhold in terms of profitability. Sullivan, Timmermann and White (1999) test filter\\n  \\nrules in the \\n\\nform of support and resistance level, channel breakout and on\\n -\\nbalance volume (OBV) on Dow \\n\\nJones Industrial Average and S&P 500 index futures and give affirmative conclusions about \\n\\ntested filter rules outperforming buy\\n-\\nand\\n-\\nhold strategy. \\nMicha\\nel (1999) used filter rules on \\n\\nlagged return and lagged volume data of large\\n-\\ncapitalization listed securities on NYSE and \\n\\nAMEX\\n \\nand  found  that  stocks  with  decreasing  volumes  experience  greater  reversals  than \\n\\nstocks with increasing volumes.\\n \\nIn later period o\\nf time, b\\ny revealing information from some \\n\\ntechnical indicators, for example, RSI (relative strength index) and ROC (rate of change)\\n  \\nand \\n\\nclosing  price,  low,  high, \\nmoving \\naverage, \\nWong,  Manzur  and  Chew  (2003)  test  Relative \\n\\nStrength  Index  (RSI)  on  Singapore \\nStraits  Times  Industrial  Index  and  find  that  RSI  rules \\n\\nproduce statistically significant returns over all three sub\\n -\\nperiods.\\n \\n 13\\n \\n\\n \\n2.3 Genetic Algorithm\\n \\n\\n     \\nAs the earliest computer scientists, Alan Turing, Norbert Weiner, John Von NeuMann and \\n\\nothers aim to cre\\nate artificial intelligence and entitle computer programs with life\\n -\\nlike abilities \\n\\nto  learn  and  adapt  to  the  environment.  The  ultimate  goal  of  artificial  intelligence  is  for \\n\\ncomputers to model human brains and mimic human learnings. Mitchell (1995) mention\\n s that \\n\\nstudies on computer artificial intelligence has grown into three fields, namely neural networks, \\n\\nmachine learning and evolutionary computations with GA being the most prominent example \\n\\nin evolutionary computations.\\n  \\nGA was first discovered by John Ho\\n lland in the 1960s to mimic \\n\\nthe  biological  evolution  in  addressing  computational  problems.  Later  on,  Holland  and  his \\n\\nstudents  made  further  progression  on  GA  in  the  1970s.  In  Holland’s  GA,  solutions  are \\n\\npresented in the form of bit\\n-\\nstrings made up by “chrom\\nosomes” and the biological evolution \\n\\nproceeds by transferring “chromosomes” from previous generations t\\no following ones. The \\n\\nevolution  is implemented\\n \\nby  crossovers  and  mutations  of  the  bit\\n-\\nstrings.  Specifically,  each \\n\\ncrossover works by cutting two bit\\n -\\nstri\\nngs into two pieces and exchanging one subpart, which \\n\\nimitates the procedure of biological recombination of  genes from  chromosomes. Mutations \\n\\nchange values of certain bits in the strings and these processes are similar to the gene mutations \\n\\nof human. Howev\\ner, the way crossovers and mutations happen to bit\\n-\\nstrings is not random. \\n\\nInstead, there is a mechanism in place to assure “\\nstrong\\n \\ngenes” are kept and passed over to \\n\\nsubsequent generations while “bad genes” are discarded. Over the years, the GA has been \\n\\nutilized  on  various  kinds  of  aspects.  For  example,  the  GA  has  been  used  in  optimization \\n\\nproblems  such  as  circuit  layout  and  job\\n-\\nshop\\n \\nscheduling.  Besides,  we  can  also  see  the \\n\\nappearance of GA in machine\\n -\\nlearning tasks such as weather predictions. However, it was not \\n\\nuntil 1999 did the GA extend its adaptive ability to trading. In financial markets, the price is \\n\\nthe most important metric\\n \\nfor any asset and market participants fulfill trading according to \\n\\ncertain prices. One logic of a trader in trading is to buy certain asset whenever its quoted price \\n\\nis lower than the fair value and sell certain asset whenever its quoted price is higher t\\nhan its \\n\\nfair value. Therefore, the rationale of trading in this case is based on the relationships between \\n\\nquoted prices and fair values and this kind of relationships can be turned into the form of bit\\n-\\n\\nstrings. To be more precise, each trading strategy  ca\\nn be transformed into a bit\\n-\\nstring, and \\n\\ncorrespondingly each bit\\n-\\nstring can be interpreted into one trading strategy. This fact makes it \\n\\npossible to using the GA to refine trading strategies since, during the evolution, only “good \\n\\ngenes” of strategies are \\n maintained to form subsequent generations of trading strategies.\\n  \\n 14\\n \\n\\n \\n     \\nAs a result of the lack of consensus on effective “filter rules”, over the years there has been \\n\\nan increasing amount of studies aimed at addressing this problem. Within those studies, Ge\\n netic \\n\\nAlgorithm  (GA)  has  be  became  one  of  the  most  important  approach  to  discover  profitable \\n\\ntrading strategies for investment purpose. As an important part of machine learning, Genetic \\n\\nAlgorithm has been used for various kinds of purposes and nowadays, an\\n d there is an increasing \\n\\nutilization of Genetic Algorithm in stock trading. One motivation to take advantage of Genetic \\n\\nAlgorithm when trading stocks is, to spare investors the necessity to perform technical analysis \\n\\nmanually, which could even be possibly \\nincorrect and conveys misleading signals, especially \\n\\nwhen considering the ability of GA to explore the entire solution space to an extent that is also \\n\\nnot achievable manua\\n lly. The second merit of GA is \\n about its covered breadth and deepness in \\n\\nlearning and\\n \\nthe reason why GA can accomplish this goal is because it can incorporate not only \\n\\nany mix of technical indicators but also diversified fundamental factors, which \\nis extremely\\n \\n\\nimportant for equity investment decision making. Also, GA is able to take variou\\ns constrains \\n\\ninto  its  framework  and  to  address  multi\\n-\\nparameter  problems,  which  led  it  to  the  widely \\n\\napplication  in  stock  trading.\\n \\nDespite  these  merits  of  GA,  the  way  how  it  is  applied  and \\n\\nconnected to practice is essential to eventual investment results. A\\nctually, there has been an \\n\\ninconsistency,  according  to  the  literature  on  this  topic  so  far,  about  the  effectiveness  of \\n\\nleveraging  GA  on  enhancing  investment  results.  By  making  GA  a  part  of  the  investment \\n\\nprocess, some researchers are able to consistently a\\nchieve outperformance in out\\n-\\nof\\n-\\nsample \\n\\nwith cost taken into consideration while others are not. Specifically, most failures up to now \\n\\nare  considered  as  the  results  of  using  daily  data  instead  of  trading  on  a  monthly  basis. \\n\\nFurthermore, another controversy \\non this topic is about the kind and complexity of technical \\n\\nindicators to use in order to achieve success.\\n  \\n\\n     \\nAs the pioneer in applying Genetic Programming (GP) to \\n find trading strategies, Allen and\\n  \\n\\nKarjalainen (1999) use S&P 500 index daily price data \\n from 1928 through 1995, but the rules \\n\\nfound c\\nan\\nnot beat \\nthe \\nbuy\\n-\\nand\\n–\\nhold strategy with\\n \\none\\n-\\nway\\n \\ntrading costs\\n \\nof 0.25%\\n \\nac\\ncounted \\n\\nin the out\\n-\\nof\\n-\\n \\nsample data set. \\nIn their work, there are two kinds of functions: real functions \\n\\nand  Boolean  functions.  Real  func\\ntions  are  those  used  to  derive  moving  average  and  local \\n\\nextrema of prices \\nas well as arithmetic operators. Boolean functions include logical functions \\n\\ndefining the relationship between two real numbers. \\n  \\n 15\\n \\n\\n \\nDempster and Jones (2001) come up with a  GA\\n-\\nbased te\\nchnical tra\\nding  rules developed \\n\\nsystem,  from  which  the  best  rule  found  achieve  significantly  modest  profit  on  trading  US \\n\\nDollar/British Pound. The first major change they make when compared to the work of A&K \\n\\n(1999)  is  that,  instead  of  relying  on  the  simpl\\nest  filter  rules  like  closing  price  and  moving \\n\\naverages, they utilize a combination of broad range of more refined technical indicators. For \\n\\nexample,  technical  indicators  listed  within  their  work  include  but  are  not  limited \\nto  CCI, \\n\\nMACD, MA Crossover, RSI \\n and AMA. \\nBesides, another modification from previous literature \\n\\nin their work that is directly associated with the consistent outperformance in out\\n -\\nof\\n-\\nsample is \\n\\nthe adaption system. Specifically, this system works by generating technical trading rules by \\n\\nG\\nA at regular intervals to have a feedback on the performance of existing rules. Namely trading \\n\\nrules are updated on a continuous basis and underperformed rules will be discarded or replaced \\n\\nby newly generated rules that deliver better performances. \\nThe Dem\\npster and Jones approach \\n\\nbreaks \\nthe \\nprevious routine in using GA to discover one fixed technical trading rules to apply \\n\\nin the entire out\\n -\\nof\\n-\\nsample test period and reach the conclu\\n sion of performance based on it\\n . For \\n\\nthe first time different trading rules \\nare utilized\\n \\nduring the tests of GA\\n-\\nbased strategies\\n \\nin one \\n\\nout\\n-\\nof\\n-\\nsample test period, the implication of this modificati\\non is that trading rules in effect \\n\\nadapt to the market climates from which they are generated. \\n  \\n\\nBecker and\\n \\nSeshadri (2003) mak\\ne some \\nmodif\\nications \\nincluding adopting monthly instead \\n\\nof  daily \\ntrading\\n, \\nand \\nintroducing  a  com\\nplexity\\n-\\npenalizing  factor  to  the  work  of \\nAllen  and\\n \\n\\nKarjalainen (1999)\\n \\nand presented GP\\n-\\nevolved technical trading rules that outperformed buy\\n-\\n\\nand\\n-\\nhold  strategy  on  the  S&\\nP  500.\\n \\nEven  though  those  two  modifications  are  considered \\n\\nessential to acquire trading rules with outperformances over buy\\n -\\nand\\n-\\nhold, there still are some \\n\\nother differences between experiment details. In the work of \\nBecker and\\n \\nSeshadri (2003)\\n, the \\n\\ndata used\\n \\ninclude not only closing prices but also openings, highs and lows of each month.  In \\n\\naddition, they also introduce two price resistance markers which are respectively \\n two previous \\n\\n3\\n-\\nmonth moving average minima and two previous 3\\n-\\nmonth moving average maxim\\na, which \\n\\ndo not exist in the work of \\n Allen and\\n \\nKarjalainen (1999)\\n. \\n  \\n \\n\\nXue\\n-\\nZhong  He  et  al  (2007)  make  further  innovation  on  the  kind  of  filter  rules  to  be \\n\\nconsidered in GA. While Dempster and Jones (2001) extend technical trading rules to a broader \\n\\nrange in\\ncluding many complicated technical indicators like MACD, RSI\\n ,\\n \\nAMA and so on, He \\n\\net al (2007) \\n co\\nme up with \\n classified rules\\n \\nin five groups\\n \\nincluding fundamental value, technical \\n 16\\n \\n\\n \\nrules, recent changes in quotes, bid\\n-\\nask spread, order book depth imbalance and\\n \\nthe last trade \\n\\nsign. \\nThis  adjustment  puts  new  elements  into \\nthe \\nsolution  space  and  additionally  absorbs \\n\\nmarket  information  other  than  price  and  volume  data.  By  adding  fundamental  values  and \\n\\ninformation from limit order book\\n  \\ninto the solution space where G\\nA explore\\n, \\nthe \\nresults show \\n\\nthat \\ngenerated trading rules \\n become \\nmore\\n \\nwell\\n-\\nrounded and\\n \\napplicable.\\n \\nFurthermore\\n, Lohpetch \\n\\nand Corne \\n(2009) display\\n \\nthat additional modification on\\n \\nthe\\n \\nwork\\n \\nof \\nBecker and Seshadri\\n \\n\\n(2003)\\n \\nled to strategies enjoying consistent excess return over \\nthe \\nbuy\\n-\\nand\\n-\\nhold\\n \\nstrategy\\n \\nfor \\n\\nmonthly trading, which is, however, relatively rare for daily trading and situation for weekly \\n\\ntrading is in between.\\n \\nThey conclude that the Becker and Seshadri\\n \\n(2003)\\n \\napproach is able to \\n\\ngenerate trading rules outperforming \\n the \\nbuy\\n-\\nand\\n-\\nhold\\n \\nstrategy\\n. \\n \\n\\nHowever,  the  outperformance  is  sensitive  to  data  splits,  especially  when  moving  from \\n\\nmonthly to daily trading.\\n \\nA majority of early research conducted on this topic end up \\nwith \\n\\nperformance  discrepancy  between  in\\n-\\nsampl\\ne  data  and  out\\n-\\nof\\n-\\nsample  data.  One  of  the \\n\\nexplanation is that, b\\n eing one of the machine learning method, GA is not able to avoid the data\\n -\\n\\nmining problem. As a result, many studies come up with some methods to re\\nlieve, if couldn’t \\n\\navoid completely, the data\\n -\\nmining problem. For instance, Allen \\n and\\n \\nKarjalainen (1999), instead \\n\\nof working on some certain technical indicators, let GA to reveal the best form of rules in \\n\\naddition  to  refine  parameters.\\n \\nAnother  mechanism  t\\nhey  have  to  deal  with \\nthe \\ndata\\n-\\nmining \\n\\nproblem is to split the entire data into 3 parts \\n–\\n \\ntraining, evaluation and testing periods. In this \\n\\nframework, the best trading rules filtered by GA is not only purely based on the data GA work \\n\\nwith, the evaluation pe\\nriod plays an essential role in reliving over\\n-\\nfitting problem in training \\n\\nperiod and leads to a more consistent result in different data set. However, they still fail in \\n\\nachieving consistent outperformance relative to\\n  \\nthe\\n \\nbuy\\n-\\nand\\n-\\nhold \\nstrategy \\nin\\n \\nthe\\n \\nout\\n-\\no\\nf\\n-\\nsample\\n \\n\\nperiods\\n. \\nSimilarly\\n, Tina Yu, Shu\\n-\\nHeng C\\nhen \\nand Tzu\\n-\\nWen Kuo (2005) utilize the same\\n \\ndata\\n-\\n\\nmining  alleviation\\n \\nmechanism  as \\nthe  work  of \\nAllen  and  Karjalainen  (1999)\\n.\\n \\nHowever,\\n \\nby \\n\\ncombining GA with lambda abstraction,\\n \\neventually \\nthey succeed in finding \\nprofitable trading \\n\\nrules regardless of the\\n \\nmarket climate. \\nIn this thesis, we also apply this method in addressing \\n\\ndata\\n-\\nmining problem\\n. \\n \\n\\nAnother example to alleviate data over\\n-\\nfitting problem can be seen in the work of Becker \\n\\nand Seshadri (2003), where the\\n y impose a complexity penalizing factor on the fitness function \\n\\nto  come  up  with  a  bias  toward  simplicity. \\nAs  a  result,  this  penalty  mechanism  greatly \\n 17\\n \\n\\n \\ncontribute\\ns\\n \\nto, if not determine directly, the improvement on the work of \\n Allen and Karjalainen \\n\\n(1999)\\n.\\n \\n \\n\\nI\\nn addition\\n \\nto help beating buy\\n-\\nand\\n-\\nhold on equity trading\\n, genetic algorithm has also been \\n\\nused in many other  aspects of \\ninvestment\\n \\nmanageme\\nnt. Mahfoud  and Mani (1995) use the\\n \\n\\ngenetic algorithm to select stocks while Kindom and Feldman (1995) try to predic\\n t ban\\nkruptcy, \\n\\nWalker (1995) uses the GA to evaluate credits\\n . Some other applications involve that Zhou and \\n\\nDunis (1998) f\\nind\\n \\nthe optimal parameter for an important technical indicator RSI using GA in \\n\\ntheir  research  of  a  FX  trading  system  and  that  Packard  (\\n1990)  appl\\nies  the\\n \\nGA  into  budget \\n\\nalloca\\ntion. Potvin et al (2004) prove\\n \\nthat Genetic Programming\\n-\\nevolved rules worked well in \\n\\nmarkets tha\\nt are either stable or falling.\\n  \\nWith increasing number of research covering this topic, \\n\\nthe GA\\n \\nhas extended its content \\nand versatile classified metrics has been put into the process \\n\\nto  investigate  some  previously  unknown  area  and  try  to  generate  potentially  beneficial \\n\\nstrategies. For instance, Marney et al. (2001) \\nintroduce\\n \\nsome risk measures while Khai and \\n\\nCheng (2002) dr\\na\\nw on modified sterling metric, to favor those rules with lower risk. \\n  \\n\\n2.4\\n \\nRegime Switching\\n \\n\\n     \\nFinancial markets are not permanently stable, instead some abrupt changes take place now \\n\\nand then. These changes may give rise to extended periods with difference\\n s\\n \\nbetween behaviors \\n\\nor dynamics of financial series. Therefore, because of the significant variations in asset pricing \\n\\nacross periods of time, those certain periods are distinguished and defined as corresponding \\n\\nregimes.\\n \\nFor instance, stock return patterns \\n with regard to mean, volatility and correlation have \\n\\nexperienced significant variation through the global financial crisis happened in 2008.\\n  \\nIn fact, \\n\\nsome previous studies on GA\\n -\\nbased trading rules give rise to the concern that it is not optimal \\n\\napplying o\\nne fixed strategy all the time regardless of the market climates. \\n  \\n\\nPereira (1999) investigate GA\\n-\\nbased technical trading rules and evaluate the single optimal \\n\\nrule in the out\\n-\\nof\\n-\\nsample from 1990 to 1997. The results show that the rule cannot beat the \\n\\nbench\\nmark  over  the  entire  out\\n-\\nof\\n-\\nsample  period.  In  fact,  when  examining  the  strategy \\n\\nperformances in sub\\n -\\nperiods, Pereira finds that excess returns are positive first but decline over \\n\\ntime and end up being negative during the last couple of years. In other word\\n , the best trading \\n\\nrule from the GA works well at first but becomes inferior gradually. Dempster and Jones (2001) \\n\\nrealize  that  GA\\n-\\nbased  strategies  may  not  persistently  deliver  superior  performances  as  the \\n\\nmarket changes its dynamics. Thus they introduce an\\n  \\nadaptive system to make the strategies in \\n 18\\n \\n\\n \\neffect  more  adaptive  to  the  market.  The  adaptive  system  works  by  leveraging  the  GA  to \\n\\ngenerate  trading  strategies  at  regular  interval,  trading  rules  in  effect  are  discarded  when \\n\\nbecoming losers or replaced when be\\ntter rules have been generated. Besides, Potvin, Soriano \\n\\nand Vallee (2004) target 14 Canadian listed companies on TSX and acquire GA\\n -\\nbased technical \\n\\ntrading rules that can be beneficial when the market is stable or in downward trends. From \\n\\nthese  three  stud\\nies,  we  find  that,  even  if  GA\\n-\\nbased  trading  rules  can  deliver  superior \\n\\nperformances  than  the  benchmark,  the  rules  cannot  handle  every  market  climate  and  their \\n\\noutperformances may not be extended to a long period of time. Thus we are motivated to make \\n\\nGA\\n-\\nba\\nsed trading rules more adaptive to the market in this thesis.\\n  \\n\\n     \\nAmong  the  early  studies  covering \\nregime  switching,  Quandt  (1958)  estimates  the \\n\\nparameters of a linear regression system experiencing two separate regimes and implies that \\n\\nthe first necessar\\ny step is to identify the position of point in time when the switching takes \\n\\nplace.  In  his  study,  economic  variables  are  linearly  connected  to  some  factors  with  the \\n\\nparameters of the relationship are subject to discontinuous changes. Namely, in addition to\\n  \\nthe \\n\\nfactors enjoying a linear relationship with economic variables, there are still other factors in \\n\\nplace that non\\n-\\nlinearly explain them as well. Goldfeld and Quandt (1973) \\ncome\\n \\nup with an \\n\\ninfluential model which is known as Markov\\n-\\nswitching model to cap\\nture the occurrence of \\n\\nregime \\nswitching\\n.\\n \\nAng and Bekaert\\n \\n(199\\n9\\n) \\nconclude\\n \\nthat two regimes exist in equity market. \\n\\nThe first regime are the periods when stock returns are more volatile while the second regime \\n\\nstands for relatively flat periods of time. Besi\\n des, stock return correlations are different between \\n\\ntwo regimes.\\n \\nAng and Timmermann (2011) co\\nme\\n \\nup with 3 advantages of regime \\nswitching \\n\\nmodels. First, regime switching is natural and intuitive, therefore the application of regime \\n\\nswitching  models  is  able\\n \\nto  help  capturing  business  activity  cycles  over  a  long\\n-\\nterm  trend. \\n\\nSecond, \\nregime switching models are  able to identify stylized dynamics  of fin\\nancial assets \\n\\nincluding skewness\\n, fat tails, time\\n-\\nvarying correlations and so on. Finally, regime switching \\n\\nmod\\nels  are  capable  of  capturing  non\\n-\\nlinear  behaviors  of  financial  asset  returns  with  linear \\n\\nspecification\\n \\nto  make  asset  pricing  under  regime  switching  tractable.\\n \\nHowever,  different \\n\\nmetrics are used to define regimes for different categories of financial asset\\n s. In terms of equity, \\n\\none  way  to  distinguish  regimes  is  to  identify  bull  and  bearish  market  periods.  In  addition, \\n\\nanother conventional approach fulfilling the same goal is to measure volatilities in the periods.  \\n  \\n\\nBuren  (2012)  studies\\n \\ntwo  prominent  stock \\nmarket  cycles  1998\\n-\\n2005  and  2006\\n-\\n2011  and \\n 19\\n \\n\\n \\nconnected financial market changes, especially financial crisis, with volatility regime switch. \\n\\nThe conclusion of this research includes that the extent of association between financial market \\n\\nchanges and volatilit\\ny regim\\ne switching varies over cycles. Maringer and Ramtohul (2012) \\n\\npresent  regime\\n-\\nswitching  recurrent  reinforcement  learning  (RSRRL)  model  and  apply  it  to \\n\\ninvestment problems. In fact, the RSRRL model is formed by connecting regime switching to \\n\\nthe \\nrecurr\\nent reinforcement learning (RRL) algorithm. In the work of Maringer and Ramtohul \\n\\n(2012), the volatility is \\n used to switch between regimes and the RSRRL model is demonstrated \\n\\nto be better than the RRL model in addressing investment problems.\\n  \\n\\n2.5 \\nIdentify t\\nhe Gap\\n \\n\\n     \\nFrom the work of Allen and Karjalainen (1999)\\n , \\nmany studies investigate\\n \\nthe effectiveness \\n\\nof \\nthe \\nGA in filte\\nring technical trading rules\\n . In fact, most of the studies\\n  \\ntarge\\nt\\n \\nS&P 500 index \\n\\nor  Dow  Jones  Industrial  Average  index \\nas  the  data  set.  H\\nowever,  the  consensus\\n \\non\\n \\nthe \\n\\nprofitability of\\n \\nGA\\n-\\nbased trading rules\\n \\nis not reached  yet. Therefore\\n, based on the Chinese \\n\\nstock market,\\n \\nthis t\\nhesis is aimed to\\n  \\njoin this debate by \\n providing an out\\n -\\nof\\n-\\nsample test \\nto verify \\n\\nwhether the\\n \\nGA\\n \\ncan discover trading\\n \\nrules that\\n \\nconsistently beat the benchmarks.\\n  \\n\\n     \\nSecond, although some of the studies covering GA\\n-\\nbased trading rules achieve consistent \\n\\noutperformances, the statistical significance of those profitable strategies is not demonstrated. \\n\\nIn other words, it \\nstill remains as a question why certain trading strategies are selected by the \\n\\nGA as the best ones while others are not.\\n \\nTherefore, this thesis attempts to open up the black \\n\\nbox of the GA by testing the statistical significance of the profitable GA\\n-\\nbased t\\nrading rules \\n\\nthrough the Fama\\n-\\nMacBeth regressions (Fama and MacBeth, 1973).\\n  \\n\\n     \\nAnother contribution of this \\nthesis\\n \\nto the academic literature is that \\nwe combine \\nregime \\n\\nswitching \\nwith the\\n \\ngenetic algorithm\\n  \\nand find that, trading rules from the regime\\n -\\nswit\\nching GA \\n\\nmodel outperform those from the GA model\\n . Most of the previous \\n studies on this topic\\n \\nuse \\nthe \\n\\ngenetic algorithm to work out one single strategy in each test and \\nto \\napply it across the entire \\n\\ndata set. Nevertheless, it is \\n not optimal to rely\\n \\non technical indicators in a fixed manner all the \\n\\ntime \\nregardless  of  market  climates\\n,  especially  when  different  market  regimes \\nare  in  place\\n. \\n\\nDempster and Jones (2001) \\nintroduce an adaptive system in the process the GA refine trading \\n\\nrules. \\nIn the adaptive\\n \\nsystem, trading rules are discarded once they become losers or better \\n\\nstrategies are presented. Maringer and\\n  \\nRamtohul (2012) combine regime\\n -\\nswitching\\n \\nmodel\\n \\nwith \\n\\nthe  recurrent  reinforcement  learning  (RRL)  algorithm  to  generate  the  regime\\n-\\nswitching \\n 20\\n \\n\\n \\nrecurren\\nt reinforcement learning (RSRRL) model and apply it to investment problems. In the \\n\\nwork of Maringer and Ramtohul (2012), the volatility is used to switch between regimes and \\n\\nthe RSRRL model is demonstrated to be better than the RRL model in finding profita\\n ble trading \\n\\nstrategies. Thus, in this thesis, we combine the literature on the GA\\n -\\nbased trading rules and that \\n\\non the regime switching to form the regime\\n -\\nswitching Genetic Algorithm (RSGA) model. The \\n\\nresults show that, trading strategies generated from the\\n \\nRSGA model are more profitable and \\n\\nadaptive to the market than those from the GA model.\\n  \\n\\n     \\nOverall, the contributions of this \\nthesis\\n \\nto the literature is as follows. First, we \\nprovide an \\n\\nout\\n-\\nof\\n-\\nsample test on the effectiveness of the GA in finding profi\\ntable trading rules by using \\n\\ndata in the Chinese stock marke\\n t\\n. Second, \\nwe open up the black box of the GA from a statistical \\n\\napproach and explain why certain strategies are chosen by the GA as the best ones.\\n  \\nFinally, we \\n\\nconnect  the  literature  on  regime  swi\\ntching  and  that  on  the  GA\\n-\\nbased  trading  rules  and \\n\\ndemonstrate that the regime\\n -\\nswitching GA beat the GA in seeking profitable trading rules.\\n  \\n\\n \\n\\n3.\\n \\nMethodology\\n \\n\\n \\n\\n     \\nThe way we conduct the tests is also based on the framework of the \\n Allen and Karjalainen \\n\\n(1999)\\n \\na\\npproach with some adjustments on the details of experiments. Specifically, filter rules \\n\\nin  the  work  of \\nAllen  and  Karjalainen  (1999)\\n \\nare  in  the  forms  of  maximum,  minimum  and \\n\\nmoving average of closing prices. However, in this thesis three popular technical i\\n ndicators are \\n\\nutilized,  which  include  RSI,  MACD  and  Bollinger  Band.  Details  of  these  three  technical \\n\\nindicators can be found in Appendix A.\\n \\nThe selections of filter rules in this thesis are similar \\n\\nto the work of Dempster and Jones (2001) except that they include a broader range of refined \\n\\ntechnical indicators. \\nIn addition, the depth of technical trading rules \\nis\\n \\nfixed in the work of \\n\\nAllen an\\nd Karjalainen \\n(1999) while we allow autonomy for GA to determine the best strategy \\n\\ndepth. \\n \\n\\n     \\nTherefore,  this \\nthesis  attempts\\n \\nto  test  whether,  based  on  three  well\\n-\\nknown  technical \\n\\nindicators \\n–\\n \\nRSI, MACD and Bollinger Band,  GA is able to help robustly acqu\\niring better \\n\\noutcomes than the benchmark, which is normally buy\\n -\\nand\\n-\\nhold. In addition, another test in this \\n\\nthesis is that, we move one step forward by putting regime\\n-\\nswitching into the framework of \\n\\nGA to generate trading strategies that are more flexible \\nand dynamic. Previous literature has \\n 21\\n \\n\\n \\nbeen focusing on developing \\nand applying \\none single trading strategy \\nfrom the\\n \\nGA\\n. T\\nhen the \\n\\nconclusion of the effectiveness of \\nthe \\nGA\\n \\nin finding profitable trading rules is\\n \\nbased on the \\n\\nperformance  of  the  single  strategy\\n \\nin  the  out\\n-\\nof\\n-\\nsample\\n \\nperiod\\n.  However, \\nwe\\n \\nassume  that \\n\\nchanged market regimes justify different application\\n s\\n \\nof technical analysis and multiple trading \\n\\nstrategies  should  be  allowed  to  respond  to  regime  changes.  Thus,  in  this  study,  we  also \\n\\ninvestigate the i\\nmpact of adding regime\\n-\\nswitching to the proc\\ness of GA on investing results.\\n  \\n\\n     \\nThe content of this section is as follows. Section 3.1 explains \\n why the \\nGA has been popular \\n\\nin modeling the expectations in market. \\nSection 3.2 shows the reason why\\n \\nin this th\\nesis\\n,\\n \\nwe \\n\\nselect those three technical indicators RSI, MACD and Bollinger Band as filter rules for \\nthe \\n\\nGA to explore. \\nSection 3.\\n3\\n \\nillustrates the detailed procedure of GA.\\n \\nSection 3.4 reviews the \\n\\nfitness  functions  used  in  the \\nevolution\\n \\nof  GA.  Section  3.5  il\\nlustrates\\n \\nthe\\n \\nGA  with  regime \\n\\nswitching, especially the difference between it and \\n the \\nGA without regime switching. \\n  \\n\\n3.1 \\nWhy Genetic Algorithm\\n  \\n\\n     \\nThe process of learning and adaption in forming, testing and replacing forecasting models \\n\\nis  time\\n-\\nconsuming  but  crucial  to  inductive  reasoning.  In  order  to  implement  it  in  a  more \\n\\nefficient manner, \\nthe \\nGenetic Algorithm is introduced and verified as a perfe\\n ct match with the \\n\\npurpose. The reason\\n s why this is the case include\\n  \\nthat \\nthe \\nGA works well with bit\\n -\\nstrings since \\n\\ntwo core refining approach “crossover” and “mutation” can be easily fulfilled in the manner of \\n\\nbit\\n-\\nstrings. When \\nthe \\nGA is working on each “cr\\nossover”, some elements of two predicting \\n\\nmodels are exchanged.  If the models come in the form of bit\\n-\\nstrings, the whole process is, \\n\\ntechnically, cutting two bit\\n-\\nstrings at one same position and exchange them. Similarly, each \\n\\n“mutation” is simply the modif\\nication of one random selected gene (bit). Besides, \\nthe \\nGA is \\n\\nable to finish the learning and adaption in a significantly lower time scale because the magic \\n\\nof machine learning is that information is thoroughly investigated and significant patterns are \\n\\ndis\\ncovered quickly. At the beginning, \\n the \\nGA randomly generate a large number of predicting \\n\\nmodels and test their performance using historical data. After that, good genes will be identified \\n\\nand used to create offspring generation by generation, promoting the\\n  \\naverage predicting ability \\n\\nof the hypotheses population. This feature makes \\nthe \\nGA or other evolutionary optimization \\n\\napproach extremely applicable whenever the size of exploration space is too large for other \\n\\noptimization method to perform. \\n  \\n 22\\n \\n\\n \\nSecond, anot\\nher advantage over traditional optimization approaches \\nthe \\nGA comes with is \\n\\nthat, discontinuous and non\\n-\\ndifferentiable problems are within the working range of \\nthe \\nGA, \\n\\nso is the case for problems with multiple optima. Third, \\n the \\nGA works with approximately\\n  \\nthe \\n\\nsame logic with inductive reasoning. In the procedure of \\n the \\nGA, large number of forecasting \\n\\nhypotheses will be  generated, tested in  each  generation with the  gene (bit\\n-\\nstrings) of those \\n\\npredicting well passed to next generation and non\\n-\\nperforming ones\\n \\nbeing discarded, which is \\n\\npretty similar to the learning and adaption in inductive reasoning. \\n  \\n\\nFinally, \\nthe \\nGA has a unique attribute that makes it a special and powerful approach. In \\n\\naddition to simply reserve good genes (bit\\n -\\nstrings) and completely drop\\n  \\nnon\\n-\\nperforming ones, \\n\\nthe two phases in \\nthe \\nGA “crossover” and “mutation” give rise to more potential desirable \\n\\npatterns. Rather than merely choose between retaining and discarding, there are many cases \\n\\nthat a fraction or just one bit of the gene will be r\\n eplaced, therefore we will end up with much \\n\\nmore diversified predictors with at least some good genes to test. What’s equivalently important \\n\\nis  that  the  introduced  probability  mechanism  prevents  the  temporarily  underperforming \\n\\nforecasting models from being\\n \\ncompletely dropped, which still maintain the some potentially \\n\\ngood piece of genes even though the bit\\n -\\nstring in a whole in not a persuasive one.\\n  \\n\\n     \\nIn each period, the expectation model will come in the form of a combination of market \\n\\ncondition and fore\\n cast. The market condition is a summary of the current phase of market while \\n\\nthe forecast is a prediction of the following market movements. As each individual will hold \\n\\nmany models available in each period and uses the most accurate ones to act upon, appr\\n opriate \\n\\nresponse will emerge in each of the scenarios recognized. For example, on the one hand, if we \\n\\ndescribe the market from 5 dimensions and conventionally use a bit\\n -\\nstring of 5 bits to express \\n\\nthe market condition, \\nthe \\nbit on each position in the bit\\n-\\ns\\ntr\\ning\\n \\nrepresent\\ns\\n \\none dimension of the \\n\\nmarket. The first bit may mean that current price is higher than the 10\\n -\\nday average and second \\n\\nbit probably stands for the fact that current trading volume is the highest in 20 days. On the \\n\\nother hand, the forecast cou\\nld be that price will increase (decrease) and corresponding action \\n\\nwill be taking long (short) position\\ns\\n \\nrespectively. Specifically, suppose we use “1” on each \\n\\nposition to stand for that certain status of market is in presence while “\\n-\\n1” means not. One \\n\\nadd\\nitional  possible  case  is  that  “0”  will  appear  on  some  position\\ns  in  the  bit\\n-\\nstring\\n \\nwith\\n \\n\\ncorresponding  dimensions  of  market  are  not  considered  before  taking  action. \\nIn  fact\\n, \\n\\nforecasting models considering more dimensions of market will give rise to bit\\n-\\nstrin\\ngs with \\n 23\\n \\n\\n \\nmore “1” or “\\n-\\n1” in them while the less sophisticated counterparts see more “0” in the bit\\n-\\n\\nstrings. Practically, each market participant will have finite predicting models and it is only \\n\\nwhen the current market conditions precisely  match the ones i\\nn predicting models will the \\n\\nparticipant take actions \\n–\\n \\nmarket condition “10010” will not trigger the action of recognized \\n\\nmodel condition “10001”.\\n \\n\\n     \\nBy forming the expectation model in the architecture of bit\\n -\\nstrings, some advantages can be \\n\\nnoticed. \\nFirst,  there  is  a  process  of  learning  and  adaption.  Since  forecasting  models  are \\n\\nrecognizing  pattern  and  base  prediction  on  previous  market  movement  under  recognized \\n\\npattern, generated appropriate response will not stay fixed as market changes \\n–\\n \\nparticipan\\nts \\n\\nwill update themselves with the most recent information and adjust the combination of market \\n\\nstatus and response in case of need. Second, there is a profound exploration of the market. \\n\\nTechnically, the number of market dimensions considered (length of b\\nit\\n-\\nstring) is positively \\n\\nrelated to the number of market status recognized. If we still use “1”, “\\n -\\n1” and “0” as possible \\n\\nvalue for each bit, in terms of a bit\\n -\\nstring of 5 bits, totally 243\\n  \\n(3\\n5\\n)\\n \\ndifferent market conditions \\n\\nwill  be  recognized  while  models  c\\nonsidering  7  dimensions  of  market  will  see  2187\\n \\n(3\\n7\\n)\\n \\n\\ndifferent patterns. Therefore, as more dimensions are put into consideration, market will be \\n\\nexplored from a detailed perspective and theoretically, as many market conditions as possible \\n\\ncould be disting\\nuished. Finally, the nature of those predictors in the form of bit\\n-\\nstrings allow \\n\\nindividuals to categorize information important to themselves. Some participants believe in \\n\\ntechnical indicators and will use a lot of them while some others may add fundament\\nals as \\n\\nsupplements. This attribute promotes different “type” of participants and a diversified market.\\n  \\n\\n3.2 Technical Indicators\\n  \\n\\n     \\nSince  all  the  forecasting  models  generated  by  inductive  reasoning  using \\nt\\nhe\\n \\nGenetic \\n\\nAlgorithm  are  based  on  the  way  we  define  th\\ne  market,  special  efforts  should  be  taken  to \\n\\nguarantee \\nth\\nat \\nthe bit\\n-\\nstrings (market dimensions) are constructed in a manner that market \\n\\nconditions  are \\nc\\nl\\nea\\nr\\nl\\ny\\n \\nsegreg\\nated  and  that  market  movements \\nare  predictable.    In  the \\n\\nexperiments,  we  use  three  technical  indic\\nators  Relative  Strength  Index  (RSI),  Moving \\n\\nAverage Convergence Divergence (MACD) and Bollinger Bands to recognize and distinguish \\n\\nmarket status. Of course, there should be a reason why, among a large number of technical \\n\\nindicators,  we  choose  those  three  t\\no  recognize  patterns  and  make  predictions  of  market \\n\\nmovement\\ns\\n. First, RSI belongs to momentum indicators and is used to determine oversold and \\n 24\\n \\n\\n \\noverbought conditions of market by comparing the magnitude of recent gains and recent losses. \\n\\nSecond, MACD is a t\\nrend\\n-\\nfollowing indicator that investigates the relationship between two \\n\\nmoving average lines of different duration. Finally, Bollinger Bands are constructed with three \\n\\nbands \\n–\\n \\nupper band, middle band and lower band. Current Market status can be identified \\n by \\n\\nthe relative location of updated price with regard to the three bands. Although those three \\n\\nindicators are among the most popular ones used by traders, we still want to get more insights \\n\\ninto the effectiveness of them.\\n  \\n\\nIn order to confirm, whether RSI, \\n MACD and Bollinger Band are able to work effectively and \\n\\nstably on judging market status and predict following movement, we perform some t\\n -\\ntests for \\n\\neach of them to show that, different market status reflected by the technical indicators are \\n\\nsignificantly \\nassociated with returns. In designing this experiment, we use RSI, MACD and \\n\\nBollinger Band to categorize the market into \\n 4\\n \\nconditions respectively, which is consistent to \\n\\nour design in GA framework. Since our objective is to reveal whether some certain conditions \\n\\nare good \\npredictors of price movements, t\\n ake RSI for example, we perform a Fama\\n -\\nMacBeth \\n\\nregression\\n \\n(Fama and MacBe\\n th, 1973)\\n \\nwhere the \\ndaily \\nrealized returns (returns of next trading \\n\\nday) of component stocks of CSI 300 Index are regressed against the \\n4\\n \\nmarket conditions \\n\\ncategorized by RSI. Namely, for each component stock, there is \\n4\\n \\nindependent variables to \\n\\nexplain it\\ns next day’s realized return, with the corresponding regressor matching its current \\n\\nstatus taking value 1 while others taking value of 0.\\n  \\nTherefore, on a daily basis, the regression \\n\\nis of the following form:\\n \\n\\n \\n\\n𝑹\\n𝒊\\n=\\n \\n𝜷\\n𝟏\\n∗\\n𝑹𝑺\\n𝑰\\n𝒔𝒕𝒂𝒕𝒖𝒔\\n𝒊\\n𝟏\\n+\\n \\n𝜷\\n𝟐\\n∗\\n𝑹𝑺\\n𝑰\\n𝒔\\n𝒕𝒂𝒕𝒖𝒔\\n𝒊\\n𝟐\\n+\\n \\n𝜷\\n𝟑\\n∗\\n𝑹𝑺\\n𝑰\\n𝒔𝒕𝒂𝒕𝒖𝒔\\n𝒊\\n𝟑\\n+\\n \\n𝜷\\n𝟒\\n∗\\n(\\n1\\n−\\n𝑹𝑺\\n𝑰\\n𝒔𝒕𝒂𝒕𝒖𝒔\\n𝒊\\n𝟏\\n−\\n𝑹𝑺\\n𝑰\\n𝒔𝒕𝒂𝒕𝒖𝒔\\n𝒊\\n𝟐\\n−\\n𝑹𝑺\\n𝑰\\n𝒔𝒕𝒂𝒕𝒖𝒔\\n𝒊\\n𝟑\\n)\\n \\n  \\n    \\n    \\n(1)\\n \\n\\n \\n\\nR\\n𝒊\\n \\nis the daily return of stock i while \\n𝑅𝑆\\n𝐼\\n𝑠𝑡𝑎𝑡𝑢𝑠\\n𝑖\\n \\nstands for current status of RSI with regard \\n\\nto stock i. \\nWe use a\\n \\nrandom\\n \\nperiod\\n \\nof 120 days and perform this cross\\n-\\nsectional regression \\n\\nday by day.\\n \\nNamely we totally perform 120 OLS regressions and end up with 120 set of \\n\\ncoefficients for each status defin\\ned for the technical indicator RSI. \\nAfter that, t\\n-\\ntest for the \\n\\ncoefficients  is  implemented \\nto  verify  the  significances  of  associations  between \\nrealized \\n\\nreturns  and  each  RSI  status.  According  to  the  results,  we\\n \\ncan  find  that \\n2\\n \\nout  of \\n4\\n \\nstatus \\n\\ncategorized  by\\n \\nRSI  have  significant  relationship  with  return\\ns  during  the  testing  period.\\n \\n\\nT\\nherefore, we can use \\n RSI\\n \\nto predict price movements. Similar results are found for the other \\n\\ntwo technical indicators MACD (\\n2\\n \\nout of \\n4\\n) and Bollinger Band (\\n2 out of 4\\n), which prove\\ns \\n 25\\n \\n\\n \\nthe  effectiveness  of  technical  indicators  form  the  perspective  of  statistics  and  leads  us  to \\n\\nbelieve  into  the  predicting  power  of  them.\\n \\nTable  1  lists  the  detail  of \\nthe  Fama\\n-\\nMacBeth \\n\\nregressions for each of those three technical indicators.\\n  \\n\\n \\n\\n[Please insert\\n \\nTable 1 here]\\n \\n\\n \\n\\nIn addition to the statistical test\\ns\\n \\nabove, we also investigate the effectiveness of these three \\n\\ntechnical  indicators  from  the  practical  point  of  view.  In  the  daily  practice,  a  trader  will \\n\\nmaintain a stock pool and construct the portfolio s\\n electing stocks from it. We show here that \\n\\ndepend\\ning\\n \\non these three technical indicators, superior returns can be \\n achieved. \\nSimilar to the \\n\\nsteps we used in the t\\n-\\ntests of technical indicators, here we also \\nconduct\\n \\nthe Fama\\n-\\nMacBeth \\n\\nregression\\ns\\n \\nwith a rolling window of 75 days\\n \\nover the period from 2010.06 to 2015.10\\n . On a \\n\\ndaily basis, we use the average coefficients of each market status to forecasting stock returns \\n\\nof  following  days \\nand  rank  them  from  the  highest  to  the  lowest.  Then  our  portfol\\nio  is \\n\\nconstructed by taking long positions of top 10% stocks and short positions of the \\n bottom\\n \\n10% \\n\\nstocks. This hedged position on each day is essentially, measuring the excess return between \\n\\n“\\nstrong\\n” stocks and “\\nweak\\n” stocks on that day, which reflects te\\nchnical indicators’ ability in \\n\\ndistinguishing them. In this experiment, we still use the data of component stocks of CSI 300 \\n\\nIndex and verify the effectiveness of RSI, MACD and Bollinger Band both individually and \\n\\naltogether.  The \\nFigure\\n \\n1, \\nFigure\\n \\n2, \\nFigure\\n \\n3  and \\nFigure\\n \\n4\\n \\nin  appendix  are  the\\n \\nplots  of\\n \\n\\ncumulated\\n \\nreturns of the hedged position using only one technical indicator (RSI, MACD and \\n\\nBollinger Band respectively) and\\n  \\nthese\\n \\nthree indicators altogether.\\n  \\n\\n \\n\\n[Please insert \\nFigure\\n \\n1 here]\\n \\n\\n[Please insert \\nFigure\\n \\n2 here]\\n \\n\\n[Please insert \\nFigure\\n \\n3 here]\\n \\n\\n[Please insert \\nFigure\\n \\n4 here]\\n \\n\\n \\n\\n     \\nConclusively\\n, regardless of whether the indicators \\n are considered individually or\\n  \\ntogether, \\n\\nthe hedged position \\n delivers\\n \\nsignificant\\nly\\n \\npositive return with small drawdown\\n s\\n. Th\\nis\\n \\nfin\\nding\\n, \\n\\npersuade\\ns\\n \\nus that \\nthe technical indicators \\nRSI, MACD and Bollinger Band are effective in \\n 26\\n \\n\\n \\nsegregating\\n \\nmarket status\\nes and predicting market\\n \\nmovements. We are then confident in \\nthe \\n\\nGA utilizing these indicators to generate forecasting models.\\n  \\n\\n \\n\\n3.\\n3\\n \\nGenetic Algorithm\\n \\nProcedure\\n \\n\\n     \\nDiscovered by Holland (1962, 1975), \\n the \\ngenetic algorithm (GA) is a kind of evolutionary \\n\\nalgorithm and a process of search, iteration which ends up with robust near\\n-\\noptimal results. \\n\\nBeing an evolutionary algorithm, first \\n of all,\\n \\nthe\\n \\nGA needs to know the environment to work \\n\\nwith. Usually problems need to be addressed show up in certain forms, then a population of \\n\\npotential  solutions  will  be  kept  and  evaluated  through  a  fitness  function  specific  to  the \\n\\nproblem. GA works by p\\n icking better solutions on a relatively basis and evolve generation by \\n\\ngeneration  to  finally  reach  the  near\\n-\\noptimal  results.  Beasley  e\\nt  al  (1993)  mak\\ne  a  detailed \\n\\ndescription of genetic algorithm.\\n  \\n\\n     \\nWhen using genetic algorithm, it is necessary to put th\\ne potential solutions in a structure \\n\\nGA could deal with, and the convention is to use bit strings with a mapping between the \\n\\nstructure and original solutions. Usually GA starts working by randomly initializing the first \\n\\npopulation of certain size from the \\nsolution space, with each sample in the population being \\n\\nthe potential candidate. On top of that, a fitness function fitting the problem must be defined \\n\\nto  evaluate  each  candidate.  For  example,  a  route  planning  problem  might  have  a  fitness \\n\\nfunction to meas\\n ure each solution from the respect of time spent or distance traveled. If instead, \\n\\na portfolio management problem displays, the fitness function can take the form of realized \\n\\ninvesting returns or risks. Whenever both the fitness function and first populati\\n on of solutions \\n\\nare ready, the next step is for GA to proceed in the evolution. The subsequent generations are \\n\\ncreated  based  on  promising  candidates  through  passing  the  elites,  crossover  and  mutation \\n\\naccording to certain probabilities. The probabilities as\\nsigned to each candidates are totally \\n\\nbased  on  their  corresponding  performances  measure  by  fitness  function.  Relatively  better \\n\\ncandidates will be favored and enjoy higher probabilities of being selected in “crossover” and \\n\\n“mutation”. This mechanism will en\\nsure that solutions are getting refined and optimized by \\n\\ngeneration and that candidates in subsequent generations will deliver better performance than \\n\\nthe previous counterparts. Specifically, within the mechanism, there are three approaches that \\n\\nmake it wo\\nrk as desired. \\n \\n\\nFirst, some of the samples with highest fitness values are called elites in generation and \\n\\nthey will be directly passed to next generation. Second, in crossovers, ‘parents’ are chosen \\n 27\\n \\n\\n \\nrandomly  with  tilts  towards  those  candidates  with  relati\\nvely  better  performance  and  then \\n\\nrecombined to form the ‘children’ for next generation. As to the recombination, each time a \\n\\npair of parents will be selected and cut their “genes” into two parts at a random location, \\n\\nexchanging a piece of which to form the\\n \\n‘children’ in next generation. Third, in terms of the \\n\\n‘mutation’, a parent is randomly chosen with probabilities in favor of high\\n -\\nstrength candidates \\n\\nand one random “gene” of the parent is changed to generate one ‘offspring’ in next generation. \\n\\nThis is re\\npeated until the formation of next generation is completed. \\n  \\n\\n \\nWith the same manner, following generations are created gradually in an identical way \\n\\nuntil one of predetermined terminating \\n criteria\\n \\nhas been met. Practically, there are two popular \\n\\nways to def\\nine the criterion. The first one is to set a generation threshold (e.g. 50 generations) \\n\\nand the evolution stops when meeting predetermined threshold. The other one is to measure \\n\\nthe degree of promotion in the performance of the best candidate in each gener\\n ation, with the \\n\\nevolution  finishes  whenever  there  is  no  significant  improvement  in  certain  number  of \\n\\ngenerations in a row. The final generation formed after all the \\n evolution\\n \\nare left with superior \\n\\ncandidates (genes) because the candidates of underperforma\\nnce have been discarded in the \\n\\nevolution\\n \\nprocess.  Then  the  top  solutions  in  the  final  generation  can  be  applied  to  the \\n\\npresented problem and normally, their performance will be near\\n -\\noptimal. However, due to the \\n\\nstochastic nature of GA, there is no guarante\\ne for the convergence of the best solution from \\n\\nGA to the global optimal one.\\n  \\n\\n     \\nActually\\n, \\nfor\\n \\npopulation  size,  there  is  a  tradeoff  between  diversity  and  cost  of \\n\\ncomputational resources. In other word, large population size can ensure better exploration \\n of \\n\\nthe solution space at\\n \\nthe expense of being more time\\n–\\nconsuming. This is not only the issue \\n\\nfor genetic algorithm, \\nsimilarly, brute\\n-\\nforce   method    even    more    heavily   \\nrelies on\\n \\n\\ncomputational resources since each possible scenario will be tested \\n in this approach. For \\nthe \\n\\nsake  of  this\\n \\nreason,  GA  is  a  more  superior  optimization \\nmethod  than  brute\\n-\\nforce.  When \\n\\nlook\\ning\\n \\nat  the  market  from  the  perspective  of  three  technical  indicators \\nRSI,  MACD  and \\n\\nBollinger Band, we\\n \\ntransform \\nthe trading strategies\\n \\ninto \\nbit\\n-\\nstrings, which is consistent to all \\n\\nthe experiments in this thesis. If there are 10, 4 and 4 \\n possible conditions for RSI, MACD and \\n\\nBollinger Band \\nrespectively\\n \\nand each pair of indicators can be connected by “AND”, “OR” \\n\\nor  “XOR”,  overall  there  wi\\nll  be  3\\n4560  (10*4*4*3*3*3*2*2*2)\\n \\ndifferent  bit\\n-\\nstrings \\n\\nrepresented through permutation and combination. In brute\\n -\\nforce method, each of these \\n 35460\\n \\n\\nscenario will be tested for performance to reveal the best one. However, when it comes to \\n the \\n 28\\n \\n\\n \\nGA, with a generation size of 1000, after 10 generations we \\n gain\\n \\nalmost the same result. The \\n\\nexplanation\\n \\nis\\n \\nthat\\n,\\n \\nthe\\n \\nGA \\nis able to retain\\n  \\nthose \\ntrading strategies\\n \\nthat have\\n \\nsuperior\\n \\n“genes” \\n\\nand\\n \\nquickly recombine “\\n strong\\n \\ngenes” from \\nkept trading strategies\\n  \\nto finally approach the best \\n\\none among all the scenarios, sparing the effort to test each of the scenario, especially the non\\n -\\n\\nperforming ones. In order t\\no test the additional efficiency\\n \\nwe are able to get switching from \\n\\nthe \\nmethod of exhaust\\nion to GA, we \\nhave run two trial\\ns with everything in common except \\n\\nfor the method and time, the conclusion is t\\nhat, by using GA, we end up saving\\n \\n65% of the \\n\\ntime spent on exhaustion.\\n \\n\\n     \\nAlthough GA carries many merits, especially when compared to traditional optimizat\\nion \\n\\nmethods, we cannot ignore the limitation it comes with. In addition to the fact that, there is no \\n\\nguarantee for the convergence between GA’s best solution to the essentially best one and the \\n\\npositive relationship between population size and execution t\\n ime, the stochastic nature of GA \\n\\ncan also be a weakness. Namely, if the initial population generated consists of no good “genes” \\n\\nbecause of the randomness, “Elite Passover” and “Crossover” will just picking relatively \\n\\nbetter member from a “bad” population \\nand “Mutation” is left as the only way to come up \\n\\nwith good “genes”. Under this condition, it will be much more difficult to reach \\nthe \\nnear\\n-\\n\\noptimal solution before the evolution meets predetermined stop point. Due to those limitations, \\n\\nthe nature of proble\\nms to be solved should be considered first, and GA will be utilized only \\n\\nwhen its overall efficiency override those of other optimization methods. In fact, it will be \\n\\nmore productive to be considered as a supplementary approach rather than replacing all of\\n  \\nthe \\n\\ntraditional methods.\\n \\n\\n     \\nGenetic algorithm is a learning process including initialization, iteration and optimization. \\n\\nThe  detailed  process  of  GA  can  be  seen  in  previous  content.  After  generating  the  first \\n\\ngeneration of potential solution, if we use \\nhold\\ning\\n \\nperiod return as the fitness function, each \\n\\ncandidate is evaluated in the form of excess return over buy\\n-\\nand\\n-\\nhold strategy and ranked \\n\\naccordingly. Then the evolution of trading tactics proceeds generation by generation to reach \\n\\nthe near\\n-\\noptimal sol\\nution. Here we explain the two most important steps in the evolution\\n-\\n \\n\\n‘Crossover’ and ‘Mutation’.\\n  \\n\\n \\n\\n \\n\\n \\n 29\\n \\n\\n \\n Crossover\\n \\n\\n101000\\n11101\\n \\nParent\\n \\nA\\n \\n\\n \\n\\n \\n\\n001101\\n00110\\n \\nParent\\n \\nB\\n \\n\\n \\n\\nOffspring A: 10100000110 & Offspring B: 00110111101\\n  \\n\\n \\n\\n \\n\\nMutation\\n \\n\\nParent: 1010001\\n1\\n101\\n \\n\\nOffspring: \\n1010001\\n0\\n101\\n \\n\\n \\n\\nSpecifically, the\\n   \\ntrading   strategies   are   randomly   selected with probabilities in favor of \\n\\nthose with \\nbetter performances\\n  \\nto perform the crossover and mutation and this is why the non\\n -\\n\\nperforming hypotheses are more likely to be discar\\n ded while models predicting well see more \\n\\nof their genes pass\\ned\\n \\nto \\nthe \\nfollowing generations. In the example above, a pair of parents \\n\\n(10100011101 and 0\\n0110100110) are chosen and cut\\n \\nat a random\\nly\\n \\nselected digit location \\n\\n(between \\nsixth and seventh digit), \\n then one\\n \\npiece of the bit string\\n  \\nof each parent\\n \\nis exchanged \\n\\nto  form  two  children  (10100000110  &00110111101)  in\\n \\nthe\\n \\nnext  generation.  As  to \\none \\n\\nmutation, a parent (10100011101) is selected and the eighth digit is chosen to mutate, \\n we\\n \\nend \\n\\nup with an offsprin\\n g 10100010101 for next generation. After several rounds of crossover and \\n\\nmutation,  when  the  number  of  offspring \\nreaches  the\\n \\npredetermined  population  size,  the \\n\\nformation of a new generation is complete\\n d\\n \\nand each member in it is again, tested in the fitness \\n\\nfunction and ranked accordingly.\\n  \\n\\n     \\nWith  sufficient  iteration\\ns \\n(generation\\ns\\n),  there  will  be  a  significant  promoti\\non\\n \\nin  the \\n\\nperformance of potential solutions since \\nthe \\n“strong \\nchromosomes\\n”\\n \\nare reserved and passed \\n\\nalong while \\nthe “weak\\n \\nchromosomes\\n” are \\ndiscarded. As the result\\n, trading strategies making \\n\\nup  the  last  population  when  the  iteration\\ns\\n \\nend  at  are  of  high  strength\\n \\nin  training  period. \\n 30\\n \\n\\n \\nHowever,\\n \\nwe\\n \\ndo not \\nchoose the best one of them as our optimal trading strategy.\\n  \\nThe reason \\n\\nwhy the best technical\\n \\ntrading rule measured by the fitness function in the last population is \\n\\nnot practically optimal is because of the data over\\n-\\nfitting problem. Namely\\n, we expect the \\n\\ntrading strategies\\n  \\nselected by\\n \\nthe\\n \\nGA\\n \\nto\\n \\nnot only behave well in the training periods (in\\n -\\nsa\\nmple) \\n\\nbut also \\nto \\ndeliver \\nconsistent\\n \\nperformances in the testing periods (out\\n-\\nof\\n-\\nsample). \\nSince we \\n\\nuse \\none  machine  learning  approach  to  optimize \\nthe \\nsolution\\ns\\n,  the  way  experiments  are \\n\\ndesigned is tightly related to the \\n degree\\n \\nof over\\n-\\nfitting problem. \\n \\n\\nPrev\\nious literature has come up with several effective methods to alleviate this problem. In \\n\\nthe work of \\nAllen and Karjalainen (1999)\\n, the entire data is separated into three pieces as \\n\\ntraining, evaluation and testing periods respectively. \\nIn this case, the op\\ntimal trading rule is \\n\\nno longer equivalent to the best candidate in the last generation from GA. Instead, the best \\n\\nmembers  from  each  generation  are  measured  again  in  the  evaluation  period  and  the  one \\n\\ndelivering top performance in the evaluation period is i\\n nstead considered as the final eventual \\n\\ntrading  rules  to  apply  in  the  testing  period. \\nAs  a  result,  those  trading  strategies  with \\n\\nsignificantly contrary performances between training and evaluation periods will be discarded \\n\\nand this is how the data over\\n -\\nfit\\nting problem is relieved in the work of \\n Allen and Karjalainen \\n\\n(1999)\\n. Ideally, the data over\\n-\\nfitting problem can be almost completely addressed if the data \\n\\nset  is  divided  into  infinite  number  of  periods  with \\nperiods  other  than  the  last  one  being \\n\\nevaluation\\n \\nperiods\\n. However, it is not reasonable and computational viable to implement this \\n\\nadjustment.\\n \\nIn this thesis, we rely on the same approach in the work of \\n Allen and Karjalainen \\n\\n(1999)\\n \\nto alleviate\\n \\nthe data\\n-\\nmining\\n \\nproblem\\n. \\nActually,\\n \\nby splitting the data se\\nt into 3 pieces \\n\\n(training, evaluation and testing), the over\\n -\\nfitting problem is greatly relieved according to the \\n\\nresults of experiments. In addition, in the work of \\n Becker and Seshadri (2003)\\n , another method \\n\\nto  solve  the  same  problem  is  to  modify  the  fitn\\ness  function  by  imposing  a  penalty  on \\n\\ncomplicated trading rules\\n \\nto\\n \\nfavor relatively simple trading rules \\nones\\n. The rationale behind \\n\\nis understandable because as more conditions or constraints are attached to a trading rule, the \\n\\nchance of\\n \\nonly\\n \\nperforming in\\n \\ncertain periods of time increases. In this thesis, we do not apply \\n\\nthis method and there in no penalty to favor any certain trading rule.\\n  \\n\\n \\n\\n3.4 Fitness Function\\n \\n\\n     \\nAs  the \\nevolution  of  GA  proceeds,  there  should  be  a  mechanism  through  which  non\\n-\\n\\npromising  solution  candidates  are  discarded  and \\nthe \\n“genes”  are  getting  promoted  by \\n 31\\n \\n\\n \\ngeneration. The f\\nitness function is then designed for this purpose. Technically, the fitness \\n\\nfunctio\\nn  can  be  of  various  forms  and  should  be  designed  specifically  to  the  presented \\n\\nproblems. Since we are going to, taking advantage of GA, promote \\n stock trading\\n \\nperformances\\n, \\n\\na good choice for the fitness function in our test\\n s\\n \\nis the excess return over certai\\n n benchmarks \\n\\nsuch as the\\n  \\nbuy\\n-\\nand\\n-\\nhold (\\npure \\nindexing) strategy, with trading costs taken into consideration. \\n\\nPractically\\n, the continuously compounding \\ncumulative\\n \\nreturns during the training period are \\n\\ncomputed, then trading costs and the corresponding buy\\n-\\nand\\n-\\nhold return\\ns\\n \\nare subtracted to \\n\\nreach the excess return\\ns\\n. In our first experiment verifying \\n the \\neffectiveness of \\nthe \\nGA on\\n \\none\\n \\n\\nstock index, short sale is not allowed and in e\\nach\\n \\nperiod of time, according to corresponding \\n\\nsignals,  our  alternatives  can  be\\n \\neither  taking  long  position  of  the  index  considered  or \\n\\nmaintaining an empty position. The daily realized returns are calculated whenever our position \\n\\nis not empty and \\n cumulated\\n \\nover the entire period to reach the holding period return. Then the \\n\\nfitness fu\\nnction is to measure and rank \\nthe \\nholding period return\\ns of\\n \\neach strategy so that \\nthe \\n\\nevolution of GA can keep working. To imitate the reality as much as possible, trading costs \\n\\nare taken into account while working out\\n  \\nthe\\n \\nrealized return\\ns\\n \\nand in our exper\\n iments, the one\\n-\\n\\nway  tradin\\ng  expense  has  been  set  at  20bps,  which  is  similar  to  the  work  of \\nAllen  and \\n\\nKarjalainen (1999)\\n.\\n \\nAs a result\\n, strategies involve frequent changes of position are easier to \\n\\nbe knocked out if we set the trading \\ncost at a relatively hi\\ngh level and\\n \\nvice versa. In other \\n\\nword\\ns\\n, \\nthe trading costs act\\n  \\nas a penalty on \\nthe \\nfrequent trading. Therefore, by controlling the \\n\\nlevel  of  trading  expense,  we  are  able  to  attain  different  strategies  with  desired  trading \\n\\nfrequency.\\n \\n\\nSimilarly, if, instead o\\nf taking positions of only indices, we now need to consider large \\n\\nnumber of stocks to construct and maintain a portfolio, then the objective of fitness function \\n\\nwill turn to the holding period of return of the portfolio as a whole. In this case, each of th\\ne \\n\\nstock in pool should be minded in the same manner as we do in experiment with only index. \\n\\nThe daily continuously compounding return for stock i in day j (\\n 𝑋\\n𝑖𝑗\\n) can be computed as:\\n \\n\\n \\n\\n𝑋\\n𝑖𝑗\\n=\\n𝐿𝑛\\n(\\n𝑃\\n𝑖𝑗\\n−\\n𝑃\\n𝑖𝑗\\n−\\n1\\n)\\n \\n \\n \\nIF stock i is in the portfolio in day\\n  \\nj\\n \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n𝑋\\n𝑖𝑗\\n \\n=\\n \\n0 IF\\n \\nstock i is not in the portfolio in day j\\n                             \\n(2)\\n \\n\\n \\n\\n     \\nTherefore,  the \\ncumulative\\n \\nreturn  for  the  portfolio  (PR)  during  the  training  period  is  as \\n\\nfollows. In the equation, W\\n ij\\n \\nis the weight of stock i on day j while X\\n ij\\n \\nstands for the return of \\n 32\\n \\n\\n \\nstock i in day j.\\n \\n\\n \\n\\n                                              \\n         \\n      \\n𝑃𝑅\\n=\\n \\n∑\\n𝑤\\n𝑖𝑗\\n𝑥\\n𝑖𝑗\\n𝑖\\n𝑗\\n \\n           \\n                    \\n                        \\n \\n(3)\\n\\nW\\nij\\n \\n=\\n \\n0 if stock i is not in the portfolio in day j\\n  \\n\\nFinally, the excess return over buy\\n -\\nand\\n-\\nhold is worked out as:\\n \\n\\n                                    \\n \\n\\nER=PR \\n-\\n \\nR\\nbh\\n-\\n \\n0.002 * n\\n                                                     \\n (\\n4)\\n \\n\\nWhere  R\\nbh\\n \\nis  the  continuously  compounding  buy\\n-\\nand\\n-\\nhold  return  and  n  is  the  total \\n\\nnumber of transaction for the portfolio during the training period.\\n  \\n\\nIn addition to target holding period return, there\\n  \\nare theoretically infinite ways to define \\n\\nthe  fitness  function.  In  practice,  the  realized  return  is  not  the  only  criterion  to  select \\n\\nstrategy  and  other  aspects  (e.g.  risk)  of  a  trading  strategy  should  be  viewed  as  well. \\n\\nActually  sometimes  risk  matters  mor\\ne  than  return.  In  order  to  reduce  risk,  some \\n\\nadjustments of the fitness function will be justified and we could introduce one of risk \\n\\nmetrics as an additional part of the fitness function so that genetic algorithm will favor \\n\\nthose strategies with lower ris\\nk. As risk comes in various kinds of form and different \\n\\ninvestors pay attention to different aspects, the way we modify the fitness function is \\n\\nsupposed to match the purpose. For example, if an investor is not comfortable with large \\n\\ndrawdown, he or she sho\\n uld utilize a fitness function which is able to filter out strategies \\n\\nwith high drawdowns. To satisfy this goal, we should consider \\n the \\nmaximum drawdown \\n\\nas  the  risk  and  the  fitness  function  should  incorporate  a  metric  to  reflect  this  risk. \\n\\nPractically, one\\n \\noption is to divide holding period return by the maximum drawdown \\n\\nduring the period, then a penalty is introduced for those strategies with large drawdowns \\n\\nand they have to achieve even higher return to be able to end up with same fitness value \\n\\nas strateg\\nies with lower drawdowns. Actually\\n ,\\n \\nthe ratio of \\nthe \\nholding period return over \\n\\nthe \\nmaximum drawdown\\n \\nduring the same holding period\\n \\nis \\ndefined as the\\n \\nsterling ratio. \\n\\nIn another situation, for  example, if investors  are concerned about volatility, then \\nthe \\n\\nS\\nharpe ratio which is the ratio of the difference  between realized return  and risk\\n-\\nfree \\n\\nreturn over standard deviation of return during the whole period of time, could be the \\n\\nobjective of fitness function. In this manner, strategies with high volatility are\\n  \\nat a definite \\n 33\\n \\n\\n \\ndisadvantage and those with smooth \\n cumulated\\n \\nreturn will be favored.\\n \\n\\n \\n\\n         \\n  \\n𝑆𝑡𝑒𝑟𝑙𝑖𝑛𝑔\\n \\n𝑟𝑎𝑡𝑖𝑜\\n=\\n \\n𝑐𝑢𝑚𝑢𝑙𝑎𝑡𝑖𝑣𝑒\\n \\n𝑟𝑒𝑡𝑢𝑟𝑛\\n\\n𝑀𝑎𝑥𝑖𝑚𝑢𝑚\\n \\n𝑑𝑟𝑎𝑤𝑑𝑜𝑤𝑛\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n(\\n5\\n)\\n \\n\\n \\n\\n             \\n          \\n            \\n𝑆\\nℎ\\n𝑎𝑟𝑝𝑒\\n \\n𝑟𝑎𝑡𝑖𝑜\\n=\\n \\n𝑐𝑢𝑚𝑢𝑙𝑎𝑡𝑖𝑣𝑒\\n \\n𝑟𝑒𝑡𝑢𝑟𝑛\\n−\\n𝑟𝑖𝑠𝑘\\n \\n𝑓𝑟𝑒𝑒\\n \\n𝑟𝑒𝑡𝑢𝑟𝑛\\n\\n𝑆𝑡𝑎𝑛𝑑𝑎𝑟𝑑\\n \\n𝑑𝑒𝑣𝑖𝑎𝑡𝑖𝑜𝑛\\n \\n                    \\n(6)\\n \\n\\n \\n\\n     \\nHowever, satisfying certain investment needs or preferences is not the only reason to \\n\\nmodi\\nfy the fitness function. Furthermore, the over\\n -\\nfitting problem may give rise to some \\n\\nnecessary  adjustment  to  the  fitness  function  and  the  magnitude  of  adjustment  varies \\n\\naccording to some predetermined criterion. For instance, one of the \\n criteria\\n \\ncould be t\\nhat, \\n\\nthe more complex the trading strategy, the higher the penalty. Since complicated trading \\n\\nstrategies \\nin place\\n \\nafter the evolution are more prone to be a result of data mining, we \\n\\nimpose more difficulties on those complicated forecasting models in achie\\nving superior \\n\\noutcomes, \\nwith\\n \\nother aspects being identical. Namely, when two strategies are totally \\n\\nsame except that three classified rules are used in one while only two classified rules are \\n\\nconsidered  in  the  other  one,  then  the  trading  strategy  using  onl\\ny  two  classified  rules \\n\\nshould be more likely to be selected than the strategy using three classified rules.\\n  \\n\\nThen we\\n \\nillustrate\\n \\nthe appearance of trading strategies\\n  \\nappearing in the fitness function\\n , \\n\\nnamely, the approach through which we \\nconduct the trading\\n.\\n \\nIn practice, portfolios are \\n\\nconstructed by taking long and short positions according to certain rules.\\n \\nT\\nhe trading \\n\\nstrategies \\nin our experiments are expressed in bit\\n-\\nstrings and describe \\nthe\\n \\nconditions \\nto\\n \\n\\nbe satisfied in order for long o\\nr short positions\\n \\nto be taken. Each trading strategy (bit\\n-\\n\\nstring) has\\n \\nfour parts in total. The first one is\\n  \\nthe\\n \\nmarket conditions\\n \\nto be met\\n \\nin the form \\n\\nof classified rules, which include fundamental metrics, technical indicators and even limit \\n\\nbook information, etc. For instance, one t\\n echnical indicator rule based on Bollinger Bands \\n\\nmight be expressed as:\\n  \\n\\n \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n𝑃\\n𝑖\\n−\\n1\\n≤\\n \\n𝐵𝑜𝑙𝑙𝑖𝑛𝑔𝑒\\n𝑟\\n𝑢𝑝𝑝𝑒𝑟\\n𝑖\\n−\\n1\\n \\n𝑨𝑵𝑫\\n \\n𝑃\\n𝑖\\n>\\n \\n𝐵𝑜𝑙𝑙𝑖𝑛𝑔𝑒\\n𝑟\\n𝑢𝑝𝑝𝑒𝑟\\n𝑖\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n(7)\\n \\n\\n \\n\\nWhere P\\ni\\n \\nand \\n𝐵𝑜𝑙𝑙𝑖𝑛𝑔𝑒\\n𝑟\\n𝑢𝑝𝑝𝑒𝑟\\n𝑖\\n \\nare the stock closing price and Bollinger upper band at \\n\\nday \\nI respectively\\n. Another techni\\ncal indicator rule, for example, could be presented as \\n 34\\n \\n\\n \\n‘The short\\n-\\nterm  moving  average  crosses  below  the  long\\n-\\nterm moving average’, \\nand \\n\\nequity \\ninvestors will be more familiar with this condition by calling it ‘Death Cross’. The \\n\\nclassified rules \\nshould\\n \\nbe in\\nterpreted from \\nthe \\nbit strings taking value\\ns\\n \\nfrom 0 and 1 \\nto \\n\\nen\\nsure \\nthat the \\nGA can work with it. \\nO\\nne \\nexample of \\ncategorized conditions for RSI, \\n\\nMACD  and  Bollinger  Band  can  be  found \\nin  the  appendix  as  table  1.  In  table  1\\n \\nwe \\n\\ncategorize RSI into 10 intervals\\n \\nwith equal length, for MACD and Bollinger Band, 4 \\n\\nsections are defined for each. In this case, we are able to tell the current status for each \\n\\nof them\\n \\naccording to the values of corresponding bits\\n.\\n \\nSecond\\n, we need to consider the \\n\\nrelationships among indic\\nators and thus, there should be connections between each pair \\n\\nof  rules.  One  approach  is  to  let  rules  contained  in  the  trading  strategies  linked  by \\n\\nconnectors in the form of Boolean functions, which might choose among ‘AND’, ‘OR’ \\n\\nand ‘XOR’ reflected respect\\nively by ‘00’, ‘01’ \\nand ‘10’ in bit\\n-\\nstrings. Third\\n, there is a \\n\\n‘structure unit’ in the trading strategies that identify which classified rules should be \\n\\nconsidered. Suppose there are five potential classified rules, then the structure unit should \\n\\nbe a bit \\nstring of five digits, with each digit taking 0 or 1. The indicators with “0” on their \\n\\ncorresponding locations\\n  \\nin the bit\\n-\\nstring are ignored when generating \\n the \\ntrading strategy. \\n\\nThe last part of a trading strategy is\\n  \\nthe ‘action’ which can be taking long positions\\n  \\n(“1”)\\n, \\n\\ntaking short positions\\n \\n(“\\n-\\n1”)\\n \\nor keeping an empty position\\n  \\n(“0”)\\n. Similarly, using binary \\n\\nnumber\\ns\\n \\ncan accomplish this \\ngoal\\n.\\n \\n\\n     \\nOverall, one example of the bit\\n -\\nstring, based on three potential classi\\n fied rules, could \\n\\nbe ‘10120011101’ and \\nthis bit\\n-\\nstring is interpreted as “if the RULE #1 is at status 1 or \\n\\nthe\\n \\nRULE #2 is at status 2, then \\n long positions of the target \\n should be \\ntaken\\n”\\n.\\n \\n\\n \\n\\n1\\n01\\n2\\n00\\n1\\n1101  \\n  \\nClassified Rules\\n \\n\\n1\\n01\\n2\\n00\\n11101     \\nConnectors\\n \\n\\n1012001\\n11\\n0\\n1\\n \\n   \\nStructure\\n \\nUnit\\n \\n\\n1012001110\\n1\\n \\n  \\n \\nAction\\n \\n\\n \\n\\n3.5 Genetic Algorithm with Regime Switching\\n  \\n\\n     \\nThe behavior of financial market is not stable. Instead, both temporary and permanent \\n\\nchanges will take place. In addition, those changes can also be categorized as recurring \\n\\nor unique ones. Whenever the market comes across such changes, financial instrume\\n nts \\n\\nacross sectors will experience significant impact as a result. For instance, during each \\n\\nglobal crisis, volatility of asset prices rises dramatically and return correlations among \\n 35\\n \\n\\n \\nasset classes jump drastically.  Since these changes will normally persi\\nst for extended \\n\\nperiod  of  time, \\ntrading  strategies  performing  well  previously  may  become  losers  for \\n\\nextended periods of time for the sake of market changes. \\n  \\n\\n     \\nTherefore it is no longer to apply one fixed strategy all the time in case such major \\n\\nchanges\\n \\ntake place. Actually, among previous literature studying GA\\n -\\nbased trading rules, \\n\\nDempster and Jones (2001) int\\nroduce an adaptive system which enable multi\\n-\\nstrategies \\n\\nto be in effect during one testing period. In their work, GA generate trading strategies \\n at \\n\\nregular intervals and update current strategy in effect. Specifically, current strategy in \\n\\neffect will be discarded once it becomes loser or whenever better trading strategies are \\n\\ngenerated. This is the first research on GA\\n-\\nbased trading strategies that\\n \\nallows updates \\n\\nof strategies to \\nmake trading rules more suitable to market climates. Overall, we agree \\n\\nthat relying on one fixed trading rule all the time is not optimal and adaption to the market \\n\\nis necessary to further improvements on trading results. \\n However, the way we make the \\n\\ntrading strategies adaptive is different from the Dempster and Jones approach (2001).\\n  \\n\\n     \\nThere  have  been  many  researches  covering  market  regimes\\n \\nand  regime  switching \\n\\nmodels have been developed and applied consequently. Market\\n \\nregimes are defined as \\n\\ncertain periods of time according to their special dynamics. For different financial asset \\n\\nclasses,  different  metrics  are  used  to  identify  regimes.  Specifically,  in  terms  of  stock \\n\\nmarket, a normal way is to identify certain regime b\\ny the level of volatility during the \\n\\nperiod.\\n \\nActually  when  investing  in  equity  markets,  key  issues  to  consider  include \\n\\nvolatilities, correlation among stocks expected return and so on. Ang and Bekaert (1999) \\n\\nconclude that two volatility regimes exist in st\\nock market. Similarly, Buren (2012) also \\n\\nsupports that volatility regimes are in place but their association with market changes vary \\n\\nacross business cycles.\\n  \\nIn addition, another understanding of stock market regimes can be \\n\\ndefined as bull and bear market \\n periods. \\nD\\nue to different dynamics of assets upon regime \\n\\nchange, the optimal investment choice justified in previous regime will not guarantee the \\n\\ntransition of its performance into the new regime. For example, buy\\n -\\nand\\n-\\nhold strategy will \\n\\nend up with totall\\ny opposite results when applied to both bull and bear market. Besides, \\n\\nvolatile markets favor strategies with higher trading frequency.  Therefore, both our intent \\n\\nto discover the near\\n-\\noptimal strategy by GA and the corresponding design of experiment \\n\\nshoul\\nd take the issue of regime switching into consideration. \\n In this thesis we pay attention \\n\\nto volatility regimes of equity and \\nmodify our experiments by admitting that one single \\n\\nstrategy is not optimal for the sake of regime switching. Namely, rather than l\\netting GA \\n\\nreveal only one unique pair of long\\n -\\nshort signals, we now entitle the \\nevolution\\n \\nautonomy \\n 36\\n \\n\\n \\nto identify two market regimes and discover the best strategy \\n specific to each of them\\n. In \\n\\norder to take advantage of the regime switching model from the per\\nspective of ex\\n-\\nante \\n\\nforecasting, we use GARCH (Generalized Autoregressive Conditional Heteroscedasticity) \\n\\nmodel. Actually there have been many models predicting volatility, the major reason why \\n\\nwe  select  GARCH  model  is  because  it  is  able  to  capture  volatil\\nity  clustering,  which \\n\\nreflects the real market well. The following is a brief introduction of GARCH model and \\n\\nway we put GARCH into the \\n evolution\\n \\nof GA.\\n \\n\\nFirst we also consider CSI 300 Index and P\\n t\\n \\nis the closing price series. Thus the daily \\n\\ncorresponding c\\nontinuously compounding return R\\n t\\n \\nis defined as:\\n \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n𝑅\\n𝑡\\n=\\n𝐿𝑜𝑔\\n(\\n𝑃\\n𝑡\\n)\\n−\\n𝐿𝑜𝑔\\n(\\n𝑃\\n𝑡\\n−\\n1\\n)\\n \\n                                        \\n (8)\\n \\n\\nThen the GARCH\\n \\n(1\\n, 1\\n) model based on daily co\\nntinuously compounding retu\\nrn R\\nt\\n \\n\\nwill be of the following form:\\n  \\n\\n𝑅\\n𝑡\\n=\\n \\n𝛿\\n+\\n𝜀\\n𝑡\\n=\\n \\n𝛿\\n+\\n \\n𝜇\\n𝑡\\n√\\nℎ\\n𝑡\\n  \\n                                        \\n (9)\\n \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nℎ\\n𝑡\\n=\\n \\n𝛼\\n0\\n+\\n \\n𝛼\\n1\\n𝜀\\n𝑡\\n−\\n1\\n+\\n𝛽\\nℎ\\n𝑡\\n−\\n1\\n \\n                                       \\n (10)\\n \\n\\nWhere \\n𝛼\\n0\\n, \\n𝛼\\n1\\nand \\n𝛽\\n \\nare positive to guarantee that conditional variance is positive and \\n\\nthe innovation is the product of an i.i.d process with zero mean and unit variance \\n 𝜇\\n𝑡\\nand \\n\\nthe square root of conditional variance.\\n  \\n\\nNow  we  implement  the  modification  on  our  experiment  o\\nnce  getting  predicted \\n\\nvolatility from GARCH and we let GA divide the market into two regimes based on a \\n\\nthreshold level of volatility. Then two pairs of strategies will be formed to suit each of \\n\\nthe regimes, on a daily basis, our final strategy to time the\\n \\nmarket will switch between \\n\\nthose two strategies and is totally dependent on  the current regime displayed.  In this \\n\\nexperiment with regime switching, in order to be consistent and comparable, we also use \\n\\nthe data of CSI 300 Index from January 2010 through N\\n ovember 2015 to be the out\\n-\\nof\\n-\\n\\nsample. In terms of the details in our experiment design, everything is identical except \\n\\nthat length “gene” for each candidate strategy are doubled to incorporate another pair of \\n\\nsignals. With the same evolution process genera\\ntion by generation, we end up with one \\n\\noutcome with two pair of signals after the training and evaluation. On top of that, we are \\n\\nalso provided with the volatility threshold to tell the regimes apart and to identify which \\n\\npair of signal to apply.\\n \\n\\nStrategy \\n1 applies IF:\\n \\n\\nPredicted volatility <= threshold volatility\\n  \\n\\nStrategy 2 applies IF:\\n \\n 37\\n \\n\\n \\nPredicted volatility > threshold volatility\\n  \\n\\n \\n\\nAs a comparison, the entire process of GA in generating optimal strategies with and \\n\\nwithout regime\\n-\\nswitching is presented as foll\\nows. In this comparison, the procedure is \\n\\ntargeting market with two regimes. Apparently, the main difference between is at the \\n\\nvery beginning of procedure. In designing experiments considering regime\\n-\\nswitching, \\n\\nthe metrics market regimes are based on shoul\\n d be defined first. In addition, the structure \\n\\nof each candidate solution become more complex as another pair of trading strategy as\\n \\n\\nwell as a threshold are added.\\n  \\n\\nProcedure of GA without regime\\n -\\nswitching\\n:\\n \\n\\n1.\\n \\nInitialize the solution population, with each c\\nandidate consists of one pair of trading \\n\\nsignals. (\\nTraining\\n)\\n \\n\\n2. \\nTest each candidate in current solution by predetermined fitness function and make a \\n\\nranking correspondingly. (\\n Training\\n)\\n \\n\\n3. \\nGenerate next solution population, by passing elites, crossover and \\nmutation, from \\n\\ncurrent generation until stopping criterion is met. (\\n Training\\n)\\n \\n\\n4. \\nRepeat step 2 and 3. (\\nTraining\\n)\\n \\n\\n5. \\nEvaluate the best candidates in each generation to alleviate data over\\n -\\nfitting problem. \\n\\n(\\nEvaluation\\n)\\n \\n\\n6. \\nTest the eventually optimal solution\\n  \\nfrom evaluation in out\\n-\\nof\\n-\\nsample. (\\nTesting\\n)\\n \\n\\n \\n\\nProcedure of GA with regime\\n -\\nswitching\\n \\n\\n1.\\n \\nDetermine the way from which market regimes are defined. (\\n Training\\n)\\n \\n\\n2. \\nInitialize the solution population, with each candidate consists of two pair of trading \\n\\nsignals co\\nrresponding to each regime in addition to a threshold to tell regimes apart. \\n\\n(\\nTraining\\n)\\n \\n\\n3. \\nTest each candidate in current solution by predetermined fitness function and make a \\n\\nranking correspondingly. (\\n Training\\n)\\n \\n\\n4. \\nGenerate next solution population, by \\npassing elites, crossover and mutation, from \\n\\ncurrent generation until stopping criterion is met. (\\n Training\\n)\\n \\n\\n5. \\nRepeat step 3 and 4. (\\nTraining\\n)\\n \\n\\n6. \\nEvaluate the best candidates in each generation to alleviate data over\\n -\\nfitting problem. \\n\\n(\\nEvaluation\\n)\\n \\n\\n7. \\nTest t\\nhe eventually optimal solution from evaluation in out\\n -\\nof\\n-\\nsample. (\\nTesting\\n)\\n \\n 38\\n \\n\\n \\n \\n\\n3.6 Constructing Equity Portfolios\\n  \\n\\nWhen it comes to trading strategy, some traders rely more on market timing while \\n\\nothers might prefer stock selection. One of the major difference\\n  \\nbetween market timing \\n\\nand stock selection is that, market timing is to predict market movements from a macro \\n\\nperspective and gives little attention to individual stock, which is a top\\n-\\ndown analysis.\\n \\n\\nIdeally, a successful market\\n -\\ntiming strategy will increa\\n se the exposure of portfolio to the \\n\\nmarket whenever market is in an upward trend and vice versa. \\n  \\nHowever, stock selection \\n\\nstarts from each individual stock and tries to identify the best ones from their peers. \\nA \\n\\nsuperior stock\\n-\\nselection strategy will disc\\nover a  pool of stocks outperforming market \\n\\nportfolio regardless of the market climate. \\n According to the Capital Asset Pricing Model \\n\\n(CAPM)\\n \\n(William Sharpe, 1964)\\n , investors are compensated in two ways: time value of \\n\\nmoney and risk. The time value of money \\nis represented by the risk\\n-\\nfree return denoted \\n\\nas \\nr\\nf\\n \\nin CAPM while the risk is reflected by “beta” in the formula, which is actually \\n the \\n\\nfocus of market\\n-\\ntiming strategies\\n.\\n \\n\\n \\n\\n     \\n  \\n \\n𝑅\\n𝑎\\n̅\\n̅\\n̅\\n̅\\n=\\n \\n𝑟\\n𝑟𝑓\\n+\\n𝛽\\n𝑎\\n(\\n𝑟\\n𝑚\\n−\\n \\n𝑟\\n𝑓\\n)\\n  \\n                                        \\n(11)\\n \\n\\n \\n\\nHowever, the realized return is not equal to the expected return from CAPM, instead \\n\\nthere is one additional part called “alpha”, which comes from stock selection and has \\n\\nnothing  to  do  with  market  timing.  To  be  more  precise,  investors  will  use  technical \\n\\nana\\nlysis, fundamental analysis and so on to distinguish between “good” stocks and “bad” \\n\\nones  and  put  different  weights  on  them  from  the  benchmark.  The  excessive  return \\n\\nachieved by this way is called the “alpha”. Thus investors with superior investing ability \\n\\nare able to enjoy positive alpha while unexperienced traders may end up with negative \\n\\nalpha.\\n \\n\\n \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n𝑅\\n𝑎\\n=\\n \\n𝑅\\n𝑎\\n̅\\n̅\\n̅\\n̅\\n+\\n \\n𝛼\\n𝑎\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n(12)\\n \\n\\n \\n\\nSince  we  are \\ntesting  whether  GA\\n-\\nbased  trading  strategies  can  increase  portfolio \\n\\nperformances, there should be some benchmarks so that we can reach the conclusion.\\n  \\n\\nIn this paper, our first benchmark is the Index and we will show that, by using GA\\n -\\nbased \\n\\ntechnical trading\\n \\nstrategies\\n \\nin market timing, we are able to achieve significantly better \\n\\nreturns  than  index  return.\\n \\nThe  equity  portfolio  constructed  in  this  way  will  have \\n 39\\n \\n\\n \\ninstruments tracking the market index as its holdings. However, it will differentiate from \\n\\npure  inde\\nxing  by  the  fact  that  both  long  and  short  positions  can  be  taken.  One \\n\\nconventional way to construct this kind of equity portfolios is to take long and short \\n\\npositions of the corresponding index ETF\\n \\nand use GA\\n-\\nbased trading strategies in the \\n\\nentire construc\\ntion of stock portfolio by taking long or short position of the index ETF \\n\\naccording to the signals came up with by GA. On each trading day, the portfolio status \\n\\nwill be one of the following three conditions: long position, short position and empty \\n\\nposition\\n. To achieve this, GA will explore historical market movements and provide us \\n\\nwith a unique combination of long\\n-\\nshort signals. Long and short positions will only be \\n\\ntaken  when  corresponding  signals  are  triggered,  otherwise  we  maintain  an  empty \\n\\nposition\\n.\\n \\nAs\\n \\nwe know, there is neither market timing nor stock selection in the buy\\n -\\nand\\n-\\n\\nhold  strategy,  therefore  all  the  excess  returns  of  the  index  ETF  portfolios  over  pure \\n\\nindexing come in the form of market timing. \\n  \\n\\nBesides, our second benchmark comes in the form o\\nf a portfolio constructed through \\n\\nstock selection. Namely \\nthis time \\nwe will compare \\nthree equity portfolios in total\\n. In \\n\\nterms of the first portfolio\\n  \\nwhich is still pure indexing\\n , there will be neither market timing \\n\\nnor stock selection\\n \\nand this portfolio h\\nas a fixed exposure to the market\\n,\\n \\ntherefore the\\n \\n\\nreturn\\ns\\n \\nof this portfolio will be equal to the index return. In the second portfolio, \\n we use \\n\\nanother  quantitative  approach  to  fulfill  stock  selections  through  Fama\\n-\\nMacBeth \\n\\nregressions (Fama and MacBeth, 1973\\n) on a daily basis.\\n \\nIn the second portfolio, fixed \\n\\nexposure to the market is still in place. However, another resource of return in the form \\n\\nof stock selections is introduced into the portfolio. In other word, there are “alpha” and \\n\\nfixed “beta” in the seco\\nnd portfolio. When compared to the first portfolio based purely \\n\\non indexing, the excess returns of the second portfolio are from stock selections. The \\n\\nthird portfolio is where market timing and stock selection are combined. \\nSpecifically, \\n\\nnot only “alpha” b\\nut also variable “beta” exist in this portfolio. The difference between \\n\\nthe second and third portfolios is that there is only one resource of excess return over \\n\\npure indexing in the second portfolio (stock selection) while  additional returns come \\n\\nfrom two \\naspects in the third portfolio (market timing and stock selection). \\n  \\n\\nFurthermore, when we conduct the experiments testing GA with regime switching, \\n\\nnaturally the most direct benchmark is the portfolios constructed by GA without regime \\n\\nswitching,  with  other\\n \\nthings  equal.  Overall,  by  conducting  our  experiments  in  such \\n\\nsequence, we get to know where excess returns come from and reach conclusions based \\n\\non that.\\n \\n 40\\n \\n\\n \\n \\n\\n4.\\n \\nData, Experiments and Results\\n  \\n\\n \\n\\nWhen  conducting  our  experiments,  we  use  the  data  of  CSI  300  index  and\\n \\nits \\n\\ncomponent stocks. First we also verify whether consistent superior daily trading rules on \\n\\nCSI 300 index\\n \\ncan be revealed by GA. After that, we turn to \\ndemonstrate that market \\n\\ntiming from technical trading strategies discovered by  GA is able to provide another \\n\\nresource of return to both pure indexing and portfolio with stock selection. \\n Moreover, \\nat \\n\\nthe same time we present generated trading rules and thei\\n r corresponding performances, \\n\\nwe also use an econometric way to \\nshow\\n \\nthat trading strategies generated by GA are \\n\\nreasonable and statistically significant\\n ly correlated to achieved returns\\n .\\n \\nLast but not least, \\n\\nwe make a comparison between the performances of\\n  \\ntrading strategies from GA and GA \\n\\nwith regime switching.\\n  \\n\\nSpecifically,  section  4.1  reviews  some  basic  facts  of  the  data  we  used  in  these \\n\\nexperiments and the reason why we target CSI 300 index as our data set. Section 4.2 \\n\\npresents \\nthe experiments aiming at\\n \\nverify the effectiveness of GA in finding superior \\n\\ntechnical trading rules. Section 4.3 presents some experiment results to demonstrate how \\n\\npure indexing strategy can benefit from the trading rules generated by GA. Section 4.4 \\n\\nshows some other experiments\\n \\nto illustrate the way portfolio based on stock selection \\n\\ncan also benefit from trading rules from GA. Section 4.5 reviews the experiments and \\n\\nresults of technical trading rules generated by GA with regime switching.\\n  \\n\\n \\n\\n4.1 \\nData\\n \\n\\nIn  this  thesis,  the  data  set \\nto  be  used  for  test\\ns\\n \\nis\\n \\nthe\\n \\nCSI  300  index,  which  was \\n\\nconstructed on 04.08.2005. \\nCSI 300 index is a capitalization\\n-\\nweighted index with free\\n-\\n\\nfloat adjustments constructed by including 300 sample stocks in Shanghai equity market \\n\\nand Shenzheng equity market ac\\n cording to certain \\n criteria\\n. The component stocks in CSI \\n\\n300 index account for 60% of the total  capitalization of Shanghai equity market and \\n\\nShenzheng equity market.\\n  \\nIn addition, the way component stocks are selected accurately \\n\\nreflects  the  industry  struct\\nure.\\n \\nWe  acquire  the  data  of  CSI  300  index  from  CSMAR \\n\\ndatabase and \\nuse the daily \\nclosing \\nprice data of CSI 300 Index\\n  \\nand its component stocks\\n  \\n\\nfrom April 2005 through October 2015\\n \\nin our experiments\\n.\\n \\nFigure\\n \\n5\\n \\nis the plot of CSI \\n\\n300 index from 2005.04 to 2015\\n .11.\\n \\n\\n \\n 41\\n \\n\\n \\n [Please insert \\nFigure\\n \\n5\\n \\nhere]\\n \\n\\n \\n\\n \\nDue to the fact that CSI 300 Index is not stationary in this period, I normalize the data \\n\\nby taking the log difference of closing prices. This will transform the closing prices into \\n\\ncontinuously  compounding  return  and \\nspare  us  the  issue  of  magnitude,  promoting \\n\\ncomparability.\\n \\nFigure\\n \\n6\\n \\nis the plot of \\ncumulative\\nly continuously compounding return of \\n\\nCSI 300 index from 2005.04 to 2015.11.\\n  \\n\\n \\n\\n[Please insert \\nFigure\\n \\n6\\n \\nhere]\\n \\n\\n \\n\\nAccording to the transformed data, we can identify thre\\n e distinct phases. Namely, the \\n\\nindex  boomed\\n \\nand  increased  from  1000  points  to  5700  points\\n \\nduring  October  2005 \\n\\nthrough December 2007, which is followed by a sharp drop\\n \\n(from 5700 points to 1800 \\n\\npoints)\\n \\nlasting approximately one year (January 2008 \\n–\\n \\nDecember 2008). The index is \\n\\nrelatively stable during October 2009 through October 2010. As a fact of this diversity \\n\\nof market condition during 2005.04 \\n–\\n \\n2010.10, we have chosen the data set of this time \\n\\nperi\\nod as our training sample (in\\n-\\nsample) for \\nverifying \\nGA\\n-\\ngenerated \\nstrategies while \\n\\n2010.11\\n \\n–\\n \\n2015.11 is defined as the out\\n-\\nof\\n-\\nsample. \\nTable 2 \\ncontains some basic facts of \\n\\nCSI 300 index during the period from 2005.04 through 2015.11\\n \\nincluding number of \\n\\ndays,\\n \\naverage daily return, \\n cumulative\\n \\nreturn, return volatility\\n , maximum drawdown\\n  \\nand \\n\\nSharpe ratio. \\n \\n\\n \\n\\n[Please insert Table 2 here]\\n  \\n\\n \\n\\nT\\nhe  unique  characteristics  of  Chinese  stock  market  make  it \\ndifficult  to  achieve \\n\\noutstanding performances by technical analysis\\n . \\nFirst, since the constructions of the two \\n\\nexchanges in 1990 (Shanghai Stock Exchange and Shenzheng Stock Exchange), China’s \\n\\nstock market has experienced significant higher growth than Japan’s Nikkei 225, Hong \\n\\nKong’s Hang Seng Index, the Dow Jones STOXX 600\\n \\ncovering Europe and the Dow \\n\\nJones World Emerging Markets Index which covers 11 major emerging markets all over \\n\\nthe world. Second, China’s stock market is greatly influenced by the government. In fact, \\n\\nup to now the China’s government still imposes a tight\\n  \\ncontrol on the issuance of IPOs. \\n\\nBesides, a lot of listed companies in China have low free\\n-\\nfloat ratios for the sake of \\n\\nwidespread  holdings  of  the  government.  Meanwhile,  market  speculations  and \\n 42\\n \\n\\n \\nmanipulations are common in China’s stock market as a result \\nof the unusual market \\n\\nstructure. Third, China’s stock market is volatile and has gone through various kinds of \\n\\nmarket  climates.  For  example,  the  Dow  Jones  China  Index  ends  up  with  an  average \\n\\nannualized volatility of 51.10% during the period from 1994 to 20\\n 01. In the same period \\n\\nof time, the Dow Jones Industrial Average achieves an average annualized volatility of \\n\\n15.8%. Besides, if a bear market is defined as 20% drop from the previous peak, then \\n\\nChina’s  stock  market  has  experienced  more  than  15  bear  market\\ns  since  its \\n\\ncommencement, which is more frequent than the Dow Jones Industrial Average. Fourth, \\n\\nChina’s stock market is slightly correlated to other stock markets all over the world such \\n\\nas  Dow  Jones  Industrial  Average,  Nikkei  225,  Hang  Seng  Index  and  STOX\\nX.\\n \\nFor \\n\\nexample, political issues have great impacts on Chinese stock markets. \\n  \\n\\nTherefore, it \\ncan shed new lights into the application of the GA on trading strategies\\n \\n\\nif we are able to find superior technical trading rules by \\nthe \\nGA in such a complicated \\n\\nma\\nrket environment\\n. \\nIn other word, b\\n y testing \\nthe \\nGA’s ability to filter trading strategies \\n\\nin such a complex environment, we are capable of deciding whether strategies revealed \\n\\nare able to \\nadapt\\n \\nto and handle \\ncomplex\\n \\nmarket sentiments and preferences. Namel\\n y, we \\n\\navoid generating strategies that perform well in \\nflat\\n \\nmarket\\ns\\n \\nbut fail to deliver similar \\n\\nperformance in \\ncomplicated ones\\n, which is reasonable and meaningful to both academy \\n\\nand practice. Second, although \\n the \\nGA has been widely used in investing proc\\n ess, few of \\n\\napplication is targeting Chinese stock market and this is definitely, a gap to bridge. By \\n\\ntaking on this study with Chinese stock market, we are going to fill this breach and verify \\n\\nwhether there will be differences between the effectiveness of\\n \\nthe\\n \\nGA in discovering \\n\\nstrategies among different markets.\\n  \\n\\n \\n\\n4.2\\n \\nVerification of Genetic Algorithm\\n  \\n\\nSince we have demonstrated in previous content that, from the perspective of predicting \\n\\nreturns, that those three technical indicators (RSI, MACD and Bollinge\\nr band) we pick \\n\\nare effective on trading within CSI 300 Index to make sure there are potentially superior \\n\\nstrategies  available  to  be  discovered  by  GA. \\nIn  this  section,  we  conduct  several \\n\\nexperiments  to  verify  whether  GA  is  effective  in  filtering  strategies\\n \\nand  trading  rules \\n\\ngenerated are able to consistently beat buy\\n-\\nand\\n-\\nhold after transaction costs.\\n \\nIn designing \\n\\nour experiments, we use daily data from 2005.04 through 2015.11 of CSI 300 index and \\n\\nuse similar framework in the work of A&K (1999) except for th\\ne modifications we list \\n\\nbefore.\\n \\n 43\\n \\n\\n \\nWith a population size of 500, ten experiments are performed on the in\\n-\\nsample data \\n\\n(2005.04 \\n–\\n \\n2010.10) and the generated trading strategies vary in term of the level of \\n\\ncomplexity, with the depth of strategies being at most \\nthree levels. For example, one \\n\\nsimple strategy could be:\\n  \\n\\n \\n\\nIF RULE #1 IS TRUE, THEN LONG POSITION IF RULE #1 IS FALSE, THEN \\n\\nSHORT POSITION\\n \\n\\nAs a comparison, one complex rule could be in the following form:\\n  \\n\\n \\n\\nIF RULE #1 IS FALSE AND (RULE #2\\n  \\nIS TRUE OR RULE #3 IS TRUE), THEN \\n\\nLONG THE POSITION\\n  \\n\\nIF RULE #1 IS TRUE OR (RULE #2 IS FALSE AND RULE #3 IS FALSE), THEN \\n\\nSHORT THE POSITION\\n \\n\\n \\n\\nThe  corresponding  Buy\\n-\\nand\\n-\\nHold  return  during  this  period  is  48.97%  and  the \\nin\\n-\\n\\nsample \\nperformance of each of the\\n  \\n10\\n \\nGA\\n-\\ngenerated strategies is in \\n Figure\\n \\n7\\n.\\n \\n\\n \\n\\n[Please insert \\nFigure\\n \\n7\\n \\nhere]\\n \\n\\n \\n\\nAccording to the results, for the training data set, GA\\n -\\ngenerated strategies outperform \\n\\nBuy\\n-\\nand\\n-\\nHold, with the mean excess return being 54.96% during A\\npril 2005 through \\n\\nOctober 2010.\\n \\n\\nAlthough satisfying outcomes are gained on the in\\n -\\nsample data, when these strategies \\n\\nare  utilized  in  the  out\\n-\\nof\\n-\\nsample  (November  2011 \\n–\\n \\nOctober  2015),  half  of  these \\n\\nstrategies are not able to beat Buy\\n -\\nand\\n-\\nHold, which indicates the existence of data over\\n -\\n\\nfi\\ntting problem. Namely, we can’t take it for granted that each strategy recommended by \\n\\ngenetic algorithm is profitable and supposed to apply in the market. However, based on \\n\\nthe fact that some of the GA\\n-\\nbased strategies do perform well in the out\\n -\\nof\\n-\\nsample,\\n \\none \\n\\napproach addressing this over\\n-\\nfitting problem and telling us, among all the strategies \\n\\ngenerated by genetic algorithm, which strategies should be relied on, is needed. \\n Figure\\n \\n8\\n \\n\\nis out\\n-\\nof\\n-\\nsample performance of each of the 10 GA\\n-\\ngenerated strategies whi\\nle \\nFigure\\n \\n9\\n \\n\\nis the plot of the \\ncumulative\\n \\nreturn of one of the 10 generated strategies in the out\\n-\\nof\\n-\\n\\nsample period.\\n \\n 44\\n \\n\\n \\n \\n\\n[Please insert \\nFigure\\n \\n8\\n \\nhere]\\n \\n\\n[Please insert \\nFigure\\n \\n9\\n \\nhere]\\n \\n\\n \\n\\nAs we know, every predicting model with parameters generated from certain peri\\nod \\n\\nof time may suffer from data mining. We definitely cannot suppose that strategies filtered \\n\\nby GA are able to avoid this problem. The fact that majority of the 10 experiments we \\n\\nperformed on CSI 300 index end up with inconsistent performances between in\\n -\\nsample \\n\\nand out\\n-\\nof\\n-\\nsample exactly justifies this concern. Thus, in order to relieve data mining to \\n\\nsome extent, if impossible to completely avoid, and for the selected strategies to not only \\n\\nperform well on the in\\n -\\nsample but also outperform Buy\\n -\\nand\\n-\\nHold str\\nategy on the out\\n -\\nof\\n-\\n\\nsample, we take on the data over\\n -\\nfitting alleviation mechanism used in the work of A&K \\n\\n(1999). Specifically, the data set is the core of this adjustment and now the entire data \\n\\nset is further organized to check on the strategies recomme\\n nded by genetic algorithm on \\n\\nthe in\\n-\\nsample. Specifically, instead of dividing data into in\\n-\\nsample and out\\n-\\nof\\n-\\nsample, \\n\\nout\\n-\\nof\\n-\\nsample are further separated into selection and testing period, thus the whole data \\n\\nset  is  consisting  of  training,  selection,  and  te\\nsti\\nng  data.  Strategies  generated  in\\n \\nthe \\n\\ntraining  period  are  evaluated  in  selection  period  to  check  their  usefulness  in  out\\n-\\nof\\n-\\n\\nsample. After that, only those strategies with consistent performances between training \\n\\nand selection period will be utilized in t\\n he testing period, which is of course, also an out\\n -\\n\\nof\\n-\\nsample.\\n \\n\\nSpecifically, the best\\n-\\nperforming predicting model in each generation from training \\n\\nwill be tested by the same criterion but instead, on the data set in evaluation period. The \\n\\nmost crucial chang\\ne we make here is that, rather than simply taking the best member in \\n\\nlast generation, a new  criterion is used \\n–\\n \\nwe narrow the candidates down to the best \\n\\nmember in each  generation and finally select the one that  ranks first in the selection \\n\\n(evaluation)  pe\\nriod.  Take  CSI  300  Index  for  example,  April  2005 \\n–\\n \\nOctober  2010  is \\n\\nchosen again as the training period as  a result of the market diversity of this period. \\n\\nNovember 2010\\n-\\n \\nOctober 2014 is the selection period while October 2014 \\n–\\n \\nOctober \\n\\n2015 is the testing \\n period. \\nTo test the effectiveness of this over\\n -\\nfitting alleviation system, \\n\\nwe  conduct  another  experiment \\nby  taking\\n \\nthe \\n10\\n \\ntrading  strategies \\nfrom  previous  10 \\n\\nexperiments\\n \\nand measure their performances in\\n  \\nthe new defined\\n \\ntraining, evaluation and \\n\\ntesting periods respectively\\n . Not surprisingly, \\n since the training period remains the same, \\n\\nall of the generated strategies outperform Buy\\n -\\nand\\n-\\nHold \\nstrategy \\nby a significant amount. \\n 45\\n \\n\\n \\nFigure\\n \\n10\\n \\nis the performance\\ns\\n \\nof these 10 tradin\\ng strategies in the training period.\\n  \\n\\n \\n\\n[Please insert \\nFigure\\n \\n10\\n \\nhere]\\n \\n\\n \\n\\nHowever, when these 10 strategies are utilized in the selection period, not all strategies \\n\\nwork well as they do in the training period. \\nHalf of these 10 strategies cannot beat buy\\n-\\n\\nand\\n-\\nho\\nld  in  the  evaluation  period. \\nThe  rationale  of  this  data  over\\n-\\nfitting  alleviation \\n\\nsystem is to identify those strategies with significantly contrary performances between \\n\\ndifferent periods and discard them for the sake of this discrepancy. Therefore, this is\\n \\na \\n\\nway to further filter the trading strategies. By measure \\ntheir performances in training, \\n\\nevaluation and testing periods respectively, we can\\n \\ntest the assumption that strategies \\n\\nperforming in not only training period but also evaluation period will end u\\np being the \\n\\ntop strategies as well in testing period.\\n \\nFigure\\n \\n11\\n \\npresents the performances of these 10 \\n\\ntrading strategies in the evaluation\\n \\nperiod while \\nFigure\\n \\n12\\n \\npresents the performances of \\n\\nthese 10 trading strategies in the testing period. In \\n Figure\\n \\n13\\n, \\nthe comparison among the \\n\\nperformances\\n, in terms of \\ncumulative\\n \\nreturn,\\n \\nof buy\\n-\\nand\\n-\\nhold and the three top trading \\n\\nrules from evaluation period in testing period is presented.\\n  \\n\\n \\n\\n[Please insert \\nFigure\\n \\n11\\n \\nhere]\\n \\n\\n[Please insert \\nFigure\\n \\n12\\n \\nhere]\\n \\n\\n[Please insert \\nFigur\\ne\\n \\n13\\n \\nhere]\\n \\n\\n \\n\\nIn fact, top three strategies measured in the selection period are still the best three \\n\\nstrategies in the testing period. Therefore, we are confident about this data over\\n-\\nfitting \\n\\nalleviation system in terms of its ability\\n \\nto address data over\\n-\\nf\\nitting problem\\n \\nby some \\n\\nextent\\n.\\n \\n\\nThe outcomes above are based on the fact that fitness function in genetic algorithm is \\n\\nthe holding period return (HPR). Practically, sometimes risk\\n -\\nadjusted return is preferred \\n\\nas  a  way  to  reduce  risk  and  maximum  drawdown  is \\na  typical  and  popular  metric  to \\n\\nrepresent risk. Therefore, as a comparison, the entire process before is repeated except \\n\\nthat fitness function is adjusted sterling ratio, rather than holding\\n-\\nperiod return (HPR). \\n\\nBy using adjusted Sterling ratio as the fitn\\ness function, we literally attach a penalty to \\n\\nthose strategies with large volatility and, as a result of this, strategies standing out are \\n\\nable to maintain a lower level of risk.\\n  \\n 46\\n \\n\\n \\nThis time, twenty experiments are performed on the training period (2005.04\\n -\\n2010.10) \\n\\nand  strategies  are  evaluated  over  selection  period  (2010.11\\n-\\n2014.10).  Finally,  testing \\n\\nperiod is used to check whether those strategies enjoy consistent performance in both \\n\\nselection  and  testing  period  (2014.10\\n-\\n2015.10).  Totally  18  different  strat\\negies  are \\n\\ngenerated  from  the  twenty  t\\nria\\nls  and  their  performances  in  each  of  three  periods  are \\n\\ndisplayed as following. One issue worth mentioning is that it is useless to measure risk\\n -\\n\\nadjusted return when return is negative. Thus we only calculate the adju\\n sted sterling ratio \\n\\nfor those strategies with positive return.\\n  \\n\\n \\n\\n𝐴𝑑𝑗𝑢𝑠𝑡𝑒𝑑\\n \\n𝑆𝑡𝑒𝑟𝑙𝑖𝑛𝑔\\n \\n𝑟𝑎𝑡𝑖𝑜\\n=\\n \\n𝑐𝑢𝑚𝑢𝑙𝑎𝑡𝑖𝑣𝑒\\n \\n𝑟𝑒𝑡𝑢𝑟𝑛\\n\\n1\\n+\\n𝑀𝑎𝑥𝑖𝑚𝑢𝑚\\n \\n𝑑𝑟𝑎𝑤𝑑𝑜𝑤𝑛\\n                                \\n (13)\\n \\n\\n \\n\\nWe find that, due to the market \\n downward \\nmovement during \\nthe \\nselection period, only \\n\\ntwo strategies end up with positive return and these two strategies are\\n \\naccidentally\\n \\nthe \\n\\ntop  2  strategies  recom\\nmended  by  GA  on  training  period,  which  is  rather  rare  in  our \\n\\nexperiments.\\n \\nAccording to previous experi\\nence, we\\n \\ntransfer those 18 trading strategies \\n\\nto testing period and find that top strategies in the evaluation period still maintain their \\n\\nrankings in the testing period\\n. \\nFigure\\n \\n1\\n4\\n \\nis the scatter plot of the performances of these \\n\\n18  trading  strategies  in  t\\nhe  training  period. \\nFigure\\n \\n1\\n5\\n \\nis  the \\ncomparison  between\\n \\nthe \\n\\nperformances, in terms of \\ncumulative\\n \\nreturn, of buy\\n-\\nand\\n-\\nhold and the \\nbest trading rule\\n \\n\\nfrom evaluation period in testing period\\n .\\n \\n\\n \\n\\n[Please insert \\nFigure\\n \\n14\\n \\nhere]\\n \\n\\n[Please insert \\nFigure\\n \\n1\\n5\\n \\nhere]\\n \\n\\n \\n\\nCon\\nsequently\\n, the strategy recommended by genetic algorithm is more or less similar \\n\\nto that when fitness function is HPR. The reason why this is the case is because China’s \\n\\nstock market has experienced a lasting sharp drawdown since June 2015 and strategy \\n\\ntha\\nt is supposed to maximize sterling ratio is able to escape from the drawdown before \\n\\nits commencement.\\n \\n\\nOverall, so far we have demonstrated that as long as the data over\\n-\\nfitting alleviation \\n\\nsystem  is  in  place, \\ntrading  strategies  generated  after  the \\nevolutio\\nn\\n \\nwill  not  deliver \\n\\nsignificantly contrary between in\\n -\\nsample periods and out\\n -\\nof\\n-\\nsample periods. Besides, all \\n\\nof the technical trading rules generated this way in our experiments are able to beat buy\\n -\\n 47\\n \\n\\n \\nand\\n-\\nhold in the out\\n-\\nof\\n-\\nsample period.\\n \\nAccording to the results of experiments so far, we \\n\\nhave two conclusions about the GA\\n-\\nbased technical trading rules. First, based on CSI \\n\\n300 index and the framework of the work of A&K (1999), GA is able to help generating \\n\\nsuperior  technical  trading  rules  t\\nhat  consistently  beat  buy\\n-\\nand\\n-\\nhold \\nafter  considering \\n\\ntrading expenses on a daily basis\\n . Second, the data over\\n -\\nfitting alleviation mechanism is \\n\\nessential in achieving consistent outperformances for strategies generated by GA in the \\n\\nout\\n-\\nof\\n-\\nsample periods.\\n \\n \\n\\nS\\nince we have gained \\n e\\nmpiri\\nca\\nl\\n \\nresults\\n \\na\\nnd\\n \\nd\\ne\\nm\\no\\nn\\ns\\nt\\nra\\nte\\nd\\n \\nt\\nhe\\n \\ne\\nf\\nf\\ne\\nc\\nt\\ni\\nv\\ne\\nn\\ne\\ns\\ns\\n \\no\\nf\\n \\nth\\ne GA\\n, \\n\\nmore  tests  are  performed  to  show \\nthat  the \\nGA  is  capable  of  enhancing  the  portfolio \\n\\nperformances from the perspective of higher returns and lower risks. In the following \\n\\nsection, we present the perfor\\nmance of four kinds of equity portfolios with the returns \\n\\nattributed  respectively  to  pure  indexing,  market  timing,  stock  selection  and  market \\n\\ntiming with stock selection. \\n  \\n\\n \\n\\n4.3\\n \\nPure Indexing\\n \\n\\nIn  this  section,  we  perform  another  several  comparisons  to  show  t\\nhat,  GA\\n-\\nbased \\n\\nstrategies can provide equity portfolios with another resource of returns by timing the \\n\\nmarket. The data we use in these experiments include daily closing prices of CSI 300 \\n\\nindex and its component stocks from 2005 through 2015. due to the fac\\n t that GA asks for \\n\\nsome data to do the training before it can provide us with the performances of trading \\n\\nstrategies  in  our\\n-\\nof\\n-\\nsample  periods,  the  real  comparison  will  be  over  5  years  from \\n\\n2010\\n.01\\n \\nthrough 2015\\n.12\\n. First, we present the performance of buy\\n-\\na\\nnd\\n-\\nhold strategy. \\n\\nSince there is no market timing or stock selection in this passive portfolio and we assume \\n\\ntaking long position of the index all the way during these 5 years without any adjustment, \\n\\nnamely pure indexing. The \\nFigure\\n \\n1\\n6\\n \\nis the plot of histo\\nrical closing points and \\nFigure\\n \\n\\n1\\n7\\n \\ndisplays  the  corresponding \\ncumulative\\n \\ncontinuously  compounding  returns  of  this \\n\\npassive  portfolio \\n–\\n \\npure  indexing.\\n \\nWe  can  see  that  buy\\n-\\nand\\n-\\nhold  strategy  achieves  a \\n\\nreturn of 6.12% with a Sharpe ratio of 0.0024 during this \\nperiod of time from 2010.01\\n-\\n\\n2015.12.\\n \\n\\n \\n\\n[Please insert \\nFigure\\n \\n1\\n6\\n \\nhere]\\n \\n\\n[Please insert \\nFigure\\n \\n1\\n7\\n \\nhere]\\n \\n\\n \\n 48\\n \\n\\n \\n4.4 \\nMarket Timing\\n \\n\\nIn order to show that performances of pure indexing can be promoted by the ability of \\n\\nGA\\n-\\nbased  technical  trading  rules  to  time  the  market\\n,  we  still  do  not  consider  stock \\n\\nselection and only long or short positions of CSI 300 Index can be taken if our position \\n\\nis  not  empty.  The  reason  we  allow  short  positions  is  that  the  costs  of  taking  short \\n\\npositions of index will be much lower than those o\\n f shorting individual stocks. Besides, \\n\\nthe flexibility and smartness of GA can be tested if we not only permit long positions, \\n\\nbut also short positions. As we explained in previous sections, there will be data over\\n-\\n\\nfitting problems for every machine learni\\nng method and GA suffers from it as well. In \\n\\norder to relieve this problem to some extent, we reserve some data  as the evaluation \\n\\nperiod. To be more precise, the daily prices of CSI 300 Index from 2005 January through \\n\\n2008 April are used by GA to do the tr\\n aining, and the evaluation is performed during the \\n\\nperiod from 2008 May to 2009 December. After the training and evaluation, GA provides \\n\\nus with one unique set of long\\n -\\nshort trading rules and we apply them in the testing period \\n\\n(out\\n-\\nof\\n-\\nsample) between 2010\\n .01 through 2015.12. With the same design of experiment, \\n\\nwe perform 10 experiments to get 10 different market timing strategies. The Table \\n3\\n \\n\\ncontains key aspects of the gained strategies in the out\\n -\\nof\\n-\\nsample.\\n \\n\\n \\n\\n[Please insert Table \\n3\\n \\nhere]\\n \\n\\n \\n\\nSince GA works w\\nith bit\\n-\\nstrings, we interpret gained results and take strategy 1 in \\n\\ntable above from the perspective of GA for example and make a detailed explanation. \\n\\nWithin this certain strategy, the trading rules for taking positions are as following:\\n  \\n\\n \\n\\nTaking long \\nposition IF:\\n \\n\\nDIFF>DEA & difference between DIFF and DEA increasing (MACD) OR\\n  \\n\\nClosing price cross above upper band (Bollinger) XOR RSI>75 (RSI)\\n  \\n\\n \\n\\nTaking short position IF:\\n  \\n\\nClosing price cross below lower band (Bollinger Band) OR\\n  \\n\\n25<=RSI<50 (RSI)\\n \\n\\n \\n\\nTaking empt\\ny position IF: Otherwise\\n  \\n 49\\n \\n\\n \\n  \\n\\nWhen we investigate this trading strategy discovered by GA, we find that one of the \\n\\nlong  signals  is  purely  based  on  MACD  while  short  position  signals  rely  on  RSI  and \\n\\nBollinger Band. Consequently, there will be 4 potential \\n different signals to be released:\\n  \\n\\n \\n\\n1. \\nOnly long position signal is released.\\n  \\n\\n2. \\nOnly short position signal is released.\\n  \\n\\n3. \\nNeither long nor short position signal is released.\\n  \\n\\n4. \\nBoth long and short position signals are released.\\n  \\n\\n \\n\\nAccording  to  the  strategy\\n,\\n \\nlong  position  signals  and  short  position  signals  are  not \\n\\nmutually  exclusive and theoretically, there is contradiction when both long and short \\n\\nsignals are conveyed, therefore we should consider whether this GA\\n-\\ngenerated strategy \\n\\nis practically reasonable \\n and we eventually reach an affirmative conclusion. As we know, \\n\\nthe  technical  indicator  MACD  is  based  on  moving  average  of  closing  prices  with \\n\\ndifferent  durations  and  whenever  the  condition  for  taking  long  positions \\n\\n“DIFF>DEA&DIFF>0” is met, the market has \\nbeen in an upward trend for a while. In \\n\\nthis  case,  recent  closing  price  has  been  rising  for  some  periods  of  time  so  that  it  is \\n\\nimpossible  for  closing  to  be  below  the  lower  band  of  Bollinger  Band.  Similarly, \\n\\nwhenever RSI takes value between 25 and 50, marke\\nt is considered as relatively weak \\n\\nand it is not likely to see MACD in the phase “DIFF>DEA&DIFF>0” simultaneously. \\n\\nTherefore,  although  the  signals  for  taking  opposite  positions  are  not  theoretically \\n\\nmutually exclusive, practically, they will not display at\\n  \\nthe same time. \\n \\n\\nWe  also  check  the  details  of  our  experiment  results  and  find  no  co\\n-\\nexistence  of \\n\\ncontrary signals in any period of time.  Besides, the meaning of this strategy is logical \\n\\nand match our understanding of the market. In terms of the first sign\\n al for long position \\n\\nconsidering only MACD, we have explained that market is keep being strong and recent \\n\\nclosings are getting higher recently and it will be good buy points then. The other buying \\n\\nsignal rely on two technical indicators \\n–\\n \\nRSI and Bollinger\\n \\nBand. RSI is known as an \\n\\napproach to judge the section market has moved into and a value above 75 for RSI is \\n\\nnormally reflect that market has been in overbought sector while values below 25 stand \\n\\nfor the opposite. Bollinger Band is used to measure the dev\\n iation of closing prices to its \\n\\nmoving average on a daily basis in our experiments, the common sense is to consider \\n\\nboth  upper  and  lower  band  as  important  points where  breakings  are  going  to  release \\n 50\\n \\n\\n \\nparticular signals. However, the exact signals from break\\n ing upper or lower band vary to \\n\\ndifferent participants or different stocks. Take the breaking above the higher band for \\n\\nexample, this phenomenon appears to some equity traders as good buying point for the \\n\\nsake of penetration of a resistant level. Whereas, \\n the same situation might convey exactly \\n\\nopposite signals for others because stocks with prices jumping above \\n the higher\\n \\nband is \\n\\nalso considered as being overbought and reverse is expected. When investigating the \\n\\nsecond  signal  (closing  price  cross  above  upp\\ner  band  XOR  RSI>75)  for  taking  long \\n\\nposition of this strategy, we surprisingly find that dilemma is addressed wisely. As we \\n\\nknow, RSI is another technical indicator tracking momentum of the target. When RSI is \\n\\nput into consideration with Bollinger Band in \\n the manner of the strategy, they are able to \\n\\nconfirm each other and a clearer picture is presented to us. Precisely, the strategy tells us \\n\\nwhenever closing price jumps above the higher band of Bollinger with a corresponding \\n\\nvalue of RSI below 75, it should\\n \\nbe considered as a breaking. However, when RSI rises \\n\\nabove  75  at  the  same  time,  overbought  market  is  more  likely  presenting  instead  and \\n\\ntherefore, a buying signal is not appropriate in this situation.\\n  \\n\\nWith one\\n-\\nway trading cost of 20bps, by using strategy \\n 1 in the training period, we are \\n\\nable to end up with a holding period return (HPR) of 216%, which exceeds the return of \\n\\nindexing by 97% after cost. Most importantly, in the testing period of 5 years, which is \\n\\ntotally out\\n-\\nof\\n-\\nsample, we are able to enjoy a H\\nPR of 134% with a Sharpe ratio of 0.94, \\n\\nwhen passive investing ends up with return of only 6% over 5 years. We pay special \\n\\nattention to the period from June 2015 through September 2015 when CSI 300 Index \\n\\nplummets by near 50% (5380 to 2900) over 3 months. A\\nccording to the strategy 1, our \\n\\nposition spends more than 90% of the time shorting the index during this period, not only \\n\\navoid  suffering  from  this  crisis  but  also  making  some  profits  from  it.\\n \\nFigure\\n \\n1\\n8\\n \\nand \\n\\nFigure\\n \\n1\\n9\\n \\nare the comparisons between strategy 1 \\n and buy\\n-\\nand\\n-\\nhold strategy in the form \\n\\nof \\ncumulative\\n \\nreturns in training and testing periods respectively.\\n  \\n\\n \\n\\n[Please insert \\nFigure\\n \\n1\\n8\\n \\nhere]\\n \\n\\n[Please insert \\nFigure\\n \\n1\\n9\\n \\nhere]\\n \\n\\n \\n\\nIn order to show that GA is able to enhance portfolio performance by discovering \\n\\nunderlying effective application of technical indicators, we conduct a statistical test on \\n\\nthe indicators GA leverages on. Similar to previous experiment we have verifying the\\n \\n\\neffectiveness  of  technical  indicators,  here  we  utilize  approximately  the  same  design. \\n 51\\n \\n\\n \\nNamely,  we  run  a  regression  of  daily  return  of  CSI  300  Index  on  an  exhaustive  and \\n\\nmutually exclusive set of factors standing for possible scenarios of technical indicato\\nrs \\n\\nover  both  the  training  period  (2005.01 \\n-\\n \\n2008.04)  and  evaluation  period  (2008.05 \\n-\\n \\n\\n2009.12).\\n \\n\\n \\n\\n𝑅\\n𝑖\\n=\\n𝛽\\n1\\n𝑅𝑆𝐼\\n1\\n+\\n \\n𝛽\\n2\\n𝑅𝑆𝐼\\n2\\n+\\n𝛽\\n3\\n𝑅𝑆𝐼\\n3\\n+\\n𝛽\\n4\\n(\\n1\\n−\\n𝑅𝑆𝐼\\n1\\n−\\n𝑅𝑆𝐼\\n2\\n−\\n𝑅𝑆𝐼\\n3\\n)\\n \\n\\n+\\n𝛽\\n5\\n𝑀𝐴𝐶𝐷\\n1\\n+\\n𝛽\\n6\\n𝑀𝐴𝐶𝐷\\n2\\n+\\n𝛽\\n7\\n𝑀𝐴𝐶𝐷\\n3\\n+\\n𝛽\\n8\\n(\\n1\\n−\\n𝑀𝐴𝐶𝐷\\n1\\n−\\n𝑀𝐴𝐶𝐷\\n2\\n−\\n𝑀𝐴𝐶𝐷\\n3\\n)\\n \\n\\n+\\n𝛽\\n9\\n𝐵𝑜𝑙𝑙𝑖𝑛𝑔𝑒𝑟\\n1\\n+\\n𝛽\\n10\\n𝐵𝑜𝑙𝑙𝑖𝑛𝑔𝑒𝑟\\n2\\n+\\n𝛽\\n11\\n𝐵𝑜𝑙𝑙𝑖𝑛𝑔𝑒𝑟\\n3\\n+\\n𝛽\\n12\\n(\\n1\\n−\\n𝐵𝑜𝑙𝑙𝑖𝑛𝑔𝑒𝑟\\n1\\n−\\n𝐵𝑜𝑙𝑙𝑖𝑛𝑔𝑒𝑟\\n2\\n−\\n𝐵𝑜𝑙𝑙𝑖𝑛𝑔𝑒𝑟\\n3\\n)\\n              \\n(\\n14)\\n \\n\\n \\n\\nWhere  R\\ni \\nis  the  daily  continuously  compounding  return  of  CSI  300  Index.  RSI\\ni\\n, \\n\\nMACD\\ni \\nand Bollinger\\ni \\nare regressors standing for scenario of those three indicators. \\nIn \\n\\nfact\\n, according to this regression, we have categorized RSI, MACD and Bollinger into 4 \\n\\nscenarios respectively. The \\nTable \\n4\\n \\ncontains detailed information of the categorization \\n\\nand t\\n-\\nstats fo\\nr each of the regressors in regression above.\\n  \\n\\n \\n\\n[Please insert Table \\n4\\n \\nhere]\\n \\n\\n \\n\\nBased on the regression, we are able to find indicator scenarios that are significantly \\n\\nassociated with positive and negative index returns and open the black box where GA \\n\\ngenerat\\ne strategies for us. One of signals for long position in strategy one exactly matches \\n\\nthe scenario of MACD that accurately predicts upward market. The same situation can \\n\\nbe found for one of the signals for taking short positions as well.\\n  \\n\\nOverall, the 10 \\nex\\nperiments\\n \\nwe perform on timing CSI 300 Index provide us with 10 \\n\\ndifferent strategies enjoying superior performances compared to indexing. Thus we have \\n\\nsuccessfully  demonstrated \\nthat  pure  indexing  can  benefit  from  GA\\n-\\nbased  technical \\n\\ntrading rules with regar\\nd to timing the market \\nand changing exposures to the market \\n\\ncorrespondingly. In next section, we will present the performance of the active portfolio \\n\\nwith stock selection and the difference when market timing from GA\\n-\\nbased technical \\n\\ntrading rule is added i\\nn.\\n \\n\\n \\n\\n4.5 \\nStock s\\nelection\\n \\nwith market timing\\n \\n\\nIn addition to pure indexing, here we prove that actively managed portfolios can also \\n\\nbenefit from GA. In terms of the actively managed portfolio involving stock selection, \\n\\nwe take advantage of Fama\\n-\\nMacBeth regres\\nsion (Fama and MacBeth, 1973) in making \\n\\nstock return forecasts on a daily basis. Details of Fama\\n -\\nMacBeth regression can be found \\n 52\\n \\n\\n \\nin previous chapter and in this experiment we also use \\n the \\nthree technical indicators (RSI, \\n\\nMACD  and  Bollinger  Band)  to  explain\\n \\nrealized  returns.  Within  the  regressions,  the \\n\\ndependent  variable  is  the  daily  realized  return  of  300  component  stocks,  which  is \\n\\ncalculated as the log\\n-\\ndifference of daily closing prices. On the other side of regressions, \\n\\nthere  are  12  regressors,  which  exha\\nustively  reflect  each  possible  condition  of  each \\n\\ntechnical indicator we considered. For example, among the 12 regressors explaining the \\n\\nrealized return of one stock, only  3  regressors  will take the value “1” while other \\n\\nregressors are valued “0”. With a ro\\n lling\\n-\\nwindow of 75 days, this approach continuingly \\n\\ninforms  us,  based  on  recent  market  movements,  the  indicator  status  significantly \\n\\nassociated with positive and negative returns and essentially, the best way  we utilize \\n\\nthose three technical indicators in \\n making predictions. We then construct and adjust this \\n\\nportfolio  according  to  the  ranking  of  stocks  by  predictions.  In  the  experiment,  we \\n\\nconstruct two portfolios through this method. The first one is made up of long positions \\n\\nin the top 5% component stocks\\n \\nwhile the second one consists of short positions in the \\n\\nbottom 5% component stocks from the ranking on a daily basis. The following \\n Figure\\n \\nis \\n\\nthe \\ncumulated\\n \\nlog\\n-\\nreturn of these two portfolios over 5 years. \\n  \\n\\nThe short\\n-\\nposition portfolio enjoys a HPR of 150%\\n \\nwith a Sharpe ratio of 1.96 while \\n\\nthe long\\n-\\nposition portfolio ends up with a HPR of 135% with a Sharpe ratio of 1.7. Those \\n\\ntwo  actively  managed  portfolios  beat  the  passive  indexing. \\nFigure\\n \\n20\\n \\ndisplays  the \\n\\nperformances of both the long\\n -\\nposition portfolio a\\n nd the short\\n -\\nposition portfolio in terms \\n\\nof \\ncumulative\\n \\nreturns.\\n \\n\\n \\n\\n[Please insert \\nFigure\\n \\n20\\n \\nhere]\\n \\n\\n \\n\\nSin\\nce we have verified GA’s market\\n -\\ntiming ability before, here we also test if \\n the \\nGA \\n\\nstill  work  well  within  actively  managed  portfolio.  Because  we  are  testing  the \\n\\nperformances of different strategies on the same period of time, we transfer the previous \\n\\nGA\\n-\\ngenerated long\\n -\\nshort signals to actively managed portfolios. Specifically, long si\\n gnal \\n\\ngenerated by \\nthe \\nGA represent an upward trend of market while the short signal conveys \\n\\nthe opposite meaning. Therefore, it is reasonable to assume long positions portfolio will \\n\\nbeat  the  short  one  in  upward  trends  and  this  relationship  will  reverse  whe\\nn  market \\n\\nplummets. Thus, when we bring \\n the \\nGA in to the portfolio construction, the outcome can \\n\\nbe even better off by taking the long positions when GA\\n-\\ngenerated positive signal is \\n\\ntriggered and taking short positions when the negative one shows up. The \\n Fi\\ngure\\n \\n21\\n \\nwill \\n 53\\n \\n\\n \\ngive us a big picture of GA’s judgment on the market\\n \\nmovements\\n, we use “100” to \\n\\nrepresent long signals and “\\n -\\n100” to stand for short signals.\\n  \\n\\n \\n\\n[Please insert \\nFigure\\n \\n21\\n \\nhere]\\n \\n\\n \\n\\nSo the refined actively managed portfolio is constructed in this \\nway: when the long \\n\\nsignals or empty signals are released, our refined portfolio takes\\n  \\nthe top 5% component \\n\\nstocks as its holding, which is same as the long position portfolio. When short signals \\n\\nshow  up,  our  refined  portfolio  will  experience  same  daily  ret\\nurns  as  those  for  short \\n\\nposition portfolio. The refined portfolio sees a growth of 261% with a Sharpe ratio of \\n\\n2.54,  which  is  apparently,  better  than  both  the  long\\n-\\nposition  portfolio  and  the  short\\n-\\n\\nposition portfolio defined before. The following is a summa\\nry of the three portfolios in \\n\\ncomparison and the \\nFigure\\n \\nof \\ncumulative\\n \\nreturns for each of them.\\n  \\n\\n \\n\\nPortfolio 1: Long positions of top 5% CSI 300 Index component stocks after ranking.\\n  \\n\\nPortfolio 2: Short positions of bottom 5% CSI 300 Index component stocks af\\n ter ranking.\\n \\n\\nPortfolio 3: S\\nwitch between Portfolio 1 and Portfolio 2 based on market timing of GA \\n\\nstrategy. \\n \\n\\n \\n\\nIn fact\\n, we provide the \\nFigure\\n \\n22\\n \\nto show the comparison among these 3 portfolios \\n\\nand Table \\n5\\n \\ncontaining  details of each portfolio we considered i\\nn this comparison to \\n\\nprove that GA is able to add value to not only \\n pure indexing\\n, but also actively managed \\n\\nportfolios from the perspectives of both higher return and lower risk.\\n  \\n\\n \\n\\n[Please insert \\nFigure\\n \\n22\\n \\nhere]\\n \\n\\n[Please insert Table \\n5\\n \\nhere]\\n \\n\\n \\n\\nOverall, accor\\nding to our experiments measuring the benefit GA brings to portfolios, \\n\\nthe results show that originally passively managed portfolio (pure indexing) is able to \\n\\nend up with a return of at least 106% with a Sharpe ratio close to 1 over the period from \\n\\n2010.01\\n \\nthrough 2015.12. In the same period of time, buy\\n-\\nand\\n-\\nhold strategy achieves a \\n\\nreturn  of  6.12%  with  a  Sharpe  ratio  of  0.0024.  With  regard  to  the  kind  of  actively \\n\\nmanaged  portfolio  with  returns  attributed  to  stock  selection,  originally  it  is  able  to \\n\\nachieve\\n \\nreturns of 135% and 150% by taking long and short positions respectively from \\n 54\\n \\n\\n \\n2010.06 to 2015.12. However, a significantly higher return of 261% is achievable during \\n\\nthe same period of time when GA is applied in the investing process. Also, there is a \\n\\npro\\nmoted Sharpe ratio associated with the actively managed portfolio for the sake of \\n\\nmarket\\n-\\ntiming ability provided by GA\\n -\\nbased technical trading rules.\\n  \\n\\n \\n\\n4.6 GA with regime switching\\n  \\n\\nSo far\\n, we \\nhave \\nconduct\\ned\\n \\nseveral experiments to show GA is able to filter s\\n trategies \\n\\nand to narrow those to superior ones still performing \\nwell \\nin out\\n-\\nof\\n-\\nsample \\nperiods \\nas \\n\\nlong as some mechanism is in place to alleviate data over\\n-\\nfitting problem Next, \\nin this \\n\\nsection \\nwe \\nare going to\\n  \\nverify and illustrate that, GA can adjust to an\\n d incorporate regime \\n\\nswitching into its working environment. Namely, comparison between investing results\\n  \\n\\nfrom  trading  strategies  generated  from  GA  only  and  those  from\\n \\nGA  and  regime\\n-\\n\\nswitching together are presented to justify our assumption that even bette\\n r performances \\n\\ncan be fulfilled when regime\\n -\\nswitching is put into consideration of GA.\\n  \\n\\nIn  the  new  experiments  to  generate  technical  trading  rules  from  GA  with  regime \\n\\nswitching  taken  into  consideration,\\n \\nwe  are  going  to  provide  GA  with  discretion  in \\n\\nidentifying market re\\ngimes with regard to volatility. In this thesis, we only consider the \\n\\nsituation  where  GA  segregates  the  market  into  two  regimes  and  generate  trading \\n\\nstrategies  for  each  of  them  correspondi\\nngly.    The  only  difference  between  our  new \\n\\nexperiments and previous ones is that, instead of only one, now two pairs of long\\n-\\nshort \\n\\nsignals are generated with a threshold point to separate regimes. Therefore, in applying \\n\\ntechnical trading rules generated fr\\nom GA, we should first judge the market regime we \\n\\nare currently in.\\n \\n\\nThe \\nFigure\\n \\n23\\n \\nshows the forecasted volatility based on GARCH model in \\n the \\nout\\n-\\nof\\n-\\n\\nsample period and the corresponding threshold point GA select from one experiment to \\n\\ndifferentiate the \\nmarket regimes.\\n \\nFigure\\n \\n24\\n \\nillustrates the percentages of each regime in \\n\\nthe form of a pie chart.\\n \\n\\n \\n\\n[Please insert \\nFigure\\n \\n23\\n \\nhere]\\n \\n\\n[Please insert \\nFigure\\n \\n24\\n \\nhere]\\n \\n\\n \\n\\nBased on this categorization, with a threshold volatility of 0.0253, regime 1 accounts \\n\\nfor 95% \\nof the entire period from 2010 through 2015. Regime 2 is defined as the periods \\n\\nwith a relatively high volatility (when daily volatility is higher than 0.0253). In other \\n 55\\n \\n\\n \\nword, in this experiment, we end up with two strategies after all the \\n evolution\\n \\nand ap\\nply \\n\\none of them in 95% of the time, with the other one used during the rest 5% period.\\n  \\n\\nWith the market regimes taken into consideration, we can easily find that, in the periods \\n\\ndefined as regime with high volatility, strategy 2 markedly beats strategy 1 an\\n d our final \\n\\nstrategy  has  taken  advantage  of  the  outperformance  of  strategy  2  over  that  period. \\n\\nSpecifically, strategy considering regime switching achieves a holding period return of \\n\\n168% with a Sharpe ratio of 1.17. As a comparison, regime 1 strategy whic\\n h is the best \\n\\nin two strategies filtered by GA, underperforms by 57% in HPR with a Sharpe ratio of \\n\\n0.77. It is noticeable that neither of the 2 strategies specific to regimes is able to beat \\n\\nstrategies we attain in previous experiments when regime switchin\\n g is not considered in \\n\\nits  framework.  However,  the  final  regime\\n-\\nswitching  strategy  based  on  two  strategies \\n\\nspecific to regimes achieve better performance instead. \\nFigure\\n \\n2\\n5\\n \\nreviews the plots of \\n\\nthe trading rules specific to each regime and the final strate\\ngy as well in the form of \\n\\ncumulative\\n \\nreturns in the out\\n-\\nof\\n-\\nsample.\\n \\n\\n \\n\\n[Please insert \\nFigure\\n \\n2\\n5\\n \\nhere]\\n \\n\\n \\n\\nThe rationale behind this phenomenon is that, on the one hand, when regime switching \\n\\nis not taken into consideration, the entire time window in test is used\\n \\nto filter trading \\n\\nstrategies, regardless of the market regimes. Thus optimal strategy gained by this way \\n\\nhas  already  gauged  its  performance  in  each  period  of  time  and  achieved  a  balance \\n\\nbetween  different  market  regimes.  In  other  word,  strategies  that  deli\\nver  significantly \\n\\ncontrary  performances  will  not  achieve  superior  ranking  from  fitness  function  that \\n\\nmeasure both return and risk. On the other hand, when regimes are clearly defined to \\n\\ngenerate corresponding suitable strategies, each strategy generated is\\n  \\naiming at achieving \\n\\nthe best performance in certain regime instead of the whole time window. Therefore, \\n\\nwhen  these  strategies  are  applied  all  the  time,  chances  are  that  they  perform  well  in \\n\\nregime where they are generated and lose in other regimes.\\n  \\n\\nTo ver\\nify our conclusion, another 9 experiments are conducted with regime switching \\n\\nin consideration and the \\n Table \\n6\\n \\ncontains outcomes of these 9 experiments. All the results \\n\\nare based on the period of time from \\n 2010.01\\n \\nthrough \\n2015.12\\n \\nand identical test design.\\n \\n\\n \\n\\n[Please insert Table \\n6\\n \\nhere]\\n \\n\\n \\n 56\\n \\n\\n \\nOverall,  according  to  the  experiment  results\\n,  regime  switching  being  part  of  the \\n\\nevolution\\n \\nof GA enables us to consistently acquire better results than any single strategy \\n\\napplied  all  the  time.  The  reason  why  this  is  the  cas\\ne  is  because  regime  switching  is \\n\\npractical and indeed take place in equity market, thus reasonable investors should not \\n\\nstick with one single trading rule across every period of time. Instead, there are optimal \\n\\ninvestment strategies for each market regime \\n and when market is clearly segregated into \\n\\nregimes and generate strategies based upon, we are able to end up with better results. \\n  \\n\\n \\n\\n \\n\\n5.\\n \\nConclusion and Implication\\n  \\n\\n \\n\\nIn this thesis, we verify\\n  \\nthe effectiveness of\\n  \\nthe\\n \\nGenetic Algorithm\\n  \\n(GA)\\n \\nin discovering \\n\\nprofitable trading rules\\n  \\nby providing an out\\n-\\nof\\n-\\nsample test in Chinese stock market\\n .\\n \\nThe \\n\\nframework of our testes follows the \\nAllen and Karjalainen (1999) approach. However, \\n\\nwhile th\\ne trading rules in the work of \\n Allen and Karjalainen (1999)\\n  \\nare based on closing \\n\\nprices, \\nmoving  averages  and  local  extrema  of  closing  prices,  we  utilize three  refined \\n\\ntechnical indicators (RSI, MACD and Bollinger Band) to construct the filter rules in our \\n\\ntests.\\n \\nIn fact, the appearance of the filter rules to be re\\nfined by the GA in this thesis\\n \\nis \\n\\nsimilar to\\n \\nthat in\\n \\nthe work of Dempster and Jones (2001). \\n  \\n\\nThe results show that\\n,\\n \\nbased on \\ndata of \\ndaily closing prices of CSI 300 index\\n \\nand its \\n\\ncomponent stocks\\n , technical trading rules generated from \\n the \\nGA can consisten\\n tly deliver \\n\\noutperformances  over \\nthe\\n \\nbuy\\n-\\nand\\n-\\nhold  strategy\\n \\nby  providing  an  additional  return \\n\\nresource in the form of timing the market\\n.\\n \\nThis finding clearly stands for our answer to \\n\\nthe question whether GA\\n -\\nbased technical trading rules are able to consiste\\n ntly beat buy\\n-\\n\\nand\\n-\\nhold in daily trading. Besides, \\nwe find that the \\nmarket timing ability of GA\\n-\\nbased \\n\\ntechnical  trading  rules  is  portable  to  benefit\\n \\nactive  equity \\nportfolios  based  on  stock \\n\\nselection as well.\\n \\nMeanwhile, by conducting statistical tests\\n, we op\\nen the black box of \\n\\nGA and verify the effectiveness of technical trading rules selected by GA.\\n  \\n\\n \\nFurthermore, we introduce regime switching into the framework of \\n the \\nGA and\\n \\ncome \\n\\nup with one regime\\n -\\nswitching genetic algorithm (RSGA). The trading strategies f\\n rom the \\n\\nRSGA model\\n \\nconsistently achieve even better results\\n \\nthan those from the GA model\\n. \\n\\nSince \\nmost \\nprevious studies\\n \\nin this field\\n  \\nstick with taking advantage of \\n the \\nGA to\\n, in each \\n\\ntest,\\n \\ndiscover \\nand apply \\none single trading strategy and reach the conclus\\nion\\n \\nbased on \\n\\ngained  strategy  performance\\n.  This  modification \\nmakes  a \\nmethodological \\nprogress  on \\n 57\\n \\n\\n \\nleveraging\\n \\nthe\\n \\nGA to generate trading strategies.\\n  \\n\\nOverall, \\nthe GA\\n \\nis a powerful tool when it comes to investment \\nproblems \\nbecause it \\n\\nenables us to efficiently in\\nvestigate the solution space and reveal satisfying strategies in \\n\\na quick manner. As a result, market participants can benefit from this tool from various \\n\\nkinds  of  perspectives.  First,  by  changing  the  objective  of  fitness  function,  strategies \\n\\nmeeting  differ\\nent  investing  preferences  or  requirements  will  be  acquired.  Second,  in \\n\\naddition to equity investments, trading of fixed income instruments, foreign exchange \\n\\nand other financial assets can also promote its performance from GA. \\n  \\n\\nHowever,  as  a  machine  learning  method, \\nthe \\nGA  suffers  from  data  over\\n-\\nfitting \\n\\nproblem,  even  though  some  alleviation  mechanism  is  in  place  already.  Thus  future \\n\\nstudies on this topic should pay special attention to further refinements on the design of \\n\\nexperim\\nents  to  address  this  problem.  Besides, \\namong  previous  studies,  experiment \\n\\ndesigns  are  different  from  various  aspects  but  there  is  no  conclusion  on  whether  the \\n\\ndesign of tests is directly associated with the outcomes. Also, there is no comments on \\n\\nthe optim\\nal design of tests on using the GA to discover profitable trading rules. Thus, \\n\\nsubsequent studies can also be aimed to answer this question.\\n\\n \\n\\n \\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n 5\\n8\\n \\n\\n \\n \\n\\n \\n\\nReferences:\\n \\n\\n \\n\\nArthur W B, Queen\\'s University (Kingston, Ont.). Institute for Economic Research.\\n  \\nOn learning \\n\\nand adaptation in the economy\\n  \\n[M]. Institute for Economic Rese\\n arch, Queen\\'s University, 1992.\\n  \\n\\nArthur W B. Inductive behavior and bounded rationality Amer\\n \\n[J]. Econ. Review, 1994, 84: \\n\\n406\\n-\\n411.\\n \\n\\nArthur W B. Complexity in economic and financial \\nmarkets: Behind the physical institutions \\n\\nand technologies of the marketplace lie the beliefs and expectations of real human beings\\n \\n[J].\\n \\n\\nComplexity, 1995, 1(1): 20\\n -\\n25.\\n \\n\\nAlexander,  S.  S.  (1961).  Price  movements  in  speculative  markets:  Trends  or  random \\n\\nwalks.\\n \\nIndustrial Management Review (pre\\n -\\n1986)\\n,\\n \\n2\\n(2), 7.\\n \\n\\nAng A, Bekaert G. International asset allocation with time\\n-\\nvarying correlations[R]. National \\n\\nBureau of Economic Research, 1999.\\n  \\n\\nAllen, F., & Karjalainen, R. (1999). Using genetic algorithms to find techni\\ncal trading \\n\\nrules.\\n \\nJournal of financial Economics,\\n  \\n51(2), 245\\n-\\n271.\\n \\n\\nArthur W B, Holland J H, LeBaron B, et al. Asset pricing under endogenous expectations \\n\\nin an artificial stock market[J]. Available at SSRN 2252\\n , 1996.\\n \\n\\nBeasley, D., Martin, R. R., & Bull, D.\\n  \\nR. (1993). An overview of genetic algorithms: Part \\n\\n1. Fundamentals.\\n \\nUniversity computing,\\n \\n15, 58\\n-\\n58.\\n \\n\\nBrock W,  Lakonishok J,  LeBaron  B. Simple technical trading rules and  the stochastic \\n\\nproperties of stock returns\\n  \\n[J]. The Journal of F\\ninance, 1992, 47(5): \\n1731\\n-\\n1764.\\n \\n 59\\n \\n\\n \\nBecker, L. A., & Seshadri, M. (2003). GP\\n -\\nevolved technical trading rules can outperform \\n\\nbuy and hold.\\n \\n\\nBloomfield, R., O’hara, M., & Saar, G. (2005). The “make or take” decision in an electronic \\n\\nmarket: Evidence on the evolution of liquidity.\\n \\nJou\\nrnal of Financial Economics\\n,\\n \\n75\\n(1), 165\\n-\\n\\n199.\\n \\n\\nCao, C., Hansch, O., & Wang, X. (2009). The information content of an open limit\\n -\\norder \\n\\nbook.\\n \\nJournal of futures markets\\n ,\\n \\n29\\n(1), 16.\\n \\n\\nChen, K. J., & Li, X. M. (2006). Is Technical analysis useful for stock trader\\ns in China? \\n\\nEvidence  from  the  SZSE  component  A\\n-\\nShare  Index.\\n \\nPacific  Economic  Review,\\n \\n11(4), \\n\\n477\\n-\\n488.\\n \\n\\nChiarella, C., He, X. Z., & Wei, L. (2015). Learning, information processing and order \\n\\nsubmission in limit order markets.\\n  \\nJournal of\\n \\nEconomic Dynamics and \\n Control.\\n \\n\\nCreamer,  G.  (2012).  Model  calibration  and  automated  trading  agent  for  Euro \\n\\nfutures.\\n \\nQuantitative Finance,\\n \\n12(4), 531\\n-\\n545.\\n \\n\\nChiarella C, Dieci R, He X Z. Heterogeneous expectations and speculative behavior in a \\n\\ndynamic multi\\n-\\nasset framework\\n \\n[J]. \\nJournal of Economic Behavior & Organization, 2007, \\n\\n62(3): 408\\n-\\n427.\\n \\n\\nChoi J H, Lee M K, Rhee M W. Trading S&P 500 stock index futures using a neural \\n\\nnetwork[C]//Proceedings  of  the  third  annual  international  conference  on  artificial \\n\\nintelligence applications \\n on wall street. 1995: 63\\n-\\n72.\\n \\n\\nColin A M. Genetic algorithms for financial modeling\\n  \\n[J]. 1994, 9: 148\\n-\\n173.\\n \\n 60\\n \\n\\n \\nDempster M A H, Payne T W, Romahi Y, et al. Computational learning techniques for \\n\\nintraday  FX  trading  using  popular  technical  indicators[J].  Neural  Net\\nworks,  IEEE \\n\\nTransactions on, 2001, 12(4): 744\\n -\\n754.\\n \\n\\nDempster, M. A. H., & Jones, C. M. (2001). A real\\n -\\ntime adaptive trading system using genetic \\n\\nprogramming.\\n \\nQuantitative Finance\\n,\\n \\n1\\n(4), 397\\n-\\n413.\\n \\n\\nDempster, M. A. H., & Jones, C. M. (2000).\\n \\nThe profitability o\\nf intra\\n-\\nday FX trading using \\n\\ntechnical indicators\\n. Judge Institute of Management, University of Cambridge.\\n  \\n\\n \\n\\nDiaz\\n-\\nGomez,  P.  A.,  &  Hougen,  D.  F.  (2007,  January).  Initial  Population  for  Genetic \\n\\nAlgorithms: A Metric Approach. In\\n  \\nGEM\\n \\n(pp. 43\\n-\\n49)\\n \\n\\nDunis, C., & \\nZhou, B. (1998).\\n \\nNonlinear modelling of high frequency financial time series\\n. \\n\\nJohn Wiley & Sons Inc.\\n  \\n\\nFama  E  F,  MacBeth  J D.  Risk,  return,  and  equilibrium:  Empirical  tests\\n \\n[J].  The Journal  of \\n\\nPolitic\\nal Economy, 1973: 607\\n -\\n636.\\n \\n\\nFama E F, Blume M E. Filter rul\\n es and stock\\n-\\nmarket trading\\n \\n[J]. The Journal of \\n Business, 1966, \\n\\n39(1): 226\\n-\\n241.\\n \\n\\nGould, M. D., Porter, M. A., Williams, S., McDonald, M., Fenn, D. J., & Howison, S. D. \\n\\n(2013). Limit order books.\\n  \\nQuantitative Finance,\\n \\n13(11), 1709\\n-\\n1742.\\n \\n\\nGoldfeld  S  M,  Quandt R  E.  A  Markov  model  for  switching  regressions[J]. Journal  of \\n\\neconometrics, 1973, 1(1): 3\\n -\\n15.\\n \\n\\nHarris, L. E., & Panchapagesan, V. (2005). The information content of the limit order \\n\\nbook:  evidence  from  NYSE  specialist  trading  decisions.\\n \\nJ\\nournal  of  Financial \\n\\nMarkets,\\n \\n8(1), 25\\n-\\n67.\\n \\n 61\\n \\n\\n \\nHolland,  J.H.,  1962.  Outline  for  a  logical  theory  of  adaptive  systems.  Journal  of  the \\n\\nAssociation for Computing Machinery 3, 297\\n -\\n314.\\n \\n\\nHolland, J.H., 1975. Adaptation in Natural and Artiﬁcial Systems\\n . University of \\n Michigan \\n\\nPress.\\n \\n\\nJiang, Weizhong, and Xi Xie. \"Stock Fundamentals Model Based on Genetic Algorithm\\n -\\n\\nRough Set.\" Journal of Management and Sustainability 6.1 (2016): 206.\\n  \\n\\nKaniel, R., & Liu, H. (2006). So what orders do informed traders use? Journal of Busines\\n s, \\n\\n79.\\n \\n\\nKoza, J. R. (1992).\\n  \\nGenetic programming: on the programming of computers by means of \\n\\nnatural selection\\n \\n(Vol. 1). MIT press.\\n \\n\\nKyle, A. S. (1985). Continuous auctions and insider trading.\\n  \\nEconometrica: Journal of the \\n\\nEconometric Society\\n, 1315\\n-\\n1335.\\n \\n\\nKap\\noor V, Dey S, Khurana A P. Genetic algorithm: An application to technical trading \\n\\nsystem design\\n \\n[J]. International Journal of Computer Ap\\n plications, 2011, 36(5): 44\\n -\\n50.\\n \\n\\nLohpetch, D., & Corne, D. (2010). Outperforming buy\\n -\\nand\\n-\\nhold with evolved technical tra\\n ding \\n\\nrules: Daily, weekly and monthly trading. In\\n \\nApplications of Evolutionary Computation\\n \\n(pp. \\n\\n171\\n-\\n181).\\n \\nSpringer Berlin Heidelberg.\\n  \\n\\nLevich  R  M,  Thomas  L  R.  The  significance  of  technical  trading\\n-\\nrule  profits  in  the  foreign \\n\\nexchange market: a bootstrap app\\n roach\\n \\n[J]. Journal of international Money and\\n  \\nFinance, 1993, \\n\\n12(5): 451\\n-\\n474.\\n \\n 62\\n \\n\\n \\nMahfoud,  S.,  &  Mani,  G.  (1995).  Genetic  algorithms  for  predicting  individual  stock \\n\\nperformance.  In\\n \\nProceedings  of  the  third  international  conference  on  artificial  intelligence \\n\\napp\\nlication\\ns on Wall Street\\n \\n(pp. 174\\n-\\n181).\\n \\n\\nMarney J P, Fyfe C, Tarbert H, et al. Risk adjusted returns to technical trading rules: a genetic \\n\\nprogramming approach[R]. Society for\\n  \\nComputational Economics, 2001.\\n  \\n\\nMaringer D, Ramtohul T. Regime\\n-\\nswitching recurrent\\n \\nreinforcement learning for investment \\n\\ndecision making\\n \\n[J]. Computational Management Science, 2012, 9(1\\n ): 89\\n-\\n107.\\n \\n\\nMitchell\\n-\\nOlds T. The molecular basis of quantitative genetic variation in natural populations\\n \\n\\n[J]. Trends in ecology & e\\n volution, 1995, 10(8):\\n \\n324\\n-\\n328.\\n \\n\\nNeely C, Weller P, Dittmar R. Is technical analysis in the foreign exchange market profitable? A \\n\\ngenetic programming approach\\n \\n[J]. Journal of financial and Quantitative An\\nalysis, 1997, 32(04): \\n\\n405\\n-\\n426. \\n \\n\\nO\\'hara M. Market microstructure theory\\n  \\n[M].\\n \\nCambridge, MA: Blackwell, 1995.\\n  \\n\\nO’Neill M, Brabazon A, Ryan C, et al. Evolving market index trading rules using grammatical \\n\\nevolution[M]//Applications of evolutionary computing. Springer Be\\nrlin Heidelberg, 2001: 343\\n-\\n\\n352.\\n \\n\\nPotvin, J. Y., Soriano, P., & Vall\\n ée, M. (2004). Generating trading rules on the stock markets with \\n\\ngenetic programming.\\n \\nComputers & Operati\\nons Research,\\n \\n31(7), 1033\\n-\\n1047.\\n \\n\\nQuandt R E. The estimation of the parameters of a linear regression system obeying two separate \\n\\nregimes\\n \\n[J]. Journal \\nof the american statistical assoc\\n iation, 1958, 53(284): 873\\n-\\n880.\\n \\n 63\\n \\n\\n \\nSeppi, D. J. (1997). Liquidity provision with limit orders and a strategic specialist.\\n \\nReview of \\n\\nFin\\nancial Studies,\\n \\n10(1), 103\\n-\\n150.\\n \\n\\nSmidt S. A Test of the Serial Independence of Price Change\\ns of Soybean Futures[M]. [Food \\n\\nResearch Instit\\nute] Stanford University, 1965.\\n  \\n\\nShiller R J, Pound J. Survey evidence on diffusion of interest and information among investors\\n  \\n\\n[J]. Journal of Economic Behavior & Organization, 1989, 12(1): 47\\n -\\n66.\\n \\n\\nSullivan R, \\nTimmermann A, White H. Data\\n ‐\\nsnooping, technical trading rule performance, and \\n\\nthe bootstrap\\n \\n[J]. The journal of F\\ninance, 1999, 54(5): 1647\\n-\\n1691.\\n \\n\\nShin,  K.  S.,  &  Lee,  Y.  J.  (2002).  A  genetic  algorithm  application  in  bankruptcy  prediction \\n\\nmodeling.\\n \\nExpert Sys\\ntems wit\\nh Applications,\\n \\n23(3), 321\\n-\\n328.\\n \\n\\nStoikov,  S.,  &  Waeber,  R.  (2012).  Optimal  Asset  Liquidation  Using  Limit  Order  Book \\n\\nInformat\\nion.\\n \\nAvailable at SSRN 2113827.\\n \\n\\nVeredas,  D.,  &  Pascual,  R.  (2004).  What  pieces  of  limit  order  book  information  are \\n\\ninformati\\nve? An empirical analysis\\n  \\nof a pure order driven market.\\n  \\n\\nWong  W  K,  Manzur  M,  Chew  B  K.  How  rewarding  is  technical  analysis?  Evidence  from \\n\\nSingapore stock market\\n  \\n[J]. Applied Financial Economics, 2003, 13(7): 543\\n -\\n551.\\n \\n\\nYu, T., Chen, S. H., & Kuo, T. W. \\n(2005). Discovering financial technical trading rules \\n\\nusing genetic programming with lambda abstraction. In\\n  \\nGenetic programming theory and \\n\\npracti\\nce II\\n \\n(pp. 11\\n-\\n30). Springer US.\\n \\n\\nMaringer  D,  Ramtohul  T.  Regime\\n-\\nswitching  recurrent  reinforcement  learning  for \\n\\ni\\nnvestment decision making\\n  \\n[J]. Computational Management Science, 2012, 9(1): 89\\n -\\n107.\\n \\n\\n \\n 64\\n \\n\\n \\nAppendix A \\n–\\n \\nRSI, MACD and Bollinger Band\\n  \\n\\n \\n\\nRSI\\n \\n\\n \\n\\nRelative \\nStrength Index \\n(RSI) \\nis one kind of momentum indicators\\n \\ndeveloped by J. \\n\\nWelles  Wilder.  This  technical  indicat\\nor  is  used  to  measure  the  changes  of  price \\n\\nmovements. RSI ranges from 0 to 100 and the formula to calculate RSI is as follows.\\n  \\n\\n \\n\\nRSI\\n=\\n100\\n−\\n \\n100\\n\\n1\\n+\\n𝑅𝑆\\n \\n\\n \\n\\nRS\\n=\\nAverage\\n \\ngain\\n\\nAverage\\n \\nloss\\n \\n\\n \\n\\nWhen working out RSI, the duration which are the periods of time all the \\n calculations \\n\\nare based on should be defined first. Take a duration of 14 days for example, the first \\n\\naverage gain and average loss are calculated as following.\\n  \\n\\n \\n\\nFirst average gain = Sum of the gains over past 14 days / 14\\n  \\n\\nFirst average loss = Sum of the \\n losses over past 14 days / 14\\n  \\n\\n \\n\\nThe  second,  and  subsequent  calculations  are  based  on  the  prior  averages  and  the \\n\\ncurrent gain \\nand \\nloss:\\n \\n\\n \\n\\nAverage Gain = [(previous Average Gain) x 13 + current Gain] / 14\\n  \\n\\nAverage Loss = [(previous Average Loss) x 13 + current \\n Loss] / 14\\n \\n\\n \\n\\nConventionally,  market  is  considered  overbought  when  RSI  rises  above  70  and \\n\\noversold  when  RSI  drops  below  30.  Signals  can  also  be  generated  by  looking  for \\n\\ndivergences, failure swings and centerline crossovers.\\n  \\n\\n \\n\\n \\n\\n \\n\\n \\n 65\\n \\n\\n \\n MACD\\n \\n\\n \\n\\nThe  Moving  Average \\nConvergence/Divergence  oscillator  (MACD)\\n \\nis  another \\n\\nmomentum indicator that turns two moving averages into an \\nindicator. \\nT\\nhe values of \\n\\nMACD  can  be  both  positive  and  negative  because  it  is  calculated  by  subtracting  the \\n\\nmoving average with longer duration fr\\nom the shorter one. For example, two moving\\n \\n\\naverages with duration of 12 and 24 respectively are used to make the MACD line.\\n  \\n\\n \\n\\nMACD line = 12\\n -\\nday exponential moving average \\n –\\n \\n24\\n-\\nday exponential moving average\\n  \\n\\n \\n\\nBesides, there is a signal line that is a \\nmoving average of the MACD Line itself and \\n\\nthe MACD histogram is the difference between MACD Line and Signal Line. Take a \\n\\nduration of 9 days for instance.\\n  \\n\\n \\n\\nSignal Line = 9\\n-\\nday exponential moving average of MACD Line\\n  \\n\\n \\n\\nMACD Histogram = MACD Line \\n–\\n \\nSignal Lin\\ne\\n \\n\\n \\n\\nPositive\\n \\nMACD\\n \\nindicates that the \\nshorter\\n \\nEMA is above the \\nlonger\\n \\nEMA. Positive \\n\\nvalues increase as the shorter EMA d\\n iverges further from the longer \\n EMA\\n \\nand the upside \\n\\nmomentum  is  increasing.  Negative  MACD  values  indicated  that  the  shorter  EMA  is \\n\\nbelow Lo\\nnger EMA. Negative values increase as the \\n shorter EMA diverg\\n es further below \\n\\nthe longer EMA and the downside momentum is increasing.\\n  \\n\\nBesides\\n, \\ntraders  also \\nlook  for  signal  line  crossovers,  centerline  crossovers  and \\n\\ndivergences to generate signals\\n .\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n 66\\n \\n\\n \\n Bollinger Band\\n \\n\\n \\n\\nBollinger bands are constructed based on moving averages and standard deviations of \\n\\nprices. The upper band is constructed by adding certain standard deviation to the middle \\n\\nband while the lower band is constructed by subtracting certain sta\\n ndard deviation from \\n\\nthe middle\\n \\nband. The middle band is \\n the moving average\\ns\\n.\\n \\nTherefore, the appearance of \\n\\nBollinger bands varies according to the standard deviations.\\n  \\n\\nSuppose  the  Bollinger  Band  is  constructed  based  on  a  duration  of  20  days  and  2 \\n\\nstandard \\ndeviations.\\n \\n\\n \\n\\nMiddle Band = 20\\n-\\nday simple moving average\\n  \\n\\n \\n\\nHigher Band = 20\\n-\\nday simple moving average + 2 * 20\\n -\\nday standard deviation\\n \\n\\n \\n\\nLower\\n \\nBand \\n= 20\\n-\\nday simple moving average \\n -\\n \\n2 * 20\\n-\\nday standard deviation\\n \\n\\n \\n\\nAccording to Bollinger, the bands should contain\\n  \\n88\\n-\\n89% of price action, which makes \\n\\na move outside the bands significant\\n. Thus, the higher band and lower band are often \\n\\nconsidered as important supporting or resisting levels.\\n  \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n 67\\n \\n\\n \\nAppendix B \\n–\\n \\nFigure\\ns\\n \\n\\n \\n\\nFigure\\n \\n1:  \\nCumulative\\n \\nreturns of the hedged portfolio constructed by taking long \\n\\npositions of the top 10% CSI 300 index component stocks and short positions of the \\n\\nbottom  10%  CSI  300  index  component  stocks  over  the  period  from  2010.06  to \\n\\n2015.10. \\n \\n\\nFigure 1 presents\\n , by Excel s\\n oftware,\\n \\nthe plot of \\n cumulative\\n \\nreturns of the hedged portfolio \\n\\nconstructed by taking long positions of the top \\n 10% CSI 300 index component stocks and \\n\\nshort positions of the bottom 10% CSI 300 index component stocks over the period from \\n\\n2010.06 to 2015.10.\\n \\nStocks are ranked and selected by Fama\\n-\\nMacBeth regressions with \\n\\nthe technical indicator RSI\\n \\non a daily basis\\n.\\n \\n\\n \\n\\n \\n\\n \\n \\n\\n \\n\\n \\n\\nFigure\\n \\n2: \\nCumulative\\n \\nreturns  of  the  hedged  portfolio  constructed  by  taking  long \\n\\npositions of the top 10% CSI 300 index component stocks and short positions of the \\n\\nbottom  10%  CSI  300  index  component  stocks  over  the  period  from  2010.06  to \\n\\n2015.10.  Stocks  are  ranked  and  selected\\n \\nby  Fama\\n-\\nMacBeth  regressions  with  the \\n\\ntechnical indicator MACD.\\n  \\n\\nFigure 2 presents, by Excel software, the plot of \\n cumulative\\n \\nreturns of the hedged portfolio \\n\\nconstructed by taking long positions of the top \\n 10% CSI 300 index component stocks and \\n\\nshort positi\\nons of the bottom 10% CSI 300 index component stocks over the period from \\n\\n2010.06 to 2015.10. Stocks are ranked and selected by Fama\\n-\\nMacBeth regressions with \\n\\nthe technical indicator \\nMACD on a daily basis\\n.\\n \\n\\n \\n\\n \\n-0.5\\n0\\n0.5\\n1\\n1.5\\n2\\n\\n20100618\\n20100812\\n20101018\\n20101210\\n20110211\\n20110411\\n20110607\\n20110801\\n20110926\\n20111125\\n20120130\\n20120323\\n20120524\\n20120719\\n20120912\\n20121113\\n20130110\\n20130313\\n20130514\\n20130711\\n20130904\\n20131107\\n20140102\\n20140305\\n20140430\\n20140627\\n20140821\\n20141023\\n20141217\\n20150212\\n20150416\\n20150611\\n20150806\\n20151009\\n\\n-1\\n0\\n1\\n2\\n3\\n4\\n\\n20100618\\n20100812\\n20101018\\n20101210\\n20110211\\n20110411\\n20110607\\n20110801\\n20110926\\n20111125\\n20120130\\n20120323\\n20120524\\n20120719\\n20120912\\n20121113\\n20130110\\n20130313\\n20130514\\n20130711\\n20130904\\n20131107\\n20140102\\n20140305\\n20140430\\n20140627\\n20140821\\n20141023\\n20141217\\n20150212\\n20150416\\n20150611\\n20150806\\n20151009\\n 68\\n \\n\\n \\nFigure\\n \\n3: \\nCumulative\\n \\nreturns  of  the  hedged  portfolio  constructed  by  taking  long \\n\\npositions of the top 10% CSI 300 index component stocks and short positions of the \\n\\nbottom  10%  CSI  300  index  component  stocks  over  the  period  from  2010.06  to \\n\\n2015.10.  Stocks  are  ranked  and  selected\\n \\nby  Fama\\n-\\nMacBeth  regressions  with  the \\n\\ntechnical indicator Bollinger Band.\\n  \\n\\nFigure 3 presents, by Excel software, the plot of \\n cumulative\\n \\nreturns of the hedged portfolio \\n\\nconstructed by taking long positions of the top \\n 10% CSI 300 index component stocks and \\n\\nsh\\nort positions of the bottom 10% CSI 300 index component stocks over the period from \\n\\n2010.06 to 2015.10. Stocks are ranked and selected by Fama\\n-\\nMacBeth regressions with \\n\\nthe technical indicator \\nBollinger Band on a daily basis\\n .\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nFigure\\n \\n4: \\nCumulative\\n \\nretur\\nns  of  the  hedged  portfolio  constructed  by  taking  long \\n\\npositions of the top 10% CSI 300 index component stocks and short positions of the \\n\\nbottom  10%  CSI  300  index  component  stocks  over  the  period  from  2010.06  to \\n\\n2015.10.  Stocks  are  ranked  and  selected  by  Fa\\nma\\n-\\nMacBeth  regressions  with  the \\n\\ntechnical indicator RSI MACD and Bollinger Band\\n  \\ntogether\\n.\\n \\n\\nFigure 4 presents, by Excel software, the plot of \\n cumulative\\n \\nreturns of the hedged portfolio \\n\\nconstructed by taking long positions of the top \\n 10% CSI 300 index compone\\n nt stocks and \\n\\nshort positions of the bottom 10% CSI 300 index component stocks over the period from \\n\\n2010.06 to 2015.10. Stocks are ranked and selected by Fama\\n-\\nMacBeth regressions with \\n\\nthe technical indicator \\nRSI, MACD and Bollinger Band on a daily basis\\n .\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n-1\\n0\\n1\\n2\\n3\\n4\\n\\n20100618\\n20100812\\n20101018\\n20101210\\n20110211\\n20110411\\n20110607\\n20110801\\n20110926\\n20111125\\n20120130\\n20120323\\n20120524\\n20120719\\n20120912\\n20121113\\n20130110\\n20130313\\n20130514\\n20130711\\n20130904\\n20131107\\n20140102\\n20140305\\n20140430\\n20140627\\n20140821\\n20141023\\n20141217\\n20150212\\n20150416\\n20150611\\n20150806\\n20151009\\n\\n-0.5\\n0\\n0.5\\n1\\n1.5\\n2\\n2.5\\n\\n20100618\\n20100812\\n20101018\\n20101210\\n20110211\\n20110411\\n20110607\\n20110801\\n20110926\\n20111125\\n20120130\\n20120323\\n20120524\\n20120719\\n20120912\\n20121113\\n20130110\\n20130313\\n20130514\\n20130711\\n20130904\\n20131107\\n20140102\\n20140305\\n20140430\\n20140627\\n20140821\\n20141023\\n20141217\\n20150212\\n20150416\\n20150611\\n20150806\\n20151009\\n 69\\n \\n\\n \\n \\n\\nFigure\\n \\n5: CSI 300 index from 2005.04 to 2015.11\\n  \\n\\nFigure 5 is the original \\nplot of the CSI 300 index from 2005.04 to 2015.11 from Excel \\n\\nsoftware.\\n \\n\\n \\n\\n \\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nFigure\\n \\n6: \\nCumulative\\n \\ncontinuously compounding returns of buy\\n-\\nand\\n-\\nhold strategy \\n\\nof CSI 300 index from 2005.04 to 2015.11\\n .\\n \\n\\nFigure  6  displays  the \\ncumulative\\n \\ncontinuously  compounding  returns  of  buy\\n-\\nand\\n-\\nhold \\n\\nstrategy of CSI 300 index from 2005.04 to 2015.11.\\n \\nThis strategy assumes \\ntaking long \\n\\nposition of the CSI 300 index from 2005.04 all the way up to 2015.11 without any change \\n\\nin between.\\n \\nThe \\ncumulative\\n \\ncontinuously compounding returns\\n  \\nare calculated as the sum \\n\\nof  the  daily \\ncontinuously  compounding  returns\\n,  which  are  the  log\\n-\\ndiffe\\nrences  of  the \\n\\nclosing prices in two consecutive days.\\n  \\n\\n \\n\\n \\n\\n \\n0\\n1000\\n2000\\n3000\\n4000\\n5000\\n6000\\n7000\\n\\n20050408\\n20050804\\n20051130\\n20060403\\n20060728\\n20061123\\n20070326\\n20070720\\n20071115\\n20080314\\n20080709\\n20081105\\n20090305\\n20090630\\n20091027\\n20100223\\n20100621\\n20101020\\n20110216\\n20110613\\n20111010\\n20120207\\n20120604\\n20120924\\n20130123\\n20130528\\n20130923\\n20140120\\n20140521\\n20140911\\n20150109\\n20150511\\n20150831\\n\\n-0.5\\n0\\n0.5\\n1\\n1.5\\n2\\n\\n20050408\\n20050802\\n20051124\\n20060324\\n20060718\\n20061109\\n20070308\\n20070702\\n20071024\\n20080219\\n20080611\\n20081006\\n20090123\\n20090521\\n20090909\\n20100105\\n20100430\\n20100823\\n20101220\\n20110418\\n20110805\\n20111130\\n20120327\\n20120720\\n20121113\\n20130312\\n20130709\\n20131104\\n20140227\\n20140620\\n20141015\\n20150203\\n20150601\\n20150921\\n 70\\n \\n\\n \\nFigure\\n \\n7:  In\\n-\\nsample performances of 10 GA\\n-\\nbased technical trading rules in terms \\n\\nof excess returns over buy\\n -\\nand\\n-\\nhold and the number of transactions for each strategy \\n\\nover the period from 2005.04 to\\n  \\n2010.10.\\n \\n\\nFigure 7\\n \\nis the in\\n-\\nsample \\nperformances of 10 GA\\n -\\nbased technical trading rules\\n  \\non CSI 300 \\n\\nindex \\nover the period from 2005.04 to 2010.10.\\n  \\n \\nFor each strategy, the excess return over \\n\\nthe buy\\n-\\nand\\n-\\nhold strategy and the number of transaction are \\n presented.\\n \\n \\n\\n \\n\\n \\n\\n \\n\\nFigure\\n \\n8:  Out\\n-\\nof\\n-\\nsample  performances  of  10  GA\\n-\\nbased  technical  trading  rules  in \\n\\nterms of excess returns over buy\\n-\\nand\\n-\\nhold and the number of transactions for each \\n\\nstrategy over the period from 2010.11 to 2015.10.\\n  \\n\\nFigure \\n8\\n \\nis the out\\n-\\nof\\n-\\nsample \\nperformances of 10 \\n GA\\n-\\nbased technical trading rules\\n  \\non CSI \\n\\n300 index over the period from 2010.11 to 2015\\n.10.\\n \\n \\nFor each strategy, the excess return \\n\\nover the buy\\n-\\nand\\n-\\nhold strategy and the number of transaction are presented.\\n  \\n \\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\nExcess return \\n0.4\\n \\n\\n \\n\\n \\n\\n \\n\\n  \\n\\n\\n0\\n \\n50\\n \\n100\\n \\n150\\n \\n\\nNumber of transaction\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nExcess return\\n \\n\\n0.2\\n \\n\\n0.1\\n \\n\\n \\n\\n-\\n0.1  \\n \\n\\n-\\n0.2\\n \\n\\n-\\n0.3\\n \\n\\n  \\n\\n\\n50\\n \\n\\n100\\n \\n\\n150\\n \\n\\n200\\n \\n\\n\\nNumber of\\n \\ntransaction\\n \\n 71\\n \\n\\n \\nFigure\\n \\n9: Comparison between one GA\\n -\\nbased strategy and buy\\n -\\nand\\n-\\nhold strategy in \\n\\nterms of \\ncumulative\\n \\nreturn\\ns\\n \\nin the out\\n-\\nof\\n-\\nsample period from 2010.11 to 2015.10.\\n  \\n\\nFigure  9 \\npresent  the  performances  of  one  GA\\n-\\nbased  strategy  and  the  buy\\n-\\nand\\n-\\nhold \\n\\nstrategy  on  CSI  300  index  from  2010.11  to  2015.10.  Performances  of  strategies  are \\n\\npresented in the form of \\n cumulative\\n \\nretu\\nrns.\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nFigure\\n \\n10:  Training  period  performances  of  10  GA\\n-\\nbased  technical  trading  rules \\n\\nwith data over\\n -\\nfitting alleviation system in place in terms of excess returns over buy\\n -\\n\\nand\\n-\\nhold  and  the  number  of  transactions  for  each  strategy  over  the  period  from \\n\\n2005.04 to 2010.1\\n0.\\n \\n\\nFigure 10\\n \\nis the in\\n-\\nsample \\nperformances of 10 GA\\n-\\nbased technical trading rules\\n \\non CSI \\n\\n300 index \\nover the period from 2005.04 to 2010.10.\\n \\n \\nFor each strategy, the excess return \\n\\nover the buy\\n-\\nand\\n-\\nhold strategy and the number of transaction are presented. \\nTh\\nese 10 \\n\\nstrategies are gained with the data over\\n -\\nfitting alleviation system in place.\\n  \\n \\n-0.6\\n-0.4\\n-0.2\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n\\n2010/11/1\\n2011/11/1\\n2012/11/1\\n2013/11/1\\n2014/11/1\\nGA strategy\\n\\nBuy-and-Hold\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\nExcess return \\n0.4\\n \\n\\n \\n\\n \\n\\n \\n\\n  \\n\\n\\n0\\n \\n50\\n \\n100\\n \\n150\\n \\n\\nNumber of transaction\\n \\n 72\\n \\n\\n \\n \\n\\nFigure\\n \\n11: Evaluation period performances of 10 GA\\n-\\nbased technical trading rules \\n\\nwith data over\\n -\\nfitting alleviation system in place in terms of excess returns over buy\\n -\\n\\nand\\n-\\nhold  and  the  number  of  transactions  for  each  strategy  over  the  period  from \\n\\n2010.11 to 2014\\n.10.\\n \\n\\nFigure \\n11\\n \\nis the evaluation\\n-\\nperiod \\nperformances of 10 GA\\n-\\nbased technical trading rules\\n \\n\\non CSI 300 index over the period from 2010.11 to 2014\\n .10.\\n \\n \\nFor each strategy, the excess \\n\\nreturn over the buy\\n-\\nand\\n-\\nhold strategy and the number of transaction are pre\\n sented\\n. \\nThese \\n\\n10 strategies are gained with the data over\\n -\\nfitting alleviation system in place.\\n  \\n \\n\\n \\n\\n \\n\\n \\n\\nFigure\\n \\n12: Testing period performances of 10 GA\\n -\\nbased technical trading rules with \\n\\ndata over\\n-\\nfitting alleviation system in place in terms of excess returns over buy\\n -\\nand\\n-\\n\\nhold and the number of transactions for each strategy over the period from 2014.11 \\n\\nto 2015.10\\n.\\n \\n\\nFigure \\n12\\n \\nis the testing\\n-\\nperiod \\nperformances of 10 GA\\n-\\nbased technical trading rules\\n \\non \\n\\nCSI 300 index over the period from 2014.11 to 2015\\n.10.\\n \\n \\nFor each strategy, the excess \\n\\nreturn over the buy\\n-\\nand\\n-\\nhold strategy and the number of transaction are presented\\n . \\nThese \\n\\n10 strategies are gained with the data over\\n -\\nfitting alleviation system in pla\\n ce.\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\nExcess return\\n \\n\\n \\n\\n Strategies\\n \\n\\n\\n \\n\\n\\n \\n\\n50\\n \\n\\n100\\n \\n\\n-\\n0.1\\n \\n\\n \\n\\nNumber of transaction\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\nExcess return  \\n-\\n0.1  \\n0\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n10\\n \\n\\n15\\n \\n\\n20\\n \\n\\n25\\n \\n\\n\\nStrategies\\n \\n\\n\\nNumber of\\n \\ntransaction\\n \\n 73\\n \\n\\n \\nFigure\\n \\n13:  Comparison between the \\ncumulative\\n \\nreturns of the top three GA\\n-\\nbased \\n\\ntechnical trading strategies and buy\\n-\\nand\\n-\\nhold over testing period from 2014.11 to \\n\\n2015.10.\\n \\n\\nFigure 13 presents the performances, in the form of \\ncumulative\\n \\nreturns, of the top 3 technical \\n\\ntrading  strategies  from  the  Figure  12  and  the  buy\\n-\\nand\\n-\\nhold  strategy  on  CSI  300  index  from \\n\\n2014.11 to 2015.10. \\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nFigure\\n \\n14:  scatter plot of the performances of these 18 GA\\n-\\nbased technical trading \\n\\nstrategies in terms of excess return over buy\\n -\\nand\\n-\\nhold and adjusted Sterling ratio in \\n\\nthe training period from 2005.04 to 2010.10\\n  \\n\\nFigure 14 is the in\\n-\\nsample \\nperformances of\\n \\n1\\n8\\n \\nGA\\n-\\nbased technical trading rules\\n \\non CSI \\n\\n300 index \\nover the period from 2005.04 to 2010.10.\\n \\n \\nFor each strategy, the excess return \\n\\nover the buy\\n-\\nand\\n-\\nhold strategy and the number of transaction are presented. These 18 \\n\\nstrategies are gained with the \\nSterling Ratio as the fitness function of the GA evolution \\n\\nprocess.\\n \\n \\n\\n \\n\\n \\n\\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\nExcess return \\n0.4\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n Strategies\\n \\n\\n\\n0\\n \\n0.5\\n \\n1\\n \\n \\n\\nAdjusted sterling ratio\\n  \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n Strategy 1 \\n \\n\\nStrategy 2 \\n \\n\\nStrategy 3\\n \\n\\n \\n 74\\n \\n\\n \\n \\n\\nFigure\\n \\n15:  The comparison between the \\ncumulative\\n \\nreturns of buy\\n-\\nand\\n-\\nhold and \\n\\nbest trading strategies from evaluation period in testing period (2014.10\\n -\\n2015.10)\\n \\n\\nFigure 15 presents the performances, in the form of \\n cumulative\\n \\nreturns, of the top technical \\n trading \\n\\nstrategy\\n \\nfrom the Figure 14 and the buy\\n-\\nand\\n-\\nhold strategy on CSI 300 index from 2014.11 to \\n\\n2015.10. \\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nFigure\\n \\n16: CSI 300 index from 2010.01 to 2015.12\\n  \\n\\nFigure 16 is the original plot of the CSI 300 index from \\n2010.01 to 2015.12 from Excel \\n\\nsoftware.\\n \\n\\n \\n\\n \\n \\n0\\n1000\\n2000\\n3000\\n4000\\n5000\\n6000\\n\\n20100104\\n20100310\\n20100511\\n20100713\\n20100909\\n20101118\\n20110118\\n20110324\\n20110526\\n20110726\\n20110923\\n20111129\\n20120206\\n20120409\\n20120608\\n20120808\\n20121012\\n20121211\\n20130219\\n20130422\\n20130627\\n20130826\\n20131101\\n20131231\\n20140307\\n20140509\\n20140709\\n20140905\\n20141112\\n20150113\\n20150319\\n20150520\\n20150720\\n20150918\\n20151124\\nCSI 300 index\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n-\\n0.1\\n \\n\\n GA Strategy\\n \\n\\n \\n 75\\n \\n\\n \\nFigure\\n \\n17: \\nCumulative\\n \\nreturn  of  buy\\n-\\nand\\n-\\nhold  strategy  on  CSI  300  index  from \\n\\n2010.01 to 2015.12\\n \\n\\nFigure \\n17\\n \\ndisplays  the \\ncumulative\\n \\ncontinuously  compounding  returns  of  buy\\n-\\nand\\n-\\nhold \\n\\nst\\nrategy of CSI 300 index from 201\\n0.01 to 2015.12\\n.\\n \\nThis strategy assumes taking long \\n\\nposition of the CSI 300 index from 2010.01 all the way up to 2015.12 without any change \\n\\nin between. The \\ncumulative\\n \\ncontinuously compounding returns\\n  \\nare calculated as the sum \\n\\nof  the  daily \\ncontinuously  compo\\nunding  returns\\n,  which  are  the  log\\n-\\ndifferences  of  the \\n\\nclosing prices in two consecutive days.\\n  \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nFigure\\n \\n18: C\\nomparisons between strategy 1 and buy\\n-\\nand\\n-\\nhold strategy in the form \\n\\nof \\ncumulative\\n \\nreturns in training period from 2005.01 to 2008.04.\\n  \\n\\nFigure 18 presents the \\ntraining\\n-\\nperiod \\nperformances, in the form of \\ncumulative\\n \\nreturns, of the \\n\\ntrading  strategy  1  and  the  buy\\n-\\nand\\n-\\nhold  strategy  on  CSI  300  index  from  2005.01  to  2008.04. \\n\\nStrategy 1 releases buy\\n-\\nsignals when the condition “\\nDIFF>DEA & differe\\nnce between DIFF and \\n\\nDEA increasing (MACD) OR\\n  \\nClosing price cross above upper band (Bollinger) XOR RSI>75 (RSI)\\n ” is \\n\\nmet. \\nStrategy 1 releases sell\\n-\\nsignals when the condition “\\nClosing price cross below lower band \\n\\n(Bollinger Band) OR\\n  \\n25<=RSI<50 (RSI)\\n” is met.\\n \\nThe signals maintain their status until the opposite \\n\\nsignal is released.\\n \\n\\n \\n\\n \\n-0.6\\n-0.4\\n-0.2\\n0\\n0.2\\n0.4\\n0.6\\n\\n20100104\\n20100310\\n20100511\\n20100713\\n20100909\\n20101118\\n20110118\\n20110324\\n20110526\\n20110726\\n20110923\\n20111129\\n20120206\\n20120409\\n20120608\\n20120808\\n20121012\\n20121211\\n20130219\\n20130422\\n20130627\\n20130826\\n20131101\\n20131231\\n20140307\\n20140509\\n20140709\\n20140905\\n20141112\\n20150113\\n20150319\\n20150520\\n20150720\\n20150918\\n20151124\\n\\n-0.5\\n0\\n0.5\\n1\\n1.5\\n2\\n2.5\\n\\n20041231\\n20050203\\n20050317\\n20050419\\n20050527\\n20050629\\n20050801\\n20050901\\n20051011\\n20051111\\n20051214\\n20060118\\n20060301\\n20060403\\n20060511\\n20060613\\n20060714\\n20060816\\n20060918\\n20061026\\n20061128\\n20061229\\n20070205\\n20070315\\n20070417\\n20070525\\n20070627\\n20070730\\n20070830\\n20071009\\n20071109\\n20071212\\n20080116\\n20080225\\n20080327\\n\\nIndexing\\nGA\\n 76\\n \\n\\n \\nFigure\\n \\n19: comparisons between strategy 1 and buy\\n -\\nand\\n-\\nhold strategy in the form of \\n\\ncumulative\\n \\nreturns in testing period from 2010.01 to 2015.12.\\n  \\n\\nFigure 19 presents the testing\\n-\\nper\\niod performances, in the form of \\ncumulative\\n \\nreturns, of \\n\\nthe trading strategy 1 and the buy\\n-\\nand\\n-\\nhold strategy on CSI 300 index from 2010.01 to \\n\\n2015.12.  Strategy  1  releases  buy\\n-\\nsignals when the condition “\\nDIFF>DEA  &  difference \\n\\nbetween  DIFF  and  DEA  increasing\\n \\n(MACD)  OR  Closing  price  cross  above  upper  band \\n\\n(Bollinger) XOR RSI>75 (RSI)” is met. \\nStrategy 1 releases sell\\n-\\nsignals when the condition \\n\\n“\\nClosing price cross below lower band (Bollinger Band) OR 25<=RSI<50 (RSI)” is met. The \\n\\nsignals maintain their status \\n until the opposite signal is released.\\n  \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nFigure\\n \\n20: \\nCumulative\\n \\nreturns of the long\\n-\\nposition portfolio constructed by taking \\n\\nlong  positions  of  the  top  5%  component  stocks  in  CSI  300  index  and  the  short\\n-\\n\\nposition portfolio constructed by taking short positions of the bottom 5% component \\n\\nstocks in CSI 300 index\\n \\nduring th\\ne period from 2010.01 to 2015.06\\n .\\n \\n\\nFigure 20 presents the performances, in the form of \\ncumulative\\n \\nreturns, of two actively \\n\\nmanaged portfolio\\n \\nfrom 2010.01 to 2015.06\\n. \\nOne is constructed by taking long positions \\n\\nof the top 5% component stocks in CSI 300 index\\n \\nwhile the other one is constructed by \\n\\ntaking short positions of the bottom 5% component stocks in CSI 300 index. Component \\n\\nstocks  of  CSI  300  index  are  ranked  by  predicted  returns  through  Fama\\n-\\nMacBeth \\n\\nregressions.\\n \\n\\n \\n\\n \\n\\n \\n-1\\n-0.5\\n0\\n0.5\\n1\\n1.5\\n2\\n\\n20100104\\n20100309\\n20100507\\n20100708\\n20100903\\n20101111\\n20110110\\n20110315\\n20110516\\n20110713\\n20110908\\n20111114\\n20120112\\n20120316\\n20120521\\n20120718\\n20120913\\n20121116\\n20130117\\n20130322\\n20130527\\n20130726\\n20130925\\n20131128\\n20140127\\n20140401\\n20140603\\n20140730\\n20140926\\n20141201\\n20150129\\n20150403\\n20150603\\n20150731\\n20150930\\n\\nIndexing\\nGA\\n\\n-0.5\\n0\\n0.5\\n1\\n1.5\\n2\\n\\n20100104\\n20100309\\n20100507\\n20100708\\n20100903\\n20101111\\n20110110\\n20110315\\n20110516\\n20110713\\n20110908\\n20111114\\n20120112\\n20120316\\n20120521\\n20120718\\n20120913\\n20121116\\n20130117\\n20130322\\n20130527\\n20130726\\n20130925\\n20131128\\n20140127\\n20140401\\n20140603\\n20140730\\n20140926\\n20141201\\n20150129\\n20150403\\n20150603\\n20150731\\n20150930\\n\\nLong\\nShort\\n 77\\n \\n\\n \\nFigure\\n \\n21: Long\\n-\\nshort signals released\\n \\nby one GA\\n-\\nbased technical trading strategy \\n\\nwith “100” stands for taking long positions and “\\n-\\n100” for taking short positions\\n \\n\\nfrom 2010.04 to 2015.12.\\n  \\n\\nFigure 21 presents the signals of one GA\\n-\\nbased strategy over the period from 2010.04 to \\n\\n2015.12. Signals \\nare used to guide the position of stock portfolio. While “100” stands for \\n\\ntaking long positions of the top 5% component stocks in CSI 300 index, “\\n -\\n100” stands for \\n\\ntaking short positions of the bottom 5% component stocks in CSI 300 index\\n . \\nComponent \\n\\nstocks  o\\nf  CSI  300  index  are  ranked  by  predicted  returns  through  Fama\\n-\\nMacBeth \\n\\nregressions.\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nFigure\\n \\n22: Comparison between the long\\n-\\nposition portfolio, short\\n-\\nposition portfolio \\n\\nand  the  combined  portfolio  according  to  GA\\n-\\nbased  technical  trading  rules\\n \\nfrom \\n\\n2010.01 to 2015.11\\n.\\n \\n\\n \\nFigure 2\\n2\\n \\npresents the performances, in the form of \\n cumulative\\n \\nreturns, of \\nthree\\n \\nactively \\n\\nmanaged port\\nfolio from 2010.01 to 2015.06. The first portfolio\\n \\nis constructed by taking \\n\\nlong positions of the top 5% component stocks in CS\\n I 300 index while the \\n second\\n \\nportfolio\\n \\n\\nis constructed by taking short positions of the bottom 5% component stocks in CSI 300 \\n\\nindex. Component stocks of CSI 300 index are ranked by predicted returns through Fama\\n -\\n\\nMacBeth  regressions.\\n \\nThe  third  portfolio  swit\\nches  between  the  first  and  the  second \\n\\nportfolios according to the long\\n -\\nshort signals in Figure 21.\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n-150\\n-100\\n-50\\n0\\n50\\n100\\n150\\n\\n201001…\\n201003…\\n201004…\\n201006…\\n201008…\\n201010…\\n201012…\\n201101…\\n201103…\\n201105…\\n201107…\\n201109…\\n201111…\\n201112…\\n201202…\\n201204…\\n201206…\\n201208…\\n201209…\\n201211…\\n201301…\\n201303…\\n201305…\\n201307…\\n201309…\\n201311…\\n201312…\\n201402…\\n201404…\\n201406…\\n201408…\\n201409…\\n201411…\\n201501…\\n201503…\\n201505…\\n201507…\\n201508…\\n201510…\\n\\n-1\\n0\\n1\\n2\\n3\\n\\n20100104\\n20100305\\n20100430\\n20100630\\n20100824\\n20101028\\n20101222\\n20110223\\n20110421\\n20110617\\n20110811\\n20111013\\n20111207\\n20120209\\n20120409\\n20120605\\n20120731\\n20120924\\n20121123\\n20130122\\n20130325\\n20130524\\n20130723\\n20130916\\n20131119\\n20140114\\n20140317\\n20140514\\n20140709\\n20140902\\n20141104\\n20141229\\n20150303\\n20150428\\n20150624\\n20150818\\n20151021\\n\\nLong\\nShort\\nGA\\n 78\\n \\n\\n \\nFigure\\n \\n23:  Forecasted volatility \\n of the CSI 300 index \\n based on GARCH model in \\n the \\n\\nout\\n-\\nof\\n-\\nsample period\\n \\nfrom 2010.01 to 2015.11\\n  \\nand the corresponding \\n threshold point \\n\\nGA select from one experiment to differentiate the market regimes.\\n  \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nFigure\\n \\n24: Percentage of each regime from one \\n GA\\n-\\nbased technical trading rule\\n  \\nwith \\n\\nregime switching taken into consideration.\\n  \\n\\nFigure 24 \\ndescribes the percentage of time, from a pie chart, in regime 1 and \\n\\nregime 2 according to the segregation \\n from one GA\\n-\\nbased trading rule \\n in Figure \\n\\n23.\\n \\n\\n \\n0.0000\\n0.0050\\n0.0100\\n0.0150\\n0.0200\\n0.0250\\n0.0300\\n0.0350\\n0.0400\\n0.0450\\n\\n20100104\\n20100318\\n20100527\\n20100806\\n20101025\\n20101230\\n20110316\\n20110526\\n20110803\\n20111018\\n20111223\\n20120309\\n20120523\\n20120731\\n20121012\\n20121219\\n20130307\\n20130521\\n20130731\\n20131016\\n20131223\\n20140307\\n20140519\\n20140725\\n20141009\\n20141216\\n20150303\\n20150512\\n20150720\\n20150928\\n\\nforecasted volatility\\n GA threshold\\n\\n\\nstrategy with regime\\n -\\nswitching\\n\\n(2010.01 \\n-\\n2015.11)\\n\\nregime 2\\nregime 1\\n 79\\n \\n\\n \\n \\n\\nFigure\\n \\n25: \\nCumulative\\n \\nreturns of technical trading strategies specific to regime 1, \\n\\nregime 2 and the final trading strategy from one experiment.\\n  \\n\\nFigure 25 presents the \\ncumulative\\n \\nreturns of 3 trading strategies. The first and the second \\n\\nstrategies are generated by the genetic \\nalgorithm specifically to regime 1 and regime 2. \\n\\nThe regime\\n-\\nswitching strategy combines the regime 1\\n -\\n \\nstrategy and the regime 2\\n -\\nstrategy \\n\\naccording to the \\nGARCH volatilities in each period of time and the volatility threshold.\\n  \\n\\n \\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n-0.5\\n0\\n0.5\\n1\\n1.5\\n2\\n\\n20100104\\n20100305\\n20100430\\n20100630\\n20100824\\n20101028\\n20101222\\n20110223\\n20110421\\n20110617\\n20110811\\n20111013\\n20111207\\n20120209\\n20120409\\n20120605\\n20120731\\n20120924\\n20121123\\n20130122\\n20130325\\n20130524\\n20130723\\n20130916\\n20131119\\n20140114\\n20140317\\n20140514\\n20140709\\n20140902\\n20141104\\n20141229\\n20150303\\n20150428\\n20150624\\n20150818\\n20151021\\nC\\numulative return of strategy on CSI 300 Index\\n\\n(2010.01 \\n-\\n2015.11)\\n\\nregime-switching strategy\\n regime 1 strategy\\nregime 2 strategy\\n 80\\n \\n\\n \\n \\n\\nAppendix C \\n--\\n \\nTables\\n \\n\\n \\n\\nTable  1:  Detail  of  Fama\\n-\\nMacBeth  regressions  on  technical  indicators  RSI,  MACD  and \\n\\nBollinger Band to identify statuses significantly associated with positive and negative returns \\n\\nover 120 days from 2013.03 to 2013.\\n  \\n06.\\n \\nSignificance at 5% significance level is indicated by \\n\\n*.\\n \\n\\nRelative Strength Index (RSI)\\n  \\n\\nStatus\\n \\n Scenario\\n \\n T\\n-\\nstat\\n \\n\\n1\\n \\n 100>=RSI>75\\n \\n  \\n-\\n3.04\\n*\\n \\n\\n2\\n \\n 75>=RSI>50\\n \\n -\\n0.84\\n \\n\\n3\\n \\n 50>=RSI>25\\n \\n -\\n0.77\\n \\n\\n4\\n \\n 25>=RSI\\n \\n   \\n2.82\\n*\\n \\n\\nMoving Average Convergence Divergence (MACD)\\n  \\n\\nStatus\\n \\n Scenario\\n \\n T\\n-\\nstat\\n \\n\\n1\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n≥\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n \\n𝐀𝐍𝐃\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n≥\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n1\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n−\\n1\\n \\n2.03\\n*\\n \\n\\n2\\n \\n \\n\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n≥\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n \\n𝐀𝐍𝐃\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n<\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n1\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n−\\n1\\n \\n\\n \\n 1.36\\n \\n\\n3\\n \\n  \\n\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n<\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n \\n𝐀𝐍𝐃\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n≥\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n1\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n−\\n1\\n \\n\\n \\n -\\n1.58\\n \\n\\n4\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n<\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n \\n𝐀𝐍𝐃\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n<\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n1\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n−\\n1\\n \\n\\n \\n -\\n2.47\\n*\\n \\n\\nBollinger Band\\n \\n\\nStatus\\n \\n Scenario\\n \\n T\\n-\\nstat\\n \\n\\n1\\n \\n closing\\ni  \\n<= lower band\\ni\\n \\n   \\n-\\n2.45\\n*\\n \\n\\n2\\n \\n middle band\\ni \\n>= closing\\ni  \\n> lower band\\ni\\n \\n -\\n1.77\\n \\n\\n3\\n \\n higher band\\ni \\n>= closing\\ni  \\n> middle band\\ni\\n \\n 0.98\\n \\n\\n4\\n \\n closing\\ni  \\n>= higher band\\ni\\n \\n  \\n2.63\\n*\\n \\n\\n \\n\\n \\n\\n \\n 81\\n \\n\\n \\nTable  2:  Basic facts  of  CSI  300  index  over  the  period  from  2005.04  to  2015.11  including \\n\\nnumber  of  days,  average  daily  return, \\ncumulative\\n \\nreturn,  return  volatility,  maximum \\n\\ndrawdown and Sharpe ratio. \\n  \\n\\n \\n\\nCSI 300 Index from 200\\n5.04 to 2015.11\\n \\n\\nNumber of \\ntrading \\ndays\\n \\n2640\\n \\n\\nAverage daily return\\n  \\n3.7*10\\n-\\n3\\n%\\n \\n\\nCumulative\\n \\nreturn\\n \\n5.39%\\n \\n\\nVolatility of return\\n  \\n1.61%\\n \\n\\nMaximum drawdown\\n \\n57.07%\\n \\n\\nSharpe ratio\\n \\n 0.036\\n \\n\\n \\n\\nTable 3:  Key facts of the 10 GA\\n-\\nbased technical trading strategies on CSI 300 index in \\n out\\n-\\n\\nof\\n-\\nsample period from 2010.01 to 2015.12. Information contained includes return attribution, \\n\\nholding period return, number of transaction, maximum drawdown and Sharpe ratio for \\n\\neach strategy.\\n \\n\\n \\n\\n \\nStrategy performances in out\\n -\\nof\\n-\\nsample ( 2010.01 \\n–\\n \\n2015.12)\\n \\n\\n \\n\\nReturn\\n \\nattribution\\n \\nHPR\\n \\nNumber of \\ntransaction\\n \\nMaximum \\ndrawdown\\n \\nSharpe\\n \\nratio\\n \\n\\nStrategy 1\\n \\nMarket timing\\n \\n136%\\n \\n150\\n \\n30%\\n \\n1.01\\n \\n\\nStrategy 2\\n \\nMarket timing\\n \\n128%\\n \\n104\\n \\n35.8%\\n \\n1.03\\n \\n\\nStrategy 3\\n \\nMarket timing\\n \\n123%\\n \\n107\\n \\n30.6%\\n \\n0.98\\n \\n\\nStrategy 4\\n \\nMarket timing\\n \\n118%\\n \\n174\\n \\n31.5%\\n \\n0.87\\n \\n\\nStrategy 5\\n \\nMarket timing\\n \\n112%\\n \\n113\\n \\n27.5%\\n \\n0.95\\n \\n\\nStrategy 6\\n \\nMarket timing\\n \\n130%\\n \\n116\\n \\n26.6%\\n \\n1.06\\n \\n\\nStrategy 7\\n \\nMarket timing\\n \\n118%\\n \\n106\\n \\n21.15%\\n \\n1.02\\n \\n\\nStrategy 8\\n \\nMarket timing\\n \\n129%\\n \\n155\\n \\n24.9%\\n \\n1.08\\n \\n\\nStrategy 9\\n \\nMarket timing\\n \\n106%\\n \\n150\\n \\n26.4%\\n \\n1..00\\n \\n\\nStrategy 10\\n \\nMarket\\n \\ntiming\\n \\n133%\\n \\n118\\n \\n26%\\n \\n1.03\\n \\n\\nBenchmark\\n \\nPure indexing\\n \\n6.12%\\n \\n1\\n \\n57%\\n \\n0.00024\\n \\n 82\\n \\n\\n \\nTable 4: Categorization of the statuses for RSI, MACD and Bollinger Band and t\\n-\\nstats for \\n\\neach of the statuses with regard to returns.\\n  \\nSignificance at 5% significance level is indicated \\n\\nby *.\\n \\n\\n \\n\\nRelative Strength Index (RSI)\\n  \\n\\nStatus\\n \\n Scenario\\n \\n T\\n-\\nstat\\n \\n\\n1\\n \\n 100>=RSI>75\\n \\n -\\n3.23\\n*\\n \\n\\n2\\n \\n 75>=RSI>50\\n \\n -\\n1.06\\n \\n\\n3\\n \\n 50>=RSI>25\\n \\n -\\n2.43\\n*\\n \\n\\n4\\n \\n 25>=RSI\\n \\n 2.56\\n*\\n \\n\\nMoving Average Convergence Divergence (MACD)\\n  \\n\\nStatus\\n \\n Scenario\\n \\n  \\n\\nT\\n-\\nstat\\n \\n\\n1\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n≥\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n \\n𝐀𝐍𝐃\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n≥\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n1\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n−\\n1\\n \\n2.25\\n*\\n \\n\\n2\\n \\n \\n\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n≥\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n \\n𝐀𝐍𝐃\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n<\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n1\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n−\\n1\\n \\n\\n \\n -\\n2.44\\n*\\n \\n\\n3\\n \\n  \\n\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n<\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n \\n𝐀𝐍𝐃\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n≥\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n1\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n−\\n1\\n \\n\\n \\n 0.86\\n \\n\\n4\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n<\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n \\n𝐀𝐍𝐃\\n \\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n<\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐼𝐹𝐹\\n𝑖\\n−\\n1\\n−\\n𝑀𝐴𝐶𝐷\\n_\\n𝐷𝐸𝐴\\n𝑖\\n−\\n1\\n \\n\\n \\n -\\n1.98\\n*\\n \\n\\nBollinger Band\\n \\n\\nStatus\\n \\n Scenario\\n \\n T\\n-\\nstat\\n \\n\\n1\\n \\n closing\\ni  \\n<= lower band\\ni\\n \\n -\\n3\\n.0\\n3\\n*\\n \\n\\n2\\n \\n middle band\\ni \\n>= closing\\ni  \\n> lower band\\ni\\n \\n -\\n1.\\n35\\n \\n\\n3\\n \\n higher band\\ni \\n>= closing\\ni  \\n> middle band\\ni\\n \\n -\\n2.43\\n*\\n \\n\\n4\\n \\n closing\\ni  \\n>= higher band\\ni\\n \\n 2.5\\n8\\n*\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n 83\\n \\n\\n \\nTable 5: Key facts of portfolio 1, portfolio 2 and portfolio 3. Information contained includes \\n\\nreturn attribution, holding period return, maximum drawdown and Sharpe ratio.\\n  \\n\\n \\n\\nPortfolio performances over 5 years ( 2010.06 \\n–\\n \\n2015.11)\\n \\n\\n \\nReturn \\nattribution\\n \\n        \\nGA\\n \\nHPR\\n \\nMaximum drawdown\\n \\nSharpe ratio\\n \\n\\nPortfolio 1\\n \\nStock selection\\n \\n       \\nNO\\n \\n135%\\n \\n16.04%\\n \\n1.70\\n \\n\\nPortfolio 2\\n \\nStock selection\\n \\n       \\nNO\\n \\n150%\\n \\n24.56%\\n \\n1.96\\n \\n\\nPortfolio 3\\n \\nStock selection\\n \\n\\nMarket timing\\n \\n      \\nYES\\n \\n261%\\n \\n16.23%\\n \\n2.54\\n \\n\\n \\n\\n \\n\\n \\n\\nTable 6:  Key\\n \\nfacts of the 10 experiments with regime\\n-\\nswitching considered. Information \\n\\ncontained includes holding period return, maximum drawdown and Sharpe ratio.\\n  \\n\\n \\n\\nExperiment\\n \\nHPR\\n \\nSharpe ratio\\n \\nMaximum \\n\\ndrawdown\\n \\n\\nExperiment \\n1\\n \\nRegime 1 strategy\\n \\n126%\\n \\n0.85\\n \\n32%\\n \\n\\nRegime 2 \\nstrategy\\n \\n62%\\n \\n0.64\\n \\n43%\\n \\n\\nFinal strategy\\n \\n158%\\n \\n1.10\\n \\n32%\\n \\n\\nExperiment \\n2\\n \\nRegime 1 strategy\\n \\n114%\\n \\n0.92\\n \\n33%\\n \\n\\nRegime 2 strategy\\n \\n56%\\n \\n0.45\\n \\n29%\\n \\n\\nFinal strategy\\n \\n162%\\n \\n1.12\\n \\n33%\\n \\n\\nExperiment \\n3\\n \\nRegime 1 strategy\\n \\n108%\\n \\n0.86\\n \\n26%\\n \\n\\nRegime 2 strategy\\n \\n77%\\n \\n0.49\\n \\n38%\\n \\n\\nFinal \\nstrategy\\n \\n149%\\n \\n1.16\\n \\n26%\\n \\n\\nRegime 1 strategy\\n \\n119%\\n \\n0.75\\n \\n35%\\n \\n 84\\n \\n\\n \\nExperiment \\n4\\n \\nRegime 2 strategy\\n \\n85%\\n \\n0.52\\n \\n49%\\n \\n\\nFinal strategy\\n \\n160%\\n \\n1.18\\n \\n35%\\n \\n\\nExperiment \\n5\\n \\nRegime 1 strategy\\n \\n120%\\n \\n0.83\\n \\n29%\\n \\n\\nRegime 2 strategy\\n \\n53%\\n \\n0.48\\n \\n38%\\n \\n\\nFinal strategy\\n \\n145%\\n \\n1.15\\n \\n29%\\n \\n\\nExperiment \\n6\\n \\nRegime 1 strategy\\n \\n119%\\n \\n0.69\\n \\n33%\\n \\n\\nRegime 2 strategy\\n \\n65%\\n \\n0.38\\n \\n24%\\n \\n\\nFinal strategy\\n \\n138%\\n \\n1.12\\n \\n33%\\n \\n\\nExperiment \\n7\\n \\nRegime 1 strategy\\n \\n121%\\n \\n0.77\\n \\n38%\\n \\n\\nRegime 2 strategy\\n \\n78%\\n \\n0.33\\n \\n32%\\n \\n\\nFinal strategy\\n \\n140%\\n \\n1.14\\n \\n38%\\n \\n\\nExperiment \\n8\\n \\nRegime 1 strategy\\n \\n111%\\n \\n0.81\\n \\n35%\\n \\n\\nRegime 2 strategy\\n \\n80%\\n \\n0.56\\n \\n42%\\n \\n\\nFinal strategy\\n \\n139%\\n \\n1.09\\n \\n35%\\n \\n\\nExperiment \\n9\\n \\nRegime 1 strategy\\n \\n125%\\n \\n0.73\\n \\n31%\\n \\n\\nRegime 2 strategy\\n \\n86%\\n \\n0.53\\n \\n33%\\n \\n\\nFinal strategy\\n \\n154%\\n \\n1.16\\n \\n31%\\n \\n\\n \\n\\n \\n\\n\\n ********************References \\n[1] \\n , 1995, PP.1942-\\n1948.   \\n[2] N. Q. Uy, N. X. Hoai, R. McKay and P. \\n-\\nProceedings of the IEEE Congress on Evolutionary Computation, 2007, pp 1985-1992. \\n[3] A.P. Engelbrechr, Fundamentals of Computational Swarm Intelligence, John Wiley & Sons, 2005. \\n[4] H. Jabeen, Z. Jalil and A.R Baig, \"Opposition Based Initialization in Particle Swarm Optimization,\" in Proceedings of the 11th Annual Conference \\nCompanion on Genetic and Evolutionary Computation Conference: Late Breaking Papers, New York, NY, USA, 2009, pp. 2047- 2052. \\n[5] M. Pant, R. Thangaraj, C. Grosan, and A. Abraham, \"Improved Particle Swarm Optimization with Low-Discrepancy Sequences,\" in IEEE Cong. on \\nEvolutionary, Hong Kong , 2008, pp. 3011-3018. \\n[6] M. G. H. Omran and S.al-\\n Opposition-\\nIntelligence Symposium, 2008, pp 1   6. \\n[7] \\n\\n- and Applications, 2009, \\npp 325 \\n 330. \\n[8] \\n\\n \\non Evolutionary Computation, vol. 6, 2002 ,pp 58 73. \\n[9] \\n\\nComputational Intelligence., The 1998 IEEE International Conference on, pp 69 73. \\n[10]  H-R LI and Y-L Gao., \"Particle swarm optimization algorithm with exponent decreasing inertia weight and stochastic mutation,\" in Second \\nInternational Conference on Information and Computing Science, Manchester , 2009, pp. 66-69. \\n[11] Huang Chongpeng, Zhang Yuling, Jiang Dingguo and Xu Baoguo, \"On Some Non-linear Decreasing Inertia Weight Strategies in Particle Swarm \\nOptimization*,\" in Proceedings of the 26th Chinese Control Conference, Zhangjiajie, Hunan, China, 2007, pp. 570-753. \\n[12] Y. Shi and R. C. Eberhart, \"Fuzzy Adaptive particle Swarm Optimization,\" in Proceedings of the IEEE Congress on Evolutionary Computation, \\nSeoul , South Korea, 2001, pp. 101-106. \\n[13] L. Zhang, H. Yu, and S. Hu, \"A new approach to improve particle swarm optimization,\" in Proceedings of the 2003 international conference on \\nGenetic and evolutionary computation, 2003, pp. 134-139. \\n[14] \\n\\n Science and \\nNetwork Security, Vol. 6, pp.221-224, July 2006. \\n[15] M. Pant and T. Thangaraj, V.P. Singh, \"Particle Swarm Optimization Using Gaussian Inertia Weight,\" in International Conference on Computational \\nIntelligence and Multimedia Applications, Sivakasi, Tamil Nadu , 2007, pp. 97-102. \\n[16] X. Liu et al, \"Particle Swarm Optimization with Dynamic Inertia Weight and Mutation,\" in Third International Conference on Genetic and \\nEvolutionary Computing, Guilin, 2009, pp. 620-623. \\n[17] \\n\\n7, pp 356  \\n360 \\n[18] H. W\\n- IEEE Congress on   Evolutionary Computation, 2007, pp 4750 \\n 4756.   \\n[19] M. Pant, R. Thangaraj, and A. Abraham , \"Particle Swarm Optimization Using Adaptive Mutation,\" in 19th International Conference on Database and \\nExpert Systems, Washington, DC, USA, 2008, pp. 519-523. \\n[20] M. Pant, R. Thangaraj1, V.P Singhand and A. Abraham \", Particle Swarm Optimization Using Sobol Mutation,\" in First International Conference on \\nEmerging Trends in Engineering and Technology, Nagpur, Maharashtra , 2008, pp. 367-372. \\n[21] Xiaoling Wu, Xiaojuan Zhao \",  Particle swarm optimization based on power mutationISECS International Colloquium on Computing, \\nCommunication, Control, and Management, \\nSanya ,2009, pp.  464 - 467 \\n[22] M. Imran, H.Jabeen, M. ahmad, Q. ababs, w.Bangyal and Q. Ababs \", Opposition Based PSO and Mutation Operators(OPSO with Power Mutation) ,\" \\n2nd International Conference on Education Technology and Computer, Shanghai, 2010,pp.V4-506 -508. \\n[23] M. Imran, Z. Manzoor, S. Ali and Q. Ababs \", Modified Particle Swarm Optimization with Student T Mutation ,\" International Conference on \\nComputer Networks and Information Technology, Abbottabad, 2011,pp.283 - 286. \\n[24] L.Chen \",Particle Swarm Optimization with a Novel Mutation Operator,\" International Conference on Mechatronic Science, Electric Engineering and \\nComputer, Jilin, 2011, pp. 970 \\n 973. \\n \\n\\n\\n ********************REFERENCES \\n[1] Man K.F., Tang K.S., and Kwong S., \"Genetic Algorithms: Concepts \\nand Designs\", Springer Verlag. 1999. \\n[2] Eberhart, R. C. and Kennedy, J. A new optimizer using particle swarm \\ntheory. Proceedings of the Sixth International Symposium on \\nMicromachine and Human Science, Nagoya, Japan. pp. 39-43, 1995. \\n[3] Kennedy, J. and Eberhart, R. C. Particle swarm optimization. \\nProceedings of IEEE International Conference on Neural Networks, \\nPiscataway, NJ. pp. 1942-1948, 1995. \\n[4] Valdez, F. and Melin P.\\n ‘‘Parallel Evolutionary Computing using a  \\n     cluster for Mathematical Function Optimization“, Nafips. San Diego CA  \\n     USA, 598-602. June 2007. \\n[5] Germundsson, R. \"Mathematical Version 4.\" Mathematical J. 7, 497-\\n524, 2000.  \\n[6] D.B. Fogel, “An introduction to simulated evolutionary optimization”, \\nIEEE transactions on neural networks, vol 5, n 1, jan 1994. [7] Holland J.H., Adaptation in natural and artificial system, Ann Arbor, \\nThe University of Michigan Press, 1975. \\n[8] Goldberg D., Genetic Algorithms, Addison Wesley, 1988. \\n[9] Emmeche C., Garden in the Machine. The Emerging Science of \\nArtificial Life, Princeton University Press, pp. 114. 1994. \\n[10] Angeline P. J., Using Selection to Improve Particle Swarm \\nOptimization , In Proceedings 1998 IEEE World Congress on \\nComputational Intelligence, Anchorage, Alaska, IEEE, 84-89. 1998 \\n[11] Angeline P. J., _Evolutionary Optimization Versus Particle Swarm \\nOptimization: Philosophy and Performance Differences, Evolutionary \\nProgramming VII, Lecture Notes in Computer Science 1447, Springer, \\n:601-610. 1998. \\n[12] Back T., Fogel D. B., and Michalewicz Z., (Eds), Handbook of \\nEvolutionary Computation, Oxford University Press, 1997. \\n[13] Montiel O, Castillo O, Melin P, Rodriguez A and Sepulveda R:     \\n    “Human evolutionary model: A new approach to optimization.” Inf. Sci.    \\n     177(10): 2075-2098, 2007. \\n[14] Castillo O., Valdez F and Melin P., “Hierarchical Genetic Algorithms  \\n     for topology optimization in fuzzy control systems”. International  \\n     Journal of General Systems, Volume 36, Issue 5., pag. 575-591, October  \\n     2007. \\n[15] Valdez F, Melin P. and Castillo O. “Evolutionay Computing for the    \\n     Optimization of Mathematical Functions”. Analysis and Design of  \\n     intelligent Systems Using Soft Computing Techniques. Advances in Soft     \\n     Computing 41. June 2007.  \\n\\n\\n ********************References\\n\\nAlberg, John, and Zachary Lipton. 2017. “Improving Factor-\\n\\nBased Quantitative Investing by Forecasting Company \\n\\nFundamentals.” Working paper, Cornell University. \\nhttps://\\n\\narxiv.org/abs/1711.04837v2\\n . \\nAsness, Clifford S. 2016. “The Siren Song of Factor Timing \\naka ‘Smart Beta Timing’ aka ‘Style Timing.’” \\nJournal of Portfolio \\n\\n\\nManagement\\n\\n 42: 1–6.\\nAsness, Clifford S., R. Burt Porter, and Ross L. Stevens. 2000. \\n“Predicting Stock Returns Using Industry-Relative Firm \\n\\nCharacteristics.” Working paper, AQR Capital Management.\\n \\nBatres-Estrada, Gilberto. 2015. “Deep Learning for Multivariate \\nFinancial Time Series.” Master’s thesis, KTH Royal Institute \\nof Technology. \\nhttps://www.math.kth.se/matstat/seminarier/\\n\\nreports/M-exjobb15/150612a.pdf\\n .\\nCarhart, Mark. 1997. “On Persistence in Mutual Fund \\n\\nPerformance.” \\n\\nJournal of Finance\\n\\n 52 (1): 57–82. \\nClemen, Robert T. 1989. “Combining Forecasts: A Review and \\nAnnotated Bibliography.” \\n\\nInternational Journal of Forecasting\\n\\n  \\n5 (4): 559–83. \\nDaniel, K., and T.J. Moskowitz. 2016. “Momentum Crashes.” \\n\\n\\nJournal of Financial Economics\\n\\n 122 (2): 221–47. \\nFama, Eugene F., and Kenneth R. French. 1992. “The Cross-\\nSection of Expected Stock Returns.” \\n\\nJournal of Finance\\n\\n 47 (2): \\n\\n427–65\\n. \\n———. 2017. “International Tests of a Five-Factor Asset Pricing \\n\\nModel.” \\n\\nJournal of Financial Economics\\n\\n 123 (3): 441–63. \\nFama, Eugene F., and J.D. MacBeth. 1973. “Risk, Return, and \\nEquilibrium: Empirical Tests.” \\n\\nJournal of Political Economy\\n\\n  \\n81 (3): 1–31.\\nGu, Shihao, Bryan T. Kelly, and Dacheng Xiu. 2018. “Empirical \\nAsset Pricing via Machine Learning.” NBER Working Paper \\n25398 (December).\\nHeaton, J.B., N.G. Polson, and J.H. Witte. 2017. “Deep Learning \\nin Finance: Deep Portfolios.” \\nApplied Stochastic Models in \\nBusiness and Industry\\n 33 (1): 3–12. López de Prado, M. 2018. \\n\\nAdvances in Financial Machine \\nLearning\\n\\n. Hoboken, NJ: John Wiley & Sons.\\nMakridakis, Spyros, and Michèle Hibon. 2000. “The \\n\\nM3-Competition: Results, Conclusions and Implications.” \\n\\n\\nInternational Journal of Forecasting\\n\\n  16 (4): 451–76 . \\nMiller, K.L, Hong Li, Tiffany G. Zhou, and Daniel Giamouridis. \\n2015. “A Risk-Oriented Model for Factor Timing Decisions.” \\n\\n\\nJournal of Portfolio Management\\n\\n  41 (3): 46–58. \\nMiller, K.L., Chee Ooi, Hong Li, and D. Giamouridis. 2013. \\n“Size Rotation in the U.S. Equity Market.” \\nJournal of Portfolio \\n\\n\\nManagement\\n\\n 39 (2): 116–27. \\nMoritz, B., and T. Zimmerman. 2016. “Tree-Based Conditional \\nPortfolio Sorts: The Relation between Past and Future Stock \\nReturns.” Working paper (March). \\nMorozov, A., J. Wang, and L. Borda. 2012. “Barra Global \\nEquity Model (GEM3).” MSCI. \\nhttps://www.msci.com/\\n\\ndocuments/10199/242721/Barra_Global_Equity_Model_\\n\\nGEM3.pdf\\n.\\nSchapire, R. 1990. “The Strength of Weak Learnability.” \\n\\n\\nMachine Learning\\n\\n 5 (2): 197–227 . \\nSrivastava, N., and G. Hinton. 2014. “Dropout: A Simple Way to \\nPrevent Neural Networks from Overfitting.” \\n\\nJournal of Machine \\n\\nLearning Research\\n\\n 15: 1929–58. \\n\\nTakeuchi, L., and Y.Y.A. Lee. 2013. “Applying Deep Learning to \\nEnhance Momentum Trading Strategies in Stocks.” Working \\npaper, Stanford University. \\nhttp://cs229.stanford.edu/proj2013/\\n\\nTakeuchiLee-ApplyingDeepLearningToEnhanceMomentumTrading\\n\\nStrategiesInStocks.pdf\\n.\\n\\nTimmermann, A. 2006. “Forecast Combinations.” In \\n\\nHandbook \\n\\n\\nof Economic Forecasting\\n\\n, edited by Graham Elliott, Clive W.J. \\nGranger, and Allan Timmerman, 1: 135–96. Amsterdam: Elsevier.\\n\\nWang, S., and Y. Luo. 2012. “Signal Processing: The Rise of the \\n\\nMachines.” Deutsche Bank Quantitative Strategy (5 June).\\n\\n———. 2014. “Signal Processing: The Rise of the Machines III.” \\n\\nDeutsche Bank Quantitative Strategy.\\n\\n\\n\\n ********************\\n\\n ********************References\\nAbid, A.; Balin, M. F.; and Zou, J. 2019. Concrete autoen-\\ncoders for differentiable feature selection and reconstruc-\\ntion.arXiv preprint arXiv:1901.09346 .\\nChalasani, P.; Chen, J.; Chowdhury, A. R.; Jha, S.; and Wu,\\nX. 2018. Concise explanations of neural networks using ad-\\nversarial training.arXivarXiv–1810.\\nChen, X.; and Tian, Y. 2019. Learning to perform local\\nrewriting for combinatorial optimization. In Advances in\\nNeural Information Processing Systems , 6278–6289.\\nEykholt, K.; Evtimov, I.; Fernandes, E.; Li, B.; Rahmati, A.;\\nXiao, C.; Prakash, A.; Kohno, T.; and Song, D. 2018. Robust\\nphysical-world attacks on deep learning visual classiﬁcation.\\nInProceedings of the IEEE Conference on Computer Vision\\nand Pattern Recognition, 1625–1634.\\nFinlay, C.; Calder, J.; Abbasi, B.; and Oberman, A. 2018.\\nLipschitz regularized deep neural networks generalize and\\nare adversarially robust.arXiv preprint arXiv:1808.09540 .\\nFord, N.; Gilmer, J.; Carlini, N.; and Cubuk, D. 2019. Ad-\\nversarial examples are a natural consequence of test error in\\nnoise.arXiv preprint arXiv:1901.10513 .\\nGoodfellow, I. 2018. Defense against the dark arts: An\\noverview of adversarial example security research and fu-\\nture research directions.arXiv preprint arXiv:180604169 .\\nHe, Z.; Rakin, A. S.; and Fan, D. 2019. Parametric Noise\\nInjection: Trainable Randomness to Improve Deep Neural\\nNetwork Robustness Against Adversarial Attack. In The\\nIEEE Conference on Computer Vision and Pattern Recog-\\nnition (CVPR).\\nIlyas, A.; Santurkar, S.; Tsipras, D.; Engstrom, L.; Tran, B.;\\nand Madry, A. 2019. Adversarial examples are not bugs,\\nthey are features. InAdvances in Neural Information Pro-\\ncessing Systems, 125–136.\\nKhaire, U. M.; and Dhanalakshmi, R. 2019. Stability of fea-\\nture selection algorithm: A review. Journal of King Saud\\nUniversity-Computer and Information Sciences .\\nKhurana, U.; Samulowitz, H.; and Turaga, D. 2018. Fea-\\nture engineering for predictive modeling using reinforce-\\nment learning. InThirty-Second AAAI Conference on Ar-\\ntiﬁcial Intelligence.\\nLi, J.; Schmidt, F.; and Kolter, Z. 2019. Adversarial camera\\nstickers: A physical camera-based attack on deep learning\\nsystems. InInternational Conference on Machine Learning .\\nLiu, K.; Fu, Y.; Wang, P.; Wu, L.; Bo, R.; and Li, X. 2019.\\nAutomating Feature Subspace Exploration via Multi-Agent\\nReinforcement Learning. InProceedings of the 25th ACM\\nSIGKDD International Conference on Knowledge Discov-\\nery & Data Mining, 207–215.\\nMadry, A.; Makelov, A.; Schmidt, L.; Tsipras, D.; and\\nVladu, A. 2017. Towards deep learning models resistant to\\nadversarial attacks.arXiv preprint arXiv:1706.06083 .Mnih, V.; Kavukcuoglu, K.; Silver, D.; Graves, A.;\\nAntonoglou, I.; Wierstra, D.; and Riedmiller, M. 2013. Play-\\ning atari with deep reinforcement learning. arXiv preprint\\narXiv:1312.5602.\\nNazari, M.; Oroojlooy, A.; Snyder, L.; and Tak ´ac, M. 2018.\\nReinforcement learning for solving the vehicle routing prob-\\nlem. InAdvances in Neural Information Processing Systems ,\\n9839–9849.\\nNg, A. Y.; Harada, D.; and Russell, S. 1999. Policy invari-\\nance under reward transformations: Theory and application\\nto reward shaping. InICML, volume 99, 278–287.\\nNguyen, T.; and Sanner, S. 2013. Algorithms for direct 0–1\\nloss optimization in binary classiﬁcation. In International\\nConference on Machine Learning , 1085–1093.\\nPeng, H.; Long, F.; and Ding, C. 2005. Feature selection\\nbased on mutual information criteria of max-dependency,\\nmax-relevance, and min-redundancy. IEEE Transactions on\\npattern analysis and machine intelligence 27(8): 1226.\\nSaeys, Y.; Abeel, T.; and Van de Peer, Y. 2008. Robust fea-\\nture selection using ensemble feature selection techniques.\\nInJoint European Conference on Machine Learning and\\nKnowledge Discovery in Databases , 313–325. Springer.\\nSundararajan, M.; Taly, A.; and Yan, Q. 2017. Axiomatic\\nattribution for deep networks. In Proceedings of the 34th\\nInternational Conference on Machine Learning-Volume 70 ,\\n3319–3328. JMLR. org.\\nTong, L.; Li, B.; Hajaj, C.; Xiao, C.; Zhang, N.; and Vorob-\\neychik, Y. 2019. Improving Robustness offMLgClassiﬁers\\nagainst Realizable Evasion Attacks Using Conserved Fea-\\ntures. In28thfUSENIXgSecurity Symposium (fUSENIXg\\nSecurity 19), 285–302.\\nTsipras, D.; Santurkar, S.; Engstrom, L.; Turner, A.; and\\nMadry, A. 2018. Robustness may be at odds with accuracy.\\narXiv preprint arXiv:1805.12152 .\\nWeng, T.-W.; Zhang, H.; Chen, H.; Song, Z.; Hsieh, C.-J.;\\nBoning, D.; Dhillon, I. S.; and Daniel, L. 2018. Towards\\nfast computation of certiﬁed robustness for relu networks.\\narXiv preprint arXiv:1804.09699 .\\nXu, W.; Evans, D.; and Qi, Y. 2017. Feature squeezing: De-\\ntecting adversarial examples in deep neural networks. arXiv\\npreprint arXiv:1704.01155.\\nXue, B.; Fu, W.; and Zhang, M. 2014. Multi-objective fea-\\nture selection in classiﬁcation: a differential evolution ap-\\nproach. InAsia-Paciﬁc Conference on Simulated Evolution\\nand Learning, 516–528. Springer.\\nXue, C.; Yan, J.; Yan, R.; Chu, S. M.; Hu, Y.; and Lin, Y.\\n2019. Transferable automl by model sharing over grouped\\ndatasets. InProceedings of the IEEE Conference on Com-\\nputer Vision and Pattern Recognition , 9002–9011.\\nXue, Y.; Xie, M.; and Roshan, U. 2020. Robust binary clas-\\nsiﬁcation with the 01 loss.arXiv:2002.03444.\\nZhai, R.; Dan, C.; He, D.; Zhang, H.; Gong, B.; Ravikumar,\\nP.; Hsieh, C.-J.; and Wang, L. 2020. MACER: Attack-free\\nand Scalable Robust Training via Maximizing Certiﬁed Ra-\\ndius.arXiv preprint arXiv:2001.02378 .\\nZhang, H.; Yu, Y.; Jiao, J.; Xing, E. P.; Ghaoui, L. E.;\\nand Jordan, M. I. 2019. Theoretically principled trade-\\noff between robustness and accuracy. arXiv preprint\\narXiv:1901.08573.\\nA Evaluating Existing Feature Scoring\\nMetrics\\nIn Figure 4, we plot the variation of performance and ro-\\nbustness as more features are selected using existing feature\\nscoring metrics. As we can see, as more features are se-\\nlected, the performance improves but the robustness drops.\\nThus, the four existing score metrics fail to scoring the fea-\\ntures w.r.t their robustness.\\nB Proof of Theorem 3.1\\nTheorem B.1.Let us assumeE= (S;A;\\r;R)andE0=\\n(S;A;\\r;R0)are two identical environments except reward\\nfunction. If a reward functionR:S\\x02A\\x02S \\x00!Rand\\na reward shaping functionF:S\\x02A\\x02S \\x00!Rsat-\\nisfyPT\\nt=1F(st;\\x19(st);st+1) =PT\\nt=1R(st;\\x19(st);st+1) =\\nR(sT;\\x19(sT);sT+1)for any policy\\x19and any sequence\\nlengthT, then, we have\\x19\\x03E=\\x19\\x03E0when\\r= 1.\\nProof.For any policy\\x19EinEand discount factor\\r= 1.\\nThe value function is\\nV\\x19E(s0) =TX\\nt=1\\rtR(st;\\x19E(st);st+1)\\n=R(s\\x19ET;\\x19E(sT);sT+1)\\n= 1\\x00^L0\\x001\\n\\x0f\\x00robust(gc\\x19E)(15)\\nSimilarly, we have the value function for policy\\x19E0inE0:\\nV\\x19E0(s0) =TX\\nt=1R(si;\\x19E0(st);st+1)\\n+TX\\nt=1F(st;\\x19E0(st);st+1)\\n= 2\\x02R(s\\x19E0\\nT;\\x19E0(s\\x19E0\\nT);s\\x19E0\\nT+1)(16)\\nAssume we have two distinct optimal policies\\x19\\x03Eand\\x19\\x03E0forEandE0, respectively. Since maximizing\\n2\\x02R(s\\x19E0\\nT;\\x19E0(s\\x19E0\\nT);s\\x19E0\\nT+1)is equivalent to maximize\\nR(s\\x19E0\\nT;\\x19E0(s\\x19E0\\nT);s\\x19E0\\nT+1). Thus, we haveV\\x19\\x03\\nE0(s0) =\\nR(s\\x19\\x03\\nE0\\nT;\\x19\\x03E0(s\\x19\\x03\\nE0\\nT);s\\x19\\x03\\nE0\\nT+1)> R(s\\x19\\x03\\nET;\\x19\\x03E(s\\x19\\x03\\nET);s\\x19\\x03\\nET+1) =\\nV\\x19\\x03\\nE(s0). However, by deﬁnition, we haveV\\x19\\x03\\nE(s0)>\\nV\\x19E(s0)for any given\\x19E2\\x05E\\x00\\x19\\x03E. AsEandE0are only\\ndifferent on the reward function, we have \\x05E= \\x05E0. Thus,\\nwe haveV\\x19\\x03\\nE(s0)>V\\x19E0(s0)for any given\\x19E02\\x05E0\\x00\\x19\\x03E.\\nSinceV\\x19\\x03\\nE0(s0)>V\\x19\\x03\\nE(s0)conﬂictsV\\x19\\x03\\nE(s0)>V\\x19E0(s0),\\nwe must have\\x19\\x03E=\\x19\\x03E0.\\n\\nC Theorem for Potential-based Reward\\nShaping Function\\nAnother way of proving\\x19\\x03E=\\x19\\x03E0is to leverage the previous\\nresult of potential-based reward shaping function and use the\\nfollowing theorem\\nTheorem C.1.(Theorem 1 in Ng, Harada, and Russell\\n1999) Let anyS,A,\\rand any shaping reward function\\nF:S\\x02A\\x02S\\x00!Rbe given. We say F is a potential-based shaping function such that for alls2S\\x00fs0g,a2A,\\ns02S,\\nF(s;a;s0) =\\r\\x08(s0)\\x00\\x08(s);(17)\\n(whereS\\x00fs0g=Sif\\r <1) Then, that F is a potential-\\nbased shaping function is a necessary and sufﬁcient condi-\\ntion for it to guarantee consistence with the optimal policy\\n(when learning fromE0= (S;A;T;\\r;R+F)rather than\\nfromE= (S;A;T;\\r;R)) if the following sense:\\n•(Sufﬁciency) If F is a potential-based shaping function,\\nthen every optimal policy inE0will also be an optimal\\npolicy inE.\\n•(Necessity) If F is not a potential-based shaping function\\n(e.g. no such\\x08exists satisfying Equation(17)), then there\\nexist (proper) transition functionTand a reward function\\nR, such that no optimal policy inE0is optimal inE.\\nD Intuitive Explanation of IG score\\nWe show that Integrated Gradient (IG) is an effective method\\nto estimate the robustness of features by measuring the lo-\\ncal sharpness along each dimension represented by each fea-\\nture. The sharpness is a good indicator of robustness because\\nthe sharp gradient is a major cause of adversarial examples.\\nLet us consider a simple case where a datasetDhas two\\nfeatures0;1and one benign sample,fxjx2R2g. Af-\\nter adding adversarial noise\\x0e, we have an adversarial ex-\\namplexadv=x+\\x0e. We further assume the gradient is\\nnear0in[x0;x0adv]while the gradient iscin[x1;x1adv].\\nHere, feature0represents the direction of[x0;x0adv]and\\nfeature1represents the direction of[x1;x1adv]. Formally,\\nwe have@fy\\nw(x)\\n\\n@x0\\x190and@fy\\nw(x)\\n\\n@x1=c. Substituting the\\ngradient in equation (12) with@fy\\nw(x)\\n\\n@x0and@fy\\nw(x)\\n\\n@x1, we have\\nIG0(x)\\x190andIG1(x)\\x19c\\x02(x1\\x00x1adv). Obviously,\\nfeature1will receive more attribution than feature 0. On the\\nother hand, it is indeed the sharper gradientcalong feature\\n1together with the perturbation(x1\\x00x1adv)makesxadvan\\nadversarial example.\\nE RL Actions\\nWe report the actions of the RL agent in a single episode\\nin Table 5, from which we choose the subset of features for\\nfurther evaluation. As Table 5 shows, the RL agent relies on\\ndifferent metrics to achieve the objective across the dataset,\\nwhich demonstrates the RL agent is capable for identifying\\nthe proper way of ensembling the feature scoring metrics.\\nTable 5 also suggests that the learned RL agent is not trans-\\nferable between the datasets. It is because the 4 datasets we\\nare using are quite different from each other. The AutoML\\ntransferability over grouped datasets or continuously chang-\\ning datasets has been studied on related works (Liu et al.\\n2019; Xue et al. 2019).\\nF Experiment Setup and Details\\nExperimental Environment We performed our evalua-\\ntion on a single machine with an Nvidia RTX 2070 GPU\\nand an Intel Core i9 CPU as well as 32GB memory and 1TB\\nhard disk.\\n(a) Random Selection\\n\\n(b) Mutual Information\\n\\n(c) Tree Score\\n\\n(d) F Score\\nFigure 4:Existing Metrics Fail to Identify Robust Features on MNIST Dataset . The performance on training set (solid line)\\nand test set (dash line) increase while the robustness (dot line) decreases.\\nTable 5: Action Counts of RL Agent\\n\\nDATASETMI TREEF MIIGTREEIGFIG\\n\\nSPAMBASE0 0 2 1 2 0\\nISOLET8 28 1 2 3 0\\nMNIST 2 20 0 0 49 0\\nCIFAR 6 1 12 2 3 17\\n\\n*The metrics with IG subscripts denote the combined metrics\\ndeﬁned in Section 4.2.\\nML ModelWe used a 2-layer fully connected neural net-\\nworkfwwith a hidden layer of size 300 as the ML model.\\nThe other dimensions ofware determined by the feature\\nselection vectorcand the label spaceY.\\nQ-NetworkWe used a 2-layer fully connected neural net-\\nwork as the Q-networkQ\\x12, whose input size was 15, the\\nhidden size was 128, output size was 6.\\nOptimizerWe used a default Adam optimizer with\\x0c1 =\\n0:9,\\x0c2 = 0:999through out the experiment.\\nRL AgentWe tried [2000, 3000, 4000] for number of\\nsteps and [1000, 2000, 3000] for the\\x0f-decay (\\x0fdecays over\\n[1000, 2000, 3000] steps). The other settings are the same\\nas (Mnih et al. 2013). Finally, we trained our RL model for\\n4000 steps with learning rate = 0.01, batch size = 64, dis-\\ncount factor\\r= 1 and\\x0f= 0.1 (\\x0f-greedy). The training started\\nafter the ﬁrst 100 steps and the target network updated every\\n1000 steps.\\nComputational CostThe framework need 1-4 hours to\\ncomplete, depends on the size of the dataset, which is slower\\nthan stable feature selection on small dataset like SpamBase\\nand Isolet. However, it’s faster on MNIST and CIFAR.\\nChoose\\x0ffor AdversaryWe start the adversary attack\\nwith\\x0f= 8=255. On Isolet and MNIST,\\x0f= 8=255is not\\nsufﬁcient to signiﬁcantly decrease the accuracy. Thus, we\\nstart again with\\x0f= 1=10and gradually increase it by1=10Select the Number of Features The optimal number of\\nfeatures for each method is close to the number of features\\nthat Robusta chooses. As is shown in Figure 5, LASSO\\nachieves good performance and robustness with 71 features\\non MNIST and 4 features on LASSO. Thus, to decide the\\noptimal number of features for each method, we simply per-\\nform grid search, with granularity 5, around the number of\\nfeatures that Robusta chooses. For stable feature selection,\\nwe tried to tune the hyper-parameter but the algorithm was\\nunable to return a small set of selected features. Thus, we\\nbase the evaluation on the smallest set of features we can\\nget, which leads to maximum robustness. The full details\\nare reported in Table 6.\\nFeature Scoring Metric Computation All the feature\\nscores can be directly calculated by the Scikit-learn 234and\\nCaptum5libraries.\\nIG ReuseComputing the IG attribution is expensive, es-\\npecially when we need to compute the IG attribution at each\\nstep in RL. To alleviate this problem, we only compute one\\nIG attribution for an ML modelfw, which is trained with\\nfull features, and reuse it at all the steps. Using the same IG\\nattribution across all steps also yield good result. The reason\\nis that the robustness offeaturesdoes not heavily depend on\\nthe ML modelparametersas (Ilyas et al. 2019) shows. Fig-\\nure 6 visualizes the similar IG attributions for three neural\\nnetworks with different parameters and attack methods.\\nFeature EvaluationWe trained a 2-layer neural network\\non each of the feature sets in order to evaluate the qual-\\nity of the selected features. We report the training hyper-\\nparameters in Table 7. For the learning rate, we performed\\na grid search over [0.01, 0.1] with step size 0.01. For the\\ntraining epoch, we performed a grid search over [10, 50]\\n\\n2https://scikit-learn.org/stable/modules/generated/\\nsklearn.feature\\nselection.mutual\\ninfo\\nclassif.html#sklearn.\\nfeature\\nselection.mutual\\ninfo\\nclassif\\n3https://scikit-learn.org/stable/modules/generated/sklearn.\\nensemble.ExtraTreesClassiﬁer.html\\n4https://scikit-learn.org/stable/modules/generated/sklearn.\\nfeature\\nselection.f\\nclassif.html#sklearn.feature\\nselection.f\\nclassif\\n5https://captum.ai/docs/extension/integrated\\n gradients\\n Table 6: ML Model Hyper-parameters for Feature Evaluation\\n\\nDATA SETSTABLEMUTUALINFOLASSO CONCRETEROBUSTA\\n\\nSPAMBASE22 4 4 4 4\\nISOLET61 40 45 50 40\\nMNIST / 71 71 66 71\\nCIFAR / 30 25 30 30\\n\\n\\n(a)\\n\\n (b)\\n\\n (c)\\nFigure 5: Performance and Robustness with Different Number of Features\\n\\n\\n(a) Net 0, PGD\\n\\n(b) Net 1, PGD\\n\\n(c) Net 1, FGSM\\nFigure 6:Heat-Map of Feature Attribution from Two\\nNeural Networks with Different Parameters under Dif-\\nferent Attacks on MNIST Dataset The perturbation size\\x0f\\nis 0.1.\\nTable 7: ML Model Hyper-parameters for Feature Evalua-\\ntion\\n\\nDATA SETLEARNINGRATEEPOCH\\n\\nSPAMBASE0.05 30\\nISOLET0.01 20\\nMNIST 0.05 20\\nCIFAR 0.05 10\\n\\nwith step size 10. We selected the hyper-parameters where\\nthe performance on training and validation set didn’t diverse\\nmuch.\\nDatasetsWe performed experiments on four real-world\\ndatasets which contain tabular data, acoustic data, and im-\\nage data:\\nSpamBase: consists of 5000 spam and non-spam e-mails.\\nThe e-mails are represented in a tabular way using word and\\ncharacter frequencies, so the features are corresponding con- tinuous values. It has 57 continuous features in total. But we\\nonly select 54 of them because the values of the remaining\\n3 are unbounded, while the values of the former 54 features\\nare bounded between 0 and 100. We further scale the fea-\\ntures to[0;1]. We choose this dataset as spam ﬁltering is a\\ncommon task where attackers can get beneﬁts.\\nIsolet: consists of 5000 pre-processed speech data sam-\\nples of people speaking the names of the letters in the En-\\nglish alphabet. This dataset is widely used as a benchmark in\\nthe feature selection literature. Each feature is one of the 617\\nquantities in the range[0;1]. We choose this dataset because\\nacoustic data is vulnerable to adversarial attacks.\\nMNIST: consists of 60,000 training and 10,000 test im-\\nages, which are 28-by-28 gray-scale images of hand-written\\ndigits. We choose these datasets because they are widely\\nknown in the machine learning community. Although there\\nare other image datasets, the objects in each image in\\nMNIST are centered, which means we can meaningfully\\ntreat every 784 pixels in the image as a separate feature.\\nCIFAR10: consists of 50,000 training and 10,000 test ex-\\namples with 10 classes, which are 32x32 colour images. Dif-\\nferent from MNIST, where each image is centered, objects\\nin CIFAR10 may appear in different parts of images. As a\\nresult, each pixel in the image is not a good candidate for a\\nfeature. Instead, we use pre-trained ResNet-18 networks to\\nextract hidden representations from the images and treat the\\nextracted representations as features.\\nData Sample AllocationFor the Robusta training, we par-\\ntitioned the training set in each dataset into RL training, RL\\nvalidation, and RL test set. At each step, We used the RL\\ntraining set to train an ML model with the current subset of\\nfeatures. We then measured the features’ performance on the\\nRL validation set. We also made a corrupted dataset from\\nthe RL validation set, which contained corrupted samples\\nwith Gaussian noise. The performance on the RL validation\\nset and the robustness on the corrupted validation set were\\nused to compute the reward. We made an adversarial test\\nset by performing adversarial attacks on the RL test set. We\\nrecorded the performance on the RL test set and robustness\\non the adversarial test set and reported them in Figure 3. For\\nthe feature subset evaluation, we used the standard train-\\ning/test sets. We trained the model on the training set and\\nevaluated the model on the test set. Hyper-parameter tun-\\ning is directly done using the training set. Through out the\\nexperiment, the data that is used to train&evaluate the RL\\nagent and the data that used to evaluate the selected features\\nare hold exclusive.\\nTips and Tricks for Training the RL Agent We describe\\nthree tricks, which is associated with the reward functionR\\nand the reward shaping functionF, we used in the experi-\\nment and their application scenarios. (1) If the RL agent only\\nselects features to improve either performance or robust-\\nness while ignores the other one, assign different weights\\nto the terms in the reward functionRand the reward shap-\\ning functionF. More speciﬁcally, tune\\x15natand\\x15Gaussian\\nin\\x15nat\\x01^L0\\x001nat(gc) +\\x15Gaussian\\x01^L0\\x001\\n\\x0f\\x00Gaussian(gc). (2) If\\nthe ﬁrst trick does not work, try to add a clipping func-\\ntion to^L0\\x001nat(gcs)\\x00^L0\\x001nat(gcs0)or^L0\\x001\\n\\x0f\\x00Gaussian(gcs)\\x00\\n^L0\\x001\\n\\x0f\\x00Gaussian(gcs0)in the reward shaping functionFand\\nmake it saturate at large value. This trick is not recom-\\nmended because it may break Theorem 3.1. (3) If the RL\\nagent only selects features from one of the scoring metrics\\nand does not produce desirable selection results, the poten-\\ntial reason is that the ﬁrst few actions get large rewards while\\nthe following actions get small rewards because the accuracy\\nimproves slower when many features have been selected. A\\npossible ﬁx is to multiply the reward shaping functionF\\nwithlog(m)wheremis the number of features that have\\nbeen selected. This is also not recommended due to the same\\nreason as the second trick. However, try these tricks if the RL\\nagent consistently fails to produce a desirable result.\\nG Evaluating the Effectiveness of Robusta\\nFramework Under FGSM Attack\\nSimilar to the experiment with PGD attacks in section 5.4,\\nthe features selected by our framework is consistently more\\nrobust against FGSM attacks as Table 10 shows.\\nTable 8: Performance (accuracy on benign samples) of the ML Model using selected features\\n\\nDATA SET(\\x0f) STABLEMUTUALINFOLASSO CONCRETEROBUSTA\\n\\nSPAM(8=255)91.7\\x061.98%85.10%\\x062.35% 80.06%\\x060.87% 80.36%\\x061.85% 77.27%\\x060.55%\\nISOLET(1=10)91.7\\x061.65%59.50%\\x061.79% 76.65%\\x060.39% 81.54%\\x060.22% 81.99%\\x060.19%\\nMNIST (1=10) / 55.02%\\x060.47% 94.55%\\x060.02% 97.21%\\x060.08% 95.76%\\x060.11%\\nMNIST (2=10) / 54.65%\\x060.41% 94.54%\\x060.07% 97.24%\\x060.09% 95.71%\\x060.21%\\nMNIST (3=10) / 54.60%\\x060.80% 94.58%\\x060.18% 97.22%\\x060.07% 95.68%\\x060.19%\\nCIFAR (8=255) / 94.13%\\x060.12% 94.43%\\x060.08% 94.44%\\x060.02% 90.92%\\x060.09%\\n\\n*We bold the numbers if the best method outperforms all the others by 3%.\\nTable 9: Robustness (accuracy on adversarial examples) of the ML model using selected features under PGD attack\\n\\nDATA SET(\\x0f) STABLEMUTUALINFOLASSO CONCRETEROBUSTA\\n\\nSPAM(8=255) 18.10%\\x060.67% 14.03%\\x061.55% 55.36%\\x062.43% 49.73%\\x060.75%68.03%\\x061.53%\\nISOLET(1=10) 25.98%\\x061.03% 23.28%\\x061.38% 42.74%\\x060.55% 24.13%\\x060.59%48.02%\\x061.07%\\nMNIST (1=10) / 27.56%\\x060.46% 77.82%\\x060.12% 77.93%\\x061.35%83.19%\\x060.35%\\nMNIST (2=10) / 16.44%\\x060.40% 38.27%\\x061.77% 27.10%\\x061.24%44.87%\\x061.74%\\nMNIST (3=10) / 10.56%\\x061.40% 14.14%\\x060.46% 4.67%\\x060.91%18.11%\\x061.76%\\nCIFAR (8=255) / 1.86%\\x060.11% 7.25%\\x060.18% 14.29%\\x060.28%36.74%\\x060.46%\\n\\n*We bold the numbers if the best method outperforms all the others by 3%.\\nTable 10: Robustness of the ML Model using Selected Features under FGSM attack\\n\\nDATA SETMUTUALINFOLASSO CONCRETEROBUSTA\\n\\nSPAMBASE(\\x0f= 8=255) 14.11%\\x061.94% 57.00%\\x061.92% 51.13%\\x061.66%69.10%\\x061.04%\\nISOLET(\\x0f= 1=10) 23.49%\\x061.07% 42.50%\\x060.36% 26.12%\\x060.68%47.18%\\x061.32%\\nMNIST(\\x0f= 1=10) 30.48%\\x060.64% 78.66%\\x060.23% 78.69%\\x060.68%83.37%\\x060.41%\\nMNIST(\\x0f= 2=10) 20.57%\\x060.14% 45.36%\\x061.77% 38.14%\\x060.79%49.92%\\x061.05%\\nMNIST(\\x0f= 3=10) 14.50%\\x060.87% 25.26%\\x061.24% 18.45%\\x060.92%29.00%\\x062.12%\\nCIFAR(\\x0f= 8=255) 49.08%\\x060.11% 53.30%\\x060.20% 56.43%\\x060.05%63.20%\\x060.19%\\n\\n*We bold the numbers if the best method outperforms all the others by 3%.\\n\\n\\n ********************\\n\\n ********************REFERENCES\\n[1] J. Von Neumann and O. Morgenstern, “Theory of games and economic\\nbehavior, 1947.\\n[2] C. Stramer, “Developments in Non-Expected Utility Theory: The Hunt\\nfor a Descriptive Theory of Choice under Risk,” Journal of Economic\\nLiteraturepp. 332–382, 2000.\\n[3] S. Frederick, G. Loewenstein, and T. O’Donoghue, “Time Discounting\\nand time preference: a critical review”, Journal of Economic Literature,\\nvol. XL, pp. 351–401, 2002.\\n[4] A. Tversky and D. Kahneman, “Judgment under uncertainty : heuristics\\nand biases,”Science, vol. 185, no. 4157, pp. 1124–1131, 1974.\\n[5] D. Kahneman, J. L. Knetsch, and R. H. Thaler, “Anomalies: The\\nEndowment Effect, Loss Aversion, and Status Quo Bias,” Journal of\\nEconomic Perspectives, vol. 5, no. 1, pp. 193–206, 1991.\\n[6] U. Hoffrage, A. Weber, R. Hertwig, and V. M. Chase, “How to\\nKeep Children Safe in Trafﬁc: Find the Daredevils Early,” Journal of\\nExperimental Psychology: Applied, vol. 9, no. 4, pp. 249–260, 2003.\\n[7] T. J. Pleskac, “Decision making and learning while taking sequential\\nrisks,”Journal of Experimental Psychology: Learning , vol. 34, no. 1,\\npp. 167–185, 2008.\\n\\n2https://www.shefﬁeld.ac.uk/neuroeconomics [8] T. S. Wallsten, T. J. Pleskac, and C. W. Lejuez, “Modeling Behavior\\nin a Clinically Diagnostic Sequential Risk-Taking Task.” Psychological\\nReview,, vol. 112, no. 4, pp. 862–880, 2005.\\n[9] K. H. Britten, W. T. Newsome, M. N. Shadlen, S. Celebrini, and J. a.\\nMovshon, “A relationship between behavioral choice and the visual\\nresponses of neurons in macaque MT.” Visual neuroscience, vol. 13,\\nno. 1, pp. 87–100, 1996.\\n[10] K. H. Britten, M. N. Shadlen, W. T. Newsome, and J. a. Movshon, “The\\nanalysis of visual motion: a comparison of neuronal and psychophysical\\nperformance,”The Journal of neuroscience: the ofﬁcial journal of the\\nSociety for Neuroscience, vol. 12, no. 12, pp. 4745–4765, 1992.\\n[11] J. I. Gold and M. N. Shadlen, “Neural computations that underlie\\ndecisions about sensory stimuli,”Trends in Cognitive Sciences, vol. 5,\\nno. 1, pp. 10–16, 2001.\\n[12] ——, “Banburismus and the brain: Decoding the relationship between\\nsensory stimuli, decisions, and reward,” Neuron, vol. 36, no. 2, pp.\\n299–308, 2002.\\n[13] ——, “The neural basis of decision making.” Annual review of neuro-\\nscience, vol. 30, pp. 535–574, 2007.\\n[14] M. N. Shadlen, K. H. Britten, W. T. Newsome, and J. a. Movshon,\\n“A computational analysis of the relationship between neuronal and\\nbehavioral responses to visual motion,” J Neurosci, vol. 16, no. 4, pp.\\n1486–1510, 1996.\\n[15] M. N. Shadlen and W. T. Newsome, “Motion perception: seeing and\\ndeciding.”Proceedings of the National Academy of Sciences of the\\nUnited States of America, vol. 93, no. 2, pp. 628–633, 1996.\\n[16] A. G. Sanfey, G. Loewenstein, S. M. McClure, and J. D. Cohen,\\n“Neuroeconomics: cross-currents in research on decision-making.”\\nTrends in cognitive sciences, vol. 10, no. 3, pp. 108–16, Mar. 2006.\\n[Online]. Available: http://www.ncbi.nlm.nih.gov/pubmed/16469524\\n[17] P. W. Glimcher and A. Rustichini, “Neuroeconomics: the\\nconsilience of brain and decision.” Science (New York, N.Y.),\\nvol. 306, no. 5695, pp. 447–52, Oct. 2004. [Online]. Available:\\nhttp://www.ncbi.nlm.nih.gov/pubmed/15486291\\n[18] G. Loewenstein, S. Rick, and J. D. Cohen, “Neuroeconomics.” Annual\\nreview of psychology, vol. 59, pp. 647–72, Jan. 2008. [Online].\\nAvailable: http://www.ncbi.nlm.nih.gov/pubmed/17883335\\n[19] D. J. Barraclough, M. L. Conroy, and D. Lee, “Prefrontal cortex and\\ndecision making in a mixed-strategy game.” Nature neuroscience, vol. 7,\\nno. 4, pp. 404–410, 2004.\\n[20] A. Soltani, D. Lee, and X. J. Wang, “Neural mechanism for stochastic\\nbehaviour during a competitive game,” Neural Networks, vol. 19, no. 8,\\npp. 1075–1090, 2006.\\n[21] R. S. Sutton and A. G. Barto,Reinforcement Learning: An introduction ,\\nA Bradford Book, Ed. MIT Press, Cambridge, MA, 1998.\\n[22] K. Doya, “Reinforcement learning: Computational theory and biological\\nmechanisms,”HFSP Journal, vol. 1, no. 1, p. 30, 2007. [Online].\\nAvailable: http://link.aip.org/link/HJFOA5/v1/i1/p30/s1&Agg=doi\\n[23] G. Tesauro, “TD-Gammon, a Self-Teaching Backgammon Program,\\nAchieves Master-Level Play,”Neural Computation, vol. 6, no. 2, pp.\\n215–219, 1994.\\n[24] A. Abbeel, P, Coates, A, Morgan, Q, Ng, An Application of Re-\\ninforcement Learning to Aerobatic Helicopter Flight. Advances in\\nNeural Information Processing Systems 19: Proceedings of the 2006\\nConference, 1-9, 2006.\\n[25] R. Hafner and M. Riedmiller, “Neural reinforcement learning controllers\\nfor a real robot application,”Proceedings - IEEE International Confer-\\nence on Robotics and Automation, no. April, pp. 2098–2103, 2007.\\n[26] M. a. Walker, “An Application of Reinforcement Learning to Dialogue\\nStrategy Selection in a Spoken Dialogue System for Email,” Journal of\\nArtiﬁcial Intelligence Research, vol. 12, p. 387, 2000.\\n[27] V. Mnih, K. Kavukcuoglu, D. Silver, A. a. Rusu, J. Veness, M. G.\\nBellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski,\\nS. Petersen, C. Beattie, A. Sadik, I. Antonoglou, H. King, D. Kumaran,\\nD. Wierstra, S. Legg, and D. Hassabis, “Human-level control through\\ndeep reinforcement learning,”Nature, vol. 518, no. 7540, pp. 529–533,\\n2015. [Online]. Available: http://dx.doi.org/10.1038/nature14236\\n[28] P. Dayan and N. D. Daw, “Decision theory, reinforcement learning,\\nand the brain.”Cognitive, affective & behavioral neuroscience ,\\nvol. 8, no. 4, pp. 429–53, Dec. 2008. [Online]. Available:\\nhttp://www.ncbi.nlm.nih.gov/pubmed/19033240\\n[29] W. Schultz, P. Dayan, and P. R. Montague, “A neural substrate\\nof prediction and reward.”Science (New York, N.Y.), vol.\\n275, no. 5306, pp. 1593–9, Mar. 1997. [Online]. Available:\\nhttp://www.ncbi.nlm.nih.gov/pubmed/9054347\\n[30] K. Doya, “Complementary roles of basal ganglia and cerebellum in\\nlearning and motor control,”Current Opinion in Neurobiology, vol. 10,\\npp. 732–739, 2000.\\n[31] N. D. Daw and K. Doya, “The computational neurobiology of learning\\nand reward,”Current Opinion in Neurobiology, vol. 16, no. 2, pp. 199–\\n204, 2006.\\n[32] B. J. Kr¨ose, “Learning from delayed rewards,” pp. 233–235, 1995.\\n[33] P. Werbos, “A menu of designs for reinforcement learning over time. In\\nNeural Networks for Control, (eds), pp , MIT Press, Cambridge, Mass,”\\ninNeural Networks for Control, 1990, pp. 67–95.\\n[34] O. Hikosaka, K. Nakamura, and H. Nakahara, “Basal ganglia orient\\neyes to reward.”Journal of neurophysiology, vol. 95, no. 2, pp. 567–\\n584, 2006.\\n[35] A. Schultz, W, Romo, R, Ljungberg, T, Mirenowicz, J, Hollerman, JR,\\nand Dickson, “Reward-related signals carried by dopamine neurons,” in\\nModels of Information Processing in the Basal Ganglia , M. Cambridge,\\nEd., 1995, pp. 233–248.\\n[36] R. E. Suri and W. Schultz, “Learning of sequential movements by neural\\nnetwork model with dopamine-like reinforcement signal,” Experimental\\nBrain Research, vol. 121, no. 3, pp. 350–354, 1998.\\n[37] P. Waelti, a. Dickinson, and W. Schultz, “Dopamine responses comply\\nwith basic assumptions of formal learning theory.” Nature, vol. 412,\\nno. 6842, pp. 43–48, 2001.\\n[38] T. Satoh, S. Nakai, T. Sato, and M. Kimura, “Correlated coding of\\nmotivation and outcome of decision by dopamine neurons.” The Journal\\nof neuroscience : the ofﬁcial journal of the Society for Neuroscience ,\\nvol. 23, no. 30, pp. 9913–9923, 2003.\\n[39] H. Nakahara, H. Itoh, R. Kawagoe, Y. Takikawa, and O. Hikosaka,\\n“Dopamine Neurons Can Represent Context-Dependent Prediction Er-\\nror,”Neuron, vol. 41, no. 2, pp. 269–280, 2004.\\n[40] G. Morris, A. Nevet, D. Arkadir, E. Vaadia, and H. Bergman, “Mid-\\nbrain dopamine neurons encode decisions for future action.” Nature\\nneuroscience, vol. 9, no. 8, pp. 1057–1063, 2006.\\n[41] A. Barto, “Adaptive critics and the basal ganglia,” in Models of\\nInformation Processing in the Basal Ganglia , M. Cambridge, Ed., 1995,\\npp. 215–232.\\n[42] P. R. Montague, P. Dayan, and T. J. Sejnowski, “A framework for mes-\\nencephalic dopamine systems based on predictive Hebbian learning.”\\nThe Journal of neuroscience : the ofﬁcial journal of the Society for\\nNeuroscience, vol. 16, no. 5, pp. 1936–1947, 1996.\\n[43] K. Samejima, Y. Ueda, K. Doya, and M. Kimura, “Representation of\\naction-speciﬁc reward values in the striatum.” Science (New York, N.Y.),\\nvol. 310, no. 5752, pp. 1337–1340, 2005.\\n[44] R. Kawagoe, Y. Takikawa, and O. Hikosaka, “Expectation of reward\\nmodulates cognitive signals in the basal ganglia.” Nature neuroscience,\\nvol. 1, no. 5, pp. 411–416, 1998.\\n[45] ——, “Reward-predicting activity of dopamine and caudate neurons–a\\npossible mechanism of motivational control of saccadic eye movement.”\\nJournal of neurophysiology, vol. 91, no. 2, pp. 1013–1024, 2004.\\n[46] W. Schultz, “Getting formal with dopamine and reward,” Neuron,\\nvol. 36, no. 2, pp. 241–263, 2002.\\n[47] J. J. Day, M. F. Roitman, R. M. Wightman, and R. M. Carelli,\\n“Associative learning mediates dynamic shifts in dopamine signaling\\nin the nucleus accumbens.”Nature neuroscience, vol. 10, no. 8, pp.\\n1020–1028, 2007.\\n[48] R. M. Costa, “Plastic corticostriatal circuits for action learning: What’s\\ndopamine got to do with it?”Annals of the New York Academy of\\nSciences, vol. 1104, pp. 172–191, 2007. [49] S. E. Hyman, R. C. Malenka, and E. J. Nestler, “Neural mechanisms\\nof addiction: the role of reward-related learning and memory.” Annual\\nreview of neuroscience, vol. 29, pp. 565–598, 2006.\\n[50] D. Joel, Y. Niv, and E. Ruppin, “Actor-critic models of the basal ganglia:\\nnew anatomical and computational perspectives,” Neural Networks,\\nvol. 15, no. 4-6, pp. 535–547, 2002.\\n[51] J. R. Wickens, J. C. Horvitz, R. M. Costa, and S. Killcross, “Dopamin-\\nergic mechanisms in actions and habits.” The Journal of neuroscience\\n: the ofﬁcial journal of the Society for Neuroscience , vol. 27, no. 31,\\npp. 8181–8183, 2007.\\n[52] A. a. Stocker and E. P. Simoncelli, “Noise characteristics and prior\\nexpectations in human visual speed perception.” Nature neuroscience,\\nvol. 9, no. 4, pp. 578–585, 2006.\\n[53] K. K¨ording, “Decision theory: what ”should” the nervous system do?”\\nScience (New York, N.Y.), vol. 318, no. 5850, pp. 606–610, 2007.\\n[54] N. D. Daw, J. P. O’Doherty, P. Dayan, B. Seymour, and R. J. Dolan,\\n“Cortical substrates for exploratory decisions in humans.” Nature, vol.\\n441, no. 7095, pp. 876–879, 2006.\\n[55] G. Luksys, W. Gerstner, and C. Sandi, “Stress, genotype and\\nnorepinephrine in the prediction of mouse behavior using reinforcement\\nlearning.”Nature neuroscience, vol. 12, no. 9, pp. 1180–6, Sep. 2009.\\n[Online]. Available: http://www.ncbi.nlm.nih.gov/pubmed/19684590\\n[56] R. Frey and R. Hertwig, “Sell in May and Go Away ? Learning and Risk\\nTaking in Nonmonotonic Decision Problems,” Journal of Experimental\\nPsychology, vol. 41, no. 1, pp. 193–208, 2015. ter\\n[57] S. Benartzi and R. H. Thaler, “Heuristics and Biases in Retirement\\nSavings Behavior,”Journal of Economic Perspectives, vol. 21, no. 3,\\npp. 81–104, 2007.\\n[58] J. Choi and D. Laibson, “Reinforcement learning and savings\\nbehavior,”The Journal of Finance, vol. 64, no. 6, 2009.\\n[Online]. Available: http://onlinelibrary.wiley.com/doi/10.1111/j.1540-\\n6261.2009.01509.x/full\\n[59] T. Odean, “Are Investors Reluctant to Realize Their Losses ?” vol. LIII,\\nno. 5, pp. 1775–1798, 1998.\\n[60] X. Huang, “Industry Investment Experience and Stock Selection,”\\nAvailable at SSRN 1786271, no. November, 2012. [Online]. Available:\\nhttp://papers.ssrn.com/sol3/Delivery.cfm?abstractid=1786271\\n[61] Y. Chen, S. Mabu, K. Hirasawa, Jinglu. Hu, “Trading rules on stock\\nmarkets using genetic network programming with sarsa learning,”\\nProceedings of the 9th annual conference on Genetic and evolutionary\\ncomputation GECCO 07, vol. 12, no. 3, pp. 1503, 2007.\\n[62] J. W. Lee, “Stock price prediction using reinforcement learning,”\\nIndustrial Electronics. Proceedings. ISIE 2001. IEEE International\\nSymposium on, vol. 1, pp. 690-695, 2001\\n[63] J. O, J. Lee, J. W. Lee, B-T. Zhang, “Adaptive stock trading with\\ndynamic asset allocation using reinforcement learning,” Information\\nSciences, vol. 176, pp. 2121-2147, 2006\\n[64] J. Moody and M. Saffell, “Learning to trade via direct reinforcement,”\\nIEEE Transactions on Neural Networks , vol. 12, pp. 875-889, 2001\\n[65] A. V. Rutkauskas and T. Ramanauskas, “Building an artiﬁcial stock\\nmarket populated by reinforcementlearning agents,” Journal of Business\\nEconomics and Management, vol. 10, pp. 329-341, 2009\\n[66] S. Beninga,Financial Modeling, 2000.\\n[67] N. D. Daw, “Trial-by-trial data analysis using computational models,”\\nDecision Making, Affect, and Learning: Attention and Performance\\nXXIIIpp. 1–26, 2009.\\n[68] J. P. Huelsenbeck and K. a. Crandall, “Phylogeny Estimation and\\nHypothesis Testing Using Maximum Likelihood,” Annual Review of\\nEcology and Systematics, vol. 28, no. 1, pp. 437–466, 1997.\\n\\n\\n ********************\\n\\n ********************\\n\\n ********************References\\n1. Lopez-Rubio E, Palomo EJ, Dominguez E. Bregman diver-\\ngences for growing hierarchical self-organizing networks. Int J\\nNeural Syst. 2014;24(4):1450016.Cogn Comput (2015) 7:706–714711\\n123\\n2. Prigogine I. The end of certainty. New York: The Free Press;\\n1996.\\n3. De Castro LN. Fundamentals of natural computing: an over-\\nview. Phys Life Rev. 2007;4:1–36.\\n4. Kari L, Rozenberg G. Many facets of natural computing.\\nCommun ACM. 2008;51(10):72–83.\\n5. Arango C, Corte´s P, Onieva L, Escudero A. Simulation–opti-\\nmisation models for the dynamic berth allocation problem.\\nComput Aided Civil Infrastruct Eng. 2013;28(10):769–79.\\n6. Chow JYJ. Activity-based travel scenario analysis with routing\\nproblem reoptimization. Comput Aided Civil Infrastruct Eng.\\n2014;29(2):91–106.\\n7. Adeli H, Park HS. Neurocomputing for design automation. Boca\\nRaton: CRC Press; 1998.\\n8. Chen X, Zhang L, He X, Xiong C, Li Z. Surrogate-based opti-\\nmization of expensive-to-evaluate objective for optimal high-\\nway toll charging in a large-scale transportation network.\\nComput Aided Civil Infrastruct Eng. 2014;29(5):359–81.\\n9. Jia L, Wang Y, Fan L. Multiobjective bilevel optimization for\\nproduction-distribution planning problems using hybrid genetic\\nalgorithm. Integr Comput Aided Eng. 2014;21(1):77–90.\\n10. Faturechi R, Miller-Hooks E. A mathematical framework for\\nquantifying and optimizing protective actions for civil infras-\\ntructure systems. Comput Aided Civil Infrastruct Eng.\\n2014;29(8):572–89.\\n11. Aldwaik M, Adeli H. Advances in optimization of highrise\\nbuilding structures. Struct Multidiscip Optim.\\n2014;50(6):899–919.\\n12. Adeli H, Kamal O. Efﬁcient optimization of space trusses.\\nComput Struct. 1986;24(3):501–11.\\n13. Smith R, Ferrebee E, Ouyang Y, Roesler J. Optimal staging area\\nlocations and material recycling strategies for sustainable\\nhighway reconstruction. Comput Aided Civil Infrastruct Eng.\\n2014;29(8):559–71.\\n14. Peng F, Ouyang Y. Optimal clustering of railroad track main-\\ntenance jobs. Comput Aided Civil Infrastruct Eng.\\n2014;29(4):235–47.\\n15. Luo D, Ibrahim Z, Xu B, Ismail Z. Optimization the geometries\\nof biconical tapered ﬁber sensors for monitoring the early-age\\ncuring temperatures of concrete specimens. Comput Aided Civil\\nInfrastruct Eng. 2013;28(7):531–41.\\n16. Adeli H. Advances in design optimization. London: Chapman\\nand Hall; 1994.\\n17. Adeli H, Sarma K. Cost optimization of structures—fuzzy logic,\\ngenetic algorithms, and parallel computing. West Sussex:\\nWiley; 2006.\\n18. Gao H, Zhang X. A Markov-based road maintenance opti-\\nmization model considering user costs. Comput Aided Civil\\nInfrastruct Eng. 2013;28(6):451–64.\\n19. Zhang G, Wang Y. Optimizing coordinated ramp metering—a\\npreemptive hierarchical control approach. Comput Aided Civil\\nInfrastruct Eng. 2013;28(1):22–37.\\n20. Yang X-S. Engineering optimisation: an introduction with\\nmetaheuristic application. New York: Wiley; 2010.\\n21. Lin M-H, Tsai J-F, Yu C-S. A review of deterministic opti-\\nmization methods in engineering and management. Math Probl\\nEng Optim Theory Methods Appl Eng. edt, 2012; vol 2012,\\narticle ID 756023.\\n22. Glover F. Heuristics for integer programming using surrogate\\nconstraints. Decis Sci. 1977;8(1):156–66.\\n23. Glover F, Kochenberger GA. Handbook of metaheuristic. New\\nYork: Kluwer; 2003.\\n24. Fister I Jr, Yang X-S, Fister I, Brest J, Fister D. A brief review of\\nnature-inspired algorithms for optimisation. Elektroteh Vestn.\\n2013;80(3):1–7.25. Manjarres D, Landa-Torres I, Gil-Lopez S, Del Ser J, Bilbao\\nMN, Salcedo-Sanz S, Geem ZW. A survey on applications of\\nthe harmony search algorithm. Eng Appl Artif Intell.\\n2013;26(8):1818–31.\\n26. Kirkpatrick S, Gelatto CD, Vecchi MP. Optimization by simu-\\nlated annealing. Science. 1983;220:671–80.\\n27. Glover F. Tabu search—part I. ORSA J Comput.\\n1989;1(3):190–206.\\n28. Hejazi F, Toloue I, Noorzaei J, Jaafar MS. Optimization of\\nearthquake energy dissipation system by genetic algorithm.\\nComput Aided Civil Infrastruct Eng. 2013;28(10):796–810.\\n29. Kociecki M, Adeli H. Shape optimization of free-form steel\\nspace-frame roof structures with complex geometries using\\nevolutionary computing. Eng Appl Artif Intell. 2015;38:168–82.\\n30. Iacca G, Carafﬁni F, Neri F. Multi-strategy coevolving aging\\nparticle optimization. Int J Neural Syst. 2014;24(1):1450008.\\n31. Shafahi Y, Bagherian M. A customized particle swarm method\\nto solve highway alignment optimization problem. Comput\\nAided Civil Infrastruct Eng. 2013;28(1):52–67.\\n32. Szeto WY, Wang Y, Wong SC. The chemical reaction opti-\\nmization approach to solving the environmentally sustainable\\nnetwork design problem. Comput Aided Civil Infrastruct Eng.\\n2014;29(2):140–58.\\n33. Geem ZW, Kim JH, Loganathan GV. A new heuristic opti-\\nmization algorithm: harmony search. Simulation.\\n2001;76(2):60–8.\\n34. Siddique N, Adeli H. Harmony search algorithm and its variants.\\nInt J Pattern Recognit Artif Intell. 2015;29(8):1539001.\\n35. Siddique N, Adeli H. Hybrid harmony search algorithms. Int J\\nArtif Intell Tools. 2015;24(6):1–16.\\n36. Siddique N, Adeli H. Applications of harmony search algo-\\nrithms in engineering. Int J Artif Intell Tools. 2015;24(6):1–15.\\n37. Zara´nd G, Pa´zma´ndi F, Pa´l KF, Zima´nyi GT. Hysteretic opti-\\nmization. Phys Rev Lett. 2002;89(15):1502011–4.\\n38. Birbil I, Fang SC. An electro-magnetism-like mechanism for\\nglobal optimization. J Glob Optim. 2003;25:263–82.\\n39. Spears DF, Spears WM. Analysis of a phase transition in a\\nphysics-based multiagent system. Lect Notes Comput Sci.\\n2003;2699:193–207.\\n40. Formato RA. Central force optimization: a new metaheuristic\\nwith applications in applied electromagnetics. PIER.\\n2007;77(1):425–91.\\n41. Siddique N, Adeli H. Central force metaheuristic optimization.\\nSci Iran Trans A Civil Eng. 2015;22(6):2015.\\n42. Rashedi E, Nezamabadi-pour H, Saryazdi S. GSA: a gravita-\\ntional search algorithm. Inf Sci. 2009;179(13):2232–48.\\n43. Flores J, Lopez R, Barrera J. Gravitational interactions opti-\\nmization. Learning and intelligent optimization. Berlin:\\nSpringer; 2011. p. 226–37.\\n44. Kaveh A, Mahdavi VR. Colliding bodies optimization: a novel\\nmeta-heuristic method. Comput Struct. 2014;139:18–27.\\n45. Hsiao YT, Chuang CL, Jiang JA, Chien CC. A novel opti-\\nmization algorithm: space gravitational optimization. In: Pro-\\nceedings of 2005 IEEE international conference on systems,\\nman and cybernetics, Oct 2005, vol. 3, p. 2323–8.\\n46. Kenyon IR. General relativity. Oxford: Oxford University Press;\\n1990.\\n47. Erol OK, Eksin I. A new optimization method: big bang–big\\ncrunch. Adv Eng Softw. 2006;37(2):106–11.\\n48. Chuang C, Jiang J. Integrated radiation optimization: inspired by\\nthe gravitational radiation in the curvature of space–time. IEEE\\nCongr Evolut Comput (CEC). 2007;25–28:3157–64.\\n49. Hosseini HS. Principal component analysis by galaxy-based\\nsearch algorithm: a novel meta-heuristic for continuous opti-\\nmisation. Int J Comput Sci Eng. 2011;6(1–2):132–40.712Cogn Comput (2015) 7:706–714\\n123\\n50. Tamura K, Yasuda K. Spiral dynamics inspired optimisation.\\nJ Adv Comput Intell Intell Inform. 2011;15(8):1116–22.\\n51. Hatamlou A. Black hole: a new heuristic optimization approach\\nfor data clustering. Inf Sci. 2013;222:175–84.\\n52. Kaveh A, Khayatazad M. A new meta-heuristic method: ray\\noptimization. Comput Struct. 2012;112–113:283–94.\\n53. Shah-Hosseini H. Intelligent water drops algorithm—a new\\noptimisation method for solving the multiple knapsack problem.\\nInt J Intell Comput Cybern. 2008;1(2):193–212.\\n54. Rabanal P, Rodrı´guez I, Rubio F. Using river formation\\ndynamics to design heuristic algorithms. In: Unconventional\\ncomputation, UC’07, LNCS 4618, Springer, 2007, p. 163–77.\\n55. Eskandar H, Sadollah A, Bahreininejad A, Hamdi M. Water\\ncycle algorithm—a novel metaheuristic optimization method for\\nsolving constrained engineering optimization problems. Comput\\nStruct. 2012;110–111:151–66.\\n56. Fraser AS. Simulation of genetic systems by automatic digital\\ncomputers, I. Introduction. Aust J Biol Sci. 1957;10:484–91.\\n57. Box GEP. Evolutionary operation: a method for increasing\\nindustrial productivity. Appl Stat. 1957;6(2):81–101.\\n58. Friedberg RM. A learning machine: part I. IBM J Res Dev.\\n1958;2(1):2–13.\\n59. Fogel LJ. Autonomous automata. Ind Res. 1962;4:14–9.\\n60. Holland J. Outline for a logical theory of adaptive systems.\\nJ ACM. 1962;3:297–314.\\n61. Rechenberg I. Cybernetic solution path of an experimental\\nproblem, royal aircraft establishment. Library translation no.\\n1122, Farnborough, Hants, UK; 1965.\\n62. Schwefel H-P. Projekt MHD-Strausstrhlrohr: Experimentelle\\nOptimierung einer Zweiphasenduese, Teil I, Technischer Ber-\\nicht 11.034/68, 35, AEG Forschungsinstitute, Berlin, Germany;\\n1968.\\n63. De Jong KA. Evolutionary computation: a uniﬁed approach.\\nCambridge: The MIT Press; 2006.\\n64. Reyes O, Morell C, Ventura S. Evolutionary feature weighting\\nto improve the performance of multi-label lazy algorithms.\\nIntegr Comput Aided Eng. 2014;21(4):339–54.\\n65. Koza John R. Genetic programming: on the programming of\\ncomputers by means of natural selection. Cambridge: The MIT\\nPress; 1992.\\n66. Reynolds RG. An overview of cultural algorithms: advances in\\nevolutionary computation. New York: McGraw Hill Press;\\n1999.\\n67. Storn R, Price K. Differential evolution—a simple and efﬁcient\\nheuristic for global optimisation over continuous space. J Glob\\nOptim. 1997;11(4):431–59.\\n68. Molina-Garcı´a M, Calle-Sa´nchez J, Gonza´lez-Merino C, Fer-\\nna´ndez-Dura´n A, Alonso JI. Design of in-building wireless\\nnetworks deployments using evolutionary algorithms. Integr\\nComput Aided Eng. 2014;21(4):367–85.\\n69. Lin DY, Ku YH. Using genetic algorithms to optimize stopping\\npatterns for passenger rail transportation. Comput Aided Civil\\nInfrastruct Eng. 2014;29(4):264–78.\\n70. Adeli H, Kumar S. Distributed computer-aided engineering for\\nanalysis, design, and visualization. Boca Raton: CRC Press;\\n1999.\\n71. Badawy R, Yassine A, Heßler A, Hirsch B, Albayrak S. A novel\\nmulti-agent system utilizing quantum-inspired evolution for\\ndemand side management in the future smart grid. Integr\\nComput Aided Eng. 2013;20(2):127–41.\\n72. Campomanes-A´lvareza BR, Cordo´n O, Damasa S. Evolutionary\\nmulti-objective optimization for mesh simpliﬁcation of 3D open\\nmodels. Integr Comput Aided Eng. 2013;20(4):375–90.\\n73. Joly MM, Verstraete T, Paniagua G. Integrated multiﬁdelity,\\nmultidisciplinary evolutionary design optimization ofcounterrotating compressors. Integr Comput Aided Eng.\\n2014;21(3):249–61.\\n74. Kim H, Adeli H. Discrete cost optimization of composite ﬂoors\\nusing a ﬂoating point genetic algorithm. Eng Optim.\\n2001;33(4):485–501.\\n75. Kociecki M, Adeli H. Two-phase genetic algorithm for size\\noptimization of free-form steel space-frame roof structures.\\nJ Constr Steel Res. 2013;90:283–96.\\n76. Kociecki M, Adeli H. Two-phase genetic algorithm for topology\\noptimization of free-form steel space-frame roof structures with\\ncomplex curvatures. Eng Appl Artif Intell. 2014;32:218–27.\\n77. Siddique N, Adeli H. Computational intelligence: synergies of\\nfuzzy logic, neural networks and evolutionary computing.\\nChichester: Wiley; 2013.\\n78. Camazine S, Deneubourg J-L, Franks NR, Sneyd J, Theraulaz G,\\nBonabeau E. Self-organization in biological systems. New Jer-\\nsey: Princeton University Press; 2001.\\n79. Amini F, Khanmohamadi Hazaveh N, Abdolahi Rad A. Wavelet\\nPSO-based LQR algorithm for optimal structural control using\\nactive tuned mass dampers. Comput Aided Civil Infrastruct Eng.\\n2013;28(7):542–57.\\n80. Kennedy J, Eberhart R. Swarm intelligence. San Francisco:\\nMorgan Kaufmann Publishers Inc; 2001.\\n81. Wu JW, Tseng JCR, Tsai WN. A hybrid linear text segmentation\\nalgorithm using hierarchical agglomerative clustering and dis-\\ncrete particle swarm optimization. Integr Comput Aided Eng.\\n2014;21(1):35–46.\\n82. Zeng Z, Xu J, Wu S, Shen M. Antithetic method-based particle\\nswarm optimization for a queuing network problem with fuzzy\\ndata in concrete transportation systems. Comput Aided Civil\\nInfrastruct Eng. 2014;29(10):771–800.\\n83. Bergh FVD, Engelbrecht AP. A study of particle swarm opti-\\nmization particle trajectories. Inf Sci. 2006;176:937–71.\\n84. Jiang M, Luo YP, Yang SY. Stochastic convergence analysis\\nand parameter selection of the standard particle swarm opti-\\nmization algorithm. Inf Process Lett. 2007;102:8–16.\\n85. Tsai H, Lin Y. Modiﬁcation of the ﬁsh swarm algorithm with\\nparticle swarm optimization formulation and communication\\nbehavior. Appl Soft Comput. 2011;11:5367–74.\\n86. Montalvo I, Izquierdo J, Herrera M, Pe´rez-Garcı´a R. Water distri-\\nbution system computer-aided design by agent swarm optimization.\\nComput Aided Civil Infrastruct Eng. 2014;29(6):433–48.\\n87. Shaw E. The schooling of ﬁshes. Sci Am. 1962;206:128–38.\\n88. Shaw E. Fish in schools. Nat History. 1975;84(8):40–6.\\n89. Reynolds C. Flocks, herds, and schools: a distributed beha-\\nvioural model. Comput Graph. 1987;21(4):25–34.\\n90. Momen S, Amavasai BP, Siddique NH. Mixed species ﬂocking\\nfor heterogenous robotic swarms. In: The international confer-\\nence on computer as a tool (EUROCON 2007), Piscataway, NJ.\\nIEEE Press; 2007, p. 2329–36.\\n91. Turgut AE, C¸ elikkanat H, Go¨kc¸e F, Sahin E. Self-organized\\nﬂocking in mobile robot swarms. Swarm Intell. 2008;2:97–120.\\n92. Sun Q, Wu S. A conﬁgurable agent-based crowd model with\\ngeneric behaviour effect representation mechanism. Comput\\nAided Civil Infrastruct Eng. 2014;29(7):531–45.\\n93. Pinto T, Prac¸a I, Vale Z, Morais H, Sousa TM. Strategic bidding\\nin electricity markets: an agent-based simulator with game\\ntheory for scenario analysis. Integr Comput Aided Eng.\\n2013;20(4):335–46.\\n94. Parrish JK, Viscido SV, Grunbaum D. Self-organized ﬁsh\\nschools: an examination of emergent properties. Biol Bull.\\n2002;202:296–305.\\n95. Mackinson S. Variation in structure and distribution of pre-\\nspawning Paciﬁc herring shoals in two regions of British\\nColumbia. J Fish Biol. 1999;55:972–89.Cogn Comput (2015) 7:706–714713\\n123\\n96. MacArthur R, Wilson E. Theory of biogeography. Princeton:\\nPrinceton University Press; 1967.\\n97. Simon D. Biogeography-based optimization. IEEE Trans Evolut\\nComput. 2008;12(6):702–13.\\n98. Farmer JD, Packard N, Perelson A. The immune system,\\nadaptation and machine learning. Phys D. 1986;2:187–204.\\n99. Lindenmayer A. Mathematical models for cellular interactions\\nin development, parts I and II. J Theor Biol. 1968;18:280–315.\\n100. Aono M, Kunii TL. Botanical tree image generation. IEEE\\nComput Graph Appl. 1984;4(5):10–34.\\n101. Smith AR. Plants, fractals, and formal languages. In: Proceed-\\nings of SIG-GRAPH’84 in computer graphics, ACM SIG-\\nGRAPH, Minneapolis, Minnesota, July 22–27, 1984, p. 1–10.\\n102. Chen J, Wu T. A Computational intelligence optimization\\nalgorithm: cloud drops algorithm. Integr Comput Aided Eng.\\n2014;21(2):177–88.\\n103. Dorigo M, Birattari M, Stutzle T. Ant colony optimization.\\nIEEE Comput Intell Mag. 2006;1(4):28–39.\\n104. Forcael E, Gonza´lez V, Orozco F, Vargas S, Moscoso P, Pantoja\\nA. Ant colony optimization model for tsunamis evacuation\\nroutes. Comput Aided Civil Infrastruct Eng. 2014;29(10):\\n723–37.\\n105. Nakrani S, Tovey C. On honey bees and dynamic server allo-\\ncation in internet hosting centers. Adapt Behav. 2004;12:\\n223–40.\\n106. Pham DT, Ghanbarzadeh A, Koc E, Otri S, Rahim S, Zaidi M.\\nThe bees algorithm, technical note. Manufacturing Engineering\\nCentre, Cardiff University, UK; 2005.\\n107. Karaboga D. An idea based on honey bee swarm for numerical\\noptimisation, technical report TR06. Erciyes University, Turkey;\\n2005.\\n108. Yang XS. Engineering optimisation via nature-inspired virtual\\nbee algorithms, IWINAC 2005. Lect Notes Comput Sci.\\n2005;3562:317–23.\\n109. Yang X-S. A new metaheuristic bat-inspired algorithm. In: Cruz\\nC, Gonzalez J, Krasnogor N, Terraza G, editors. Nature inspired\\ncooperative strategies for optimization (NISCO 2010), studies in\\ncomputational intelligence, vol. 284. Berlin: Springer; 2010.\\np. 65–74.\\n110. Yang XS, Deb S. Engineering optimisation by cuckoo search.\\nInt J Math Modell Numer Optim. 2010;1(4):330–43.\\n111. Yang X-S. Fireﬂy algorithms for multimodal optimization. In:\\nStochastic algorithms: foundations and applications, SAGA\\n2009. Lect Notes Comput Sci. 2009;5792:169–78.\\n112. Passino KM. Biomimicry of bacterial foraging for distributed\\noptimization and control. IEEE Control Syst Mag.\\n2002;22(3):52–67.113. Adeli H, Park HS. A neural dynamics model for structural\\noptimization—theory. Comput Struct. 1995;57(3):383–90.\\n114. Adeli H, Park HS. Optimization of space structures by neural\\ndynamics. Neural Netw. 1995;8(5):769–81.\\n115. Adeli H, Karim A. Scheduling/cost optimization and neural\\ndynamics model for construction. J Constr Manag Eng ASCE.\\n1997;123(4):450–8.\\n116. Adeli H, Kim H. Cost optimization of composite ﬂoors using the\\nneural dynamics model. Commun Numer Methods Eng.\\n2001;17:771–87.\\n117. Huo J, Gao Y, Yang W, Yin H. Multi-instance dictionary\\nlearning for detecting abnormal event detection in surveillance\\nvideos. Int J Neural Syst. 2014;24(3):1430010.\\n118. Park HS, Adeli H. Distributed neural dynamics algorithms for\\noptimization of large steel structures. J Struct Eng ASCE.\\n1997;123:880–8.\\n119. Wang Z, Guo L, Adjouadi M. A generalized leaky integrate-\\nand-ﬁre neuron model with fast implementation method. Int J\\nNeural Syst. 2014;24(5):1440004.\\n120. Yang YB, Li YN, Gao Y, Yin HJ, Tang Y. Structurally\\nenhanced incremental neural learning for image classiﬁcation\\nwith subgraph extraction. Int J Neural Syst. 2014;24(7):\\n1450024.\\n121. Menendez H, Barrero DF, Camacho D. A genetic graph-based\\napproach to the partitional clustering. Int J Neural Syst.\\n2014;24(3):1430008.\\n122. Ahmadlou M, Adeli H. Fuzzy synchronization likelihood with\\napplication to attention-deﬁcit/hyperactivity disorder. Clin EEG\\nNeurosci. 2011;42(1):6–13.\\n123. Kodogiannis VS, Amina M, Petrounias I. A clustering-based\\nfuzzy-wavelet neural network model for short-term load fore-\\ncasting. Int J Neural Syst. 2013;23(5):1350024.\\n124. Boutalis Y, Christodoulou M, Theodoridis D. Indirect adaptive\\ncontrol of nonlinear systems based on bilinear neuro-fuzzy\\napproximation. Int J Neural Syst. 2013;23(5):1350022.\\n125. Forero Mendoza L, Vellasco M, Figueiredo K. Intelligent mul-\\ntiagent coordination based on reinforcement hierarchical neuro-\\nfuzzy models. Int J Neural Syst. 2014;24(8):1450031.\\n126. Adeli H, Hung SL. Machine learning—neural networks, genetic\\nalgorithms, and fuzzy sets. New York: Wiley; 1995.\\n127. Alexandridis A. Evolving RBF neural networks for adaptive\\nsoft-sensor design. Int J Neural Syst. 2013;23(6):1350029.\\n128. Cabessa J, Siegelmann HT. The super-turing computational\\npower of evolving recurrent neural networks. Int J Neural Syst.\\n2014;24(8):1450029.714Cogn Comput (2015) 7:706–714\\n123\\n\\n\\n ********************REFERENCES\\n\\n\\nhttps://www.kdnuggets.com/2020/01/5-most-useful-techniques-handle-imbalanced-datase\\n\\n\\n\\n1.\\nts.html\\nhttps://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.N\\n\\n\\n\\n2.\\nearMiss.html\\nhttps://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.Ran\\n\\n\\n\\n3.\\ndomOverSampler.html\\nhttps://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SM\\n\\n\\n\\n4.\\nOTE.html\\nhttps://www.quora.com/What-is-an-imbalanced-dataset\\n\\n\\n\\n5.\\nhttps://www.quora.com/When-I-can-say-a-dataset-is-unbalanced\\n\\n\\n\\n6.\\nhttps://www.kaggle.com/dskagglemt/handling-imbalance-class\\n\\n\\n\\n7.\\nhttps://www.analyticsvidhya.com/blog/2017/03/imbalanced-data-classification/\\n\\n\\n\\n8.\\nhttps://www.kaggle.com/dskagglemt/handling-imbalance-class\\n\\n\\n\\n9.\\nData Science Foundation\\nData Science Foundation, Atlantic Business Centre, Atlantic Street, Altrincham, WA14 5NQ\\nTel: 0161 926 3641   Email: admin@datascience.foundation  Web: www.datascience.foundation\\nRegistered in England and Wales 4th June 2015, Registered Number 9624670About the Data Science Foundation\\n\\n\\nThe Data Science Foundation is a professional body representing the interests of the Data\\nScience Industry. Its membership consists of suppliers who offer a range of big data analytical\\nand technical services and companies and individuals with an interest in the commercial\\nadvantages that can be gained from big data. The organisation aims to raise the profile of this\\ndeveloping industry, to educate people about the benefits of knowledge based decision making\\nand to encourage firms to start using big data techniques.\\n\\n\\nContact Data Science Foundation\\n\\n\\nEmail:admin@datascience.foundation\\nTelephone: 0161 926 3641\\nAtlantic Business Centre\\nAtlantic Street\\nAltrincham\\nWA14 5NQ\\nweb: www.datascience.foundation\\n\\n\\n ********************References \\n\\n[1]\\n \\nAllen, F., Karjalainen, R., 1999. Using genetic algorithms to find technical trading rules. J. \\nFinanc. Econ. 51, 245-271. \\n[2]\\n \\nBekiros,  S.D.,  2010.  Fuzzy  adaptive  decision-making  for boundedly  rational  traders in \\nspeculative stock markets. Eur. J. Oper. Res. 202(1), 285\\n –\\n293. \\n[3]\\n \\nBoyacioglu, M.A.,  Avci,  D.,  2010.  An  adaptive  network-based  fuzzy  inference  system \\n(ANFIS)  for  the  prediction  of  stock  market  return:  the  case  of  the  Istanbul  stock \\nexchange. Expert Syst. Appl. 37, 7908 -7912. \\n[4]\\n \\nChavarnakul, T., Enke, D., 2009. A hybrid stock trading system for intelligent technical \\nanalysis-based equivolume charting. Neurocomputing. 72, 3517 -3528. \\n[5]\\n \\nChen, Y.-S., Cheng, C.-H., Chiu, C.-L., Huang, S.-T., 2016. A study of ANFIS -based multi-\\nfactor time series models for forecasting stock index. Appl. Intell. DOI 10.1007/s10489 -\\n016-0760-8. \\n[6]\\n \\nChen, Y., Mabu, S., Shimada, K., Hirasawa, K., 2009. A genetic network programming \\nwith learning approach for enhanced stock trading model. Expert Syst. Appl. 36, 12537 -\\n12546. \\n[7]\\n \\nChiang, W.C., Enke, D., Wu, T., Wang, R., 2016. An adaptive stock index trading decision \\nsupport system. Expert Syst. Appl. 59, 195 -207. \\n[8]\\n \\nDempster, M.A.H. , Jones, C. M., 2001. A real-time adaptive trading system using genetic \\nprogramming. Quant. Financ. 1, 397 -413. \\n[9]\\n \\nEsfahanipour,  A.,  Mousavi,  S.,  2011.  A  genetic  programming  model  to  generate  risk-\\nadjusted technical trading rules in stock markets. Expert Syst. Appl. 38, 8438 -8445. \\n[10]\\n \\nHsu, Y., Chen, A., Chang, J., 2011. An inter-market arbitrage trading system based on \\nextended classifier systems. Expert Syst. Appl.  38(4), 3784-3792. \\n[11]\\n \\nHu,  J.,  Pedrycz,  W.,  Wang,  G.,  Wang,  K.,  2016.  Rough  sets  in  distributed  decision \\ninformation systems. Knowl. Based Syst. 94, 13-22. \\n \\n\\n  33 \\n[12]\\n \\nHu, Y., Feng, B., Zhang, X., Ngai, E.W.T., Ngai, M., 2015a. Stock trading rule discovery \\nwith an evolutionary trend following model. Expert Syst. Appl. 42, 212 -222. \\n[13]\\n \\nHu, Y., Liu, K., Zhang, X., Su, L.,  Ngai,  E.W.T.,  Liu,  M.,  2015b.  Application  of \\nevolutionary  computation  for  rule  discovery  in  stock  algorithmic  trading:  A  literature \\nreview. Appl. Soft Comput. 36, 534 -551.  \\n[14]\\n \\nJanusz,  A., \\nŚlęzak,  D.,  2012.  Utilization  of  attribute  clustering  methods  for  scalable \\n\\ncomputation of reducts from high-dimensional data. Proc. Federated Conf. Comput. Sci. \\nInf. Syst. 295-302.  \\n[15]\\n \\nJia, X., Shang, L., Zhou,  B., Yao, Y., 2016. Generalized attribute reduct  in rough set \\ntheory. Knowl. Based Syst. 91, 204 -218. \\n[16]\\n \\nJing, Y., Li, T., Luo, C., Horng, S.-J., Wang, G., Yu, Z., 2016. An incremental approach \\nfor attribute reduction based on knowledge granularity. Knowl. Based Syst. 104, 24 -38. \\n[17]\\n \\nKim,  K.-j.,  Ahn,  H.,  2012.  Simultaneous  optimization  of  artificial  neural  networks  for \\nfinancial forecasting. Appl. Intell. 36, 88 7-898. \\n[18]\\n \\nKim, K., Han, I., 2000. Genetic algorithms approach to feature discretization in artificial \\nneural networks for the prediction of stock price index. Expert Syst. Appl. 19(2), 125-\\n132. \\n[19]\\n \\nKim,  Y.,  Enke,  D.,  2016.  Developing  a  rule  change  trading  system for  the  futures \\nmarket using rough set analysis. Expert Syst. Appl. 59, 165 -173. \\n[20]\\n \\nKotsiantis, S.,  Kanellopoulos,  D.,  2006.  Discretization  techniques:  A  recent  survey. \\nGESTS Int. Trans. Comput. Sci. Eng. 32(1), 47 -58. \\n[21]\\n \\nLai R.K., Fan C., Huang W., Chang P., 20 09. Evolving and clustering fuzzy decision tree \\nfor financial time series data forecasting. Expert Syst. Appl. 36, 3761 -3773. \\n[22]\\n \\nLee, S. J., Ahn, J. J., Oh, K. J., Kim, T. Y., 2010. Using rough set to support investment \\nstrategies of real-time trading in futures market. Appl. Intell. 32, 364 -77. \\n \\n\\n  34 \\n[23]\\n \\nLee,  S.  J., Oh,  K.  J.,  Kim,  T.  Y.,  2012.  How  many  reference  patterns  can  improve \\nprofitability for real-time trading in futures market?. Expert Syst. Appl. 39, 7458 -7470. \\n[24]\\n \\nLuo, C., Li, T., Yi, Z., Fujita, H., 2016. Matrix approach to decision-theoretic rough sets \\nfor evolving data. Knowl. Based Syst. 99, 123 -134. \\n[25]\\n \\nMabu, S., Hirasawa, K., Obayashi, M., Kuremoto, T., 2013. Enhanced decision making \\nmechanism  of  rule-based  genetic  network  programming  for  creating  stock  trading \\nsignals. Expert Syst. Appl. 40, 6311 -6320. \\n[26]\\n \\nMehdiyev, N., Enke, D., 2014. Interest rate prediction: A neuro-hybrid approach with \\ndata preprocessing. Int. J. Gen. Sys. 43(5), 535 -550. \\n[27]\\n \\nMenkhoff,  L.,  2010.  The  use  of  technical  analysis  by  fund  managers:  International \\nevidence. J. Bank. Financ. 34(11), 2573 -2586. \\n[28]\\n \\nMoshkov  M.J.,  Piliszczuk  M.,  Zielosko  B.,  2008.  Partial  covers,  reducts  and  decision \\nrules in rough sets \\n–\\n Theory and applications. Studies Comput. Intell. 145, Springer.  \\n[29]\\n \\nMousavi, S., Esfahanipour,  A., Zarandi, M. H. F., 2014. A novel approach to dynamic \\nportfolio trading system using multitree generic programming. Knowl. Based Syst. 66, \\n68-81. \\n[30]\\n \\nNguyen H.S., Skowron A., 1995. Quantization of real values attributes, rough set and \\nBoolean reasoning approach. Proc. 2nd Joint Annual Conf. Inf. Sci., Wrightsville Beach, \\nNC, 1995, 34-37. \\n[31]\\n \\nOh, K. J., Kim, T. Y., Min, S. \\n –\\nH., Lee, H. Y., 2006. Portfolio algorithm based on portfolio \\nbeta using generic algorithm. Expert Syst. Appl. 30, 527 -534. \\n[32]\\n \\nOzturk, M., Toroslu, I.  H., Fidan, G., 2016.  Heuristic  based  trading  system  on  Forex \\ndata using technical indicator rules. Appl. Soft Comput. 43, 170 -186. \\n[33]\\n \\nPardo, R., 2008. The evaluation and optimization of trading strategies . Wiley. \\n[34]\\n \\nPawlak, Z., 1982. Rough sets. Int. J.  Comput. Inf. Sci. 11, 341 -356. \\n \\n\\n  35 \\n[35]\\n \\nPawlak,  Z.,  1997.  Rough  set  approach  to  knowledge-based  decision  support.  Eur.  J. \\nOper. Res. 99(1) , 48-57. \\n[36]\\n \\nPawlak, Z., 2002. Rough sets and intelligent data analysis. Inf. Sci. 147, 1 -12. \\n[37]\\n \\nPawlak,  Z., Grzymala-Busse,  J.,  Sloinski,  R.,  Ziarko,  W.,  1997.  Rough  set.  Commun. \\nACM. 38(11), 88-95. \\n[38]\\n \\nPring,  M.,  1991.  Technical  analysis  explained:  the  successful  investor’s  guide  to \\n\\nspotting investment trends and turning points. McGraw -Hill. \\n[39]\\n \\nRamírez-Gallego,  S.,  García,  S.,  Benítez,  J.  M., Herrera,  F.,  2016.  Multivariate \\ndiscretization based on evolutionary cut points selection for classification. IEEE Trans. \\nCyb. 46, 595-608. \\n[40]\\n \\nSharpe, W.F. , 1994. The Sharpe ratio. J. Portfolio Manage. 21, 49-58. \\n[41]\\n \\nShen,  L., Loh,  H.  T.,  2004.  Applying  rough  sets  to  market  timing  decisions.  Decis. \\nSupport Syst. 37, 583-597. \\n[42]\\n \\nWang,  F., Yu,  P.  L.H.,  Cheung,  D.  W.,  2014.  Combining  technical  trading  rules  using \\nparticle swarm optimization. Expert Syst. Appl. 41, 3016 -3026. \\n[43]\\n \\nWiles,  P.S.,  Enke,  D.,  2015.  A  hybrid  neuro-fuzzy  model  to  forecast  the  soybean \\ncomplex.  Proceedings  of  the  2015  American  Society  of  Engineering  Management \\nconference, Indianapolis, IN, October.  \\n[44]\\n \\nWiles,  P.S.,  Enke,  D.,  2015.  Optimizing  MACD  parameters  via  genetic  algorithms  for \\nsoybean futures. Procedia Comput. Sci. 61, 85-91. \\n[45]\\n \\nYao, J., Herbert, J.P., 2009. Financial time-series analysis with rough sets. Appl. Soft \\nComput. 9, 1000-1007. \\n[46]\\n \\nZhang,  X.,  Y.  Hu,  K.  Xie,  W.  Zhang,  L.  Su,  Liu,  M.,  2015. An  evolutionary  trend \\nreversion model for stock trading rul e discovery. Knowl. Based Syst. 79, 27 -35. \\n[47]\\n \\nZhong,  N.,  Dong,  J.,  2001.  Using  rough  sets  with  heuristics  for  feature  selection.  J. \\nIntell. Inf. Syst. 16, 199 -214. \\n \\n\\n  36 \\nFigures and Tables: \\n\\n \\n  \\nFig. 1. The framework of an intelligent hybrid trading system for discovering trading  rules. \\n \\n  \\n Data transformation\\n\\nExtract decision rules\\n[Rough set analysis]\\nGenerate trading \\nsignals\\n(Buy or Sell)\\n\\nOptimal trading \\n\\nrulesDiscovery trading rules\\n[Genetic algorithm]Phase 1: \\nData transformation for generating the decision  table\\nPhase 2:\\nA rule discovery mechanism The testing \\ndata\\nPhase 3:\\nTrading signal generationThe training \\ndata\\nTrading simulation\\n\\nTrading \\n\\nsimulation\\n \\n\\n  37   \\n\\n \\n\\nFig. 2. Chromosome structure of the GA. \\n\\n  \\nthe number \\n\\nof cut points\\nreducts\\n\\n\\n\\n\\n\\n\\n…\\nZ-score(*,2.13) AND RMI(*,20) AND  MACD(-3.33,*) \\n\\uf0e8\\n1 (up)\\n\\nZ-score(*,2.13) AND RMI(45.6,*) AND  MACD(-3.33,*) \\n\\uf0e8\\n-1 (down)\\nS-ROC(67.44,*) AND EOM(-1.76,3.31) AND MFI(-0.27,-0.09) \\n\\uf0e8\\n1 (down)\\n\\nS-ROC(67.44,*) AND EOM(-1.76,3.31) AND MFI(-0.09,0.07) \\n\\uf0e8\\n-1 (down)\\n\\nS-ROC(67.44,*) AND EOM(-1.76,3.31) AND MFI(0.07,*) \\n\\uf0e8\\n-1 (down)\\n 1 1 2{ , }DR dr dr\\uf03d\\n…\\n\\nChromosome structure cut points\\n\\n…\\n 2 1 2 3{ , , }DR dr dr dr\\uf03d\\n \\n\\n  38   \\n\\n \\n\\nFig. 3. Cumulative return for the rule discovery mechanism with the random approach.  \\n\\n  \\n-50.00%\\n-40.00%\\n-30.00%\\n-20.00%\\n-10.00%\\n0.00%\\n10.00%\\n20.00%\\n30.00%\\n40.00%\\n50.00%\\n J=30\\nJ=60\\nBuy & Hold\\n \\n\\n  39 \\n \\n \\n\\n \\nFig. 4. Cumulative return for the rule discovery  mechanism with EFB. \\n\\n \\n \\n-60.00%\\n-40.00%\\n-20.00%\\n0.00%\\n20.00%\\n40.00%\\n60.00%\\n80.00%\\n J=15\\nJ=30\\nJ=60\\nBuy & Hold\\n \\n\\n  40 \\n  \\n \\nFig. 5. Cumulative return for the rule discovery mechanism with DMGA . \\n-60.00%\\n-40.00%\\n-20.00%\\n0.00%\\n20.00%\\n40.00%\\n60.00%\\n80.00%\\n J=15\\nJ=30\\nJ=60\\nBuy & Hold\\n \\n\\n  41    \\n\\nFig.  6. Cumulative  return  for  the  rule  discovery  mechanism  using  a  6  month  training \\nperiod \\n  \\n-60.00%\\n-40.00%\\n-20.00%\\n0.00%\\n20.00%\\n40.00%\\n60.00%\\n80.00%\\n100.00%\\n J=25\\nJ=50\\nBuy & Hold\\nConventional approach\\n \\n\\n  42 \\nTable 1 \\n\\nTrading performance of the random approach.\\n  \\n\\nModel\\n \\nMeasure\\n \\nReturn rate (%) by t\\nhe \\nnumber of sets of decision rules (=\\n J\\n)\\n \\n\\n1\\n \\n6\\n \\n15\\n \\n30\\n \\n60\\n \\n120\\n \\n\\nMaximize \\n\\nSharpe \\n\\nratio\\n \\n \\nA\\nnnualized \\n \\n\\nreturn\\n \\n(%)\\n \\n1.55\\n \\n2.29\\n \\n4.45\\n \\n5.66\\n \\n5.51\\n \\n3.53\\n \\n\\nS\\ntandard \\n \\n\\ndeviation\\n \\n10.27\\n \\n6.68\\n \\n12.85\\n \\n11.08\\n \\n11.1\\n \\n7.71\\n \\n\\nMaximum \\n\\ndrawdown (%)\\n \\n-\\n41.07\\n \\n-\\n32.64\\n \\n-\\n40.13\\n \\n-\\n28.99\\n \\n-\\n22.86\\n \\n-\\n28.29\\n \\n\\nSharpe ratio\\n \\n0.15\\n \\n0.34\\n \\n0.35\\n \\n0.51\\n \\n0.5\\n \\n0.46\\n \\n\\nMaximize \\n\\np\\nrofit\\n \\nA\\nnnualized \\n \\n\\nreturn\\n \\n(%)\\n \\n3.19\\n \\n3.43\\n \\n-\\n0.45\\n \\n4.04\\n \\n3.62\\n \\n1.8\\n \\n\\nS\\ntandard \\n \\n\\ndeviation\\n \\n10.39\\n \\n22.75\\n \\n12.89\\n \\n14.75\\n \\n10.67\\n \\n13.22\\n \\n\\nMaximum \\n\\ndrawdown (%)\\n \\n-\\n29.97\\n \\n-\\n74.31\\n \\n-\\n40.78\\n \\n-\\n41.9\\n \\n-\\n38.02\\n \\n-\\n50.53\\n \\n\\nSharpe ratio\\n \\n0.31\\n \\n0.15\\n \\n-\\n0.04\\n \\n0.27\\n \\n0.34\\n \\n0.14\\n \\n\\nMaximize\\n \\n\\nSharpe \\n\\nratio\\n \\n \\n\\nand \\n\\nvalidation \\n\\ndataset\\n \\nA\\nnnualized \\n \\n\\nreturn\\n \\n(%)\\n \\n3.87\\n \\n3.09\\n \\n3.74\\n \\n4.34\\n \\n3.44\\n \\n2.41\\n \\n\\nS\\ntandard \\n \\n\\ndeviation\\n \\n17.02\\n \\n14.77\\n \\n10.65\\n \\n14.63\\n \\n17.45\\n \\n15.32\\n \\n\\nMaximum \\n\\ndrawdown (%)\\n \\n-\\n28.76\\n \\n-\\n41.24\\n \\n-\\n29.76\\n \\n-\\n35.83\\n \\n-\\n21.79\\n \\n-\\n36.87\\n \\n\\nSharpe ratio\\n \\n0.23\\n \\n0.21\\n \\n0.35\\n \\n0.3\\n \\n0.2\\n \\n0.16\\n \\n\\nMaximize \\n\\nProfit \\n \\n\\nand \\n\\nvalidation \\n\\ndataset\\n \\nA\\nnnualized \\n \\n\\nreturn\\n \\n(%)\\n \\n1.26\\n \\n-\\n4.85\\n \\n1.85\\n \\n-\\n2.46\\n \\n2.41\\n \\n0.11\\n \\n\\nS\\ntandard \\n \\n\\ndeviation\\n \\n14.98\\n \\n11.69\\n \\n13.17\\n \\n13.1\\n \\n13.48\\n \\n18.64\\n \\n\\nMaximum \\n\\ndrawdown (%)\\n \\n-\\n42.22\\n \\n-\\n74.66\\n \\n-\\n40.43\\n \\n-\\n43.8\\n \\n-\\n45.74\\n \\n-\\n41.28\\n \\n\\nSharpe ratio\\n \\n0.08\\n \\n-\\n0.42\\n \\n0.14\\n \\n-\\n0.19\\n \\n0.18\\n \\n0.01\\n \\n\\n \\n\\n   \\n \\n\\n  43 \\nTable 2 \\n\\nTrading performance of the rule discovery mechanism with EFB.\\n  \\n\\nYear\\n \\nReturn rate (%) by t\\nhe \\nnumber of sets of decision rules (=\\n J\\n)\\n \\n\\n1\\n \\n6\\n \\n15\\n \\n30\\n \\n60\\n \\n120\\n \\n\\n2008\\n \\n8.99\\n \\n14.86\\n \\n30.63\\n \\n20.88\\n \\n25.20\\n \\n-\\n26.09\\n \\n\\n2009\\n \\n15.61\\n \\n18.00\\n \\n15.04\\n \\n10.59\\n \\n19.04\\n \\n22.32\\n \\n\\n2010\\n \\n12.53\\n \\n0.62\\n \\n21.20\\n \\n15.64\\n \\n15.30\\n \\n29.44\\n \\n\\n2011\\n \\n-\\n25.48\\n \\n-\\n36.98\\n \\n-\\n33.49\\n \\n-\\n33.83\\n \\n-\\n34.68\\n \\n7.73\\n \\n\\n2012\\n \\n-\\n3.98\\n \\n8.54\\n \\n10.46\\n \\n9.29\\n \\n10.99\\n \\n5.58\\n \\n\\n2013\\n \\n12.25\\n \\n0.36\\n \\n-\\n2.92\\n \\n-\\n1.60\\n \\n5.99\\n \\n-\\n1.83\\n \\n\\n2014\\n \\n-\\n3.88\\n \\n-\\n0.51\\n \\n-\\n7.73\\n \\n-\\n7.03\\n \\n-\\n1.28\\n \\n-\\n3.90\\n \\n\\nA\\nnnualized \\n \\n\\nreturn\\n \\n(%)\\n \\n2.29\\n \\n0.70\\n \\n4.74\\n \\n1.99\\n \\n5.79\\n \\n4.75\\n \\n\\nS\\ntandard \\n \\n\\ndeviation\\n \\n13.49\\n \\n16.83\\n \\n19.84\\n \\n17.10\\n \\n18.35\\n \\n16.89\\n \\n\\nMaximum \\n\\ndrawdown (%)\\n \\n53.85\\n \\n54.11\\n \\n46.18\\n \\n53.19\\n \\n53.87\\n \\n36.57\\n \\n\\nSharpe ratio\\n \\n0.17\\n \\n0.04\\n \\n0.24\\n \\n0.12\\n \\n0.32\\n \\n0.28\\n \\n \\n  \\n \\n\\n  44 \\nTable 3 \\n\\nTrading performance of the rule discovery mechanism with DMGA.  \\nYear Return rate (%) by the number of sets of decision rules (=\\n J) \\n1 6 15 30 60 120 \\n2008 -10.33 2.83 8.33 -12.99 -21.04 16.94 \\n2009 -13.85 -18.27 -16.89 -4.11 8.12 23.20 \\n2010 7.52 29.12 29.99 38.07 44.12 1.83 \\n2011 -2.11 4.73 6.84 10.46 -6.31 -25.69 \\n2012 -4.88 -2.77 3.73 0.94 23.37 9.76 \\n2013 35.08 19.83 19.96 16.40 -12.99 21.52 \\n2014 -0.58 -1.73 -7.69 -0.68 8.07 -2.41 \\nAnnualized  \\nreturn (%) 1.55 4.82 6.32 6.87 6.19 6.45 \\nStandard  \\ndeviation 15.11 14.41 14.60 15.51 20.72 15.86 \\nMaximum \\ndrawdown (%) 30.36 26.91 20.32 23.84 36.61 44.78 \\nSharpe ratio 0.10 0.33 0.43 0.44 0.30 0.41 \\n \\n\\n \\n  \\n \\n\\n  45 \\n \\nTable 4 \\n\\nSliding window scheme and the experimental dataset.  \\nTraining dataset  Testing dataset  Total number of \\ntesting windows Start date Window size Start / End date Window size \\nOct. 1, 2007 3 months \\nJan.1, 2008 / \\nDec. 31, 2014 1 month 84 Jul. 1, 2007 6 months \\nApr. 1, 2007  9 months \\nJan. 1, 2007 12 months \\n \\n\\n  46 \\nTable 5 \\n\\nTrading performance of the rule discovery mechanism  using a 3 month training period. \\nYear Return rate (%) by the number of sets of decision rules (=\\n J) \\n1 10 25 50 100 200 \\n2008 -9.53 9.42 10.91 9.56 11.18 10.47 \\n2009 22.62 13.16 15.53 18.30 4.07 1.53 \\n2010 6.20 4.60 -9.37 -8.86 7.95 8.46 \\n2011 -4.35 -5.37 -2.32 2.64 -5.24 -14.55 \\n2012 2.34 13.68 25.01 12.93 -1.94 -0.58 \\n2013 6.94 -10.37 -7.18 -8.41 -3.77 10.27 \\n2014 12.31 10.99 11.52 12.55 13.51 8.95 \\nAnnualized  \\nreturn (%) 5.22 5.16 6.30 5.53 3.68 3.51 \\nStandard  \\ndeviation 9.82 8.79 11.86 9.95 6.95 8.41 \\nMaximum \\ndrawdown (%) 30.57 30.12 28.20 16.83 23.54 27.50 \\nSharpe ratio 0.53 0.59 0.53 0.56 0.53 0.42 \\n\\n \\n  \\n \\n\\n  47 \\nTable 6 \\n\\nTrading performance of the rule discovery mechanism  using a 6 month training period. \\nYear Return rate (%) by the number of sets of decision rules (=\\n J) \\n1 10 25 50 100 200 \\n2008 26.83 6.98 12.85 6.83 4.21 -2.88 \\n2009 -21.64 9.69 -7.11 1.87 13.51 5.54 \\n2010 -1.38 8.97 3.71 4.47 0.11 5.18 \\n2011 -2.22 -17.38 9.03 6.69 18.90 8.18 \\n2012 3.96 21.17 25.48 25.37 10.14 9.56 \\n2013 -16.45 4.26 23.52 19.79 2.83 11.14 \\n2014 23.18 12.10 4.84 9.07 -5.20 -4.88 \\nAnnualized  \\nreturn (%) 1.75 6.54 10.33 10.59 6.36 4.55 \\nStandard  \\ndeviation 16.89 10.95 10.62 8.00 7.67 5.70 \\nMaximum \\ndrawdown (%) 47.80 34.85 24.60 15.81 24.19 28.10 \\nSharpe ratio 0.10  0.60  0.97  1.32  0.83  0.80  \\n\\n \\n\\n  \\n \\n\\n  48 \\nTable 7 \\n\\nTrading performance of the rule discovery mechanism  using a 9 month training period.\\n \\n\\nYear\\n \\nReturn rate (%) by t\\nhe \\nnumber of sets of decision rules (=\\n J\\n)\\n \\n\\n1\\n \\n10\\n \\n25\\n \\n50\\n \\n100\\n \\n200\\n \\n\\n2008\\n \\n-\\n12.67\\n \\n-\\n2.15\\n \\n-\\n18.21\\n \\n-\\n27.46\\n \\n23.19\\n \\n5.01\\n \\n\\n2009\\n \\n-\\n5.94\\n \\n0.26\\n \\n-\\n6.14\\n \\n1.36\\n \\n-\\n11.69\\n \\n-\\n8.78\\n \\n\\n2010\\n \\n-\\n12.38\\n \\n0.28\\n \\n5.73\\n \\n-\\n2.02\\n \\n7.26\\n \\n14.85\\n \\n\\n2011\\n \\n33.06\\n \\n18.49\\n \\n28.31\\n \\n25.65\\n \\n0.00\\n \\n6.09\\n \\n\\n2012\\n \\n1.09\\n \\n-\\n7.09\\n \\n30.61\\n \\n29.44\\n \\n31.51\\n \\n16.57\\n \\n\\n2013\\n \\n21.17\\n \\n21.32\\n \\n9.76\\n \\n23.07\\n \\n14.81\\n \\n13.21\\n \\n\\n2014\\n \\n9.88\\n \\n6.75\\n \\n1.98\\n \\n-\\n1.83\\n \\n1.13\\n \\n-\\n3.13\\n \\n\\nA\\nnnualized \\n \\n\\nreturn\\n \\n(%)\\n \\n4.89\\n \\n5.41\\n \\n7.44\\n \\n6.89\\n \\n9.46\\n \\n6.26\\n \\n\\nS\\ntandard \\n \\n\\ndeviation\\n \\n16.13\\n \\n9.95\\n \\n16.27\\n \\n18.85\\n \\n13.70\\n \\n8.82\\n \\n\\nMaximum \\n\\ndrawdown (%)\\n \\n49.16\\n \\n35.34\\n \\n36.98\\n \\n33.06\\n \\n20.51\\n \\n28.69\\n \\n\\nSharpe ratio\\n \\n0.30\\n \\n0.54\\n \\n0.46\\n \\n0.37\\n \\n0.69\\n \\n0.71\\n \\n\\n \\n\\n  \\n \\n\\n  49 \\nTable 8 \\n\\nTrading performance of the rule discovery mechanism  using a 12 month training period. \\nYear Return rate (%) by the number of sets of decision rules (=\\n J) \\n1 10 25 50 100 200 \\n2008 -30.87 -43.94 -33.38 -32.73 -35.92 -31.27 \\n2009 -11.25 -29.23 -30.55 -27.76 -34.19 -23.97 \\n2010 8.71 7.29 20.13 1.62 6.73 -2.66 \\n2011 -11.12 -17.81 19.13 -0.28 -10.82 -3.47 \\n2012 -8.01 6.84 16.25 29.21 -1.30 0.85 \\n2013 2.51 25.48 22.71 9.71 15.40 31.83 \\n2014 12.40 -7.14 -14.36 -16.53 -14.74 -14.32 \\nAnnualized  \\nreturn (%) -5.37 -8.36 -0.01 -5.25 -10.69 -6.14 \\nStandard  \\ndeviation 13.63 22.08 23.31 20.26 18.04 18.99 \\nMaximum \\ndrawdown (%) 76.03 94.19 50.55 77.15 81.72 63.80 \\nSharpe ratio -0.39 -0.38 0.00 -0.26 -0.59 -0.32 \\n\\n \\n\\n\\n ********************References\\n 1. Goodfellow, I., Bengio, Y. & Courville, A. Deep Learning (MIT Press, \\nCambridge, 2016).\\n 2. LeCun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature 521,  \\n436–444 (2015).\\n 3. Mnih, V. et al. Human-level control through deep reinforcement learning. \\nNature 518, 529–533 (2015).\\n 4. Sutton, R. S. & Barto, A. G. Reinforcement Learning: An Introduction  \\n(MIT Press, Cambridge, 2018).\\n 5. Rumelhart, D. E., Hinton, G. E. & Williams, R. J. Learning representations \\nby back-propagating errors. Nature 323, 533–536 (1986).\\n 6. De Jong, K. A. Evolutionary Computation: A Unified Perspective (MIT Press, \\nCambridge, 2002).\\nNatuRe MaChiNe iNteLLigeNCe | VOL 1 | JANUARY 2019 | 24–35 | www.nature.com/natmachintell\\n32\\n Review ARticleNATuRe MAchiNe iNTelligeNce 7. Gruau, F. Automatic definition of modular neural networks. Adapt. Behav. \\n3, 151–183 (1994).\\n 8. Yao, X. A review of evolutionary artificial neural networks. Int. J. Intell. Syst. \\n8, 539–567 (1993).\\n 9. Floreano, D., Dürr, P. & Mattiussi, C. Neuroevolution: from architectures to \\nlearning. Evol. Intell. 1, 47–62 (2008).\\n 10. Soltoggio, A., Stanley, K. O. & Risi, S. Born to learn: the inspiration, \\nprogress, and future of evolved plastic artificial neural networks.  \\nNeural Netw. 108, 48–67 (2018).\\n 11. Dasgupta, D. & McGregor, D. Designing application-specific neural \\nnetworks using the structured genetic algorithm. In Proc. COGANN-92: \\nInternational Workshop on Combinations of Genetic Algorithms and Neural \\nNetworks 87–96 (IEEE, 1992).\\n 12. Pujol, J. C. F. & Poli, R. Evolving the topology and the weights of neural \\nnetworks using a dual representation. Appl. Intell. J. 8, 73–84 (1998).\\n 13. Bongard, J. C. & Pfeifer, R. in Morpho-functional Machines: The New Species \\n(eds Hara, F. & Pfeifer, R.) 237–258 (Springer, Tokyo, 2003).\\n 14. Gruau, F. Genetic synthesis of modular neural networks. In Proc. 5th \\nInternational Conference on Genetic Algorithms (ed. Forrest, S.) 318–325 \\n(Morgan Kaufmann, San Francisco, 1993).\\n 15. Khan, M. M., Ahmad, A. M., Khan, G. M. & Miller, J. F. Fast learning \\nneural networks using cartesian genetic programming. Neurocomputing 121, \\n274–289 (2013).\\n 16. Turner, A. J. & Miller, J. F. Neuroevolution: evolving heterogeneous artificial \\nneural networks. Evol. Intell. 7, 135–154 (2014).\\n 17. Mattiussi, C. & Floreano, D. Analog genetic encoding for the evolution of \\ncircuits and networks. IEEE Trans. Evol. Comput. 11, 596–607 (2006).\\n 18. Stanley, K. O. & Miikkulainen, R. Evolving neural networks through \\naugmenting topologies. Evol. Comput. 10, 99–127 (2002).\\n 19. Moriarty, D. E. & Miikkulainen, R. Evolving obstacle avoidance behavior in \\na robot arm. In From Animals to Animats 4: Proc. 4th International \\nConference on Simulation of Adaptive Behavior (eds Maes, P. et al.)  \\n468–475 (MIT Press, Cambridge, 1996).\\n 20. Nolfi, S. & Floreano, D. Evolutionary Robotics (MIT Press, Cambridge, 2000).\\n 21. Hornby,  G et al. Evolving robust gaits with AIBO. In Proc. IEEE Conference \\non Robotics and Automation 3040–3045 (IEEE, 2000).\\n 22. Lipson, H. & Pollack, J. B. Automatic design and manufacture of robotic \\nlifeforms. Nature 406, 974–978 (2000).\\n 23. Aaltonen, T. et al. Measurement of the top quark mass with dilepton events \\nselected using neuroevolution at CDF. Phys. Rev. Lett. 102, 2001 (2009).\\n 24. Togelius, J., Yannakakis, G. N., Stanley, K. O. & Browne, C. Search-based \\nprocedural content generation: a taxonomy and survey. IEEE Trans. \\nComput. Intell. AI Games 3, 172–186 (2011).\\n 25. Stanley, K. O., Bryant, B. D. & Miikkulainen, R. Real-time neuroevolution \\nin the NERO video game. IEEE Trans. Evol. Comput. 9, 653–668 (2005).\\n 26. Clune, J., Mouret, J.-B. & Lipson, H. The evolutionary origins of modularity. \\nProc. R. Soc. B 280, 20122863 (2013).\\n 27. Huizinga, J., Mouret, J.-B. & Clune, J. Evolving neural networks that are \\nboth modular and regular: Hyperneat plus the connection cost technique. \\nIn Proc. Genetic and Evolutionary Computation Conference (GECCO) \\n697–704 (ACM, 2014).\\n 28. Polyak, B. T. Some methods of speeding up the convergence of iteration \\nmethods. USSR Comput. Math. Math. Phys. 4, 1–17 (1964).\\n 29. Qian, N. On the momentum term in gradient descent learning algorithms. \\nNeural Netw. 12, 145–151 (1999).\\n 30. LeCun, Y., Bottou, L., Bengio, Y. & Haffner, P. Gradient-based learning \\napplied to document recognition. Proc. IEEE 86, 2278–2324 (1998).\\n 31. Hochreiter, S. & Schmidhuber, J. Long short-term memory. Neural Comput. \\n9, 1735–1780 (1997).\\n 32. Dahl, G., Yu, D., Deng, L. & Acero, A. Context-dependent pre-trained deep \\nneural networks for large vocabulary speech recognition. IEEE Trans. Audio \\nSpeech Lang. Process. 20, 30–42 (2012).\\n 33. Hinton, G. et al. Deep neural networks for acoustic modeling in speech \\nrecognition: the shared views of four research groups. IEEE Signal Process. \\nMag. 29, 82–97 (2012).\\n 34. Krizhevsky, A., Sutskever, I. & Hinton, G. E. ImageNet classification with \\ndeep convolutional neural networks. In Advances in Neural Information \\nProcessing Systems 25 (NIPS 2012) (eds. Pereira, F. et al.) 1097–1105  \\n(NIPS, 2012).\\n 35. Lillicrap, T. P. et al. Continuous control with deep reinforcement learning. \\nPreprint at https://arxiv.org/abs/1509.02971 (2016).\\n 36. Schulman, J., Levine, S., Abbeel, P., Jordan, M. & Moritz, P. Trust region \\npolicy optimization. J. Mach. Learn. Res. 37, 1889–1897 (2015).\\n 37. Schulman, J., Wolski, F., Dhariwal, P., Radford, A. & Klimov, O. Proximal \\npolicy optimization algorithms. Preprint at https://arxiv.org/abs/1707.06347 \\n(2017).\\n 38. Salimans, T., Ho, J., Chen, X. & Sutskever, I. Evolution strategies as a \\nscalable alternative to reinforcement learning. Preprint at https://arxiv.org/\\nabs/1703.03864 (2017). 39. Rechenberg, I. in Simulationsmethoden in der Medizin und Biologie 83–114 \\n(Springer, Hannover, 1978).\\n 40. Wierstra, D. et al. Natural evolution strategies. J. Mach. Learn. Res. 15, \\n949–980 (2014).\\n 41. Mnih, V. et al. Asynchronous methods for deep reinforcement learning.  \\nIn International Conference on Machine Learning 1928–1937 (PMLR, 2016).\\n 42. Such, F. P. et al. Deep neuroevolution: genetic algorithms are a competitive \\nalternative for training deep neural networks for reinforcement learning. \\nPreprint at https://arxiv.org/abs/1712.06567 (2017).\\n 43. Hessel, M. et al. Rainbow: combining improvements in deep reinforcement \\nlearning. In Proc. 2018 AAAI Conference on Artificial Intelligence  \\n(AAAI, 2017).\\n 44. Horgan, D. et al. Distributed prioritized experience replay. In Proc. 2018 \\nInternational Conference on Learning Representations (OpenReview, 2018).\\n 45. Mania, H., Guy, A. & Recht, B. Simple random search provides a \\ncompetitive approach to reinforcement learning. Preprint at https://arxiv.\\norg/abs/1803.07055 (2018).\\n 46. Clune, J., Stanley, K. O., Pennock, R. T. & Ofria, C. On the performance of \\nindirect encoding across the continuum of regularity. IEEE Trans. Evol. \\nComput. 15, 346–367 (2011).\\n 47. Cully, A., Clune, J., Tarapore, D. & Mouret, J.-B. Robots that can adapt like \\nanimals. Nature 521, 503–507 (2015).\\n 48. Lehman, J., Chen, J., Clune, J. & Stanley, K. O. Safe mutations for deep and \\nrecurrent neural networks through output gradients. In Proc. Genetic and \\nEvolutionary Computation Conference (GECCO) 117–124 (ACM, 2018).\\n 49. Gangwani, T. & Peng, J. Genetic policy optimization. In Proc. 2018 \\nInternational Conference on Learning Representations (OpenReview, 2018).\\n 50. Fortunato, M. et al. Noisy networks for exploration. In Proc. 2018 \\nInternational Conference on Learning Representations (OpenReview, 2018).\\n 51. Plappert, M. et al. Parameter space noise for exploration. In Proc. 2018 \\nInternational Conference on Learning Representations (OpenReview, 2018).\\n 52. Lehman, J. et al. The surprising creativity of digital evolution: A collection \\nof anecdotes from the evolutionary computation and artificial life research \\ncommunities. Preprint at https://arxiv.org/abs/1803.03453 (2018).\\n 53. Conti, E. et al. Improving exploration in evolutionary strategies for deep \\nreinforcement learning via a population of novelty-seeking agents. Advances \\nin Neural Information Processing Systems (NIPS) (Curran Associates, Red \\nHook, 2018).\\n 54. Stanton, C. & Clune, J. Deep curiosity search: Intra-life exploration \\nimproves performance on challenging deep reinforcement learning \\nproblems. Preprint at https://arxiv.org/abs/1806.00553 (2018).\\n 55. Stanley, K. O. & Miikkulainen, R. A taxonomy for artificial embryogeny. \\nArtif. Life 9, 93–130 (2003).\\n 56. Rawal, A. & Miikkulainen, R. From nodes to networks: evolving recurrent \\nneural networks. Preprint at https://arxiv.org/abs/1803.04439 (2018).\\n 57. Real, E., Aggarwal, A., Huang, Y. & Le, Q. V. Regularized evolution for \\nimage classifier architecture search. Preprint at https://arxiv.org/\\nabs/1802.01548 (2018).\\n 58. Dawkins,  R. The Extended Phenotype: The Gene as the Unit of Selection \\n(Freeman, Oxford, 1982).\\n 59. Gould, S. J. Full House (Harvard Univ. Press, Cambridge, 2011).\\n 60. Goldberg, D. E. & Richardson, J. Genetic algorithms with sharing for \\nmultimodal function optimization. In Proc. 2nd International Conference on \\nGenetic Algorithms 41–49 (L. Erlbaum, Hillsdale, 1987).\\n 61. Mahfoud, S. W. Niching Methods for Genetic Algorithms. PhD thesis, Univ. \\nIllinois at Urbana-Champaign (1995).\\n 62. Jong, De, K. A. An Analysis of the Behavior of a Class of Genetic Adaptive \\nSystems. PhD thesis, Univ. Michigan (1975).\\n 63. Lehman, J. & Stanley, K. O. Abandoning objectives: evolution through the \\nsearch for novelty alone. Evol. Comput. 19, 189–223 (2011).\\n 64. Neyshabur, B., Salakhutdinov, R. R. & Srebro, N. Path-SGD: path-\\nnormalized optimization in deep neural networks. In Advances in Neural \\nInformation Processing Systems 28 (NIPS 2015) 2422–2430 (MIT Press, \\nCambridge, 2015).\\n 65. Radcliffe, N. J. Genetic set recombination and its application  \\nto neural network topology optimisation. Neural Comput. Appl. 1,  \\n67–90 (1993).\\n 66. Benson-Amram, S. & Holekamp, K. E. Innovative problem solving by wild \\nspotted hyenas. Proc. R. Soc. B 279, 4087–4095 (2012).\\n 67. Kanter, R. M. The Change Masters: Binnovation and Entrepreneturship in the \\nAmerican Corporation (Simon & Schuster, New York, 1984).\\n 68. Mouret, J.-B. & Doncieux, S. Encouraging behavioral diversity in \\nevolutionary robotics: an empirical study. Evol. Comput. 20, 91–133 (2012).\\n 69. Mengistu, H., Lehman, J. & Clune, J. Evolvability search: directly selecting \\nfor evolvability in order to study and produce it. In Proc. Genetic and \\nEvolutionary Computation Conference (GECCO) 141–148 (ACM, 2016).\\n 70. Gravina, D., Liapis, A. & Yannakakis, G. Surprise search: beyond objectives \\nand novelty. In Proc. Genetic and Evolutionary Computation Conference \\n(GECCO) 677–684 (ACM, 2016).\\nNatuRe MaChiNe iNteLLigeNCe | VOL 1 | JANUARY 2019 | 24–35 | www.nature.com/natmachintell\\n33\\nReview ARticle NATuRe MAchiNe iNTelligeNce 71. Deb, K., Pratap, A., Agarwal, S. & Meyarivan, T. A. M. T. A fast and elitist \\nmultiobjective genetic algorithm: NSGA-II. IEEE Trans. Evolut. Comput. 6, \\n182–197 (2002).\\n 72. Zitzler, E. & Thiele, L. Multiobjective evolutionary algorithms: a \\ncomparative case study and the strength pareto approach. IEEE Trans. \\nEvolut. Comput. 3, 257–271 (1999).\\n 73. Pugh, J. K., Soros, L. B. & Stanley, K. O. Quality diversity: a new frontier \\nfor evolutionary computation. Front. Robot. AI 3, 40 (2016).\\n 74. Lehman, J. & Stanley, K. O. Evolving a diversity of virtual creatures through \\nnovelty search and local competition. In Proc. 13th Annual Conference on \\nGenetic and Evolutionary Computation (GECCO) 211–218 (ACM, 2011).\\n 75. Mouret, J.-B. & Clune, J. Illuminating search spaces by mapping elites. \\nPreprint at https://arxiv.org/abs/1504.04909 (2015).\\n 76. Brant, J. C. & Stanley, K. O. Minimal criterion coevolution: a new approach \\nto open-ended search. In Proc. Genetic and Evolutionary Computation \\nConference (GECCO) 67–74 (ACM, 2017).\\n 77. Hodjat, B., Shahrzad, H. & Miikkulainen, R. Distributed age-layered  \\nnovelty search. In Proc. 15th International Conference on the Synthesis  \\nand Simulation of Living Systems (Alife XV) 131–138 (MIT Press, \\nCambridge, 2016).\\n 78. Huizinga, J., Mouret, J.-B. & Clune, J. Does aligning phenotypic and \\ngenotypic modularity improve the evolution of neural networks? In Proc. \\nGenetic and Evolutionary Computation Conference (GECCO) 125–132 \\n(ACM, 2016).\\n 79. Meyerson, E. & Miikkulainen, R. Discovering evolutionary stepping stones \\nthrough behavior domination. In Proc. Genetic and Evolutionary \\nComputation Conference (GECCO) 139–146 (ACM, 2017).\\n 80. Nguyen, A., Yosinski, J. & Clune, J. Understanding innovation engines: \\nautomated creativity and improved stochastic optimization via deep \\nlearning. Evol. Comput. 24, 545–572 (2016).\\n 81. Herculano-Houzel, S. The human brain in numbers: a linearly scaled-up \\nprimate brain. Front. Hum. Neurosci. 3, 31 (2009).\\n 82. Venter, J. C. et al. The sequence of the human genome. Science 291, \\n1304–1351 (2001).\\n 83. Striedter, G. F. Principles of Brain Evolution (Sinauer Associates,  \\nSunderland, 2005).\\n 84. Russakovsky, O. et al. Imagenet large scale visual recognition challenge.  \\nInt. J. Comput. Vision. 115, 211–252 (2015).\\n 85. Turing, A. The chemical basis of morphogenesis. Phil. Trans. R. Soc. B 237, \\n37–72 (1952).\\n 86. Lindenmayer, A. Mathematical models for cellular interactions in \\ndevelopment I. Filaments with one-sided inputs. J. Theor. Biol. 18,  \\n280–299 (1968).\\n 87. Bongard, J. C. & Pfeifer, R . Repeated structure and dissociation of \\ngenotypic and phenotypic complexity in artificial ontogeny. In Proc.  \\nGenetic and Evolutionary Computation Conference (GECCO) 829–836 \\n(Kaufmann, 2001).\\n 88. Hornby, G. S. & Pollack, J. B. Creating high-level components with  \\na generative representation for body-brain evolution. Artif. Life 8,  \\n223–246 (2002).\\n 89. Stanley, K. O. Compositional pattern producing networks: a novel \\nabstraction of development. Genet. Program. Evol. Mach. Spec. Issue Dev. \\nSyst. 8, 131–162 (2007).\\n 90. Meinhardt,  H. Models of Biological Pattern Formation (Academic,  \\nLondon, 1982).\\n 91. Secretan, J. et al. Picbreeder: a case study in collaborative evolutionary \\nexploration of design space. Evol. Comput. 19, 345–371 (2011).\\n 92. Clune, J. & Lipson, H. Evolving three-dimensional objects with a generative \\nencoding inspired by developmental biology. In Proc. European Conference \\non Artificial Life 144–148 (MIT Press, Cambridge, 2011).\\n 93. Cheney, N, MacCurdy, R, Clune, J. & Lipson, H. Unshackling evolution: \\nevolving soft robots with multiple materials and a powerful generative \\nencoding. In Proc. Genetic and Evolutionary Computation Conference \\n(GECCO) (ACM, 2013).\\n 94. Nguyen, A., Yosinski, J. & Clune, J. Deep neural networks are easily fooled: \\nHigh confidence predictions for unrecognizable images. In IEEE Conference \\non Computer Vision and Pattern Recognition (CVPR) (IEEE, 2015).\\n 95. Huizinga, J., Stanley, K. O. & Clune, J. The emergence of canalization and \\nevolvability in an open-ended, interactive evolutionary system. Artif. Life \\n24, 157–181 (2018).\\n 96. Liu, R. et al. An intriguing failing of convolutional neural networks and the \\ncoordconv solution. In Proc. 2018 Conference on Neural Information \\nProcessing Systems (NIPS) (Curran Associates, Red Hook, 2018).\\n 97. Gauci, J. & Stanley, K. O. Autonomous evolution of topographic  \\nregularities in artificial neural networks. Neural Comput. 22,  \\n1860–1898 (2010).\\n 98. Stanley, K. O., D’Ambrosio, D. B. & Gauci, J. A hypercube-based  \\nindirect encoding for evolving large-scale neural networks. Artif. Life 15, \\n185–212 (2009). 99. Fernando, C. et al. Convolution by evolution: differentiable pattern \\nproducing networks. In Proc. Genetic and Evolutionary Computation \\nConference (GECCO) 109–116 (ACM, 2016).\\n 100. Ha, D., Dai, A. & Le, Q. V. Hypernetworks. In Proc. 2017 International \\nConference on Learning Representations Vol. 2 (OpenReview, 2017).\\n 101. van Steenkiste, S., Koutník, J., Driessens, K. & Schmidhuber, J. A \\nwavelet-based encoding for neuroevolution. In Proc. Genetic and \\nEvolutionary Computation Conference (GECCO) 517–524 (ACM, 2016).\\n 102. Koutnik, J., Gomez, F. & Schmidhuber, J. Evolving neural networks in \\ncompressed weight space. In Proc. Genetic and Evolutionary Computation \\nConference (GECCO) 619–626 (ACM, 2010).\\n 103. Hausknecht, M., Lehman, J., Miikkulainen, R. & Stone, P. A neuroevolution \\napproach to general atari game playing. IEEE Trans. Comput. Intell. AI \\nGames 6, 355–366 (2014).\\n 104. Turner, A. J. & Miller, J. F. Recurrent cartesian genetic programming of \\nartificial neural networks. Genet. Program. Evol. Mach. 18, 185–212 (2017).\\n 105. Risi, S. & Stanley, K. O. Indirectly encoding neural plasticity as a pattern of \\nlocal rules. In Proc 11th International Conference on Simulation of Adaptive \\nBehavior (Springer, New York, 2010).\\n 106. Risi, S. & Stanley, K. O. An enhanced hypercube-based encoding for \\nevolving the placement, densty and connectivity of neurons. Artif. Life J. 18, \\n331–363 (2012).\\n 107. Schmidhuber,  J. Evolutionary Principles in Self-referential Learning, or on \\nLearning How to Learn: The Meta-meta-...Hook. PhD thesis, Technische \\nUniv. München (1987).\\n 108. Duan, Y. et al. RL\\n2\\n: Fast reinforcement learning via slow reinforcement \\nlearning. Preprint at https://arxiv.org/abs/1611.02779 (2016).\\n 109. Finn, C, Abbeel, P. & Levine, S. Model-agnostic meta-learning for fast \\nadaptation of deep networks. In Proc. 34th International Conference on \\nMachine Learning 1126–1135 (PMLR, 2017).\\n 110. Miconi, T. Learning to learn with backpropagation of Hebbian plasticity. \\nPreprint at https://arxiv.org/abs/1609.02228 (2016).\\n 111. Wang, J. X. et al. Learning to reinforcement learn. Preprint at https://arxiv.\\norg/abs/1611.05763 (2016).\\n 112. Floreano, D. & Urzelai, J. Evolutionary robots with on-line self-organization \\nand behavioral fitness. Neural Netw. 13, 431–4434 (2000).\\n 113. Floreano, D. & Mondada, F. Evolution of plastic neurocontrollers for \\nsituated agents. IEEE Trans. Syst. Man. Cybern. 26, 396–407 (1996).\\n 114. Hebb, D. O. The Organization of Behavior: A Neuropsychological Theory \\n(Wiley, Hoboken, 1949).\\n 115. Soltoggio, A., Bullinaria, A. J., Mattiussi, C., Dürr, P. & Floreano, D. \\nEvolutionary advantages of neuromodulated plasticity in dynamic, \\nreward-based scenarios. In Proc. 11th International Conference on Artificial \\nLife (Alife XI) (eds Bullock, S. et al.) 569–576 (MIT Press, Cambridge, 2008).\\n 116. Risi, S. & Stanley, K. O. A unified approach to evolving plasticity and neural \\ngeometry. In Proc. International Joint Conference on Neural Networks \\n(IJCNN-2012) (IEEE, 2012).\\n 117. Tonelli, P. & Mouret, J.-B. On the relationships between generative \\nencodings, regularity, and learning abilities when evolving plastic artificial \\nneural networks. PLoS One 8, e79138 (2013).\\n 118. Barnes, J. M. & Underwood, B. J. ‘Fate’ of first-list associations in transfer \\ntheory. J. Exp. Psychol. 58, 97 (1959).\\n 119. French, R. M. Catastrophic forgetting in connectionist networks.  \\nTrends Cogn. Sci. 3, 128–135 (1999).\\n 120. Ellefsen, K. O., Mouret, J.-B., Clune, J. & Bongard, J. C. Neural modularity \\nhelps organisms evolve to learn new skills without forgetting old skills. \\nPLoS Comput. Biol. 11, e1004128 (2015).\\n 121. Velez, R. & Clune, J. Diffusion-based neuromodulation can eliminate \\ncatastrophic forgetting in simple neural networks. PLoS One 12,  \\ne0187736 (2017).\\n 122. Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. \\nProc. Natl Acad. Sci. USA 114, 3521–3526 (2017).\\n 123. Zenke, F, Poole, B. & Ganguli, S. Continual learning through synaptic \\nintelligence. In Proc. 34th International Conference on Machine Learning \\n3987–3995 (PMLR, 2017).\\n 124. Miikkulainen, R. et al. Evolving deep neural networks. Preprint at  \\nhttps://arxiv.org/abs/1703.00548 (2017).\\n 125. He, K., Zhang, X., Ren, S. & Sun, J. Identity mappings in deep residual \\nnetworks. In European Conference on Computer Vision 630–645 (Springer, \\nBerlin, 2016).\\n 126. G. Huang,Liu, Z. Van Der Maaten, L. &Weinberger, K. Q. Densely \\nconnected convolutional networks. In Proc. IEEE Conference on Computer \\nVision and Pattern Recognition (CVPR) (IEEE, 2017).\\n 127. Szegedy, C., Ioffe, S. & Vanhoucke, V. Inception-v4, Inception-ResNet and \\nthe impact of residual connections on learning. In Proc. 2017 AAAI \\nConference on Artificial Intelligence 4278–4284 (AAAI, 2017).\\n 128. Real, E. et al. Large-scale evolution of image classifiers. In Proc. 34th \\nInternational Conference on Machine Learning (eds Precup, D. & Teh, Y. W.) \\n2902–2911 (PLMR, 2017).\\nNatuRe MaChiNe iNteLLigeNCe | VOL 1 | JANUARY 2019 | 24–35 | www.nature.com/natmachintell\\n34\\n Review ARticleNATuRe MAchiNe iNTelligeNce 129. Zoph, B., Vasudevan, V., Shlens, J. & Le, Q. V. Learning transferable \\narchitectures for scalable image recognition. In Proc. IEEE Conference on \\nComputer Vision and Pattern Recognition 8697–8710 (IEEE, 2018).\\n 130. He, K., Zhang, X., Ren, S. & Sun, J. Deep residual learning for image \\nrecognition. In Proc. IEEE Conference on Computer Vision and Pattern \\nRecognition 770–778 (IEEE, 2016).\\n 131. Cubuk, E. D., Zoph, B., Mane, D., Vasudevan, V. & Le, Q. V. Autoaugment: \\nlearning augmentation policies from data. Preprint at https://arxiv.org/\\nabs/1805.09501 (2018).\\n 132. Schmidhuber, J. Deep learning in neural networks: an overview.  \\nNeural Netw. 61, 85–117 (2015).\\n 133. Greff, K., Srivastava, R. K., Koutník, J., Steunebrink, B. R. & Schmidhuber, \\nJ. LSTM: a search space odyssey. IEEE Trans. Neural Netw. Learn. Syst. 28, \\n2222–2232 (2017).\\n 134. Melis, G., Dyer, C. & Blunsom, P. On the state of the art of evaluation in \\nneural language models. In Proc. 2018 International Conference on Learning \\nRepresentations (OpenReview, 2018).\\n 135. Zoph, B. & Le, Q. V. Neural architecture search with reinforcement \\nlearning. In Proc. 2017 International Conference on Learning Representations \\n(OpenReview, 2017).\\n 136. Marcus, M. P., Santorini, B. & Marcinkiewicz, M. A. Building a large \\nannotated corpus of English: the Penn treebank. Comput. Linguist. 19, \\n313–330 (1993).\\n 137. Caruana, R. Multitask learning. Mach. Learn. 28, 41–75 (1997).\\n 138. Meyerson, E. & Miikkulainen, R. Pseudo-task augmentation: from deep \\nmultitask learning to intratask sharing—and back. In Proc. 35th \\nInternational Conference on Machine Learning (PMLR, 2018).\\n 139. Liang, J., Meyerson, E. & Miikkulainen, R. Evolutionary architecture search \\nfor deep multitask networks. In Proc. Genetic and Evolutionary Computation \\nConference (GECCO) 466–473 (ACM, 2018).\\n 140. Elsken, T., Metzen, J. H. & Hutter, F. Neural architecture search: a survey. \\nPreprint at https://arxiv.org/abs/1808.05377 (2017).\\n 141. Fernando, C. et al. Pathnet: evolution channels gradient descent in super \\nneural networks. Preprint at https://arxiv.org/abs/1701.08734 (2017).\\n 142. Houthooft, R. et al. Evolved policy gradients. Preprint at https://arxiv.org/\\nabs/1802.04821 (2018).\\n 143. Wang, C., Xu, C., Yao, X. & Tao, D. Evolutionary generative adversarial \\nnetworks. Preprint at https://arxiv.org/abs/1803.00657 (2018).\\n 144. Jaderberg, M. et al. Population based training of neural networks. Preprint \\nat https://arxiv.org/abs/1711.09846 (2017).\\n 145. Jaderberg, M. et al. Human-level performance in first-person multiplayer \\ngames with population-based deep reinforcement learning. Preprint at \\nhttps://arxiv.org/abs/1807.01281 (2018).\\n 146. Eysenbach, B., Gupta, A., Ibarz, J. & Levine, S. Diversity is all you need: \\nlearning skills without a reward function. Preprint at https://arxiv.org/\\nabs/1802.06070 (2018). 147. Miconi, T., Clune, J. & Stanley, K. O. Differentiable plasticity: training \\nplastic neural networks with backpropagation. Proc. International \\nConference on Machine Learning 3556–3565 (PMLR, 2018).\\n 148. Mordvintsev, A., Pezzotti, N., Schubert, L. & Olah, C. Differentiable image \\nparameterizations. Distill 3, e12 (2018).\\n 149. Bansal, T., Pachocki, J., Sidor, S., Sutskever, I. & Mordatch, I. Emergent \\ncomplexity via multi-agent competition. In Proc. 2018 International \\nConference on Learning Representations (OpenReview, 2018).\\n 150. Silver, D. et al. Mastering the game of Go without human knowledge. \\nNature 550, 354–359 (2017).\\n 151. Paredis, J. Coevolutionary computation. Artif. Life 2, 355–375 (1995).\\n 152. Pollack, J. B., Blair, A. D. & Land, M. Coevolution of a backgammon player. \\nIn Proc. 5th International Workshop on Artificial Life: Synthesis and \\nSimulation of Living Systems (ALIFE-96) (eds Langton. C. G. & Shimohara, \\nK.) (MIT Press, Cambridge, 1996).\\n 153. Potter, M. A. & De Jong, K. A. Evolving neural networks with collaborative \\nspecies. In Proc. 1995 Summer Computer Simulation Conference 340–345 \\n(Society for Computer Simulation, 1995).\\n 154. Rosin, C. D. & Belew, R. K. Methods for competitive co-evolution: finding \\nopponents worth beating. In Proc. 1995 International Conference on Genetic \\nAlgorithms 373–381 (Morgan Kaufmann, Burlington, 1995).\\n 155. Cussat-Blanc, S., Harrington, K. & Pollack, J. Gene regulatory network \\nevolution through augmenting topologies. IEEE Trans. Evolut. Comput. 19, \\n823–837 (2015).\\n 156. Auerbach, J. E. & Bongard, J. C.On the relationship between environmental \\nand morphological complexity in evolved robots. In Proc. Genetic and \\nEvolutionary Computation Conference (GECCO) 521–528 (ACM, 2012).\\n 157. Pfeifer, R. & Bongard, J. How the Body Shapes the Way We Think: A New \\nView of Intelligence (MIT Press, Cambridge, 2006).\\n 158. Howard, D. et al. Evolving embodied intelligence from materials to machines. \\nNat. Mach. Intell. https://doi.org/10.1038/s42256-018-0009-9 (2019).\\n 159. Stanley, K. O., Lehman, J. & Soros, L. Open-endedness: the last grand \\nchallenge you’ve never heard of. O’Reilly Online https://www.oreilly.com/\\nideas/open-endedness-the-last-grand-challenge-youve-never-heard-of (2017).\\nCompeting interests\\nThe authors declare no competing interests.\\nadditional information\\nReprints and permissions information is available at www.nature.com/reprints.\\nCorrespondence should be addressed to K.O.S. or J.C. or J.L. or R.M.\\nPublisher’s note: Springer Nature remains neutral with regard to jurisdictional claims in \\npublished maps and institutional affiliations.\\n© Springer Nature Limited 2019\\nNatuRe MaChiNe iNteLLigeNCe | VOL 1 | JANUARY 2019 | 24–35 | www.nature.com/natmachintell\\n35\\n\\n\\n ********************\\n\\n ********************\\n\\n ********************REFERENCES \\n\\n\\n[1]  Ming-Syan Chen, Jiawei Han, and Philip Yu, Data Mining: An \\nOverview from a Database Perspective, IEEE Transactions on \\nKnowledge and Data Engineering, 8 (1996), 6: 866-883. \\n\\n\\n[2]  John Elder IV and Daryl Pregibon, A Statistical Perspective on \\nKnowledge Discovery in Databases, in Advances in Knowledge \\nDiscovery and Data Mining, Usama M. Fayyad, Gregory Piatetsky-\\nShapiro, Padhraic Smyth, and Ramasamy Uthurusamy (Eds.), AAAI \\nPress, 1996, 83-113. \\n\\n[3]  Jiawei Han and Micheline Kamber, \\n\\nData Mining: Concepts and \\n\\n\\nTechniques\\n\\n, Morgan Kaufmann, 2000. \\n\\n\\n[4]  Stuart Russell and Peter Norvig, \\n\\nArtificial Intelligence: A Modern \\n\\n\\nApproach, Second Edition\\n\\n, Prentice-Hall, 2003. \\n\\n\\n[5] X. Wu, Knowledge Acquisition from Databases, Ablex Publishing \\nCorp., U.S.A., 1995. \\n\\n\\n[6]  S Zhang, C Zhang, and X Wu, Knowledge Discovery in Multiple \\nDatabases, Springer-Verlag, 2004. \\n\\n\\n[7] Zhi-Hua Zhou, Three Perspectives of Data Mining, Artificial \\nIntelligence, 143(2003), 1: 139-146. \\n\\n\\n  \\n\\n\\n ********************REFERENCES\\n \\n\\nAl\\n-\\nQaheri,  H.,  Hassanien,  A.  E. and Abraham, A.\\n  (\\n2008\\n) \\nDiscovering  Stock \\n\\nPrice Prediction Rules Using Rough Sets. Neural Network World Journal, (to \\n\\nappear).\\n \\n\\nAltman, E.I\\n.\\n, \\n1968\\n. \\nFinancial \\nratios\\n \\ndiscriminat\\ne analys\\nis and the prediction of \\n\\ncorporate \\nbankruptcy. The Journal \\nof Finance\\n \\n23\\n, \\n589\\n-\\n609\\n.\\n \\n\\nAltman,  E.I\\n.\\n, \\n1984\\n. \\nThe  success  of  business  failure  prediction  models\\n: \\nAn \\n\\ninternational survey. Journal of\\n Banking and Finance \\n8\\n (\\n2\\n)\\n, \\n171\\n-\\n198\\n.\\n \\n\\nAltman, E.I.\\n, \\n1993\\n. \\nCorporate \\nFinancial Distress and Bankruptcy. John Wiley, New \\n\\nYork.\\n \\n\\nAltman,  E.I.,  Marco,  G.,  Varetto,  F.,\\n \\n1994\\n. \\nCorporate  distress  diagnosis\\n: \\n\\nComparisons using discriminant analysis and neural networks (the Italian experience). \\n\\nJournal of Banking and Finance \\n18\\n, \\n505±\\n529\\n.\\n \\n\\nBarber, Brad M., Lee, Yi\\n-\\nTsung, Liu, Yiu\\n-\\nJane,  and Oden, Terrance\\n, \\n2007\\n, \\nJust \\n\\nhow  much  do  individual  investors  lose  by  trading?  Working  paper,  University  of \\n\\nCalifornia at Davis.\\n \\n\\nBeaver\\n, \\nW\\n.\\nH\\n.\\n, \\n1966\\n. Financial ratios as predictors of \\nfailure. Empirical\\n Research in \\n\\nAccounting\\n: \\nSelected Studies\\n. \\nJournal of Accounting Research\\n, \\nSupplement to vol\\n. \\n4\\n, \\n\\npp\\n. \\n71±\\n \\n111\\n.\\n \\n\\nCai, Fang, and Zheng, Lu,\\n \\n2004\\n, \\nInstitutional trading and stock indices\\n, \\nJournal of \\n\\nFinance\\n, \\n61\\n (\\n2\\n).\\n \\n\\nCampbell, John Y.\\n, Ramadorai\\n, Tarun, and Vuol\\nteenaho, Tomo\\n, \\n2005\\n, \\nCaught on \\n\\ntape\\n: \\ninstitutional order flow and stock returns\\n , \\nNBER Working Paper No\\n. \\n11439\\n. \\n \\n\\nChakravarty, S.,\\n \\n2001\\n, \\nStealth\\n trading: which traders move stock prices? Journal of \\n\\nfinancial economics \\n61\\n (\\n2\\n).\\n \\n\\nChen, C. Y., Guoli, Z, Qiao, S. \\nY. and Wen, S. P. \\n2003\\n Study on discertization in \\n\\nrough set based on genetic algorithm, IEEE Proceedings of the Second International \\n\\nConference on Machine Learning and Cybernetics, Xi\\'an.\\n  \\n\\nCohen, R.\\n,\\n \\n1999\\n, Asset allocation decision of individuals and instit\\nutions, Harvard \\n\\nUniversity, Working Paper.\\n \\n\\nCourtis\\n, \\nJ\\n.\\nK\\n.\\n, \\n1978\\n. \\nModeling a \\nfi\\nnancial ratios categorical framework. \\nJournal of \\n\\nBusiness Finance and Accounting \\n5\\n (\\n4\\n)\\n, \\n371±386\\n. \\n \\n\\nDel Guercio, D.\\n, \\n1996\\n, \\nThe distorting effect of the prudent\\n-\\n man laws on institut\\nional \\n\\nequity investment\\n, \\nJournal of Financial Economics \\n40\\n, \\n(\\n31\\n).\\n \\n\\nDennis,  Patrick  J.,  Strickland,  Deon,\\n \\n2002\\n, \\nWho  blinks  in  volatile  markets\\n, \\n\\nindividuals or institutions\\n? \\nJournal of Finance \\n57\\n (\\n5\\n). \\n \\n\\nDimitras\\n, \\nA\\n.\\nI\\n.\\n, \\n1995\\n.\\n Multicriteria methods for business \\nfailure prediction (in Greek). \\n\\nPh.D. Dissertation, Technical University of Crete, Chania, Greece.\\n  \\n\\nDimitras, A.I., Zanakis, S.H., Zopounidis, C.\\n, \\n1996\\n. \\nA survey of business failures \\n\\nwith an emphasis on prediction methods \\n278\\n. \\n \\n\\nDimitras,  A.I.,  Zopounidis,  C.\\n,  Hurson,  Ch.\\n, \\n1995\\n. \\nA  multicriteria  decision  aid \\n\\nmethod for the assessment of business failure risk.  Foundations of Computing and \\n\\nDecision Sciences \\n20\\n (\\n2\\n)\\n, \\n99±112\\n. \\n \\n\\nEisenbeis, R.A\\n.\\n, \\n1977\\n. \\nPitfalls in the application of discriminant analysis in business \\n\\na\\nnd economics\\n. \\nThe Journal of Finance \\n32\\n, \\n875±900\\n.\\n \\n\\nFriedman\\n, H., Altman, E.I., Kao, D.\\n-\\nL\\n.\\n, \\n1985\\n. \\nIntroducing recursive partitioning for\\n \\n\\nfi\\nnancial \\nclassifi\\ncation: the case of financial distress. \\nThe Journal of Finance \\n40\\n (\\n1\\n)\\n, \\n\\n269±291\\n.\\n \\nGolan,  R.H.  and  Ziarko,\\n  W.\\n  (\\n1995\\n) \\nA  methodology  for  stock  market  analysis \\n\\nutilizing rough set theory. Proceedings of the IEEE/IAFE Computational Intelligence \\n\\nfor Financial Engineering\\n , \\n9\\n-\\n11\\n Apr\\n, \\npp\\n. \\n32\\n-\\n40\\n.\\n \\n\\nGompers,  Paul  A.,    Metrick,  Andrew,\\n \\n2001\\n, \\nInstitutional  investors  and  equ\\nity \\n\\nprices\\n. \\nQuarterly Journal of Economics\\n, \\n116\\n, \\n229\\n-\\n259\\n.\\n \\n\\nGriffin,John,  M.,  Harris,  Jeffrey\\n,   \\nTopaloglu\\n, \\nSelim\\n, \\n2003\\n. \\nThe  Dynamics  of \\n\\ninstitutional and individual trading\\n, \\nJournal of Finance\\n, \\n58\\n, \\n2285\\n-\\n2320\\n.\\n \\n\\nGupta,  Y.P.,  Rao,  R.P.,  Bagghi,  P.K.,\\n \\n1990\\n. \\nLinea\\nr  goal  programming  as  an \\n\\nalternative to multivariate discriminant analysis: a note. Journal of Business Finance \\n\\nand Accounting \\n17\\n (\\n4\\n)\\n, \\n593±598\\n.\\n \\n\\nJaaman, S. H., Shamsuddin, S. M., Yusob, B. and Ismail, M\\n. (\\n2009\\n) \\na predictive \\n\\nfor  Malaysian  stock  market  return\\ns,  International  Research  Journal  of  Finance  and \\n\\nEconomics Euro Journal publishing\\n , \\nInc\\n. \\nI\\n. \\n30\\n.\\n \\n\\nJones,  F.L., \\n1987\\n. \\nCurrent  techniques  in  bankruptcy  prediction\\n. \\nJournal  of \\n\\nAccounting Literature \\n6\\n, \\n131±164\\n.\\n \\n\\nKaniel,\\n Ron, Saar, Gideon, \\nTitma\\nn, Sheridan,\\n \\n2008\\n, \\nindividual investor trading and \\n\\nstock returns, Journal of \\nFinance\\n, \\n63\\n, \\n273\\n-\\n310\\n.\\n \\n\\nKeasey, K., Watson, R.,\\n \\n1991\\n. \\nFinancial distress prediction models\\n: \\na review of their \\n\\nusefulness\\n. \\nBritish Journal of Management \\n2\\n, \\n89±102\\n.\\n \\n\\nLawrence  R\\n.  (\\n1997\\n) \\nUsing  Neural  Netwo\\nrks \\nto\\n  Forecast  Stock  Market  Prices, \\n\\nDepartment  of  computer  Science\\n, \\nUniversity  of  Manitobo\\n, \\npp\\n. \\n5\\n-\\n10\\n. \\nRetrieved \\n\\nSeptember \\n2006\\n from\\n:  \\nhttp\\n://\\nwww\\n.\\ncs\\n.\\nuiowa\\n.\\nedu\\n/\\n~\\nrlawrenc\\n/\\nresearch\\n/\\nPapers\\n/\\nnn\\n. \\npdf\\n.\\n \\n\\nLuoma, M., Laitinen, E.K., \\n1991\\n. \\nSurvival analysis as a tool f\\nor company failure \\n\\nprediction\\n. \\nOmega \\n19\\n (\\n6\\n)\\n, \\n673±678\\n. \\n \\n\\nMessier, W.F., Hansen, J.V., \\n1988\\n. \\nIncluding rules for expert system development\\n:  \\n\\nan  example\\n  using  default  and  bankruptcy  data\\n. \\nManagement  Science \\n34\\n  (\\n12\\n)\\n, \\n\\n1403±1415\\n.\\n \\n\\nNguyen  H  S.  and  Skowron  A.\\n  (\\n1995\\n)\\n  Quantization  of  real  value  attributes. \\n\\nProceedings  of  Second  Joint  Annual  Conf.  on  Information  Science,  Wrightsville \\n\\nBeach, North\\n \\nCarolina\\n, \\np\\n34\\n-\\n37\\n \\n\\nNofsinger\\n,  John  R., \\n Sias\\n,  Richard  W., \\n1999\\n, \\nHerding  and  feedback  trading  by \\n\\ninstitutional and individual in\\nvestors\\n, \\nJournal of Finance \\n54\\n. \\n2263\\n-\\n2295\\n.\\n \\n\\nOhlson, J.A., \\n1980\\n. \\nFinancial ratios and the probabilistic prediction of bankruptcy\\n. \\n\\nJournal of Accounting Research \\n(\\nSpring\\n)\\n, \\n109±131\\n. \\n \\n\\nPawlak Z. \\n(\\n1982\\n) \\nRough Sets\\n, \\nInt\\n. \\nJ\\n. \\nof information and computer science\\n.\\n, \\nV\\n.\\n \\n11\\n p\\n. \\n\\n341\\n-\\n356\\n.\\n \\n\\nPawlak  Z.,  Grzymala,  B.  J.,  Slowinski  R.  and  Ziarko,  W.\\n  (\\n1995\\n) \\nRough  sets\\n. \\n\\nCommunications of the ACM\\n , \\nV\\n. \\n38\\n, \\nNo\\n. \\n11\\n, \\npp\\n. \\n89\\n-\\n95\\n.\\n \\n\\nPawlak,  Z.\\n  (\\n1991\\n) \\nRough  Sets\\n. \\nTheoretical  Aspects  of  Reasoning  About  Data\\n, \\n\\nKluwer Academic Publishers, The Nethe\\n rlands.\\n \\n\\nPolkowski,\\n L\\n. (\\n2003\\n) \\nRough Sets\\n: \\nMathematical Foundations\\n . \\nPhysica\\n-\\nVerlag.\\n \\n\\nScott, J.,\\n \\n1981\\n. \\nThe probability of bankruptcy\\n: \\na comparison of empirical predictions \\n\\nand theoretical models\\n. \\nJournal of Banking and Finance \\n5,317±344\\n.\\n \\n\\nSiskos, Y., Zopounidi\\ns, C., Pouliezos, A.,\\n \\n1994\\n. \\nAn integrated DSS for financing \\n\\nfirms by an industrial development bank in Greece\\n. \\nDecision Support Systems \\n12\\n, \\n\\n151±168\\n.\\n \\n\\nTay, F. E.H. and Shen, L\\n. (\\n2002\\n) \"\\nEconomic and financial prediction using rough \\n\\nsets model Computing\", Euro\\n pean Journal of Operational Research \\n 141\\n, \\np \\n641\\n–\\n659\\n \\n\\nVasanthi, S., Subha, M. V. & Nambi, S. Th. \\n(\\n2011\\n) \\nAn empirical study on stock \\n\\nindex  trend  prediction  using  Markov  chain  analysis,  Sri  Krishna  International \\nResearch \\n& \\nEducational Consortium\\n, \\nJBFSIR V\\n. \\n1\\n, \\nI\\n. \\n1\\n.\\n \\n\\nVermeulen,  E.M., Spronk,  J.,  Van  der  Wijst,  N., \\n1998\\n. \\nThe  application  of  the \\n\\nmulti\\n-\\nfactor  model  in  the  analysis  of  corporate  failure.  In:  Zopounidis,  C.  (Ed.), \\n\\nOperational  Tools  in  the  Management  of  Financial  Risks.  Kluwer  Academic \\n\\nPublishers, Dordre\\ncht\\n, \\npp\\n. \\n59±73\\n.\\n \\n\\nWermers\\n, \\nRuss\\n, \\n1999\\n, \\nMutual Fund trading and impact on stock prices\\n, \\nJournal of \\n\\nfinance\\n, \\n54\\n, \\n581\\n-\\n622\\n.\\n \\n\\nZavgren, \\nC\\n.\\nV\\n.\\n, \\n1983\\n. \\nThe prediction of corporate failure\\n: \\nthe state of the art\\n. \\nJournal \\n\\nof Financial Literature \\n2\\n, \\n1±37\\n.\\n \\n\\nZmijewski, M.E.\\n, \\n1984\\n. \\nMethodological issue\\ns related to the estimation of fi\\nnancial \\n\\ndistress  prediction  models. \\nStudies  on  Current  Econometric  Issues  in  Accounting \\n\\nResearch\\n, \\npp\\n. \\n59±82\\n.\\n \\n\\nZopounidis\\n, \\nC\\n.\\n, \\n1987\\n.  A  multicriteria  decision  making  methodology  for  the \\n\\nevaluation  of \\nthe  risk  of  failure  and  an  application.  Foundations  of  Control \\n\\nEngineering \\n12\\n (\\n1\\n)\\n, \\n45±67\\n.\\n \\n\\nZopounidis, C., Dimitras, A.I., Le Rudulier, L.,\\n \\n1995\\n. \\nA multicriteria approach for \\n\\nthe analysis and prediction of business failure in Greece. Cahier du LAMSADE, no. \\n\\n132\\n, \\nUniversit\\n_\\ne de Paris Dauphine\\n.\\n \\n\\n\\n ********************\\n\\n ********************REFERENCES\\n[1] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.\\nBellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski,\\net al., “Human-level control through deep reinforcement learning,”\\nNature, vol. 518, no. 7540, p. 529, 2015.\\n[2] Y. Chen, E. Keogh, B. Hu, N. Begum, A. Bagnall, A. Mueen, and\\nG. Batista, “The ucr time series classiﬁcation archive,” July 2015. www.\\ncs.ucr.edu/~eamonn/time_series_data/.\\n[3] J. J. Rodríguez, C. J. Alonso, and H. Boström, “Boosting interval based\\nliterals,”Intelligent Data Analysis, vol. 5, no. 3, pp. 245–262, 2001.\\n[4] Z. Xing, J. Pei, G. Dong, and P. S. Yu, “Mining sequence classiﬁers\\nfor early prediction,” inProceedings of the 2008 SIAM International\\nConference on Data Mining, pp. 644–655, SIAM, 2008.\\n[5] Z. Xing, J. Pei, P. S. Yu, and K. Wang, “Extracting interpretable features\\nfor early classiﬁcation on time series,” in Proceedings of the 2011 SIAM\\nInternational Conference on Data Mining , pp. 247–258, SIAM, 2011.\\n[6] Z. Xing, J. Pei, and S. Y. Philip, “Early prediction on time series: A\\nnearest neighbor approach.,” inIJCAI, pp. 1297–1302, 2009.\\n[7] N. Parrish, H. S. Anderson, M. R. Gupta, and D. Y. Hsiao, “Classifying\\nwith conﬁdence from incomplete information,” The Journal of Machine\\nLearning Research, vol. 14, no. 1, pp. 3561–3589, 2013.\\n[8] U. Mori, A. Mendiburu, S. Dasgupta, and J. A. Lozano, “Early clas-\\nsiﬁcation of time series from a cost minimization point of view,” in\\nProceedings of the NIPS Time Series Workshop , 2015.\\n[9] A. Dachraoui, A. Bondu, and A. Cornuéjols, “Early classiﬁcation of time\\nseries as a non myopic sequential decision making problem,” in Joint\\nEuropean Conference on Machine Learning and Knowledge Discovery\\nin Databases, pp. 433–447, Springer, 2015.\\n[10] C. J. Watkins and P. Dayan, “Q-learning,” Machine learning, vol. 8,\\nno. 3-4, pp. 279–292, 1992.\\n\\n\\n ********************\\n\\n ********************REFERENCES\\n[1] R. C. Cavalcante, R. C. Brasileiro, V. L. Souza, J. P. Nobrega, and A. L.\\nOliveira, “Computational intelligence and ﬁnancial markets: A survey\\nand future directions,”Expert Systems with Applications, vol. 55, pp.\\n194–211, 2016.\\n[2] C. Slamka, B. Skiera, and M. Spann, “Prediction market performance\\nand market liquidity: A comparison of automated market makers,” IEEE\\nTransactions on Engineering Management , vol. 60, no. 1, pp. 169–185,\\nFeb 2013.\\n[3] G. Nuti, M. Mirghaemi, P. Treleaven, and C. Yingsaeree, “Algorithmic\\ntrading,”Computer, vol. 44, no. 11, pp. 61–69, Nov 2011.\\n[4] Y. Hu, K. Liu, X. Zhang, L. Su, E. Ngai, and M. Liu, “Application of\\nevolutionary computation for rule discovery in stock algorithmic trading:\\nA literature review,”Applied Soft Computing, vol. 36, pp. 534–551,\\n2015.\\n[13] M. Radeerom, “Automatic trading system based on genetic algorithm\\nand technical analysis for stock index,” International Journal of Infor-\\nmation Processing and Management, vol. 5, no. 4, p. 124, 2014. [5] E. Chan,Quantitative trading: how to build your own algorithmic\\ntrading business. New York: John Wiley & Sons, 2009, vol. 430.\\n[6] B. Graham,O Investidor Inteligente. Rio de Janeiro: Nova Fronteira,\\n2007.\\n[7] G. F. Santana, “O poder de previs ˜ao da an´alise t´ecnica: uma aplicac¸˜ao\\npara o mercado futuro de IBOVESPA,” Master’s thesis, 1997.\\n[8] M. Ozturk, I. H. Toroslu, and G. Fidan, “Heuristic based trading system\\non forex data using technical indicator rules,” Applied Soft Computing,\\nvol. 43, pp. 170–186, 2016.\\n[9] D. B. Fogel, “What is evolutionary computation?” IEEE Spectrum,\\nvol. 37, no. 2, pp. 26, 28–32, 2000.\\n[10] D. E. Goldberg,Genetic Algorithms in Search, Optimization and Ma-\\nchine Learning, 1st ed. Boston, MA, USA: Addison-Wesley Longman\\nPublishing Co., Inc., 1989.\\n[11] R. Aguilar-Rivera, M. Valenzuela-Rend ´on, and J. Rodr´ıguez-Ortiz, “Ge-\\nnetic algorithms and darwinian approaches in ﬁnancial applications: A\\nsurvey,”Expert Systems with Applications, vol. 42, no. 21, pp. 7684 –\\n7697, 2015.\\n[12] H. S. Lopes, L. C. de Abreu Rodrigues, and M. T. A. Steiner, Eds., Meta-\\nHeursticas em Pesquisa Operacional, 1st ed. Curitiba, PR: Omnipax,\\n2013.\\n[14] K. Matsui and H. Sato, “A comparison of genotype representations\\nto acquire stock trading strategy using genetic algorithms,” in Proc.\\nof International Conference on Adaptive and Intelligent Systems , Sept\\n2009, pp. 129–134.\\n[15] T.-C. Fu, C.-P. Chung, and F.-L. Chung, “Adopting genetic algorithms\\nfor technical analysis and portfolio management,” Computers & Math-\\nematics with Applications, vol. 66, no. 10, pp. 1743–1757, 2013.\\n[16] F. A. Badawy, H. Y. Abdelazim, and M. Darwish, “Genetic algorithms\\nfor predicting the egyptian stock market,” in Proc. International Con-\\nference on Information and Communication Technology . IEEE, 2005.\\n[17] J. Straßburg, C. Gonz´alez-Martel, and V. Alexandrov, “Parallel genetic\\nalgorithms for stock market trading rules,” Procedia Computer Science,\\nvol. 9, pp. 1306–1313, 2012.\\n[18] J.ˇStˇep´anek, J.ˇStov´ıˇcek, and R. Cimler, “Application of genetic algo-\\nrithms in stock market simulation,”Procedia – Social and Behavioral\\nSciences, vol. 47, pp. 93–97, 2012.\\n[19] C.-F. Huang and H.-C. Li, “An evolutionary method for ﬁnancial fore-\\ncasting in microscopic high-speed trading environment,” Computational\\nIntelligence and Neuroscience, no. Article ID 9580815, 2017.\\n[20] D. J. Bodas-Sagi, P. Fern´andez-Blanco, J. I. Hidalgo, and F. J. Soltero-\\nDomingo, “A parallel evolutionary algorithm for technical market indi-\\ncators optimization,”Natural Computing, vol. 12, no. 2, pp. 195–207,\\n2013.\\n\\nView publication stats\\nView publication stats\\n\\n\\n ********************'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6d3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
