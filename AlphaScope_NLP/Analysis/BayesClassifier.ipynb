{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize.stanford_segmenter import StanfordSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segmenter = StanfordSegmenter(path_to_jar='/Users/nhu2000/desktop/nltk/stanford-segmenter-2014-08-27/stanford-segmenter-3.4.1.jar', \n",
    "                              path_to_slf4j='/Users/nhu2000/desktop/nltk/stanford-segmenter-2014-08-27/slf4j-api.jar',\n",
    "                              path_to_sihan_corpora_dict='/Users/nhu2000/desktop/nltk/stanford-segmenter-2014-08-27/data', \n",
    "                              path_to_model='/Users/nhu2000/desktop/nltk/stanford-segmenter-2014-08-27/data/pku.gz', \n",
    "                              path_to_dict='/Users/nhu2000/desktop/nltk/stanford-segmenter-2014-08-27/data/dict-chris6.ser.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup = pd.read_csv('../data/final/HuizhouTitleClassifier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4813"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dup['flag'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df_no_dup)) < 0.8\n",
    "train_ = df_no_dup[msk]\n",
    "test_= df_no_dup[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio = 0.5\n",
    "train0 = 2567\n",
    "test0 = 1234\n",
    "train1 = int(0.5*len(train_) + train0)\n",
    "test1 = int(0.5*len(test_) + test0)\n",
    "train = train_[train0:train1]\n",
    "test = test_[test0:test1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print train0, train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train['flag']\n",
    "Y_test = test['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sum(Y_train), sum(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_articles = train['token title'].values\n",
    "train_flag = train['flag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_articles = test['token title'].values\n",
    "test_url = test['url'].values\n",
    "test_flag = test['flag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(train)):\n",
    "    flag = train_flag[i]\n",
    "    t = train_articles[i]\n",
    "    temp = (t, flag)\n",
    "    res.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = NaiveBayesClassifier(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_pickle import my_pickle_dump "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_pickle_dump(\"BayesClassifier.pkl\", cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl.classify(\"徽雕 技艺 代代 传\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.show_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snownlp import SnowNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9767675999295893"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SnowNLP(u'这个东西真心很赞')\n",
    "\n",
    "s.words # [u'这个', u'东西', u'真心',\n",
    "# u'很', u'赞']\n",
    "\n",
    "s.tags # [(u'这个', u'r'), (u'东西', u'n'),\n",
    "# (u'真心', u'd'), (u'很', u'd'),\n",
    "# (u'赞', u'Vg')]\n",
    "\n",
    "s.sentiments # 0.9769663402895832 positive的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = '自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。\\\n",
    "它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。\\\n",
    "自然语言处理是一门融语言学、计算机科学、数学于一体的科学。\\\n",
    "因此，这一领域的研究将涉及自然语言，即人们日常使用的语言，\\\n",
    "所以它与语言学的研究有着密切的联系，但又有重要的区别。\\\n",
    "自然语言处理并不是一般地研究自然语言，\\\n",
    "而在于研制能有效地实现自然语言通信的计算机系统，\\\n",
    "特别是其中的软件系统。因而它是计算机科学的一部分。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = SnowNLP(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个东西真心很赞\n"
     ]
    }
   ],
   "source": [
    "print s.han"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "赞\n"
     ]
    }
   ],
   "source": [
    "print s.keywords()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'\\u8fd9\\u4e2a', u'r'), (u'\\u4e1c\\u897f', u'n'), (u'\\u771f\\u5fc3', u'd'), (u'\\u5f88', u'd'), (u'\\u8d5e', u'Vg')]\n"
     ]
    }
   ],
   "source": [
    "print s.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = SnowNLP(u'「繁體字」「繁體中文」的叫法在臺灣亦很常見。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9030299791436573"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「繁体字」「繁体中文」的叫法在台湾亦很常见。\n"
     ]
    }
   ],
   "source": [
    "print s.han"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\u300c', u'fan', u'\\u9ad4', u'zi', u'\\u300d\\u300c', u'fan', u'\\u9ad4', u'zhong', u'wen', u'\\u300d', u'de', u'jiao', u'fa', u'zai', u'\\u81fa', u'\\u7063', u'yi', u'hen', u'chang', u'\\u898b', u'\\u3002']\n"
     ]
    }
   ],
   "source": [
    "print s.pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = u'''\n",
    "自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。\n",
    "它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。\n",
    "自然语言处理是一门融语言学、计算机科学、数学于一体的科学。\n",
    "因此，这一领域的研究将涉及自然语言，即人们日常使用的语言，\n",
    "所以它与语言学的研究有着密切的联系，但又有重要的区别。\n",
    "自然语言处理并不是一般地研究自然语言，\n",
    "而在于研制能有效地实现自然语言通信的计算机系统，\n",
    "特别是其中的软件系统。因而它是计算机科学的一部分。\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = SnowNLP(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "法\n"
     ]
    }
   ],
   "source": [
    "print s.keywords(5)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自然语言处理是一门融语言学、计算机科学、数学于一体的科学\n"
     ]
    }
   ],
   "source": [
    "print s.summary(3)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-314f80d241f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSnowNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "cl = SnowNLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named Bayes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-ebf3184da6a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnownlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named Bayes"
     ]
    }
   ],
   "source": [
    "from snownlp.Bayes import Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(8000, 10000):\n",
    "    t0 = new_df.loc[i]['title']\n",
    "    url = new_df.loc[i]['url']\n",
    "    print i, t0\n",
    "    print url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
